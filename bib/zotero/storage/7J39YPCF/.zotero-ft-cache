Received February 17, 2022, accepted February 24, 2022, date of publication March 8, 2022, date of current version March 11, 2022. Digital Object Identifier 10.1109/ACCESS.2022.3157626
Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges
SIFAT REZWAN , (Student Member, IEEE), AND WOOYEOL CHOI , (Member, IEEE)
Department of Computer Engineering, Chosun University, Gwangju 61452, Republic of Korea
Corresponding author: Wooyeol Choi (wyc@chosun.ac.kr) This work was supported by the research fund from Chosun University, 2021.

ABSTRACT Unmanned aerial vehicles (UAVs) applications have increased in popularity in recent years because of their ability to incorporate a wide variety of sensors while retaining cheap operating costs, easy deployment, and excellent mobility. However, controlling UAVs remotely in complex environments limits the capability of the UAVs and decreases the efﬁciency of the whole system. Therefore, many researchers are working on autonomous UAV navigation where UAVs can move and perform the assigned tasks based on their surroundings. With recent technological advancements, the application of artiﬁcial intelligence (AI) has proliferated. Autonomous UAV navigation is an example of an application in which AI plays a critical role in providing fundamental human control characteristics. Thus, many researchers have adopted different AI approaches to make autonomous UAV navigation more efﬁcient. This paper comprehensively surveys and categorizes several AI approaches for autonomous UAV navigation implicated by several researchers. Different AI approaches comprise mathematical-based optimization and model-based learning approaches. The fundamentals, working principles, and main features of the different optimization-based and learningbased approaches are discussed in this paper. In addition, the characteristics, types, navigation models, and applications of UAVs are highlighted to make AI implementation understandable. Finally, the open research directions are discussed to provide researchers with clear and direct insights for further research.
INDEX TERMS Artiﬁcial intelligence, deep neural network, optimization, unmanned air vehicles, navigation.

I. INTRODUCTION Unmanned aerial vehicles (UAVs) are vehicles that can ﬂy without a human pilot onboard [1]. Because of their high mobility, easy deployment, low maintenance, UAVs are increasingly being used in civilian and military applications [2]–[4]. In addition, UAVs can accommodate a wide range of potential sensors for any crucial missions. [5]. There are many UAV applications such as wildﬁre monitoring [6], [7], crowd monitoring [8] target tracking [9], goods delivery [10], medical assistance, search and rescue (SaR) [11], emergency cellular deployment [12], and intelligent transportation. However, UAVs cannot perform optimally in a complex dynamic environment owing to the dependency on human control and limitation of radio frequency (RF) communication [1]. Autonomous navigation
The associate editor coordinating the review of this manuscript and
approving it for publication was Guillermo Valencia-Palomo .

of UAVs in large-scale dynamic environments is one of the key components for optimal outcome. Localization and mapping techniques [13], [14], and sensing and avoidance techniques [15] are often used in traditional approaches to achieve autonomous navigation.
The implementation of 5G networks has paved many new ways to optimize autonomous UAV navigation [16]. However, three-dimensional (3D) deployment, navigation, and resource utilization of UAVs are only a few of the engineering issues that have been explored in early research contributions [17], [18]. To solve these fundamental problems, powerful optimization methods such as convex optimization [17], game theory [19], transport theory [20], and stochastic optimization have been used. Although many non-linear techniques have shown satisfactory results, they are typically conﬁned to primary and narrow habitats, such as the countryside or indoor areas. It is impossible to apply them speciﬁcally to large-scale complex environments

26320

This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

because passively navigating signiﬁcant barriers or constantly constructing maps is impractical in large and complex environments [21].
Various navigation methods have been proposed to date and are categorized into three groups: inertial navigation, satellite navigation, and vision-based navigation [1]. Nonetheless, neither of these approaches is perfect; thus, it is crucial to choose the optimal technique for autonomous UAV navigation based on the mission at hand [1]. For the past few years, researchers have been studying and attempting to automate UAV navigation in which UAVs learn from their surroundings. Autonomous navigation is one of the most critical aspects of UAV automation. One of the main challenges of autonomous UAV navigation is the avoidance of obstacles to reach the desired destination.
Artiﬁcial intelligence (AI) has become an essential element of nearly every engineering-related study ﬁeld owing to recent advances in computer technology and hardware. AI is an ideal tool for solving complex problems where no speciﬁc solutions are available or conventional solutions require a considerable amount of hand-tuning. Automatic feature extraction, which eliminates costly handcrafted feature engineering, is a signiﬁcant distinction between AI and traditional cognitive algorithms. In general, an AI task can spot anomalies, forecast potential scenarios, respond to changing situations, gain insights into complicated issues involving vast quantities of data, and ﬁnd patterns that a person might ignore [22]. It can exploit and learn the surrounding big data to improve UAV maneuvering. Moreover, AI can intelligently manage onboard resources compared with traditional optimization approaches.
AI methods can be divided into two groups based on their level of intelligence. The ﬁrst group are the most fundamental, allowing the machine to react predictably to the environment. This enables UAVs to perform according to performance metrics. The second group of methods allow UAVs to communicate with their surroundings, enabling them to make decisions even when the environment is unpredictable [23]. Thus, AI techniques are increasingly being used to improve autonomous UAV navigation. There are many parameters in autonomous UAV navigation, and some are set using heuristic equations, because solid closed-form solutions for their value do not exist or are computationally expensive to ﬁnd. AI can help with these problems by forecasting parameters and calculating functions based on available data [22]. Furthermore, artiﬁcial neural networks (ANNs), a type of AI technique, can be used to model the objective functions of nonlinear problems that involve optimization or approximation [24].
Nonetheless, there are many challenges in applying AI in autonomous navigation, such as reducing training time, reducing computational power, reducing complexity, updating information for extended periods, and quick adaptation to new environments [25]. Thus, many researchers have investigated and proposed different solutions to overcome the
VOLUME 10, 2022

challenges of autonomous UAV navigation while utilizing AI efﬁciently.
A. EXISTING SURVEYS The signiﬁcant advancements in AI and the contribution of AI to autonomous UAV navigation are the primary motivations behind this study. Several surveys on UAVs in different aspects have been published in the last decade. In [26], Souissi et al. discussed several state-of-the-art methods for UAV path planning, such as Dijkstra’s algorithm [38], A∗ algorithms [39], particle swarm optimization (PSO) [40], ant colony optimization (ACO) [41], probabilistic roadmapping [42], rapidly-exploring random trees (RRT), and multi-agent path planning [43], and outlined their advantages and disadvantages. Moreover, the authors categorized UAV path planning in terms of environmental modeling. UAVs with environmental knowledge have a higher probability of achieving an optimal or near-optimal solution compared with the UAVs having no environmental knowledge, however, they cannot deal with sudden changes in the environment.
Sujit et al. [27] analyzed ﬁve traditional path-following algorithms: carrot-chasing, nonlinear guidance law (NLGL) [44], pure pursuit with line-of-sight (PLOS) [45], linear quadratic regulator (LQR) [46], and vector ﬁeld (VF) [47] algorithms for ﬁxed-wing UAVs. Moreover, the authors simulated these algorithms using Monte Carlo simulations and provided performance comparisons.
Pandey et al. discussed different single solution-based and population-based meta-heuristic approaches in [28], including simulated annealing (SA) [48], tabu search [49], evolutionary computation, and swarm intelligence [40], [50]. They also analyzed various algorithms and highlighted research gaps. Ghambari et al. performed an experimental analysis and compared different meta-heuristic algorithms such as PSO [40], differential evolution (DE) [51], artiﬁcial bee colony (ABC) [52], invasive weed optimization (IWO) [53], teaching learning-based optimization (TLBO) [54], grey wolf optimization (GWO) [55], and lightning search algorithm (LSA) [56].
Meanwhile, Zhao et al. [30] discussed computational intelligence (CI)-based approaches for UAV path planning. The authors highlighted the genetic algorithm (GA), PSO, ACO [41], artiﬁcial neural network (ANN), fuzzy logic (FL), and Q-learning based papers considering online/ofﬂine planning and 2D/3D environments. However, research works based on AI/ML were not included in the paper. Radmanesh et al. carried out a comparative study of UAV path planning algorithms for heuristic and non-heuristic methods in [31]. The authors tested algorithms, such as the potential ﬁeld, Floyd-Warshall, GA, greedy algorithm, multistep look-ahead policy, Dijkstra’s, A∗, Bellman-Ford, Qlearning algorithms, and mixed-integer linear programming (MILP), under three different obstacle scenarios in terms of computational time and optimality.
In contrast, Lu et al. [1] surveyed vision-based methods of UAV navigation while focusing on visual localization
26321

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges TABLE 1. Comparative analysis of the existing surveys and our work.

and mapping, obstacle avoidance, and path planning. Sub- including AI-based approaches for handling challenges, such sequently, many authors analyzed all types of approaches, as security, communication, interference, and localization,

26322

VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

related to cellular-connected UAVs in wireless networks in [22], [33], [34], [36], [57]. In addition, Liu et al. [37] highlighted the AI-based approaches for resource allocation, big data handling, dynamic deployment, and trajectory design for UAV-aided wireless networks (UAWN).
The majority of the surveys focus on AI for UAVconnected wireless communication or CI-based solutions for autonomous UAV navigation, explaining their future applications. However, none of them focuses solely on AI approaches for autonomous UAV navigation and future AI potential approaches as shown in Table 1. Unassociated with these works, this paper discusses the present and future AI approaches for autonomous UAV navigation. This paper provides a comprehensive survey of this crucial paradigm of AI approaches covering all UAV navigation scenarios, identifying the prevailing gap in the literature that inspired the current research. This survey aims to help the researchers to work in the direction of AI-based methods in autonomous UAV navigation.
B. CONTRIBUTION This study focuses on different AI approaches, such as deep learning, mathematical optimization methods, reinforcement learning, and transfer learning, for different types of UAV navigation. After analyzing different AI techniques, future research directions for UAV navigation are highlighted. The main contributions of this study are as follows.
• Many authors have simulated and incorporated different types of UAVs and their characteristics. Knowledge of different UAV parameters is mandatory for implementing different AI algorithms. These parameters help researchers to develop appropriate system models and simulation scenarios. Moreover, setting an reasonable goal is very important for implementing AI algorithms. Thus, the key characteristics and types of UAVs are highlighted to familiarize the reader with UAV architecture. A brief overview of the UAV navigation system and application-based categorization are provided, which will help new researchers to easily understand the various methods of AI implementation.
• AI is a vast area that includes different types of learning and optimization algorithms. Thus, the AI approaches for autonomous UAV navigation are divided into two parts: optimization-based and learning-based approaches. Different types of memory-free computational heuristic approaches are discussed in the optimization-based part. In these types of approaches, the AI agent has to perform all the necessary calculations from the beginning every time to obtain the optimal solution. Thus, optimization-based solutions have high time complexity and require high computational power. The memory-based computational learning approaches are discussed. Here, the AI agent learns the surrounding, obtains an optimal policy, and saves it for future use. The agent can use and update the saved policy later if needed.
VOLUME 10, 2022

FIGURE 1. Different types of UAVs: (a) fixed-wing, (b) helicopters, (c) multi-copters, and (d) loons.
Therefore, the fundamentals and working principles of several AI techniques implemented by different researchers for autonomous UAV navigation in terms of optimization-based and learning-based approaches are presented in this paper, as shown in Fig. 4. • A comparative study of different optimization-based and learning-based AI approaches for autonomous UAV navigation is conducted in this paper. Here, the features of the approaches are identiﬁed and compared them in terms of their complexity, hyper-parameters, and objectives. Extended categorizations of the optimizationbased and learning-based AI approaches are included in the comparative analysis. • Finally, the open research challenges and future directions are highlighted to accelerate the current research on autonomous UAV navigation in terms of the different crucial parameters and features of the UAV. New possible AI approaches for autonomous UAV navigation are highlighted.
II. UAV CHARACTERISTICS AND NAVIGATION MODEL The realization of unmanned aerial systems have been a signiﬁcant challenge for engineers and scientists since the invention of airplanes. There are many different types of UAVs available today for military and civilian applications. UAVs are often classiﬁed based on characteristics related to shape, range, price, maximum take-off weight, and pricing as shown in Table 2. One of the most crucial features of a UAV is its payload. The maximum weight that a UAV can carry, or payload, is a measurement of its lifting capabilities. UAV payloads can range from a few grams to hundreds of kilograms [33], [60]. The larger the payload, the more equipment, and accessories can be carried at the price of the UAV’s size, battery capacity, and ﬂight time. Conventional payloads include cameras, sensors, mobile phones, and base stations for cellular assistance.
In general, UAVs can be categorized into four categories based on their ﬂight mechanisms: ﬁxed-wing,
26323

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges TABLE 2. Characteristics of different types of UAVs.

helicopters, loons, and multi-copters, as shown in Fig. 1. Fixed-wing UAVs can glide through the air, making them more energy-efﬁcient and capable of carrying heavier payloads. In addition, ﬁxed-wing UAVs can beneﬁt from gliding to go quicker. However, they require more space to take off and land, and they cannot hover over a ﬁxed position. Helicopters are a combination of multi-copters and ﬁxed-wings. They can glide through the air with tail wings and take off and land vertically. In contrast, loons depend entirely on air pressure and have no motors for directed movement [59]. Lastly, Multi-copters can take off and land vertically and hover over a certain place. Thus, they are excellent for any application because of their exceptional maneuverability. However, multi-copters have limited ﬂight time and use a considerable amount of energy because they always ﬂy against gravity.
As ﬂying is the main characteristic of UAVs, UAV navigation can be categorized into four categories based on application: outdoor navigation, indoor navigation, navigation for SaR, and navigation for wireless networking, as shown in Fig. 2. Here, outdoor navigation includes applications, such as surveillance, good delivery, target tracking, and crowd monitoring, and indoor navigation includes applications, such as indoor mapping, factory automation, and indoor surveillance. In addition, the UAV navigation can
26324

FIGURE 2. Application-based categorization of UAV Navigation.
be categorized based on navigation parameters: inertia-based, signal-based, and vision-based navigation. For inertia-based navigation, UAVs mainly use gyroscopes, accelerometers, and altimeters to guide the onboard ﬂight controller [62]. UAVs use GPS modules and a remote radio head (RRH) in the case of cellular connectivity for signal-based navigation and cameras for vision-based navigation.
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 3. UAV navigation system model [61].
FIGURE 4. A taxonomy of the artificial intelligence approaches for UAV navigation.
Initially, the altitude and horizontal controllers receive feedback from these sensors and guide the pitch and yaw controllers depending on the desired path planning. Then, the pitch and yaw controllers guide the elevators and ailerons to maneuver the UAV depending on the feedback of these sensors, as shown in Fig. 3 [61]. UAVs obtain the desired path planning in case of autonomous navigation, as shown in Fig. 3 utilizing various AI techniques. Thus, this paper focuses on different AI approaches implemented by different researchers for UAV navigation.
III. OPTIMIZATION-BASED APPROACHES Optimization-based approaches cover the traditional mathematical-based problem-solving algorithms of AI. These algorithms can achieve near-optimal solutions for any given non-deterministic polynomial-time hard (NP-hard) problems. However, these algorithms are quite complex in terms of time and space. This section brieﬂy discusses the most widely used optimization-based AI approaches for autonomous UAV navigation, namely PSO, ACO, GA, cuckoo search (CS) algorithm [63], SA, DE, pigeon-inspired optimization (PIO), Dijkstra’s algorithm, A* algorithm, greywolf optimization (GWO) [64], and other miscellaneous algorithms. Moreover, Table 3 shows a comparative analysis among of these optimization-based AI approaches where
VOLUME 10, 2022

FIGURE 5. Particle swarm optimization (PSO).
their main features, time complexities with a number of m operations, and hyper-parameter counts are highlighted.
A. PARTICLE SWARM OPTIMIZATION (PSO) Eberhart and Kennedy introduced PSO in 1995 [40]. PSO is a population-based search algorithm that simulates different animal groups, such as birds and bees. In PSO, each animal can be represented as a vector particle in a 3D space. PSO determines the movement of a particle depending on its current position and velocity. The velocity of the particle continues to update based on the optimal position vector explored by it (Pbest ) and the swarm (Gbest ), as shown in Fig 5. PSO reaches the optimal point when it achieves its goal or minimum error possible.
In UAV navigation, PSO considers UAVs as particles and controls their movement in a 3D space. In [65], Autor Jalal modiﬁed the conventional PSO for ofﬂine UAV navigation while avoiding obstacles. The modiﬁed PSO (MPSO) functions like the conventional PSO; however, an additional error factor is modeled to ensure convergence. The main function of the error factor is to convert the infeasible paths generated by PSO into feasible paths. MPSO relocates and reinitializes particles that fall within an obstacle boundary for conﬁrmed optimality. The authors ensured the efﬁcacy of the MPSO by simulating single and multiple obstacle scenarios.
Similarly, Phung et al. modiﬁed the conventional continuous PSO into discrete PSO (DPSO) to solve the UAV path planning problem in [66]. The authors modeled the UAV path planning problem as a traveling salesman problem (TSP) while considering discrete 3D space and obstacles. Moreover, deterministic initialization, random mutation, edge exchange, and parallel implementation of GPU techniques were used to speed up the convergence of the DPSO. In 2018, Huang et al. proposed a competition strategy-based PSO (GBPSO) for selecting the global best path for UAVs in [67]. The proposed competition strategy compares the current global path with other global path candidates to select the optimal path for particles.
B. ANT COLONY OPTIMIZATION (ACO) Colorni et al. ﬁrst proposed ACO in 1991 [41] to solve NPhard optimization problems. As the name suggests, the foodsearching technique of ants inspired ACO. In the search for foods, ants use a legacy volatile chemical called pheromone
26325

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 6. Ant colony optimization (ACO).

to communicate and collaborate. Initially, ants start searching for paths towards the source of food and release pheromones on the way to the source of food. Once an ant reaches the food source, other ants follow the pheromone traces and discover other paths to reach the food source. Thus, the shortest path discovered by the ants will have a higher concentration of pheromones, as shown in Fig 6. Moreover, the concentration of pheromones on the abandoned paths decays with time.
For autonomous UAV navigation, Cekmez et al. proposed a multi-colony ACO-based solution while avoiding obstacles in a 3D space in [68]. According to the authors, multi-colony ACO overcomes the premature convergence problem caused by single-colony ACO. Initially, the authors formulated the UAV navigation problem as a TSP problem, and then multiple UAV groups searched for optimal routes to the destination. In multi-colony ACO, the UAVs are responsible for not only intra-colony but also inter-colony pheromone value exchange. Similarly, Guan et al. proposed a double-colony ACO in which pheromones are generated exploiting the GA in [69].
Jin et al. [70] proposed a combination of an artiﬁcial potential ﬁeld (APF) and ACO named potential ﬁeld ACO (PFACO) to overcome the premature convergence problem. APF is an obstacle avoidance algorithm that ensures the optimal speed and safety of the UAV in an environment with gravitational and repulsive forces. Furthermore, the APF manipulates the transition probability of a UAV from one node to another in ACO to improve global searching. Moreover, the authors used the min-max ant system (MMAS) to ﬁnd the best path and the worst path and weaken the worst path while updating the global pheromone value for faster convergence.
C. GENETIC ALGORITHM (GA) The GA is a stochastic optimization algorithm that starts with a population of randomly produced chromosomes known as the starting population. Each chromosome gene is a series of numerical numbers. Each chromosome or individual in this study reﬂects a UAV trajectory that is restricted by
26326

FIGURE 7. Genetic algorithm (GA) for UAV navigation.
the UAV dynamics. Genetic operations, such as crossover, mutation, selection, insertion, and deletion, will alter the population periodically in each generation; the modiﬁed chromosomes will be selected according to a ﬁtness function. This procedure aims to reduce the ﬁtness function as much as possible by identifying the chromosome with the nearminimal ﬁtness value. Thus, the chromosomes achieve a nearoptimal solution. The GA method is thoroughly explained in [71].
In [71], Bagherian implemented GA to solve the NP-hard problem of UAV navigation. First, the author encodes the 3D position of the UAV into chromosomes that consist of the acceleration, climbing angle rate, and heading angle rate at discrete time steps of a UAV as shown in Fig 7. At the present time-step, this chromosome is decoded to get 3D coordinates at the next time-step for the UAV. Then the 3D coordinate is evaluated using a ﬁtness function that considers the costs of the distance between two points, total path length, height, and obstacles. Afterward, the genetic operations are performed where selection refers to selecting paths, crossover refers to exchanging path information, mutation deals with the information loss, and insertion and deletion handle the path information management.
Tao et al. improved the GA by designing a temporary path based on the encoding vector, with each individual guidance including not only the guide point location information but
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 8. UAV navigation problem solved with simulated annealing (SA).

also the status variables in [72]. Thus, it keeps track of whether the guiding point is feasible if it meets the constraint condition, and whether the path between the connecting point and the next guide points had the lowest performance cost. The temporary path is practicable if all the guiding points are reliable. The encoding method is based on the change in the UAV yaw angle sequence.
Yang et al. proposed a hierarchical recursive multi-agent GA (HR-MAGA) in [73]. During the evolution process of HR-MAGA, agents can detect the environment, communicate with their neighbors, and decrease their loss by employing the corresponding operators, who discover a good solution instantaneously. Moreover, HR-MAGA can optimize the local path to obtain a more reﬁned path using the hierarchical recursive process.
Meantime, Gao et al. proposed the opposite and chaos searching GA (OCGA) to speed up the convergence in [74]. An opposite and chaotic search is used to produce a highquality initial population. Chaos searching can span a speciﬁc range of solutions. On the basis of chaotic searching, opposite searching can provide more suitable reverse sequences. The convergence speed is also an essential parameter in optimization. Thus, to accelerate convergence, the authors proposed a unique crossover technique based on the teachinglearning-based optimization learning mechanism (TLBO).

D. SIMULATED ANNEALING (SA)
SA is a continuous-time approximation approach that tends to converge with the global minimum [48]. Annealing is a controlled heating and cooling process for metals that minimize the defects at the atomic level. When the metal is heated, the atoms vibrate and reconﬁgure themselves with minimum energy. Afterward, the metal is cooled slowly to ensure that the conﬁguration has minimum energy. Otherwise, the atoms can become stuck in a conﬁguration with a local minimum internal energy. The SA algorithm emulates the same process to obtain a global minimum for NP-hard problems. The fundamental strategy for implementing the SA is to select random points in the surroundings of the present best point and quantify the cost functions [75]. Then, the UAVs move from one point to another, comparing the present and next point values. The Boltzmann-Gibbs distribution probability density function value named temperature, which determines the acceptability of a point. Initially, the temperature is initialized with a very high value, and then it decreases with each iteration. As the temperature decreases, the acceptance probability gradually reduces until it reaches zero, as shown in Fig 8. Thus, UAVs achieve their goals. However, SA optimization is a time-consuming process.
In [76], Behnck et al. proposed a modiﬁed SA algorithm that interprets multi-UAV navigation problem as multiple

VOLUME 10, 2022

26327

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 9. Map and compass and landmark based pigeon-inspired optimization (PIO).
TSP (mTSP). The authors stochastically chose the points of interest so that UAVs travelled smaller distances. Moreover, the energy consumption was considered within the temperature value. Later, Liu and Zhang [77] incorporated SA with ACO to solve the navigation problem, where the temperature value of SA depends on the pheromone value of ACO. In their approach, the optimal path must satisfy both ACO and SA conditions, ensuring an obstacle-free shortest path for the UAVs. Recently, Xiao et al. proposed a UAV path planning algorithm utilizing SA and a grid map in [78]. Their primary goal was to develop a 3D reconstruction of an area using multiple UAVs circulating on an optimized path energyefﬁciently. However, the authors considered UAVs ﬂying at a ﬁxed altitude and did not consider obstacles while optimizing the ﬂying paths.
E. PIGEON-INSPIRED OPTIMIZATION (PIO) Pigeons are the most common bird on the planet, and Egyptians previously employed them to deliver messages and numerous military operations. Pigeons use three homing aids to ﬁnd their way home: the magnetic ﬁeld, the sun, and landmarks [79]. Similarly, the fundamental PIO algorithm is based on the phenomena of pigeon self-navigation and is primarily determined by two operators: the map and compass operator and the landmark operator. Pigeons in the wild go through several stages of nerve feedback when homing and use magnetic ﬁelds and landmarks to locate their ﬂight path. The magnetic ﬁeld factor, which occurs in the initial stages, is represented by the map and compass operators [80]. The map and compass operator helps the virtual pigeons locate themselves and calculate their velocity. The landmark operator helps to identify the global center coordinates for autonomous navigation as shown in Fig 9. Although the standard PIO has been shown to be superior in several areas,
26328

it still has signiﬁcant ﬂaws, such as a lack of diversity and immaturity.
In [81], Zhang et al. proposed a social-class PIO (SCPIO) to overcome the shortcomings of traditional PIO for autonomous multi-UAV navigation. The authors divided the pigeons into different layers of classes, where lowerclass pigeons followed the top-class pigeon. Pigeons can also go from one class to another, depending on the obtained optimal path. Hu et al. [82] proposed an adaptive operator quantum-behaved PIO (AOQPIO) with adaptive operators to overcome the problems of PIO for autonomous UAV navigation. Moreover, the authors introduced chaotic strategies to generate initial solutions in advance to obtain a wider solution space coverage. Chaos is an apparently random motion that appears in a critical dynamic system. The features of chaotic motion are (1) high sensitivity to starting values, (2) ergodicity of motion trajectories, and (3) randomization.
F. CUCKOO SEARCH (CS) ALGORITHM The CS algorithm replicates the natural egg-laying strategy of the parasitic cuckoo birds. The cuckoo searches for a nest by random walk, utilizing Levy ﬂight, and lays eggs. Frequent short ﬂights and infrequent long ﬂights utilizing the Levy distribution are considered to be Levy ﬂights [83]. The CS algorithm mainly follows three rules: each cuckoo randomly chooses a nest and lays one egg at a time, the nest with the best quality egg is passed to the next generation, and the total number of host nests is ﬁxed with egg uncertainty probability [0, 1] [63]. Egg uncertainty refers to discovering of the cuckoo eggs by a host bird. In this case, the host can throw eggs or leave the nest for good. In the case of UAV navigation, UAVs are the cuckoo, and the coordinates are the nests. UAVs randomly choose a nest or coordinate to reach the target location. Target location can remain same or change depending on the UAV’s mission. If the coordinate is blocked by an obstacle, the UAV chooses another nest or coordinate to reach the target. Otherwise, the coordinate is considered as the best solution and carried to next generation, where its used to ﬁnd the next coordinate.
Xie and Zheng proposed an improved CS algorithm combining genetic operators for UAV path planning in [84]. The authors incorporated crossover and mutation operators of the GA with the CS algorithm to speed up the convergence of the algorithm and avoid local optimums. In contrast, Hu et al. implemented a conventional CS algorithm for UAV trajectory planning in an urban area where each egg represents a trajectory and each trajectory includes multiple coordinates in [85]. To reduce the computational load, the authors used the Chevyshev collocation points to represent the coordinates. Moreover, they showed that with optimal parameters, the CS can outperform the PSO algorithm.
G. DIJKSTRA’S AND A* ALGORITHMS Dijkstra’s algorithm is a weighted graph method that calculates the shortest distance between two nodes. Edsger Wybe
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 10. A* algorithm.

Dijkstra, a Dutch mathematician and computer scientist, created this algorithm. Algorithms are employed in a variety of applications, including navigation [86]. A starting point is chosen in the Dijkstra’s algorithm. All the other nodes are regarded as inﬁnitely distant. As the nodes are approached, the distances are updated. Dijkstra’s algorithm examines neighbors leaving a node at each step, and if a shorter path is discovered, the distances are updated.
Similarly, the A* algorithm is a hybrid of Dijkstra’s algorithm and the greedy best-ﬁrst-search because it can not only discover the shortest path but also employ a heuristic to steer itself [87]. The A* combines the information used by Dijkstra’s algorithm (favoring vertices near the beginning point) with the information used by greedy bestﬁrst-search (favoring vertices close to the target) as shown in Fig 10. Many authors in [88]–[90] have proposed different modiﬁed versions of the Dijkstra’s and A* algorithms that consider target tracking, and real-time environment updates for obstacle avoidance for autonomous UAV navigation. However, these two algorithms are quite complex compared to other optimization-based approaches.
H. DIFFERENTIAL EVOLUTION (DE) Differential evolution (DE) is a population-based optimization method that was ﬁrst proposed in 1997 [51]. It combines the parent or initial points with a few additional points from the overall population of paths to create new solutions. Each solution has a group of variables that are subjected to mutation, selection, and crossover search operators to generate new solutions, as shown in Fig 11. DE only considers solutions that are better than their parents and passes them to the next generation. DE is straightforward to implement in real-life applications, such as UAV navigation, owing to its minimal control parameters.
Ghambari et al. proposed a hybrid evolutionary algorithm combining A* and DE algorithms to optimize the NP-hard problem of UAV navigation in [91]. Here, the DE algorithm is responsible for exploring and exploiting the entire ﬂying space, and generating multiple connected regions between the start and destination points while ensuring the shortest distance from the straight-line path in an admissible space. In contrast, the A* algorithm searches for the shortest paths in every region generated by the DE algorithm. Although this hybrid method decreases the overall computational time, higher computational power is required to compute
VOLUME 10, 2022

FIGURE 11. Differential evolution (DE) for UAV navigation.
the two algorithms simultaneously. In [92], Yu et al. proposed a constraint DE (CDE) to solve the UAV path planning problem in disaster scenarios where a mutation is performed selectively for better convergence. They modeled the UAV path planning with different nonlinear constraints and ranked all the probable traveling points depending on the ﬁtness values and constraint violation. The CDE only selects points that have high ﬁtness values and minimum constraint violations. Then, the authors proposed the kneeguided DE algorithm (DEAKP) for autonomous UAV navigation in [93], where the knee point depends on minimum Manhattan distance (MMD). The DEAKP algorithm reduces the overall computational complexity by focusing on knee solutions instead of Pareto front solutions in constrained multi-objective optimization scenarios. It identiﬁes the knee solution based on MMD and generates offspring for nextgeneration combing with non-dominated points.
I. GREY WOLF OPTIMIZATION (GWO) Grey wolf optimization was ﬁrst proposed in [64] in 2014 based on the prey hunting strategy of grey wolves. Grey wolves have a social hierarchy where they are divided into alpha, beta, delta, and omega groups. Alpha group wolves are the leaders, and other groups follow and help them make decisions. Initially, the alpha, beta, and delta groups start searching for the static target stochastically, and the omega wolves wait for the order to join. The decision to ﬁnd the
26329

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

FIGURE 12. Grey-wolf optimization (GWO).
target of the alpha group has the highest priority compared to the beta and delta groups. To identify the exact position of the target, the alpha, beta, and delta wolves estimate the distance between their current position and the target position as shown in Fig 12. After locating the target, the wolves send signals to other wolves to join them during target hunting. GWO has only two parameters, A, which is responsible for exploration, and exploitation and C, which helps the wolves avoid obstacles during the search.
In [94], Zhang et al. utilized conventional GWO to solve the 2D path planning problem of unmanned combat aerial vehicles (UCAVs) while ensuring minimum fuel usage and zero threat. The authors compared GWO with other optimization algorithms such as ACO, PSO, and CS in three different scenarios. Following this, Dewangan et al. implemented conventional GWO to solve the 3D path planning problem of UAVs while avoiding obstacles in [95]. The authors compared 3D GWO with other optimization methods for three different maps. Qu et al. proposed a hybrid GWO algorithm that combines a modiﬁed symbiotic organisms search (MSOS) named HSGWO-MSOS for UAV path planning in [96]. The authors combined GWO and MSOS for fast convergence and efﬁcient global and local environmental exploitation. Finally, they analyzed the complexity of HSGWO-MSOS and showed that HSGWOMSOS outperformed the SA algorithm.
J. MISCELLANEOUS ALGORITHMS In addition to the aforementioned optimization-based approaches, several AI techniques are available, and are discussed in this section. However, there has been very little or no signiﬁcant and simple study utilizing these methods in recent years.
1) IMPROVED INTELLIGENT WATER DROP ALGORITHM The water drop visits only neighboring cells instead of soil probability-based movement. This algorithm utilizes both
26330

soil and the distance from the destination to guide the water. Moreover, the global soil update rate increases with the evolution of the water-dropping path, affecting local and global path searching [97].
2) APF-BASED RRT-CONNECT The APF-based target attraction function is integrated with the bare rapidly exploring random tree (RRT) connect algorithm that helps a random tree grow in the direction of the goal. This function reduces the overall search space and complexity of the algorithm, which ensures near-optimal convergence of the path planning problem [98].
3) FUZZY LOGIC A fuzzy logic-based solution is proposed to control the leader-follower formation of a swarm of homogeneous UAVs and enable the swarm to avoid collisions and maintain the formation depending on the leader’s moves [99].
4) FIREFLY FUZZY LOGIC A hybrid ﬁreﬂy fuzzy controller is proposed where the ﬁreﬂy algorithm estimates the intermediate turning angle considering the Euclidean distance from the obstacles and goal. Finally, the fuzzy logic conﬁrms the ﬁnal turning angle and speed, validating the measured distances using the ﬁreﬂy algorithm [100].
5) GLOW-WORM SWARM OPTIMIZATION In glow-worm optimization, worms move toward another worm with a higher luciferin content. UAVs ﬁrst identify the obstacles around them and search for higher luciferin content in the neighboring points in the case of navigation. The point nearest to the goal has the highest luciferin content. The luciferin content is distributed randomly initially, and then it decays and gets updated with time [101].
6) MODIFIED CENTRAL FORCE OPTIMIZATION The central force optimization (CFO) method depends on the law of gravity among particles. In UAV navigation, each point acts as a particle, and higher mass particles attract the UAV. However, CFO tends to become stuck in local minima and has a poor memory-less searching capability. The search strategy of the PSO and mutation capability of the GA are introduced in the modiﬁed CFO to mitigate the shortcomings [102].
7) UNSUPERVISED SA The UAV ﬂying area is divided into multiple small areas for multiple UAVs. Then, the target points of the entire ﬂying area are clustered using the k-means algorithm. Finally, each UAV autonomously ﬂies towards the targets using the SA algorithm in each ﬂying area [103].
8) IMPROVED T -DISTRIBUTION EVOLUTION ALGORITHM An evolutionary algorithm based on an improved T -distribution is proposed for autonomous UAV navigation
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

with little or no prior knowledge of the ﬂying area. A directional perturbation operator obtained by the Sigmoid function is introduced to the improved T -distribution evolution algorithm to reduce the computational complexity, increase the convergence rate and make the algorithm more robust [104].

9) BIO-INSPIRED PREDATOR-PREY
The main concept of the predator-prey algorithm is that in a search space, there are many prey representing solutions, and the predators (e.g., UAVs) search for prey with the highest ﬁtness value. Whenever the predator consumes a solution, new solutions are generated around the predator. Moreover, mutation and crossover are the main parameters that help the predators reach the optimal solution [105].

10) PREDATOR-PREY PIO
The predator-prey characteristics are incorporated with the traditional PIO to ﬁnd the best optimal path and speed up the convergence of the algorithm. The goal of predatorprey is to eliminate the solutions with the most negligible ﬁtness value in the neighborhood, increasing the diversity of the population. Thus, UAVs tend to ﬁnd optimal solutions faster [106].

IV. LEARNING-BASED APPROACHES Learning-based approaches cover the traditional modelbased AI algorithms. These algorithms can achieve nearoptimal solutions for any given NP-hard problem with very low complexity. This section brieﬂy discusses the most widely used learning-based AI approaches for UAV navigation: reinforcement learning (RL), deep learning (DL), asynchronous advantage actor-critic (A3C), and deep reinforcement learning (DRL) utilizing the Markov decision process (MDP), Partially Observable MDP (POMDP), or convolutional neural network (CNN). Moreover, Table 4 summarizes their main features, goals, time complexities with a number of operations m, number of layers, and number of hyper-parameters and presents a comparative analysis of these learning-based AI approaches.

A. REINFORCEMENT LEARNING (RL)

Reinforcement learning is an effective and widely used AI

technique that learns about the environment by performing

various actions and determining the best operating strategy.

An agent and environment are the two fundamental com-

ponents of RL. Using the MDP, the agent interacts with

the environment and determines which action to take [107]. At each time step t, the agent observes its current state st in the environment and takes action at , as depicted in Fig. 13. The environment then rewards the agent with reward rt . Thereafter the agent moves to a new state st+1. The agent’s

principal aim is to establish a policy π that collects the

possible reward from the environment. The agent also seeks

to maximize the predicted discounted total reward deﬁned by

max[

T t =0

δr

t

(st

,

π

(st

))]

in

the

long

run,

where

the

discount

VOLUME 10, 2022

FIGURE 13. Reinforcement learning (RL) [108].
factor δ ∈ [0, 1]. When the state transition probabilities are known in advance, a Bellman equation called the Q-function (1) is built using the discounted reward. Initially, the agent investigates each state of the environment by performing various actions and creating a Q-table for each state-action pair using the Q-function. The agent then begins to exploit the environment by performing actions that have the highest Q-value in the Q-table.
Q(st , at ) = (1 − α) × Q(st , at ) +α[r + δ(max Q∗(st+1, at ))], (1)
Because of its self-learning capabilities and energy efﬁciency, RL is an excellent option for autonomous UAV navigation systems. The autonomous UAV navigation systems that have been used in the past are inefﬁcient and sluggish. If RL is employed, each UAV acts as an agent and tries to ﬂy towards the target. The target can be ﬁxed or dynamic depending on the system model. The closer the UAV gets to the target, the more rewards it receives from the environment.
Therefore, Pham et al. proposed a Q-learning algorithm in [109] for autonomous UAV navigation where Q-learning controls the proportional–integral–derivative (PID) controller parameters to navigate the UAV in a 2D indoor space. Later in [110], the authors upgraded Q-learning with function approximation based on ﬁxed sparse representation (FSR) for better convergence. In contrast, Chowdhury et al. [111] proposed a received signal strength (RSS)-based Q-learning algorithm utilizing -greedy policy for indoor SaR. To make the UAVs more efﬁcient, Liu et al. [112] proposed a double Q-learning solution for navigating a UAV base station autonomously to serve ground users in 2D space. In [113], Colonnese et al. implemented a Q-learning algorithm for UAV path planning to improve the quality of experience (QoE) of ground users. The authors considered autonomous visits to charging stations to maintain interrupted communication. Liu et al. proposed a multi-agent Q-learning algorithm for UAV deployment and navigation to satisfy user QoE in a 3D space [114]. The authors separated the ﬂying zone of each UAV by utilizing the GA and k-means algorithms. Furthermore, in [115], the authors incorporated the prediction of user movement for advance path planning utilizing an echo state network. Later, Hu et al. proposed a multi-agent Q-leaning-based real-time
26331

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges TABLE 3. Comparative study of different optimization-based AI approaches.

decentralized trajectory planning algorithm in which multiple UAVs perform sense-and-send tasks assigned by the nearest BS in [116]. For better convergence and low complexity, the authors reduced the state-action space and incorporated a model-based reward system. Zeng and Xu proposed a Q-learning algorithm utilizing the temporal difference (TD) method to achieve an optimal solution for cellular-connected autonomous UAV navigation in [117]. In addition, the authors discretized the state-action space and introduced a linear function approximation with tile coding to handle large stateaction space.
B. DEEP REINFORCEMENT LEARNING (DRL) Deep reinforcement learning (DRL) uses Q-values in the same way as Q-learning, except for the Q-table component, as illustrated in Fig. 14. The Q-table is replaced with a deep
26332

FIGURE 14. Deep reinforcement learning (DRL) [108].
neural network (DNN) to ensure RL scalability. The primary objective of the DNN is to learn from the data to avoid performing manual calculations every time. A DNN is a nonlinear computational model that can train and execute tasks
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges TABLE 4. Comparative study of different learning-based AI approaches.

such as decision-making, prediction, classiﬁcation, and visualization, similar to the human brain structure [108]. Unlike RL, there are different decision-making processes in DRL:
1) MARKOV DECISION PROCESS (MDP) DP is a decision-making process generally utilized by RL. However, DRL can also utilize the MDP environment for
VOLUME 10, 2022

UAV navigation. In this case, two DNNs are used to train the agent. One DNN acts as the target DNN, and the other is the policy DNN. Zeng et al. implemented an MDP-based dueling deep DQN algorithm in [118] for simultaneous UAV navigation and radio mapping in 3D space. The authors discretized the action and used the ANN to approximate the ﬂying direction. In contrast, Huang et al. [119] utilized
26333

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

massive MIMO communication to guide UAVs on their optimal path using MDP-based DRL. Similarly, in [124], Abedin et al. proposed an MDP-based DRL approach for UAV-BS navigation considering data freshness and energy-efﬁcient. The authors derived the UAV-BS navigation problem as an NP-hard problem using DRL with experience reply memory.
Oubbati et al. proposed an MDP-based DRL algorithm for the urban vehicular network to minimize the average energy consumption and maximize the vehicle coverage with multiple UAVs [120]. They considered centralized training of the UAVs to cover as many vehicles as possible with the minimum number of UAVs while avoiding obstacles and collisions. Oubbati et al. also proposed an MDPbased multi agent DQN (MADQN) algorithm where two UAVs ﬂy over several Internet of Thing (IoT) devices to minimize the age of information (AoI) and enable wireless powered communication networks (WPCN) [121]. They utilized centralized training of the UAVs to maximize energy efﬁciency and avoid a collision.
Moreover, Wang et al. [21] proposed an autonomous UAV navigation system while avoiding obstacles by utilizing MDP-based DRL with extremely sparse rewards utilizing non-expert helpers (LwH). LwH generates a policy before DRL training, which helps the agent to reach optimality by setting dynamic learning goals. Theile et al. [122] proposed a CNN-based double DQN (DDQN) for UAV coverage path planning considering energy consumption and map-based movement. In contrast, He et al. proposed a vision-based DRL algorithm is used to solve the navigation problem in which the navigation problem is modeled as an MDP, a CNN is used, and a twin delayed deep deterministic policy gradient (TD3) from a demonstration is used [125]. Chen et al. proposed an object detection-assisted MDP-based DRL for collision-free autonomous UAV navigation in [123]. The authors considered the positions of the objects, UAV orientation angle and velocity, and 2D coordinates in the state space for faster convergence.
2) PARTIALLY OBSERVABLE MARKOV DECISION PROCESS (POMDP) POMDP is an extension of the MDP, where the agent can observe the environment without knowing the actual state and take action. POMDP considers all possible uncertainties of the environment to estimate the actions. POMDP comprises observation space, state space, and action space. It is a time-consuming process and can provide precise optimality compared with MDP. Thus, Walker et al. proposed a POMDP-based DRL framework for autonomous UAV indoor navigation in [126]. Here the agent utilizes MDP for global and POMDP for local path planning while avoiding obstacles. In addition, the authors used trust region policy optimization (TRPO) to control the policy upgrading during learning. In [127], Pearson et al. used POMDP to develop vision-based DRL algorithm for autonomous UAV navigation. The authors proposed an extended double deep
26334

Q-learning (EDDQN) method, including a modiﬁed Q-function that uses the surrounding image to navigate the UAV to explore the environment. Similarly, Theile et al. proposed a POMDP-based DDQN for autonomous UAV navigation. The main goal of the UAV is to move around and harvest data from a certain area by utilizing the map of the area.
C. ASYNCHRONOUS ADVANTAGE ACTOR-CRITIC (A3C) A3C is an advanced DRL algorithm where each agent consists of two networks: an actor network and critic network. A3C is commonly used in multi-agent environments. The actor network is responsible for observing the current state of the environment and selecting actions. After executing the actions, the agents obtain rewards. Collecting all the states, actions, rewards, and next states of all UAVs, the critic network produces the Q-values and updates the actor network using a deep deterministic policy gradient (DDPG). A3C is highly efﬁcient in multi-UAV scenarios. Thus, Wang et al. [129], [130] proposed an A3C-based DRL framework for autonomous UAV navigation to support mobile edge computing. Each UAV consists of a critic and actor network. All the actor networks in the UAVs are trained using the same data from the entire network. However, critic networks are trained using individual UAV data utilizing a multi-agent DDPG. Moreover, Wang et al. [131] proposed a fast recurrent deterministic policy gradient algorithm (fastRDPG) to navigate UAVs in a large complex environment while avoiding obstacles. Fast-RDPG is an A3C-based DRL online algorithm that can easily handle POMDP problems and converge faster. In contrast, Liu et al. proposed a an A3C-based DRL algorithm for decentralized energy-efﬁcient autonomous UAV navigation for long-term cellular coverage in [132]. The authors used a modiﬁed policy gradient to update the target network by considering the observations of the actor network.
D. DEEP LEARNING (DL) Deep learning is the common tool for vision-based UAV navigation. Deep learning comprises only the deep neural network (DNN) part of the DRL. Considering recent improvements in a variety of tasks such as object identiﬁcation and localization, image segmentation, and depth recognition from monocular or stereo images, the DNN method has been successfully utilized by several researchers for the identiﬁcation of roads and streets on key routes and metropolitan regions by focusing on achieving a high level of autonomy for self-driving cars [133]. DNNs can be used to achieve autonomous navigation for UAVs in extremely difﬁcult environments. There are different types of DNNs, such as fully connected NN (FNN) and CNN.
Menfoukh [133] proposed an image augmentation method utilizing a CNN for vision-based UAV navigation. Back et al. proposed vision-based UAV navigation utilizing CNN in [134], where UAVs perform trail following, disturbance recovery, and obstacle avoidance. In contrast,
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

Pearson et al. [135] proposed autonomous trail following and steering for UAVs by utilizing real-time photos and CNN. For indoor navigation, Chhikara et al. proposed a GA-based deep CNN (DCNN-GA) architecture in which the hyper-parameters of the neural network are tuned using GA. The trained DCNN-GA was utilized for autonomous UAV navigation using transfer learning.
E. MISCELLANEOUS LEARNING ALGORITHMS In addition to the aforementioned learning-based approaches, several other AI techniques exist. For example, proximal policy optimization [137], Monte Carlo [138], linear regression, and deep deterministic policy gradient. However, there are limited and insigniﬁcant studies utilizing these methods.
V. FUTURE RESEARCH DIRECTIONS This section discusses and highlights future possible research directions based on the present research trends described in the previous sections. Previous sections have summarized and presented a comparative study of different AI approaches implemented by researchers. The AI sector is growing, and many efﬁcient AI approaches have not yet been explored adequately for autonomous UAV navigation. The open research issues are summarized below.
• New approaches: Federated learning (FL) is at the top of the list of new approaches. The goal of FL is to train an AI model in a distributed manner across multiple devices using local datasets without sharing them. In addition, FL prevents cyberattacks naturally, as UAVs do not require any data sharing. FL can be integrated with any AI algorithms for autonomous UAV navigation, and it reduces the space and time complexity by utilizing central learning. However, FL has not yet been implemented yet for autonomous UAV navigation, which necessitates its exploration. In addition, the implementation of ontology-based approaches for navigating a UAV swarm is still not explored properly. Karimi et al. utilized an ontology-based approach to navigate robots in a construction site in [139] which can be modiﬁed to use in UAV swarm navigation in future research.
• Energy consumption: UAVs use batteries as their primary power source to support all activities, including ﬂight, communication, and processing. However, the capacities of UAV batteries are insufﬁcient for extended ﬂight. Many researchers have applied different algorithms, such as sleep and wake-up schemes, incorporating mobile edge devices for external computing, and use of solar, to optimize the energy usage of UAVs [140]. Solving the energy issue using energy harvesting while ﬂying is a direction for future research. However, an autonomous visit to a charging station utilizing AI can also solve this issue.
• Computational power: UAVs are very small in size compared to other vehicles. Thus, their memory and energy capacities are low, which gives them a low
VOLUME 10, 2022

computational power. In contrast, the implementation of both the optimization-based and learning-based AI approaches requires high computational power. Overcoming this issue remains an open research problem. Developing efﬁcient AI approaches with low computational power consumption can be a key solution to this problem. Thus, this area needs to be explored adequately. • Physical threats: Physical threats are very recurrent when it comes to surveillance and SaR UAV missions. Many AI approaches have been previously implemented for obstacle avoidance. However, there is no existing solution that avoids sudden physical threats. Consequently, AI-based solutions for physical threat avoidance require an in-depth investigation. • Fault handling: Faults occur frequently in moving vehicles. The handling of software faults is very easy to achieve with an onboard emergency program. However, AI-based solution for faults that are difﬁcult to handle are lacking, such as hardware problems, equipment failures, and inter-component communication failures. Therefore, this area remains an open research problem.
VI. CONCLUSION Autonomous UAV navigation has introduced great ﬂexibility and increased performance in complex dynamic surroundings. This survey highlights UAVs’ essential characteristics and types to familiarize the reader with the UAV architecture. Furthermore, the UAV navigation system and applicationbased classiﬁcation were summarized to make it easier for researchers to grasp the concepts introduced in this survey. In terms of optimization-based and learning-based methods, the fundamentals, operating principles, and critical features of numerous AI algorithms applied by different researchers for autonomous UAV navigation were described. Different optimization-based approaches such as the PSO, ACO, GA, SA, PIO, CS, A*, DE, and GWO algorithms were analyzed and highlighted. Many researchers have modiﬁed these methods according to their requirements to achieve optimal objectives.
In addition, this survey categorized and analyzed learningbased algorithms such as RL, DRL, A3C, and DL. The researchers utilized different neural networks, learning parameters, and decision-making processes to fulﬁll their objectives. After analyzing all AI approaches, comparative studies were presented comparing all the methods from the same ground. In summary, various resources and data related to autonomous UAV navigation and AI are available to further research and development. Furthermore, there is a scope of improvement and novel ideas in different scenarios, such as big data processing, computing power, energy efﬁciency, and fault handling. Thus, this survey highlights future research directions to speed up the present research on AI-based autonomous UAV navigation. Finally, AI can be computationally expensive, but it increases the overall performance of UAVs in terms of signiﬁcant parameters,
26335

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

such as energy consumption, ﬂight time, and communication delay, in a complex dynamic environment for any critical mission.
REFERENCES
[1] Y. Lu, X. Zhucun, G.-S. Xia, and L. Zhang, ‘‘A survey on vision-based UAV navigation,’’ Geo-spatial Inf. Sci., vol. 21, no. 1, pp. 1–12, Jan. 2018.
[2] P. Grippa, D. Behrens, C. Bettstetter, and F. Wall, ‘‘Job selection in a network of autonomous UAVs for delivery of goods,’’ in Proc. Robot., Sci. Syst. XIII, Jul. 2017, pp. 1–10, doi: 10.15607/RSS.2017.XIII.018.
[3] Z. Huang, C. Chen, and M. Pan, ‘‘Multiobjective UAV path planning for emergency information collection and transmission,’’ IEEE Internet Things J., vol. 7, no. 8, pp. 6993–7009, Aug. 2020.
[4] M. Y. Arafat and S. Moh, ‘‘A survey on cluster-based routing protocols for unmanned aerial vehicle networks,’’ IEEE Access, vol. 7, pp. 498–516, 2018.
[5] M. Liu, J. Yang, and G. Gui, ‘‘DSF-NOMA: UAV-assisted emergency communication technology in a heterogeneous Internet of Things,’’ IEEE Internet Things J., vol. 6, no. 3, pp. 5508–5519, Jun. 2019, doi: 10.1109/JIOT.2019.2903165.
[6] M. Y. Arafat and S. Moh, ‘‘Bio-inspired approaches for energy-efﬁcient localization and clustering in UAV networks for monitoring wildﬁres in remote areas,’’ IEEE Access, vol. 9, pp. 18649–18669, 2021.
[7] O. M. Bushnaq, A. Chaaban, and T. Y. Al-Naffouri, ‘‘The role of UAVIoT networks in future wildﬁre detection,’’ IEEE Internet Things J., vol. 8, no. 23, pp. 16984–16999, Dec. 2021.
[8] R. S. de Moraes and E. P. de Freitas, ‘‘Multi-UAV based crowd monitoring system,’’ IEEE Trans. Aerosp. Electron. Syst., vol. 56, no. 2, pp. 1332–1345, Apr. 2020.
[9] M. Wan, G. Gu, W. Qian, K. Ren, X. Maldague, and Q. Chen, ‘‘Unmanned aerial vehicle video-based target tracking algorithm using sparse representation,’’ IEEE Internet Things J., vol. 6, no. 6, pp. 9689–9706, Dec. 2019.
[10] S. H. Chung, B. Sah, and J. Lee, ‘‘Optimization for drone and drone-truck combined operations: A review of the state of the art and future directions,’’ Comput. Oper. Res., vol. 123, Nov. 2020, Art. no. 105004.
[11] C. Wu, B. Ju, Y. Wu, X. Lin, N. Xiong, and G. X. Xu Liang, ‘‘UAV autonomous target search based on deep reinforcement learning in complex disaster scene,’’ IEEE Access, vol. 7, pp. 117227–117245, 2019.
[12] B. Wang, Y. Sun, Z. Sun, L. D. Nguyen, and T. Q. Duong, ‘‘UAVassisted emergency communications in social IoT: A dynamic hypergraph coloring approach,’’ IEEE Internet Things J., vol. 7, no. 8, pp. 7663–7677, Aug. 2020.
[13] O. Esraﬁlian, R. Gangula, and D. Gesbert, ‘‘Three-dimensional-mapbased trajectory design in UAV-aided wireless localization systems,’’ IEEE Internet Things J., vol. 8, no. 12, pp. 9894–9904, Jun. 2021.
[14] R. Chen, B. Yang, and W. Zhang, ‘‘Distributed and collaborative localization for swarming UAVs,’’ IEEE Internet Things J., vol. 8, no. 6, pp. 5062–5074, Mar. 2021.
[15] N. Gageik, P. Benz, and S. Montenegro, ‘‘Obstacle detection and collision avoidance for a UAV with complementary low-cost sensors,’’ IEEE Access, vol. 3, pp. 599–609, 2015.
[16] Y. Zeng, R. Zhang, and T. J. Lim, ‘‘Wireless communications with unmanned aerial vehicles: Opportunities and challenges,’’ IEEE Commun. Mag., vol. 54, no. 5, pp. 36–42, May 2016.
[17] B. Li, Z. Fei, and Y. Zhang, ‘‘UAV communications for 5G and beyond: Recent advances and future trends,’’ IEEE Internet Things J., vol. 6, no. 2, pp. 2241–2263, Apr. 2019.
[18] S. Rezwan and W. Choi, ‘‘Priority-based joint resource allocation with deep Q-Learning for heterogeneous NOMA systems,’’ IEEE Access, vol. 9, pp. 41468–41481, 2021.
[19] S. Yan, M. Peng, and X. Cao, ‘‘A game theory approach for joint access selection and resource allocation in UAV assisted IoT communication networks,’’ IEEE Internet Things J., vol. 6, no. 2, pp. 1663–1674, Apr. 2019.
[20] M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, ‘‘Wireless communication using unmanned aerial vehicles (UAVs): Optimal transport theory for hover time optimization,’’ IEEE Trans. Wireless Commun., vol. 16, no. 12, pp. 8052–8066, Dec. 2017.
[21] C. Wang, J. Wang, J. Wang, and X. Zhang, ‘‘Deep-reinforcement-learningbased autonomous UAV navigation with sparse rewards,’’ IEEE Internet Things J., vol. 7, no. 7, pp. 6180–6190, Jul. 2020.
26336

[22] M. E. Morocho-Cayamcela, H. Lee, and W. Lim, ‘‘Machine learning for 5G/B5G mobile and wireless communications: Potential, limitations, and future directions,’’ IEEE Access, vol. 7, pp. 137184–137206, 2019.
[23] M. Sheraz, M. Ahmed, X. Hou, Y. Li, D. Jin, Z. Han, and T. Jiang, ‘‘Artiﬁcial intelligence for wireless caching: Schemes, performance, and challenges,’’ IEEE Commun. Surveys Tuts., vol. 23, no. 1, pp. 631–661, 1st Quart., 2021.
[24] G. Villarrubia, J. F. De Paz, P. Chamoso, and F. D. la Prieta, ‘‘Artiﬁcial neural networks used in optimization problems,’’ Neurocomputing, vol. 272, pp. 10–16, Jan. 2018. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S0925231217311116
[25] B. Liu, L. Wang, and M. Liu, ‘‘Lifelong federated reinforcement learning: A learning architecture for navigation in cloud robotic systems,’’ IEEE Robot. Autom. Lett., vol. 4, no. 4, pp. 4555–4562, Oct. 2019.
[26] O. Souissi, R. Benatitallah, D. Duvivier, A. Artiba, N. Belanger, and P. Feyzeau, ‘‘Path planning: A 2013 survey,’’ in Proc. Int. Conf. Ind. Eng. Syst. Manage., 2013, pp. 1–8.
[27] P. B. Sujit, S. Saripalli, and J. B. Sousa, ‘‘Unmanned aerial vehicle path following: A survey and analysis of algorithms for ﬁxed-wing unmanned aerial vehicless,’’ IEEE Control Syst., vol. 34, no. 1, pp. 42–59, Feb. 2014.
[28] P. Pandey, A. Shukla, and R. Tiwari, ‘‘Aerial path planning using metaheuristics: A survey,’’ in Proc. 2nd Int. Conf. Electr., Comput. Commun. Technol. (ICECCT), Feb. 2017, pp. 1–7.
[29] S. Ghambari, J. Lepagnot, L. Jourdan, and L. Idoumghar, ‘‘A comparative study of meta-heuristic algorithms for solving UAV path planning,’’ in Proc. IEEE Symp. Ser. Comput. Intell. (SSCI), Nov. 2018, pp. 174–181.
[30] Y. Zhao, Z. Zheng, and Y. Liu, ‘‘Survey on computational-intelligencebased UAV path planning,’’ Knowl.-Based Syst., vol. 158, pp. 54–64, Oct. 2018.
[31] M. Radmanesh, M. Kumar, P. Guentert, and M. Sarim, ‘‘Overview of path planning and obstacle avoidance algorithms for UAVs: A comparative study,’’ Unmanned Syst., vol. 6, pp. 1–24, Apr. 2018.
[32] P. S. Bithas, E. T. Michailidis, N. Nomikos, D. Vouyioukas, and A. G. Kanatas, ‘‘A survey on machine-learning techniques for UAV-based communications,’’ Sensors, vol. 19, no. 23, p. 5170, Nov. 2019. [Online]. Available: https://www.mdpi.com/1424-8220/19/23/5170
[33] A. Fotouhi, H. Qiang, M. Ding, M. Hassan, L. G. Giordano, A. Garcia-Rodriguez, and J. Yuan, ‘‘Survey on UAV cellular communications: Practical aspects, standardization advancements, regulation, and security challenges,’’ IEEE Commun. Surveys Tuts., vol. 21, no. 4, pp. 3417–3442, 4th Quart., 2019.
[34] M. Mozaffari, W. Saad, M. Bennis, Y.-H. Nam, and M. Debbah, ‘‘A tutorial on UAVs for wireless networks: Applications, challenges, and open problems,’’ IEEE Commun. Surveys Tuts., vol. 21, no. 3, pp. 2334–2360, Mar. 2019.
[35] C. T. Cicek, H. Gultekin, B. Tavli, and H. Yanikomeroglu, ‘‘UAV base station location optimization for next generation wireless networks: Overview and future research directions,’’ in Proc. 1st Int. Conf. Unmanned Veh. Syst.-Oman (UVS), Feb. 2019, pp. 1–6.
[36] D. Mishra and E. Natalizio, ‘‘A survey on cellular-connected UAVs: Design challenges, enabling 5G/B5G innovations, and experimental advancements,’’ Comput. Netw., vol. 182, Dec. 2020, Art. no. 107451. [Online]. Available: https://www.sciencedirect.com/science/article/ pii/S1389128620311324
[37] X. Liu, M. Chen, Y. Liu, Y. Chen, S. Cui, and L. Hanzo, ‘‘Artiﬁcial intelligence aided next-generation networks relying on UAVs,’’ IEEE Wireless Commun., vol. 28, no. 1, pp. 120–127, Feb. 2021.
[38] E. W. Dijkstra, ‘‘A note on two problems in connexion with graphs,’’ Numer. Math., vol. 1, no. 1, pp. 269–271, Dec. 1959. [Online]. Available: https://doi.org/10.1007/BF01386390
[39] J. F. Canny, The Complexity of Robot Motion Planning. Cambridge, MA, USA: MIT Press, 1988.
[40] J. Kennedy and R. Eberhart, ‘‘Particle swarm optimization,’’ in Proc. IEEE ICNN, vol. 4, Nov./Dec. 1995, pp. 1942–1948.
[41] P. Svestka and M. H. Overmars, ‘‘Coordinated motion planning for multiple car-like robots using probabilistic roadmaps,’’ in Proc. IEEE Int. Conf. Robot. Autom., vol. 2, May 1995, pp. 1631–1636.
[42] S. M. LaValle, Planning Algorithms. New York, NY, USA: Cambridge Univ. Press, 2006.
[43] D. Ferguson, M. Likhachev, and A. Stentz, ‘‘A guide to heuristic-based path planning,’’ in Proc. Int. Workshop Planning Under Uncertainty Auton. Syst., Int. Conf. Automated Planning Scheduling, 2005, pp. 9–18.
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

[44] N. Cho, Y. Kim, and S. Park, ‘‘Three-dimensional nonlinear pathfollowing guidance law based on differential geometry,’’ IFAC Proc. Volumes, vol. 47, no. 3, pp. 2503–2508, 2014. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S1474667016419853
[45] M. Kothari, I. Postlethwaite, and D.-W. Gu, ‘‘A suboptimal path planning algorithm using rapidly-exploring random trees,’’ Int. J. Aerosp. Innov., vol. 2, nos. 1–2, pp. 93–104, Apr. 2010.
[46] B. Wang, X. Dong, and B. M. Chen, ‘‘Cascaded control of 3D path following for an unmanned helicopter,’’ in Proc. IEEE Conf. Cybern. Intell. Syst., Jun. 2010, pp. 70–75.
[47] D. R. Nelson, D. B. Barber, T. W. McLain, and R. W. Beard, ‘‘Vector ﬁeld path following for miniature air vehicles,’’ IEEE Trans. Robot., vol. 23, no. 3, pp. 519–529, Jun. 2007.
[48] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi, ‘‘Optimization by simulated annealing,’’ Science, vol. 220, no. 4598, pp. 671–680, May 1983.
[49] F. Glover, ‘‘Future paths for integer programming and links to artiﬁcial intelligence,’’ Comput. Oper. Res., vol. 13, no. 5, pp. 533–549, 1986. [Online]. Available: https://www.sciencedirect.com/science/article/ pii/0305054886900481
[50] L. Zhou, S. Leng, Q. Liu, and Q. Wang, ‘‘Intelligent UAV swarm cooperation for multiple targets tracking,’’ IEEE Internet Things J., vol. 9, no. 1, pp. 743–754, Jan. 2022.
[51] R. Storn and K. Price, ‘‘Differential evolution—A simple and efﬁcient heuristic for global optimization over continuous spaces,’’ J. Global Optim., vol. 11, no. 4, pp. 341–359, 1997.
[52] D. Karaboga, ‘‘An idea based on honey bee swarm for numerical optimization,’’ Erciyes Univ., Kayseri, Turkey, Tech. Rep. TR-06, 2005.
[53] A. R. Mehrabian and C. Lucas, ‘‘A novel numerical optimization algorithm inspired from weed colonization,’’ Ecological Informat., vol. 1, no. 4, pp. 355–366, Dec. 2006.
[54] R. V. Rao, V. J. Savsani, and D. P. Vakharia, ‘‘Teaching-learningbased optimization: A novel method for constrained mechanical design optimization problems,’’ Comput.-Aided Des., vol. 43, no. 3, pp. 303–315, Mar. 2011. [Online]. Available: https://www.sciencedirect.com/science/ article/pii/S0010448510002484
[55] S. Mirjalili, S. M. Mirjalili, and A. Lewis, ‘‘Grey wolf optimizer,’’ Adv. Eng. Softw., vol. 69, pp. 46–61, Mar. 2014. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0965997813001853
[56] H. Shareef, A. A. Ibrahim, and A. H. Mutlag, ‘‘Lightning search algorithm,’’ Appl. Soft Comput. J., vol. 36, pp. 315–333, Nov. 2015, doi: 10.1016/j.asoc.2015.07.028.
[57] W. Tong, A. Hussain, W. X. Bo, and S. Maharjan, ‘‘Artiﬁcial intelligence for vehicle-to-everything: A survey,’’ IEEE Access, vol. 7, pp. 10823–10843, 2019.
[58] (2021). Unmanned Systems Technology. [Online]. Available: https://www.unmannedsystemstechnology.com/company/anavia/
[59] Google.com. (2021). [Online]. Available: https://www.google.com/intl/enU.S./loon/
[60] M. Y. Arafat, S. Poudel, and S. Moh, ‘‘Medium access control protocols for ﬂying ad hoc networks: A review,’’ IEEE Sensors J., vol. 21, no. 4, pp. 4097–4121, Feb. 2021.
[61] R. Zhai, Z. Zhou, W. Zhang, S. Sang, and P. Li, ‘‘Control and navigation system for a ﬁxed-wing unmanned aerial vehicle,’’ AIP Adv., vol. 4, no. 3, Mar. 2014, Art. no. 031306.
[62] S. Zhang, S. Wang, C. Li, G. Liu, and Q. Hao, ‘‘An integrated UAV navigation system based on geo-registered 3D point cloud,’’ in Proc. IEEE Int. Conf. Multisensor Fusion Integr. Intell. Syst. (MFI), Nov. 2017, pp. 650–655.
[63] X.-S. Yang and S. Deb, ‘‘Cuckoo search via Lévy ﬂights,’’ in Proc. World Congr. Nature Biologically Inspired Comput. (NaBIC), 2009, pp. 210–214.
[64] S. Mirjalili, S. M. Mirjalili, and A. Lewis, ‘‘Grey wolf optimizer,’’ Adv. Eng. Softw., vol. 69, pp. 46–61, Mar. 2014. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0965997813001853
[65] L. Dlwar, ‘‘Three-dimensional off-line path planning for unmanned aerial vehicle using modiﬁed particle swarm optimization,’’ International Journal of Aerospace and Mechanical Engineering, vol. 9, no. 8, pp. 1–5, Jan. 2015.
[66] M. D. Phung, C. H. Quach, Q. Ha, and T. H. Dinh, ‘‘Enhanced discrete particle swarm optimization path planning for UAV visionbased surface inspection,’’ Autom. Construct., vol. 81, pp. 25–33, Sep. 2017. [Online]. Available: https://www.sciencedirect.com/science/ article/pii/S0926580517303825
VOLUME 10, 2022

[67] C. Huang and J. Fei, ‘‘UAV path planning based on particle swarm optimization with global best path competition,’’ Int. J. Pattern Recognit. Artif. Intell., vol. 32, no. 6, Jun. 2018, Art. no. 1859008.
[68] U. Cekmez, M. Ozsiginan, and O. K. Sahingoz, ‘‘Multi colony ant optimization for UAV path planning with obstacle avoidance,’’ in Proc. Int. Conf. Unmanned Aircr. Syst. (ICUAS), Jun. 2016, pp. 47–52.
[69] Y. Guan, M. Gao, and Y. Bai, ‘‘Double-ant colony based UAV path planning algorithm,’’ in Proc. 11th Int. Conf. Mach. Learn. Comput., 2019, pp. 258–262, doi: 10.1145/3318299.3318376.
[70] Z. Jin, B. Yan, and R. Ye, ‘‘The ﬂight navigation planning based on potential ﬁeld ant colony algorithm,’’ in Proc. Int. Conf. Adv. Control, Automat. Artif. Intell., Jan. 2018, pp. 200–204.
[71] M. Bagherian and A. Alos, ‘‘3D UAV trajectory planning using evolutionary algorithms: A comparison study,’’ Aeronaut. J., vol. 119, no. 1220, pp. 1271–1285, Oct. 2015.
[72] J. Tao, C. Zhong, L. Gao, and H. Deng, ‘‘A study on path planning of unmanned aerial vehicle based on improved genetic algorithm,’’ in Proc. 8th Int. Conf. Intell. Hum.-Mach. Syst. Cybern. (IHMSC), vol. 2, Aug. 2016, pp. 392–395.
[73] Q. Yang, J. Liu, and L. Li, ‘‘Path planning of UAVs under dynamic environment based on a hierarchical recursive multiagent genetic algorithm,’’ in Proc. IEEE Congr. Evol. Comput. (CEC), Jul. 2020, pp. 1–8.
[74] M. Gao, Y. Liu, and P. Wei, ‘‘Opposite and chaos searching genetic algorithm based for UAV path planning,’’ in Proc. IEEE 6th Int. Conf. Comput. Commun. (ICCC), Dec. 2020, pp. 2364–2369.
[75] J. Arora, ‘‘Discrete variable optimum design concepts and methods,’’ in Introduction to Optimum Design. Cambridge, MA, USA: Academic, 2004, pp. 683–706.
[76] L. P. Behnck, D. Doering, C. E. Pereira, and A. Rettberg, ‘‘A modiﬁed simulated annealing algorithm for SUAVs path planning,’’ IFACPapersOnLine, vol. 48, no. 10, pp. 63–68, 2015. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S2405896315009763
[77] K. Liu and M. Zhang, ‘‘Path planning based on simulated annealing ant colony algorithm,’’ in Proc. 9th Int. Symp. Comput. Intell. Des., vol. 2, 2016, pp. 461–466.
[78] S. Xiao, X. Tan, and J. Wang, ‘‘A simulated annealing algorithm and grid map-based UAV coverage path planning method for 3D reconstruction,’’ Electronics, vol. 10, no. 7, p. 853, Apr. 2021. [Online]. Available: https://www.mdpi.com/2079-9292/10/7/853
[79] H. Duan and P. Qiao, ‘‘Pigeon-inspired optimization: A new swarm intelligence optimizer for air robot path planning,’’ Int. J. Intell. Comput. Cybern., vol. 7, no. 1, pp. 24–37, Mar. 2014.
[80] S. Li and Y. Deng, ‘‘Quantum-entanglement pigeon-inspired optimization for unmanned aerial vehicle path planning,’’ Aircr. Eng. Aerosp. Technol., vol. 91, no. 1, pp. 171–181, Jan. 2018.
[81] D. Zhang and H. Duan, ‘‘Social-class pigeon-inspired optimization and time stamp segmentation for multi-UAV cooperative path planning,’’ Neurocomputing, vol. 313, pp. 229–246, Nov. 2018. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0925231218307689
[82] C. Hu, Y. Xia, and J. Zhang, ‘‘Adaptive operator quantum-behaved pigeon-inspired optimization algorithm with application to UAV path planning,’’ Algorithms, vol. 12, no. 1, p. 3, Dec. 2018. [Online]. Available: https://www.mdpi.com/1999-4893/12/1/3
[83] P.-C. Song, J.-S. Pan, and S.-C. Chu, ‘‘A parallel compact cuckoo search algorithm for three-dimensional path planning,’’ Appl. Soft Comput., vol. 94, Sep. 2020, Art. no. 106443. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S1568494620303835
[84] C. Xie and H. Zheng, ‘‘Application of improved cuckoo search algorithm to path planning unmanned aerial vehicle,’’ in Intelligent Computing Theories and Application, D.-S. Huang, V. Bevilacqua, and P. Premaratne, Eds. Cham, Switzerland: Springer, 2016, pp. 722–729.
[85] H. Hu, Y. Wu, J. Xu, and Q. Sun, ‘‘Cuckoo search-based method for trajectory planning of quadrotor in an urban environment,’’ Proc. Inst. Mech. Eng., G, J. Aerosp. Eng., vol. 233, no. 12, pp. 4571–4582, Sep. 2019.
[86] E. Dhulkeﬂ, A. Durdu, and H. Terziogˇlu, ‘‘Dijkstra algorithm using UAV path planning,’’ Selcuk Univ. J. Eng. Sci. Technol., vol. 8, pp. 92–105, Dec. 2020.
[87] X. Chen and J. Zhang, ‘‘The three-dimension path planning of UAV based on improved artiﬁcial potential ﬁeld in dynamic environment,’’ in Proc. 5th Int. Conf. Intell. Hum.-Mach. Syst. Cybern., vol. 2, Aug. 2013, pp. 144–147.
[88] K. Sundar, S. Misra, S. Rathinam, and R. Sharma, ‘‘Routing unmanned vehicles in GPS-denied environments,’’ in Proc. Int. Conf. Unmanned Aircr. Syst. (ICUAS), Jun. 2017, pp. 62–71, doi: 10.1109/ICUAS.2017.7991488.
26337

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

[89] S. Ghambari, J. Lepagnot, L. Jourdan, and L. Idoumghar, ‘‘UAV path planning in the presence of static and dynamic obstacles,’’ in Proc. IEEE Symp. Ser. Comput. Intell. (SSCI), Dec. 2020, pp. 465–472.
[90] Z. Zhang, J. Wu, J. Dai, and C. He, ‘‘A novel real-time penetration path planning algorithm for stealth UAV in 3D complex dynamic environment,’’ IEEE Access, vol. 8, pp. 122757–122771, 2020.
[91] S. Ghambari, L. Idoumghar, L. Jourdan, and J. Lepagnot, ‘‘A hybrid evolutionary algorithm for ofﬂine UAV path planning,’’ in Artiﬁcial Evolution, L. Idoumghar, P. Legrand, A. Liefooghe, E. Lutton, N. Monmarché, and M. Schoenauer, Eds. Cham, Switzerland: Springer, 2020, pp. 205–218.
[92] X. Yu, C. Li, and J. Zhou, ‘‘A constrained differential evolution algorithm to solve UAV path planning in disaster scenarios,’’ Knowl.Based Syst., vol. 204, Sep. 2020, Art. no. 106209. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0950705120304263
[93] X. Yu, C. Li, and G. G. Yen, ‘‘A knee-guided differential evolution algorithm for unmanned aerial vehicle path planning in disaster management,’’ Appl. Soft Comput., vol. 98, Jan. 2021, Art. no. 106857. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S156849462030795X
[94] S. Zhang, Y. Zhou, Z. Li, and W. Pan, ‘‘Grey wolf optimizer for unmanned combat aerial vehicle path planning,’’ Adv. Eng. Softw., vol. 99, pp. 121–136, Sep. 2016. [Online]. Available: https://www.sciencedirect. com/science/article/pii/S0965997816301193
[95] R. K. Dewangan, A. Shukla, and W. W. Godfrey, ‘‘Three dimensional path planning using grey wolf optimizer for UAVs,’’ Int. J. Speech Technol., vol. 49, no. 6, pp. 2201–2217, Jun. 2019, doi: 10.1007/s10489018-1384-y.
[96] C. Qu, W. Gai, J. Zhang, and M. Zhong, ‘‘A novel hybrid grey wolf optimizer algorithm for unmanned aerial vehicle (UAV) path planning,’’ Knowl.-Based Syst., vol. 194, Apr. 2020, Art. no. 105530. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S0950705120300356
[97] X. Sun, S. Pan, C. Cai, Y. Chen, and J. Chen, ‘‘Unmanned aerial vehicle path planning based on improved intelligent water drop algorithm,’’ in Proc. 8th Int. Conf. Instrum. Meas., Comput., Commun. Control (IMCCC), Jul. 2018, pp. 867–872.
[98] D. Zhang, Y. Xu, and X. Yao, ‘‘An improved path planning algorithm for unmanned aerial vehicle based on RRT-connect,’’ in Proc. 37th Chin. Control Conf. (CCC), Jul. 2018, pp. 4854–4858.
[99] W. O. Quesada, J. I. Rodriguez, J. C. Murillo, G. A. Cardona, D. Yanguas-Rojas, L. G. Jaimes, and J. M. Calderón, ‘‘Leader-follower formation for UAV robot swarm based on fuzzy logic theory,’’ in Artiﬁcial Intelligence and Soft Computing, L. Rutkowski, R. Scherer, M. Korytkowski, W. Pedrycz, R. Tadeusiewicz, and J. M. Zurada, Eds. Cham, Switzerland: Springer, 2018, pp. 740–751.
[100] B. Patel and B. Patle, ‘‘Analysis of ﬁreﬂy–fuzzy hybrid algorithm for navigation of quad-rotor unmanned aerial vehicle,’’ Inventions, vol. 5, no. 3, p. 48, Sep. 2020. [Online]. Available: https://www.mdpi.com/24115134/5/3/48
[101] U. Goel, S. Varshney, A. Jain, S. Maheshwari, and A. Shukla, ‘‘Three dimensional path planning for UAVs in dynamic environment using glow-worm swarm optimization,’’ Proc. Comput. Sci., vol. 133, pp. 230–239, Jul. 2018. [Online]. Available: https://www.sciencedirect. com/science/article/pii/S1877050918309724
[102] Y. Chen, J. Yu, Y. Mei, Y. Wang, and X. Su, ‘‘Modiﬁed central force optimization (MCFO) algorithm for 3D UAV path planning,’’ Neurocomputing, vol. 171, pp. 878–888, Jan. 2016. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0925231215010267
[103] X. Yue and W. Zhang, ‘‘UAV path planning based on K-means algorithm and simulated annealing algorithm,’’ in Proc. 37th Chin. Control Conf. (CCC), Jul. 2018, pp. 2290–2295.
[104] X. Liu, X. Du, X. Zhang, Q. Zhu, and M. Guizani, ‘‘Evolutionalgorithm-based unmanned aerial vehicles path planning in complex environment,’’ Comput. Electr. Eng., vol. 80, Dec. 2019, Art. no. 106493. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S0045790618328416
[105] J. Xu, T. Le Pichon, I. Spiegel, D. Hauptman, and S. Keshmiri, ‘‘Bioinspired predator-prey large spacial search path planning,’’ in Proc. IEEE Aerosp. Conf., Mar. 2020, pp. 1–6.
[106] B. Zhang and H. Duan, ‘‘Three-dimensional path planning for uninhabited combat aerial vehicle based on predator-prey pigeon-inspired optimization in dynamic environment,’’ IEEE/ACM Trans. Comput. Biol. Bioinf., vol. 14, no. 1, pp. 97–107, Jan. 2017.
26338

[107] M. Ponsen, M. E. Taylor, and K. Tuyls, ‘‘Abstraction and generalization in reinforcement learning: A summary and framework,’’ in Adaptive and Learning Agents, M. E. Taylor and K. Tuyls, Eds. Berlin, Germany: Springer, 2010, pp. 1–32.
[108] S. Rezwan and W. Choi, ‘‘A survey on applications of reinforcement learning in ﬂying ad-hoc networks,’’ Electronics, vol. 10, no. 4, p. 449, Feb. 2021. [Online]. Available: https://www.mdpi.com/20799292/10/4/449
[109] H. X. Pham, H. M. La, D. Feil-Seifer, and L. Van Nguyen, ‘‘Reinforcement learning for autonomous UAV navigation using function approximation,’’ in Proc. IEEE Int. Symp. Saf., Secur., Rescue Robot. (SSRR), Aug. 2018, pp. 1–6.
[110] H. X. Pham, H. M. La, D. Feil-Seifer, and L. Van Nguyen, ‘‘Reinforcement learning for autonomous UAV navigation using function approximation,’’ in Proc. IEEE Int. Symp. Saf., Secur., Rescue Robot. (SSRR), Aug. 2018, pp. 1–6.
[111] M. M. U. Chowdhury, F. Erden, and I. Guvenc, ‘‘RSS-based Qlearning for indoor UAV navigation,’’ in Proc. IEEE Mil. Commun. Conf. (MILCOM), Nov. 2019, pp. 121–126.
[112] X. Liu, M. Chen, and C. Yin, ‘‘Optimized trajectory design in UAV based cellular networks for 3D users: A double Q-learning approach,’’ 2019, arXiv:1902.06610.
[113] S. Colonnese, F. Cuomo, G. Pagliari, and L. Chiaraviglio, ‘‘Q-SQUARE: A Q-learning approach to provide a QoE aware UAV ﬂight path in cellular networks,’’ Ad Hoc Netw., vol. 91, Aug. 2019, Art. no. 101872. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S1570870518309508
[114] X. Liu, Y. Liu, and Y. Chen, ‘‘Reinforcement learning in multiple-UAV networks: Deployment and movement design,’’ IEEE Trans. Veh. Technol., vol. 68, no. 8, pp. 8036–8049, Aug. 2019.
[115] X. Liu, Y. Liu, Y. Chen, and L. Hanzo, ‘‘Trajectory design and power control for multi-UAV assisted wireless networks: A machine learning approach,’’ IEEE Trans. Veh. Technol., vol. 68, no. 8, pp. 7957–7969, Aug. 2019.
[116] J. Hu, H. Zhang, and L. Song, ‘‘Reinforcement learning for decentralized trajectory design in cellular UAV networks with sense-and-send protocol,’’ IEEE Internet Things J., vol. 6, no. 4, pp. 6177–6189, Aug. 2019.
[117] Y. Zeng and X. Xu, ‘‘Path design for cellular-connected UAV with reinforcement learning,’’ in Proc. IEEE Global Commun. Conf. (GLOBECOM), Dec. 2019, pp. 1–6.
[118] Y. Zeng, X. Xu, S. Jin, and R. Zhang, ‘‘Simultaneous navigation and radio mapping for cellular-connected UAV with deep reinforcement learning,’’ IEEE Trans. Wireless Commun., vol. 20, no. 7, pp. 4205–4220, Jul. 2021.
[119] H. Huang, Y. Yang, H. Wang, Z. Ding, H. Sari, and F. Adachi, ‘‘Deep reinforcement learning for UAV navigation through massive MIMO technique,’’ IEEE Trans. Veh. Technol., vol. 69, no. 1, pp. 1117–1121, Jan. 2020.
[120] O. S. Oubbati, M. Atiquzzaman, A. Baz, H. Alhakami, and J. Ben-Othman, ‘‘Dispatch of UAVs for urban vehicular networks: A deep reinforcement learning approach,’’ IEEE Trans. Veh. Technol., vol. 70, no. 12, pp. 13174–13189, Dec. 2021.
[121] O. S. Oubbati, M. Atiquzzaman, A. Lakas, A. Baz, H. Alhakami, and W. Alhakami, ‘‘Multi-UAV-enabled AoI-aware WPCN: A multi-agent reinforcement learning strategy,’’ in Proc. IEEE Conf. Comput. Commun. Workshops (INFOCOM WKSHPS), May 2021, pp. 1–6.
[122] M. Theile, H. Bayerlein, R. Nai, D. Gesbert, and M. Caccamo, ‘‘UAV coverage path planning under varying power constraints using deep reinforcement learning,’’ in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), Oct. 2020, pp. 1444–1449.
[123] Y. Chen, N. Gonzalez-Prelcic, and R. W. Heath, ‘‘Collision-free UAV navigation with a monocular camera using deep reinforcement learning,’’ in Proc. IEEE 30th Int. Workshop Mach. Learn. Signal Process. (MLSP), Sep. 2020, pp. 1–6.
[124] S. F. Abedin, M. S. Munir, N. H. Tran, Z. Han, and C. S. Hong, ‘‘Data freshness and energy-efﬁcient UAV navigation optimization: A deep reinforcement learning approach,’’ IEEE Trans. Intell. Transp. Syst., vol. 22, no. 4, pp. 5994–6006, Sep. 2021.
[125] L. He, N. Aouf, J. F. Whidborne, and B. Song, ‘‘Deep reinforcement learning based local planner for UAV obstacle avoidance using demonstration data,’’ 2020, arXiv:2008.02521.
[126] O. Walker, F. Vanegas, F. Gonzalez, and S. Koenig, ‘‘A deep reinforcement learning framework for UAV navigation in indoor environments,’’ in Proc. IEEE Aerosp. Conf., Mar. 2019, pp. 1–14.
VOLUME 10, 2022

S. Rezwan, W. Choi: Artificial Intelligence Approaches for UAV Navigation: Recent Advances and Future Challenges

[127] B. G. Maciel-Pearson, L. Marchegiani, S. Akcay, A. Atapour-Abarghouei, J. Garforth, and T. P. Breckon, ‘‘Online deep reinforcement learning for autonomous UAV navigation and exploration of outdoor environments,’’ 2019, arXiv:1912.05684.
[128] M. Theile, H. Bayerlein, R. Nai, D. Gesbert, and M. Caccamo, ‘‘UAV path planning using global and local map information with deep reinforcement learning,’’ in Proc. 20th Int. Conf. Adv. Robot. (ICAR), 2021, pp. 539–546.
[129] L. Wang, K. Wang, C. Pan, W. Xu, N. Aslam, and A. Nallanathan, ‘‘Deep reinforcement learning based dynamic trajectory control for UAV-assisted mobile edge computing,’’ IEEE Trans. Mobile Comput., early access, Feb. 16, 2021, doi: 10.1109/TMC.2021.3059691.
[130] L. Wang, K. Wang, C. Pan, W. Xu, N. Aslam, and L. Hanzo, ‘‘Multiagent deep reinforcement learning-based trajectory planning for multiUAV assisted mobile edge computing,’’ IEEE Trans. Cognit. Commun. Netw., vol. 7, no. 1, pp. 73–84, Mar. 2021.
[131] C. Wang, J. Wang, Y. Shen, and X. Zhang, ‘‘Autonomous navigation of UAVs in large-scale complex environments: A deep reinforcement learning approach,’’ IEEE Trans. Veh. Technol., vol. 68, no. 3, pp. 2124–2136, Mar. 2019.
[132] C. H. Liu, X. Ma, X. Gao, and J. Tang, ‘‘Distributed energy-efﬁcient multi-UAV navigation for long-term communication coverage by deep reinforcement learning,’’ IEEE Trans. Mobile Comput., vol. 19, no. 6, pp. 1274–1285, Jun. 2020.
[133] K. Menfoukh, M. M. Touba, F. Khenfri, and L. Guettal, ‘‘Optimized convolutional neural network architecture for UAV navigation within unstructured trail,’’ in Proc. 1st Int. Conf. Commun., Control Syst. Signal Process. (CCSSP), May 2020, pp. 211–214.
[134] S. Back, G. Cho, J. Oh, X.-T. Tran, and H. Oh, ‘‘Autonomous UAV trail navigation with obstacle avoidance using deep neural networks,’’ J. Intell. Robotic Syst., vol. 100, pp. 1–17, Dec. 2020.
[135] B. G. Maciel-Pearson, P. Carbonneau, and T. Breckon, ‘‘Extending deep neural network trail navigation for unmanned aerial vehicle operation within the forest canopy,’’ in Proc. TAROS, 2018, pp. 147–158.
[136] P. Chhikara, R. Tekchandani, N. Kumar, V. Chamola, and M. Guizani, ‘‘DCNN-GA: A deep neural net architecture for navigation of UAV in indoor environment,’’ IEEE Internet Things J., vol. 8, no. 6, pp. 4448–4460, Mar. 2021.
[137] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, ‘‘Proximal policy optimization algorithms,’’ 2017, arXiv:1707.06347.
[138] N. Metropolis and S. Ulam, ‘‘The Monte Carlo method,’’ J. Amer. Statist. Assoc., vol. 44, no. 247, pp. 335–341, 1949.
[139] S. Karimi, I. Iordanova, and D. St-Onge, ‘‘Ontology-based approach to data exchanges for robot navigation on construction sites,’’ J. Inf. Technol. Construction, vol. 26, pp. 546–565, Jul. 2021.
[140] K. Kuru, ‘‘Planning the future of smart cities with swarms of fully autonomous unmanned aerial vehicles using a novel framework,’’ IEEE Access, vol. 9, pp. 6571–6595, 2021.

SIFAT REZWAN (Student Member, IEEE) received the B.S. degree from the Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh, in 2018. He is currently pursuing the M.Sc. degree with the Smart Networking Laboratory, Chosun University, South Korea, under the supervision of Prof. W. Choi. From 2019 to 2020, he was with Grameenphone Ltd., where he was involved in transmission network operations and automation and received the Top Performer Award, in 2020. His research interests include multiple access for 5G and beyond 5G networks, deep learning-based resource optimization, and heterogeneous wireless networks.
WOOYEOL CHOI (Member, IEEE) received the B.S. degree from the Department of Computer Science and Engineering, Pusan National University, Busan, Republic of Korea, in 2008, and the M.S. and Ph.D. degrees from the School of Information and Communications, Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea, in 2010 and 2015, respectively. He was a Senior Research Scientist with the Korea Institute of Ocean Science and Technology (KIOST), Ansan-si, Republic of Korea, from 2015 to 2017, and a Senior Researcher with the Korea Aerospace Research Institute (KARI), Daejeon, Republic of Korea, from 2017 to 2018. He is currently an Assistant Professor with the Department of Computer Engineering, Chosun University, Gwangju. His research interests include cross-layer protocol design, learning-based resource optimization, and experimentdriven evaluation of wireless networks.

VOLUME 10, 2022

26339

