Choset-79066 book February 22, 2005 17:43
4 Potential Functions

HAVING SEEN the difﬁculty of explicitly representing the conﬁguration space, an alter-

native is to develop search algorithms that incrementally “explore” free space while

searching for a path. Already, we have seen that the Bug algorithms maneuver through

free space without constructing the conﬁguration space, but the Bug algorithms are

limited to simple two-dimensional conﬁguration spaces. Therefore, this chapter intro-

duces navigation planners that apply to a richer class of robots and produce a greater

variety of paths than the Bug methods, i.e., they apply to a more general class of

conﬁguration spaces, including those that are multidimensional and non-Euclidean.

A potential function is a differentiable real-valued function U : Rm → R. The value

of a potential function can be viewed as energy and hence the gradient of the potential

is force. The gradient

is a vector ∇U (q)

=

DU (q )T

=

[

∂U ∂ q1

(q

),

...,

∂U ∂ qm

(

q

)

]T

which

points in the direction that locally maximally increases U . See appendix C.5 for a

more rigorous deﬁnition of the gradient. We use the gradient to deﬁne a vector ﬁeld,

which assigns a vector to each point on a manifold. A gradient vector ﬁeld, as its name

suggests, assigns the gradient of some function to each point. When U is energy, the

gradient vector ﬁeld has the property that work done along any closed path is zero.

The potential function approach directs a robot as if it were a particle moving

in a gradient vector ﬁeld. Gradients can be intuitively viewed as forces acting on a

positively charged particle robot which is attracted to the negatively charged goal.

Obstacles also have a positive charge which forms a repulsive force directing the robot

away from obstacles. The combination of repulsive and attractive forces hopefully

directs the robot from the start location to the goal location while avoiding obstacles

(ﬁgure 4.1).

Choset-79066 book February 22, 2005 17:43

78
+
qstart

4 Potential Functions

+++++++

+

+

+

+

+

+++++++

+

+

+

+

qgoal

Figure 4.1 The negative charge attracts the robot and the positive charge repels it, resulting in a path, denoted by the dashed line, around the obstacle and to the goal.

Note that in this chapter, we mainly deal with ﬁrst-order systems (i.e., we ignore dynamics), so we view the gradients as velocity vectors instead of force vectors. Potential functions can be viewed as a landscape where the robots move from a “high-value” state to a “low-value” state. The robot follows a path “downhill” by following the negated gradient of the potential function. Following such a path is called gradient descent, i.e.,

c˙(t) = −∇U (c(t)).

The robot terminates motion when it reaches a point where the gradient vanishes, i.e., it has reached a q∗ where ∇U (q∗) = 0. Such a point q∗ is called a critical point of U . The point q∗ is either a maximum, minimum, or a saddle point (ﬁgure 4.2).

One can look at the second derivative to determine the type of critical point. For

real-valued functions, this second derivative is the Hessian matrix

 ∂2U  ∂q...12

... ...

∂2U 

∂

q1 ∂
...

qn



.

∂2U ∂ q1 ∂ qn

···

∂2U ∂ qn2

When the Hessian is nonsingular at q∗, the critical point at q∗ is non-degenerate,

implying that the critical point is isolated [173]. When the Hessian is positive-deﬁnite,

the critical point is a local minimum; when the Hessian is negative-deﬁnite, then

Choset-79066 book February 22, 2005 17:43

4 Potential Functions

79

(Maximum)

(Saddle)

(Minimum)

Figure 4.2 Different types of critical points: (Top) Graphs of functions. (Bottom) Gradients of functions.

the critical point is a local maximum. Generally, we consider potential functions whose Hessians are nonsingular, i.e., those which only have isolated critical points. This also means that the potential function is never ﬂat.
For gradient descent methods, we do not have to compute the Hessian because the robot generically terminates its motion at a local minimum, not at a local maximum or a saddle point. Since gradient descent decreases U, the robot cannot arrive at a local maximum, unless of course the robot starts at a maximum. Since we assume that the function is never ﬂat, the set of maxima contains just isolated points, and the likelihood of starting at one is practically zero. However, even if the robot starts at a maximum, any perturbation of the robot position frees the robot, allowing the gradient vector ﬁeld to induce motion onto the robot. Arriving at a saddle point is also unlikely, because they are unstable as well. Local minima, on the other hand, are stable because after any perturbation from a minimum, gradient descent returns the robot to the minimum. Therefore, the only critical point where the robot can generically terminate is a local minimum. Hopefully this is where the goal is located. See ﬁgure 4.3 for an example of a conﬁguration space with its corresponding potential function, along with its energy surface landscape and gradient vector ﬁeld.

Choset-79066 book February 22, 2005 17:43

80

4 Potential Functions

qstart qgoal

(a)

(b)

(c)

(d)

Figure 4.3 (a) A conﬁguration space with three circular obstacles bounded by a circle. (b) Potential function energy surface. (c) Contour plot for energy surface. (d) Gradient vectors for potential function.

There are many potential functions other than the attractive/repulsive potential. Many of these potential functions are efﬁcient to compute and can be computed online [234]. Unfortunately, they all suffer one problem—the existence of local minima not corresponding to the goal. This problem means that potential functions may lead the robot to a point which is not the goal; in other words, many potential functions do not lead to complete path planners. Two classes of approaches address this problem: the ﬁrst class augments the potential ﬁeld with a search-based planner, and the second deﬁnes a potential function with one local minimum, called a navigation function [239]. Although complete (or resolution complete), both methods require full knowledge of the conﬁguration space prior to the planning event.
Finally, unless otherwise stated, the algorithms presented in this chapter apply to spaces of arbitrary dimension, even though the ﬁgures are drawn in two dimensions. Also, we include some discussion of implementation on a mobile base operating in the plane (i.e., a point in a two-dimensional Euclidean conﬁguration space).

4.1 Additive Attractive/Repulsive Potential
The simplest potential function in Qfree is the attractive/repulsive potential. The intuition behind the attractive/repulsive potential is straightforward: the goal attracts the robot while the obstacles repel it. The sum of these effects draws the robot to the goal while deﬂecting it from obstacles. The potential function can be constructed as the sum of attractive and repulsive potentials
U (q) = Uatt(q) + Urep(q).

Choset-79066 book February 22, 2005 17:43

4.1 Additive Attractive/Repulsive Potential

81

The Attractive Potential

There are several criteria that the potential ﬁeld Uatt should satisfy. First, Uatt should

be monotonically increasing with distance from qgoal. The simplest choice is the conic potential, measuring a scaled distance to the goal, i.e., U (q) = ζ d(q, qgoal). The ζ is

a parameter used to scale the effect of the attractive potential. The attractive gradient

is

∇U (q )

=

d

(q

ζ , qgoal

)

(

q

− qgoal).

The

gradient

vector

points

away

from

the

goal

with

magnitude ζ at all points of the conﬁguration space except the goal, where it is

undeﬁned. Starting from any point other than the goal, by following the negated

gradient, a path is traced toward the goal.

When numerically implementing this method, gradient descent may have “chatter-

ing” problems since there is a discontinuity in the attractive gradient at the origin. For

this reason, we would prefer a potential function that is continuously differentiable,

such that the magnitude of the attractive gradient decreases as the robot approaches

qgoal. The simplest such potential function is one that grows quadratically with the

distance to qgoal, e.g.,

Uatt (q )

=

1 ζ d2(q, 2

qgoal),

with the gradient

(4.1)

∇Uatt(q) = ∇

1 2

ζ

d

2

(

q

,

qgoal)

,

=

1 2

ζ

∇

d

2

(q

,

qgoal)

,

= ζ (q − qgoal),

which is a vector based at q, points away from qgoal, and has a magnitude proportional to the distance from q to qgoal. The farther away q is from qgoal, the bigger the magnitude of the vector. In other words, when the robot is far away from the goal, the robot quickly approaches it; when the robot is close to the goal, the robot slowly approaches it. This feature is useful for mobile robots because it reduces “overshoot” of the goal (resulting from step quantization).
In ﬁgure 4.4(a), the goal is in the center and the gradient vectors for various points are drawn. Figure 4.4(b) contains a contour plot for Uatt; each solid circle corresponds to a set of points q where Uatt(q) is constant. Finally, ﬁgure 4.4(c) plots the graph of the attractive potential.
Note that while the gradient ∇Uatt(q) converges linearly to zero as q approaches qgoal (which is a desirable property), it grows without bound as q moves away from qgoal. If qstart is far from qgoal, this may produce a desired velocity that is too large. For this reason, we may choose to combine the quadratic and conic potentials so that the

Choset-79066 book February 22, 2005 17:43
82

4 Potential Functions

(a)

(b)

(c)

Figure 4.4 (a) Attractive gradient vector ﬁeld. (b) Attractive potential isocontours. (c) Graph of the attractive potential.

(4.2) (4.3)

conic potential attracts the robot when it is very distant from qgoal and the quadratic potential attracts the robot when it is near qgoal. Of course it is necessary that the gradient be deﬁned at the boundary between the conic and quadratic portions. Such a ﬁeld can be deﬁned by

Uatt(q) =

1 2

ζ

d

2

(

q

,

qgoal)

,

dg∗oalζ d(q,

qgoal)

−

1 2

ζ

(dg∗oal

)2

,

d(q, qgoal) ≤ dg∗oal, d(q, qgoal) > dg∗oal.

and in this case we have

 ζ (q − qgoal),

∇Uatt(q) = 

, dg∗oalζ (q−qgoal)
d (q , qgoal )

d(q, qgoal) ≤ dg∗oal, d(q, qgoal) > dg∗oal,

where dg∗oal is the threshold distance from the goal where the planner switches between conic and quadratic potentials. The gradient is well deﬁned at the boundary of the two ﬁelds since at the boundary where d(q, qgoal) = dg∗oal, the gradient of the quadratic potential is equal to the gradient of the conic potential, ∇Uatt(q) = ζ (q − qgoal).

The Repulsive Potential
A repulsive potential keeps the robot away from an obstacle. The strength of the repulsive force depends upon the robot’s proximity to the an obstacle. The closer the robot is to an obstacle, the stronger the repulsive force should be. Therefore, the

Choset-79066 book February 22, 2005 17:43

4.1 Additive Attractive/Repulsive Potential

83

Obstacle Q*

Figure 4.5 The repulsive gradient operates only in a domain near the obstacle.

(4.4)

repulsive potential is usually deﬁned in terms of distance to the closest obstacle D(q), i.e.,

Urep(q) =

2

1 2

η

1 D(q)

−

1 Q∗

,

0,

D(q) ≤ Q∗, D(q) > Q∗,

whose gradient is

(4.5)

∇Urep(q) =

η

1 Q∗

−

1 D(q)

1 D2(q

)

∇

D

(q

),

0,

D(q) ≤ Q∗, D(q) > Q∗,

where the Q∗ ∈ R factor allows the robot to ignore obstacles sufﬁciently far away from it and the η can be viewed as a gain on the repulsive gradient. These scalars are usually determined by trial and error. (See ﬁgure 4.5.)
When numerically implementing this solution, a path may form that oscillates around points that are two-way equidistant from obstacles, i.e., points where D is nonsmooth. To avoid these oscillations, instead of deﬁning the repulsive potential function in terms of distance to the closest obstacle, the repulsive potential function is redeﬁned in terms of distances to individual obstacles where di (q) is the distance to obstacle QOi , i.e.,

(4.6) di (q) = min d(q, c).
c∈QOi
Note that the min operator returns the smallest d(q, c) for all points c in QOi .

Choset-79066 book February 22, 2005 17:43
84

4 Potential Functions

di(q)
∇di(q) q

QOi co

Figure 4.6 The distance between x and QOi is the distance to the closest point on QOi . The gradient is a unit vector pointing away from the nearest point.

It can be shown for convex obstacles QOi where c is the closest point to x that the

gradient of di (q) is

(4.7)

∇di (q)

=

q−c . d(q, c)

The vector ∇di (q) describes the direction that maximally increases the distance to QOi from q (ﬁgure 4.6).
Now, each obstacle has its own potential function,

Urepi (q) =

2

1 2

η

− 1

1

di (q)

Qi∗

,

0,

if

di (q)

≤

Q

∗ i

,

if

di (q)

>

Q

∗ i

,

where

Q

∗ i

deﬁnes the size of the domain of inﬂuence for obstacle

QOi . Then Urep(q)

=

n i =1

Urepi

(

q

).

Assuming

that

there

are

only

convex

obstacles

or

nonconvex

ones

can

be decomposed into convex pieces, oscillations do not occur because the planner does

not have radical changes in the closest point anymore.

4.2 Gradient Descent
Gradient descent is a well-known approach to optimization problems. The idea is simple. Starting at the initial conﬁguration, take a small step in the direction opposite the gradient. This gives a new conﬁguration, and the process is repeated until the gradient is zero. More formally, we can deﬁne a gradient descent algorithm (algorithm 4).

Choset-79066 book February 22, 2005 17:43

4.3 Computing Distance for Implementation in the Plane

85

Algorithm 4 Gradient Descent Input: A means to compute the gradient ∇U (q) at a point q Output: A sequence of points {q(0), q(1), . . . , q(i)}
1: q(0) = qstart 2: i = 0 3: while ∇U (q(i)) = 0 do 4: q(i + 1) = q(i) + α(i)∇U (q(i)) 5: i = i + 1 6: end while

In algorithm 4, the notation q(i) is used to denote the value of q at the ith iteration and the ﬁnal path consists of the sequence of iterates {q(0), q(1), . . . , q(i)}. The value of the scalar α(i) determines the step size at the i iteration. It is important that α(i) be small enough that the robot is not allowed to “jump into” obstacles, while being large enough that the algorithm does not require excessive computation time. In motion planning problems, the choice for α(i) is often made on an ad hoc or empirical basis, perhaps based on the distance to the nearest obstacle or to the goal. A number of systematic methods for choosing α(i) can be found in the optimization literature [45]. Finally, it is unlikely that we will ever exactly satisfy the condition ∇U (q(i)) = 0. For this reason, this condition is often replaced with the more forgiving condition ∇U (q(i)) < , in which is chosen to be sufﬁciently small, based on the task requirements.

4.3 Computing Distance for Implementation in the Plane
In this section, we discuss some implementation issues in constructing the attractive/repulsive potential function. The attractive potential function is rather straightforward if the robot knows its current location and the goal location. The challenge lies in computing the repulsive function because it requires calculation of distance to obstacles. Therefore, in this section, we discuss two different methods to compute distance, and hence the repulsive potential function. The ﬁrst method deals with sensor-based implementation on a mobile robot and borrows ideas from chapter 2 in inferring distance information from sensors. The second method assumes the conﬁguration space has been discretized into a grid of pixels and computes distance on the grid.

Choset-79066 book February 22, 2005 17:43

86

4 Potential Functions

QO4

d4

Robot

d3

QO3

q

d1 QO1

d2 QO2

Figure 4.7 Local minima of rays determine the distance to nearby obstacles.
4.3.1 Mobile Robot Implementation
Thus far, the discussion has been general to any conﬁguration space where we can deﬁne distance. Now let’s consider some issues in implementing these potential functions on a planar mobile robot equipped with range sensors radially distributed around its circumference. These range sensors approximate a value of the raw distance function ρ deﬁned in chapter 2. Whereas D(q) corresponds to the global minimum of the raw distance function ρ, a di (q) corresponds to a local minimum with respect to θ of ρ(q, θ ) (ﬁgure 4.7). For example, any sensor in the sonar array whose value is less than that of both its left and right neighbors is a local minimum. Such sensors face the closest points on their corresponding obstacles. Therefore, these sensors point in the direction that maximally brings the robot closest to the obstacles, i.e., −∇di (q). The distance gradient points in the opposite direction. An obstacle distance function may be incorrect if the obstacle is partially occluded by another.
4.3.2 Brushﬁre Algorithm: A Method to Compute Distance on a Grid
In this subsection, we explain a method for computing distance from a map representation called a grid, which is a two-dimensional array of square elements called pixels. A pixel has a value of zero if it is completely free of obstacles and one if it is completely or even partially occupied by an obstacle.

Choset-79066 book February 22, 2005 17:43

4.3 Computing Distance for Implementation in the Plane

87

n1

n2

n3

n1

n2

n3

n4

n5

n6

n4

n5

n6

n7

n8

n9

n7

n8

n9

Four-point

Eight-point

Figure 4.8 Four-point vs. eight-point connectivity.

The user or planner has a choice in determining the neighboring relationships of pixels in a grid. When only the north, south, east, and west pixels are considered neighbors, the grid has four-point connectivity. When the grid also includes the diagonals as neighbors, then it has eight-point connectivity (ﬁgure 4.8). Four-point connectivity has the advantage in that it respects the Manhattan distance function (the L1 metric) because it measures distance as if one were driving in city blocks in midtown Manhattan.
The brushﬁre algorithm uses a grid to approximate distance, and hence the repulsive function. The input to the algorithm is a grid of pixels where the free-space pixels have a value of zero and the obstacles have a value of one. The output is a grid of pixels whose corresponding values each measure distance to the nearest obstacle. These values can then be used to compute a repulsive potential function, as well as its gradient.
In the ﬁrst step of the brushﬁre algorithm, all zero-valued pixels neighboring onevalued pixels are labeled with a two. The algorithm can use four-point or eight-point connectivity to determine adjacency. Next, all zero-valued pixels adjacent to two’s are labeled with a three. This procedure repeats, i.e., all zero-valued pixels adjacent to an i are labeled with an i + 1, as if a brushﬁre is growing from each of the obstacles until the ﬁre consumes all of the free-space pixels. The procedure terminates when all pixels have an assigned value (ﬁgure 4.9).
The brushﬁre method produces a map of distance values to the nearest obstacle. The gradient of distance at a pixel is determined by ﬁnding a neighbor with the lowest pixel value. The gradient is then a vector which points to this neighbor. Note that this vector points in either one of four or one of eight possible directions. If there are multiple neighbors with the same lowest value, simply pick one to deﬁne the gradient. Just as the grid is an approximation of the workspace, so is the computed gradient an approximation of the actual distance gradient.

Choset-79066 book February 22, 2005 17:43

88

4 Potential Functions

22222222222222222222222

2

2

2

222 2 2222

2

2

2 2 2 2222

2

2

2 2 2 222

2

2

2 2 2 22

2

2

2 2 22

2

2

22

2

2

22

2

2

22

2

2

22

2

2

222

2

2

222

2

2

2

2

2

2

2

22222222222222222222222

22222222222222222222222

23333333333333333333332

23 32223222223

32

23 32 23222223

32

23 32 22222233

32

23 32 2322233

32

23 32 23223

32

23 32 23333

32

23 32 23

32

23 32 23

32

23 32 23

32

23 32223

32

23 32223

32

23 33333

32

23

32

23333333333333333333332

22222222222222222222222

22222222222222222222222

23333333333333333333332 23432223222223444444432

23432 232222234 23432 222222334

432 432

23432 23432 23432

232223344 23223344 2333344

432 432 432

23432 23432 23432

234444 234 234

432 432 432

234322234 234322234

432 432

234333334

432

23444444444444444444432

23333333333333333333332

22222222222222222222222

22222222222222222222222

23333333333333333333332 23432223222223444444432

23432 23222223455555432

23432 2222223345

5432

23432 23432 23432

2322233445 2322334455 233334455

5432 5432 5432

23432 23432 23432

23444455 2345555 2345

5432 5432 5432

2343222345

5432

2343222345

5432

23433333455555555555432 23444444444444444444432

23333333333333333333332

22222222222222222222222

22222222222222222222222

23333333333333333333332

23432223222223444444432

23432 23222223455555432

23432 22222233456665432

23432 23222334456 65432

23432 23223344556 65432

23432 23333445566 65432

23432 2344445566

65432

23432 234555566

65432

23432 23456666

65432

23432223456

65432

23432223456666666665432

23433333455555555555432

23444444444444444444432

23333333333333333333332

22222222222222222222222

22222222222222222222222

23333333333333333333332

23432223222223444444432

23432 23222223455555432

23432 22222233456665432

23432 23222334456765432

23432 23223344556765432

23432 23333445566765432

23432 2344445566 765432

23432 234555566

765432

23432 23456666

765432

23432 23456777777765432

23432223456666666665432

23433333455555555555432

23444444444444444444432

23333333333333333333332

22222222222222222222222

Figure 4.9 Propagation of the brushﬁre algorithm with eight-point connectivity. The solid lines pass through pixels where fronts collide.

Choset-79066 book February 22, 2005 17:43

4.4 Local Minima Problem

89

With distance and gradient to the nearest obstacle inhand, a planner can compute the repulsive function. The attractive potential function can be computed analytically and together with the repulsive function, a planner can invoke the additive attractive/ repulsive function described in section 4.1.
It is worth noting that the method described here generalizes into higher dimensions where pixels then become volume elements. For example, in three-dimensions, fourpoint connectivity generalizes to six-point connectivity and eight-point connectivity generalizes to twenty-six-point connectivity. So, when assigning incremental pixel values to neighboring pixels in higher dimensions, the algorithm choses the appropriate adjacency relationship and then iterates through as described above. Although possible, it would become computationally intractable to compute the brushﬁre in higher dimensions.

4.4 Local Minima Problem
The problem that plagues all gradient descent algorithms is the possible existence of local minima in the potential ﬁeld. For appropriate choice of α(i), it can be shown that the gradient descent algorithm is generically guaranteed to converge to a minimum in the ﬁeld, but there is no guarantee that this minimum will be the global minimum. This means that there is no guarantee that gradient descent will ﬁnd a path to qgoal. In ﬁgure 4.10, the robot is initially attracted to the goal as it approaches the horseshoeshaped obstacle. The goal continues to attract the robot, but the bottom arm of the obstacle deﬂects the robot upward until the top arm of the horseshoe begins to inﬂuence

qgoal
Figure 4.10 Local minimum inside the concavity. The robot moves into the concavity until the repulsive gradient balances out the attractive gradient.

Choset-79066 book February 22, 2005 17:43
90

4 Potential Functions

qgoal
Figure 4.11 Local minimum without concave obstacles. The robot moves away from the two convex obstacles until it reaches a point where the gradient vanishes; at this point, the sum of the attractive gradient and the repulsive gradient is zero.
the robot. At this point, the effect of the top and bottom arms keeps the robot halfway between them and the goal continues to attract the robot. The robot reaches a point where the effect of the obstacle’s base counteracts the attraction of the goal. In other words, the robot has reached a q∗ where ∇U (q∗) = 0 and q∗ is not the goal. Note, this problem is not limited to concave obstacles as can be seen in ﬁgure 4.11. Local minima present a signiﬁcant drawback to the attractive/repulsive approach, and thus the attractive/repulsive technique is not complete.
Barraquand and Latombe [37] developed search techniques other than gradient descent to overcome the problem of local minima present when planning with potential functions. Their planner, the Randomized Path Planner (RPP) [37], used a variety of potential functions some of which were simpliﬁed expressions of the potentials presented in this chapter. RPP followed the negative gradient of the speciﬁed potential function and when stuck at a local minimum, it initiated a series of random walks. Often the random walks allowed RPP to escape the local minimum and in that case, the negative gradient to the goal was followed again.
4.5 Wave-Front Planner
The wave-front planner [38, 208] affords the simplest solution to the local minima problem, but can only be implemented in spaces that are represented as grids. For the sake of discussion, consider a two-dimensional space. Initially, the planner starts with the standard binary grid of zeros corresponding to free space and ones to obstacles. The

Choset-79066 book February 22, 2005 17:43

4.5 Wave-Front Planner

91

planner also knows the pixel locations of the start and goal. The goal pixel is labeled with a two. In the ﬁrst step, all zero-valued pixels neighboring the goal are labeled with a three. Next, all zero-valued pixels adjacent to threes are labeled with four. This procedure essentially grows a wave front from the goal where at each iteration, all pixels on the wave front have the same path length, measured with respect to the grid, to the goal. This procedure terminates when the wave front reaches the pixel that contains the robot start location.
The planner then determines a path via gradient descent on the grid starting from the start. Essentially, the planner determines the path one pixel at a time. Assume that the value of the start pixel is 33. The next pixel in the path is any neighboring pixel whose value is 32. There could be multiple choices; simply pick any one of the choices. The next pixel is then one whose value is 31. Boundedness of the free space (and hence the discretization) and continuity of the distance function ensure that construction of the wave front guarantees that there will always be a neighboring pixel whose value is one less than that of the current pixel and that this procedure forms a path in the grid to the goal, i.e., to the pixel whose value is two.
Figure 4.12 contains six panels that demonstrate various stages of the wave-front propagation using four-point connectivity. Note that all points on the wave front have the same Manhattan distance to the goal. In the lower-left panel, note how the wavefront seemingly collides on itself. We will see later that the point of initial collision corresponds to a saddle point of the function that measures distance to the goal. This point then propagates away from the start as well. The trace of this propagation corresponds to a set of points that have two choices for shortest paths back to the goal, either going around the top of the triangle or below it.
The wave-front planner essentially forms a potential function on the grid which has one local minimum and thus is resolution complete. The planner also determines the shortest path, but at the cost of coming dangerously close to obstacles. The major drawback of this method is that the planner has to search the entire space for a path.
Finally, just like the brushﬁre method, the wave-front planner generalizes into higher dimensions as well. Consider the three-dimensional case ﬁrst. Just as a pixel has four edges, a voxel (a three-dimensional pixel) has six faces. Therefore, the analogy to four-point connectivity with pixels is six-point connectivity with voxels. For a voxel with value i, if we assume six-point connectivity, then we assign i + 1 to the surrounding six voxels that share a face with the current voxel. Likewise, if we assume twenty-six-point connectivity (analogous to eight-point connectivity), then we assign i + 1 to all surrounding voxels that share a face, edge or vertex. It should be noted, however, implementation of the wavefront planner in higher dimensions becomes computationally intractable.

Choset-79066 book February 22, 2005 17:43

92

4 Potential Functions

7 76 7656 7654567 65434567 543234567 65434567 7654567

12

12 11

12 11 10

12 11 10 9

12

11 10 9 8

11 12

10 9 8 7

10 11 12

9876

9 10 11 12

8 7 6 5 6 8 9 10 11 12

7 6 5 4 5 6 7 8 9 10 11 12 6 5 4 3 4 5 6 7 8 9 10 11 12 5 4 3 2 3 4 5 6 7 8 9 10 11 12 6 5 4 3 4 5 6 7 8 9 10 11 12

7 6 5 4 5 6 7 8 9 10 11 12

17 16 16 17

17 16 15 15 16 17

17 16 15 14 14 17

16 15 14 13 15 14 13 12 14 13 12 11 13 12 11 10 12 11 10 9 11 10 9 8 10 9 8 7 9876 87656

16 17 15 16 14 15 13 14 15 16 17 12 13 14 15 16 17 11 12 13 14 15 16 17 10 11 12 13 14 15 16 17 9 10 11 12 13 14 15 16 17 8 9 10 11 12 13 14 15 16 17

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 5 4 3 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17

19 18 17 16 16 17 18 19 20

18 17 16 15 15 16 17 18 19 20

17 16 15 14 14 17 18

16 15 14 13

16 17

15 14 13 12

15 16

20

14 13 12 11

14 15

18 19 20

13 12 11 10

13 14 15 16 17 18 19 20

12 11 10 9

12 13 14 15 16 17 18 19 20

11 10 9 8

11 12 13 14 15 16 17 18 19 20

10 9 8 7

10 11 12 13 14 15 16 17 18 19 20

9876

9 10 11 12 13 14 15 16 17 18 19 20

8 7 6 5 6 8 9 10 11 12 13 14 15 16 17 18 19 20

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

5 4 3 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

19 18 17 16 16 17 18 19 20 21 22

18 17 16 15 15 16 17 18 19 20 21 22

17 16 15 14 14 17 18

16 15 14 13

16 17

22

15 14 13 12

15 16

20 21 22

14 13 12 11

14 15

18 19 20 21 22

13 12 11 10

13 14 15 16 17 18 19 20 21 22

12 11 10 9

12 13 14 15 16 17 18 19 20 21 22

11 10 9 8

11 12 13 14 15 16 17 18 19 20 21 22

10 9 8 7

10 11 12 13 14 15 16 17 18 19 20 21 22

9876

9 10 11 12 13 14 15 16 17 18 19 20 21 22

8 7 6 5 6 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

5 4 3 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

19 18 17 16 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34

18 17 16 15 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33

17 16 15 14 14 17 18

16 15 14 13

16 17

23 24 25 26 27 28 29 30 31 32 33 22 23 24 25 26 27 28 29 30 31 32

15 14 13 12

15 16

20 21 22 23 24 25 26 27 28 29 30 31

14 13 12 11

14 15

18 19 20 21 22 23 24 25 26 27 28 29 30

13 12 11 10 12 11 10 9 11 10 9 8

13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27

10 9 8 7

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26

9876 87656

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

5 4 3 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

6 5 4 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

7 6 5 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

Figure 4.12 Propagation of the wave front using four-point connectivity (assume the start is in the upper-right corner and the goal is the origin of the wave front).

Choset-79066 book February 22, 2005 17:43

4.6 Navigation Potential Functions

93

4.6 Navigation Potential Functions
Thus far, we have seen in chapter 2 that the Bug algorithms are complete sensor-based planners that work in unknown spaces, but are limited to planar conﬁguration spaces. Then, at the beginning of this chapter, we have seen that the attractive/repulsive potential function approach applies to a general class of conﬁguration spaces, but suffers from local minima problems, and hence is not complete. The wave-front planner addresses the local minima problem, but requires time and storage exponential in the dimension of the space. In this section, we introduce a new potential that is a function of distance to the obstacles, has only one minimum and applies to a limited class of conﬁguration spaces with dimension two, three, and more. Such potential functions are called navigation functions, formally deﬁned in [239, 364].
DEFINITION 4.6.1 A function ϕ : Qfree → [0, 1] is called a navigation function if it is smooth (or at least Ck for k ≥ 2),
has a unique minimum at qgoal in the connected component of the free space that contains qgoal,
is uniformly maximal on the boundary of the free space, and
is Morse.
A Morse function is one whose critical points are all non-degenerate. This means that critical points are isolated, and if a Morse function is used for gradient descent, any random perturbation will destabilize saddles and maxima. The navigation function approach represents obstacles as QOi = {q | βi (q) ≤ 0}; in other words, βi (q) is negative in the interior of QOi , zero on the boundary of QOi , and positive in the exterior of QOi .
4.6.1 Sphere-Space
This approach initially assumes that the conﬁguration space is bounded by a sphere centered at q0 and has n dim(Qfree)-dimensional spherical obstacles centered at q1, . . . qn. The obstacle distance functions are easy to deﬁne as β0(q) = −d2(q, q0) + r02, βi (q) = d2(q, qi ) − ri2, where ri is the radius of the sphere. Note that βi (q) increases continuously as q moves away from the obstacle. Instead of considering the distance to the closest obstacle or

Choset-79066 book February 22, 2005 17:43

94

4 Potential Functions

(4.8) (4.9)
(4.10) (4.11)

the distance to each individual obstacle, we consider

n
β(q) = βi (q).
i =0
Note that β(q) is zero on the boundary of any obstacle, and positive at all points in the interior of the free space. This presumes that the obstacles are disjoint.
This approach uses β to form a repulsive-like function. The attractive portion of the navigation function is a power of distance to the goal, i.e.,

γκ (q) = (d(q, qgoal))2κ ,

where γκ has zero value at the goal and continuously increases as q moves away from

the

goal.

The

function

γκ β

(

q

)

is

equal

to

zero

only

at

the

goal,

and

it

goes

to

inﬁnity

as q approaches the boundary of any obstacle. More importantly, for a large enough

κ,

the

function

γκ β

(q)

has

a

unique

minimum.

This

is

true

because

as

κ

increases,

the

term ∂γκ /∂q

dominates ∂β/∂q, meaning that the gradient of

γκ β

points toward the

goal. Essentially, increasing κ

has the effect of making

γκ β

take the form of a steep

bowl centered at the goal. Increasing κ also causes other critical points to gravitate

toward the obstacles, as the range of repulsive inﬂuence of the obstacles becomes

small relative to the overwhelming inﬂuence of the attractive ﬁeld.

Near

an

obstacle,

only

that

obstacle

has

a

signiﬁcant

effect

on

the

value

of

γκ β

.

Therefore, the only opportunity for a local minimum to appear is along a radial line

between the obstacle and the goal. On this line near the boundary of an obstacle,

the Hessian of

γκ β

cannot be positive deﬁnite because

γκ β

is quickly decreasing in

value moving from the obstacle to the goal. Therefore there cannot be any local

minimum for large κ, except at the goal [239].

So

γκ β

has a unique minimum, but unfortunately it can have arbitrarily large values,

making it difﬁcut to compute. Therefore, we introduce the analytical switch, which

is deﬁned as

σλ ( x )

=

λ

x +

, x

λ > 0.

Since σλ(x) is zero at x = 0, converges to one as x approaches ∞, and is continuous

(ﬁgure

4.13),

we

can

use

σλ ( x )

to

bound

the

value

of

the

function

γκ β

,

i.e.,

s(q, λ) =

σλ

◦

γκ β

(q) =

γκ λβ + γκ

(q).

The function s(q, λ) has a zero value at the goal, unitary value on the boundary

of any obstacle, and varies continuously in the free space. It has a unique minimum

for a large enough κ. However, it is still not necessarily a Morse function because it

may have degenerate critical points. So, we introduce another function that essentially

Choset-79066 book February 22, 2005 17:43

4.6 Navigation Potential Functions

95

(x)

x
Figure 4.13 Analytic switch function which is used to map the range of a function to the unit interval.

qstart

qgoal

Figure 4.14 Conﬁguration space bounded by a circle with ﬁve circle obstacles.

(4.12) (4.13)

sharpens s(q, λ) so its critical points become nondegenerate, i.e., so that s(q, λ) can become a Morse function. This sharpening function is

ξκ (x)

=

x

1 κ

.

For λ = 1, the resulting navigation function on a sphere-world is then

ϕ(q) =

ξκ

◦

σ1

◦

γκ β

(q)

=

[( d (q ,

d2(q, qgoal) qgoal))2κ + β

(q

)

]1/κ

,

which is guaranteed to have a single minimum at qgoal for a sufﬁciently large κ [239]. Consider the conﬁguration space in ﬁgure 4.14. The effect of increasing κ can be seen

in ﬁgure 4.15, which plots the contour lines for ϕ as κ increases. For κ = 3, ϕ has

three local minima, one of which is the global minimum. For κ = 4 and 6, the local

minima become more apparent because it is easier to see the contour lines (actually

loops) that encircle the local minima. For κ = 7 and 8, the “bad” minima are there

Choset-79066 book February 22, 2005 17:43

96

4 Potential Functions

4

4

4

2

2

2

0

0

0

-2

-2

-2

-4

-4 -2

0

2

4

4

2

0

-2

-4

-4 -2

0

2

4

-4

-4 -2

0

2

4

4

2

0

-2

-4

-4 -2

0

2

4

-4

-4 -2

0

2

4

4

2

0

-2

-4

-4 -2

0

2

4

Figure 4.15 Navigation function for a sphere-space with ﬁve obstacles for κ = 3, κ = 4, κ = 6, κ = 7, κ = 8, and κ = 10.

but hard to see. Eventually, the “bad” minima morph into saddle points, which are unstable. For κ = 10, ϕ has a unique minimum. Therefore, gradient descent will direct the robot to the goal.
We can see the effect of the potential function steepening, critical points gravitating toward the goal, and local minima turning into saddles, in ﬁgure 4.16. Unfortunately, this steepening effect has an adverse consequence. The drawback to this particular navigation function is that it is ﬂat near the goal and far away from the goal, but has sharp transitions in between (ﬁgure 4.16). This makes implementation of a gradient descent approach quite difﬁcult because of numerical errors.

4.6.2 Star-Space
The result of sphere-spaces is just the ﬁrst step toward a more general planner. A sphere-space can serve as a “model space” for any conﬁguration space that is diffeomorphic to the sphere-space. Once we have a navigation function for the model space, to ﬁnd a navigation function for the diffeomorphic conﬁguration space, we need only ﬁnd the diffeomorphism relating the two spaces.

Choset-79066 book February 22, 2005 17:43

4.6 Navigation Potential Functions

97

-4

-2

0

2

4

4

2

0

-2

-4

-2

0

2

4

4

2

0

-2

-4

-2

0

2

4

4

2

0

-2

-4

-4

-4

0.070.15.255 0

-4

-2

0

2

4

0.070.15.255 0

-4

-2

0

2

4

0.070.15.255 0

-4

-2

0

2

4

4

4

4

2

2

2

0

0

0

-2

-2

-2

-4

-4

-4

0.070.15.255 0

0.070.15.255 0

00.190.8.7

Figure 4.16 Navigation function for a sphere-space with ﬁve obstacles for κ = 3, κ = 4, κ = 6, κ = 7, κ = 8, and κ = 10.

Figure 4.17 (Left) Star-shaped set. (Right) Not a star-shaped set.
In this subsection we consider star-spaces consisting of a star-shaped conﬁguration space populated by star-shaped obstacles. A star-shaped set S is a set where there exists at least one point that is within line of sight of all other points in the set, i.e., ∃x such that ∀y ∈ S, t x + (1 − t) y ∈ S ∀t ∈ [0, 1]. See ﬁgure 4.17. All convex sets are star-shaped, but the converse is not true.

Choset-79066 book February 22, 2005 17:43

98

4 Potential Functions

h

F

M

Figure 4.18 The diffeomorphism h maps the star-space F to the sphere-space M.

(4.14) (4.15)
(4.16) (4.17)

The approach is to map a conﬁguration space populated by star-shaped obstacles into a space populated by sphere-shaped obstacles. It can be shown [364] that for two free conﬁguration spaces M and F, if ϕ : M → [0, 1] is a navigation function on M and there exists a mapping h : F → M which is a diffeomorphism, i.e., it is smooth, bijective, and has a smooth inverse, then φ = ϕ ◦ h is a navigation function on F (see ﬁgure 4.18). This diffeormorphism ensures that there is a one-to-one correspondence between critical points. We will use this property to deﬁne navigation functions in star-spaces using results from sphere-spaces.
The h mapping between the star- and sphere-spaces will be constructed using a translated scaling map

Ti (q) = νi (q)(q − qi ) + pi ,

where

νi (q)

=

(1

+

βi (q))1/2

ri d(q,

qi )

,

where qi is the center of the star-shaped set, and pi and ri are, respectively, the center

and radius of the spherical obstacle. Here βi (q) deﬁnes a star-shaped set such that

βi (q) is negative in the interior, zero on the boundary, and positive in the exterior.

Note that if q is in the boundary of the star-shaped obstacle, then (1 + βi (q)) = 1,

and

thus

Ti (q)

=

ri

q −qi d(q,qi )

+

pi .

In

other

words,

Ti (q)

maps

points

on

the

boundary

of the star-shaped set to a sphere.

For the star-shaped obstacle QOi , we deﬁne the analytical switch

si (q, λ) =

σλ

◦

γκ β¯ i βi

(q) =

γκ β¯ i γκ β¯ i + λβi

(q),

where

n

β¯i =

βj,

j=0, j =i

Choset-79066 book February 22, 2005 17:43

4.7 Potential Functions in Non-Euclidean Spaces

99

(4.18) (4.19)

i.e., β¯i is zero on the boundary of the obstacles except the “current” obstacle QOi . Note that si (q, λ) is one on the boundary of QOi , but is zero at the goal and on the boundary of all other obstacles except QOi .
We deﬁne a similar switch for the goal which is one at the goal and zero on the boundary of the free space, i.e.,
M
sqgoal (q, λ) = 1 − si .
i =0
Now, using the above switches and a translated scaling map, we can deﬁne a mapping between star-space and sphere-space as
M
hλ(q) = sqgoal (q, λ)Tqgoal (q) + si (q, λ)Ti (q),
i =0
where Tqgoal (q) = q is just the identity map, used for notational consistency. Note that hλ(q) is exactly Ti (q) on the boundary of the QOi because si is one on
the boundary of QOi and for all j = i, s j is zero on the boundary of QOi (here we include sqgoal as one of the s j ’s). In other words, for each i , hλ(q) is Ti on the boundary of obstacle QOi , which maps the boundary of a star to a sphere. Moreover, hλ(q) is continuous and thus hλ(q) maps the entire star-space to a sphere-space. It can be shown that for a suitable λ, hλ(q) is smooth, bijective, and has a smooth inverse, i.e., is a diffeomorphism [239]. Therefore, since we have a navigation function on a sphere-space, we also have a navigation function on the star-space.

4.7 Potential Functions in Non-Euclidean Spaces
Putting the issue of local minima aside for a moment, another major challenge for implementing potential functions is constructing the conﬁguration space in the ﬁrst place. This is especially challenging when the conﬁguration space is non-Euclidean and multidimensional. In order to deal with this difﬁculty, we will deﬁne a potential function in the workspace, which is Euclidean, and then lift it to the conﬁguration space. Here, we compute a gradient in the conﬁguration space as a function of gradients in the workspace. To do so, instead of thinking of gradients as velocity vectors, we will now think of them as forces. We then establish a relationship between a workspace force and a conﬁguration space force. Then we apply this relationship to a single rigid-body robot, i.e., we show how to derive a conﬁguration space force using workspace forces acting a rigid-body robot. Finally, we apply this relationship to a multibody robot. We focus the discussion in this section on the attractive/repulsive potentials from section 4.1.

Choset-79066 book February 22, 2005 17:43

100

4 Potential Functions

4.7.1

Relationship between Forces in the Workspace and Conﬁguration Space
Since the workspace is a subset of a low-dimensional space (either R2 or R3), it is much easier to implement and evaluate potential functions over the workspace than over the conﬁguration space. Now, we will treat the gradient in the workspace as forces. Naturally, workspace potential functions give rise to workspace forces, but ultimately, we will need forces in the conﬁguration space to determine the path for the robot.
Let x and q be coordinate vectors representing a point in the workspace and the conﬁguration of the robot, respectively, where the coordinates x and q are related by the forward kinematics (chapter 3) x = φ(q). Let f and u denote generalized forces in the workspace and the conﬁguration space, respectively. To represent a force f acting at a point x = φ(q) in the workspace as a generalized force u acting in the robot’s conﬁguration space, we use the principle of virtual work, which essentially says that work (or power) is a coordinate-independent quantity. This means that power measured in workspace coordinates must be equal to power measured in conﬁguration space coordinates. In the workspace, the power done by a force f is the familiar f T x˙. In the conﬁguration space, power is given by uT q˙. From chapter 3, section 3.8, we know that x˙ = J q˙, where J = ∂φ/∂q is the Jacobian of the forward kinematic map. Therefore, the mapping from workspace forces to conﬁguration space forces is given by
f T J q˙ = uT q˙ f T J = uT JT f = u.

(4.20) (4.21)

EXAMPLE 4.7.1 (A Force Acting on a Vertex of a Polygonal Robot) Consider the polygonal robot shown in ﬁgure 4.19. The vertex a has coordinates [ax , ay]T in the robot’s local coordinate frame. Therefore, if the robot’s coordinate frame is located at [x, y]T with orientation θ , the forward kinematic map for vertex a (i.e., the mapping from q = [x, y, θ ]T to the global coordinates of the vertex a) is given by

φ(q) =

x + ax cos θ − ay sin θ y + ax sin θ + ay cos θ

.

The corresponding Jacobian matrix is given by

J (q)

=

∂φ ∂q (q)

=

1 0

0 1

−ax sin θ − ay cos θ ax cos θ − ay sin θ

.

Choset-79066 book February 22, 2005 17:43

4.7 Potential Functions in Non-Euclidean Spaces

101

f a
ay

ax

y

x

Figure 4.19 The robot A, with coordinate frame oriented at angle θ from the world frame, and vertex a with local coordinates (ax , ay).

(4.22) (4.23)

Therefore, the conﬁguration space force is given by



ux  uy  = J T (q)
uθ

fx fy





1

0

=

0

1

 fx

−ax sin θ − ay cos θ ax cos θ − ay sin θ fy





fx

= 

fy



− fx (ax sin θ + ay cos θ ) + fy(ax cos θ − ay sin θ )

and uθ corresponds to the torque exerted about the origin of the robot frame. Our result for uθ can be veriﬁed by the familiar torque equation τ = r × f , where r is the vector from the robot’s origin to the point of application of f , and τ = uθ .

4.7.2 Potential Functions for Rigid-Body Robots
As before, our goal in deﬁning potential functions is to construct a potential function that repels the robot from obstacles, with a global minimum that corresponds to qgoal. In the conﬁguration space, this task was conceptually simple because the robot was represented by a single point, which we treated as a point mass under the inﬂuence of

Choset-79066 book February 22, 2005 17:43

102

4 Potential Functions

(4.24) (4.25)

a potential ﬁeld. In the workspace, things are not so simple; the robot has ﬁnite area in the plane and volume in three dimensions. Evaluating the effect of a potential ﬁeld on the robot would involve computing an integral over the area/volume deﬁned by the robot, and this can be quite complex (both mathematically and computationally). An alternative approach is to select a subset of points on the robot, called control points, and to deﬁne a workspace potential for each of these points. Evaluating the effect of the potential ﬁeld on a single point is no different from the evaluations required in section 4.1. We then use the relationship established in the previous subsection to convert the individual workspace forces to conﬁguration space forces. We then add them to get the total conﬁguration space force. As a result, we have approximately “lifted” the total workspace forces on the robot to a generalized force in the conﬁguration space.
We need to pick control points {ri } on the robot. The minimum number of control points depends upon the number of degrees of freedom of the robot. It is the number of points required to “pin down” the robot. For example, for a rigid-body robot in the plane, we can ﬁx the position of the robot by ﬁxing the position of two of its points. For each r j , the attractive potential is

Uatt, j (q) =

1 2

ζi

d

2

(r

j

(q

),

r

j

(qgoal

)),

dg∗oalζ j d(r j (q),

r j (qgoal))

−

1 2

ζ

j

dg∗oal,

d(r j (q), r j (qgoal)) ≤ dg∗oal d(r j (q), r j (qgoal)) > dg∗oal.

With this potential function, the workspace force for attractive control point ri is

deﬁned by



 ζi (r j (q) − r j (qgoal)),

∇Uatt, j (q) = 

, dg∗oalζ j (r j (q)−r j (qgoal))
d(r j (q),r j (qgoal))

d(r j (q), r j (qgoal)) ≤ dg∗oal, d(r j (q), r j (qgoal)) > dg∗oal.

For the workspace repulsive potential ﬁelds, we use the same control points {r j },

and deﬁne the repulsive potential for r j as



Urepi, j (q)

=

 

1 2

η

j

2

− 1

1

di (r j (q))

Q

∗ i

,

0,

di (r j (q)) ≤ Qi∗, di (r j (q)) > Qi∗,

where di (r j (q)) is the shortest distance between the control point r j and obstacle

WOi ,

and

Q

∗ i

is

the

workspace

distance

of

inﬂuence

for

obstacles.

The

gradient

of

each Urepi, j corresponds to a workspace force, 

ηj ∇Urepi, j (q) = 

− 1

1

Q

∗ i

di (r j (q))

di2

1 (r j (q

))

∇

di

(r

j

(q

))

,

0,

di (r j (q)) ≤ Qi∗,

di (r j (q))

>

Q

∗ i

.

Choset-79066 book February 22, 2005 17:43

4.7 Potential Functions in Non-Euclidean Spaces

103

R(q)

r1

E1

r2

WOi

Figure 4.20 The repulsive forces exerted on the robot vertices r1 and r2 may not be sufﬁcient to prevent a collision between edge E1 and the obstacle.

(4.26)

Often the vertices of the robot are used as the repulsive control points, but it is important to note that this selection of repulsive control points does not guarantee that the robot cannot collide with an obstacle. Figure 4.20 shows an example where this is the case. In this ﬁgure, the repulsive control points r1 and r2 are very far from the obstacle WOi , and therefore the repulsive inﬂuence may not be great enough to prevent the robot edge E1 from colliding with the obstacle. For this reason, we could add a ﬂoating repulsive control point, rﬂoat. The ﬂoating control point is deﬁned as that point on the boundary of the robot that is closest to any workspace obstacle. Obviously the choice of rﬂoat depends on the conﬁguration q. For the example shown in ﬁgure 4.20, rﬂoat would be located at the center of edge E1, thus repelling the robot from the obstacle. The repulsive force acting on rﬂoat is deﬁned in the same way as for the other control points, using (4.25).
The total conﬁguration space force acting on the robot is the sum of the conﬁguration space forces that result from all attractive and repulsive control points, i.e.,

u(q) = uatt j + urepi j

j

ij

=

J

T j

(q ) ∇ u att i

j

(q)

+

j

i

J

T j

(q

)∇

u repi

j

j

in which Jj (q) is the Jacobian matrix for control point r j . It is essential that the addition of forces be done in the conﬁguration space and not in the workspace.

Choset-79066 book February 22, 2005 17:43

104

4 Potential Functions

Path-Planning Algorithm
Having deﬁned a conﬁguration space force, which we will again treat as a velocity, we can use the same gradient descent method for this case as in section 4.1. As before, there are a number of design choices that must be made.
ζ j controls the relative inﬂuence of the attractive potential for control point r j . It is not necessary that all of the ζi be set to the same value. We might choose to weight one of the control points more heavily than the others, producing a “follow the leader” type of motion, in which the leader control point is quickly attracted to its ﬁnal position, and the robot then reorients itself so that the other attractive control points reach their ﬁnal positions.

η j controls the relative inﬂuence of the repulsive potential for control point r j . As with the ζi it is not necessary that all of the η j be set to the same value.

Qi∗

We

can

deﬁne

a

distinct

Q

∗ i

for

each

obstacle.

In

particular,

we

do

not

want

any obstacle’s region of inﬂuence to include the goal position of any repulsive

control point. We may also wish to assign distinct Qi∗’s to the obstacles to avoid

the possibility of overlapping regions of inﬂuence for distinct obstacles.

4.7.3 Path Planning for Articulated Bodies
It is straightforward to extend the methods of the previous subsection to the case of articulated manipulators. Attractive control points are deﬁned on the end effector and repulsive control points are placed on the links. It may be a good idea to use at least one ﬂoating control point for each link of the robot, since each link is a rigid body and we would like to prevent the links from colliding with obstacles. For each control point, a Jacobian matrix is computed (see chapter 3, section 3.8). These Jacobians map workspace forces to generalized conﬁguration space forces (joint torques for revolute joints, joint forces for prismatic joints). With these exceptions, the formalism of section 4.7.2 can be directly applied to the path-planning problem for articulated arms (of course the implementation may be a bit more difﬁcult, since the Jacobians may be a bit more difﬁcult to construct, and computing distances to polyhedrons in three dimensions is a bit more involved than computing distances to polygons in the plane). Naturally, this method will be plagued with local minima.

Choset-79066 book February 22, 2005 17:43

Problems

105

Problems
1. Prove that di (x) is a local minimum of ρ(x, s) with respect to s. Show that D(x) can be deﬁned in terms of di (x).
2. Does the wave-front planner in a discrete grid yield the shortest distance? (If so, in what metric?)
3. Write a program that determines a path between two points in a planar grid using the wavefront planner. Input from a ﬁle a set of obstacles in a known workspace. This ﬁle should be a list of vertices and the program should automatically convert the polygonal representation to a binary grid of pixels. Input from the keyboard a start and goal location and write a program to display a meaningful output that a path is indeed determined. Use either four-point or eight-point connectivity.
4. Write a program that determines a path for a planar convex robot that can orient from a start to a ﬁnal conﬁguration using the wave-front planner. Input from a ﬁle a robot and from a separate ﬁle a set of obstacles in a known workspace. Input a start and goal conﬁguration from the keyboard. Hand in meaningful output where the robot must orient to get from start to goal. Hand in meaningful output where a path is not found.
5. The two-link manipulator in ﬁgure 4.21 has no joint limits. Use the wavefront planner to draw the shortest path between the start and goal conﬁgurations.
6. Implement, either in simulation or on a mobile robot, a sensor-based attractive/repulsive potential function.
360 S•

180

Theta 2

•G

0

0

180

360

Theta 1

Figure 4.21 (Left) The initial conﬁguration of a two-link manipulator in a polygonal workspace. (Right) The conﬁguration space of the two-link manipulator with a start and goal conﬁguration labeled S and G respectively.

Choset-79066 book February 22, 2005 17:43

106

4 Potential Functions

7. Implement the attractive/repulsive potential function for a point robot in a conﬁguration space with the following obstacles (a) polygons (b) polygons and circles (c) polyhedrons (d) polyhedrons and spheres (e) polyhedrons, spheres, and cylinders.
8. Adapt the attractive/repulsive potential function method to handle moving obstacles.
9. Explain why the paths resulting from the Bug2 algorithm and the navigation potential function look similar.

