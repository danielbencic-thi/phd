Choset-79066 book February 22, 2005 17:34
2 Bug Algorithms
EVEN A simple planner can present interesting and difﬁcult issues. The Bug1 and Bug2 algorithms [301] are among the earliest and simplest sensor-based planners with provable guarantees. These algorithms assume the robot is a point operating in the plane with a contact sensor or a zero range sensor to detect obstacles. When the robot has a ﬁnite range (nonzero range) sensor, then the Tangent Bug algorithm [217] is a Bug derivative that can use that sensor information to ﬁnd shorter paths to the goal. The Bug and Bug-like algorithms are straightforward to implement; moreover, a simple analysis shows that their success is guaranteed, when possible. These algorithms require two behaviors: move on a straight line and follow a boundary. To handle boundary-following, we introduce a curve-tracing technique based on the implicit function theorem at the end of this chapter. This technique is general to following any path, but we focus on following a boundary at a ﬁxed distance.
2.1 Bug1 and Bug2
Perhaps the most straight forward path planning approach is to move toward the goal, unless an obstacle is encountered, in which case, circumnavigate the obstacle until motion toward the goal is once again allowable. Essentially, the Bug1 algorithm formalizes the “common sense” idea of moving toward the goal and going around obstacles. The robot is assumed to be a point with perfect positioning (no positioning error) with a contact sensor that can detect an obstacle boundary if the point robot “touches” it. The robot can also measure the distance d(x, y) between any two points x

Choset-79066 book February 22, 2005 17:34

18

2 Bug Algorithms

and y. Finally, assume that the workspace is bounded. Let Br (x) denote a ball of radius r centered on x, i.e., Br (x) = {y ∈ R2 | d(x, y) < r }. The fact that the workspace is bounded implies that for all x ∈ W, there exists an r < ∞ such that W ⊂ Br (x).
The start and goal are labeled qstart and qgoal, respectively. Let q0L = qstart and the m-line be the line segment that connects qiL to qgoal. Initially, i = 0. The Bug1 algorithm exhibits two behaviors: motion-to-goal and boundary-following. During
motion-to-goal, the robot moves along the m-line toward qgoal until it either encounters the goal or an obstacle. If the robot encounters an obstacle, let q1H be the point where the robot ﬁrst encounters an obstacle and call this point a hit point. The robot then circumnavigates the obstacle until it returns to q1H . Then, the robot determines the closest point to the goal on the perimeter of the obstacle and traverses to this point. This point is called a leave point and is labeled q1L . From q1L , the robot heads straight toward the goal again, i.e., it reinvokes the motion-to-goal behavior. If the line that connects q1L and the goal intersects the current obstacle, then there is no path to the goal; note that this intersection would occur immediately “after” leaving q1L . Otherwise, the index i is incremented and this procedure is then repeated for qiL and qiH until the goal is reached or the planner determines that the robot cannot reach the goal (ﬁgures 2.1, 2.2). Finally, if the line to the goal “grazes” an obstacle, the robot
need not invoke a boundary following behavior, but rather continues onward toward
the goal. See algorithm 1 for a description of the Bug1 approach.
qgoal

q1L q2H WO1

q2L WO2

q1H qstart Figure 2.1 The Bug1 algorithm successfully ﬁnds the goal.

Choset-79066 book February 22, 2005 17:34

2.1 Bug1 and Bug2

19

qgoal q1L

qstart

q1H

Figure 2.2 The Bug1 algorithm reports the goal is unreachable.

Algorithm 1 Bug1 Algorithm

Input: A point robot with a tactile sensor

Output: A path to the qgoal or a conclusion no such path exists

1: while Forever do

2: repeat

3:

From qiL−1, move toward qgoal.

4: until qgoal is reached or an obstacle is encountered at qiH .

5: if Goal is reached then

6:

Exit.

7: end if

8: repeat

9: Follow the obstacle boundary.
10: until qgoal is reached or qiH is re-encountered. 11: Determine the point qiL on the perimeter that has the shortest distance to the goal. 12: Go to qiL .
13: if the robot were to move toward the goal then

14:

Conclude qgoal is not reachable and exit.

15: end if

16: end while

Like its Bug1 sibling, the Bug2 algorithm exhibits two behaviors: motion-to-goal and boundary-following. During motion-to-goal, the robot moves toward the goal on the m-line; however, in Bug2 the m-line connects qstart and qgoal, and thus remains ﬁxed. The boundary-following behavior is invoked if the robot encounters an obstacle,

Choset-79066 book February 22, 2005 17:34

20

2 Bug Algorithms

qgoal

WO1

q2L

q2H q1L

WO2

q1H qstart

qgoal

q1H
qstart
Figure 2.3 (Top) The Bug2 algorithm ﬁnds a path to the goal. (Bottom) The Bug2 algorithm reports failure.
but this behavior is different from that of Bug1. For Bug2, the robot circumnavigates the obstacle until it reaches a new point on the m-line closer to the goal than the initial point of contact with the obstacle. At this time, the robot proceeds toward the goal, repeating this process if it encounters an object. If the robot re-encounters the original departure point from the m-line, then there is no path to the goal (ﬁgures 2.3, 2.4). Let x ∈ Wfree ⊂ R2 be the current position of the robot, i = 1, and q0L be the start location. See algorithm 2 for a description of the Bug2 approach.
At ﬁrst glance, it seems that Bug2 is a more effective algorithm than Bug1 because the robot does not have to entirely circumnavigate the obstacles; however, this is not always the case. This can be seen by comparing the lengths of the paths found by the two algorithms. For Bug1, when the ith obstacle is encountered, the robot completely circumnavigates the boundary, and then returns to the leave point. In the worst case, the robot must traverse half the perimeter, pi , of the obstacle to reach this leave point.

Choset-79066 book February 22, 2005 17:34

2.1 Bug1 and Bug2

21

qstart

q1H

q1L

q2L

q2H

qgoal

Figure 2.4 Bug2 Algorithm.

Moreover, in the worst case, the robot encounters all n obstacles. If there are no obstacles, the robot must traverse a distance of length d(qstart, qgoal). Thus, we obtain

(2.1)

n
LBug1 ≤ d(qstart, qgoal) + 1.5 pi .
i =1

For Bug2, the path length is a bit more complicated. Suppose that the line through qstart and qgoal intersects the i th obstacle ni times. Then, there are at most ni leave points for this obstacle, since the robot may only leave the obstacle when it returns to a point on this line. It is easy to see that half of these intersection points are not valid leave points because they lie on the “wrong side” of the obstacle, i.e., moving toward the goal would cause a collision. In the worst case, the robot will traverse nearly the entire perimeter of the obstacle for each leave point. Thus, we obtain

(2.2)

L Bug2

≤ d(qstart, qgoal) +

1 2

n i =1

ni pi .

Naturally, (2.2) is an upper-bound because the summation is over all of the obstacles

as opposed to over the set of obstacles that are encountered by the robot.

Choset-79066 book February 22, 2005 17:34

22

2 Bug Algorithms

Algorithm 2 Bug2 Algorithm

Input: A point robot with a tactile sensor

Output: A path to qgoal or a conclusion no such path exists

1: while True do

2: repeat

3:

From qiL−1, move toward qgoal along m-line.

4: until

qgoal is reached or an obstacle is encountered at hit point qiH . 5: Turn left (or right).

6: repeat

7: Follow boundary

8: until

9: qgoal is reached or

10: qiH is re-encountered or

11: m-line is re-encountered at a point m such that

12:

m = qiH (robot did not reach the hit point),

13:

d(m, qgoal) < d(m, qiH ) (robot is closer), and

14:

If robot moves toward goal, it would not hit the obstacle

15: Let qiL+1 = m

16: Increment i

17: end while

A casual examination of (2.1) and (2.2) shows that LBug2 can be arbitrarily longer than LBug1. This can be achieved by constructing an obstacle whose boundary has many intersections with the m-line. Thus, as the “complexity” of the obstacle increases, it becomes increasingly likely that Bug1 could outperform Bug2 (ﬁgure 2.4).
In fact, Bug1 and Bug2 illustrate two basic approaches to search problems. For each obstacle that it encounters, Bug1 performs an exhaustive search to ﬁnd the optimal leave point. This requires that Bug1 traverse the entire perimeter of the obstacle, but having done so, it is certain to have found the optimal leave point. In contrast, Bug2 uses an opportunistic approach. When Bug2 ﬁnds a leave point that is better than any it has seen before, it commits to that leave point. Such an algorithm is also called greedy, since it opts for the ﬁrst promising option that is found. When the obstacles are simple, the greedy approach of Bug2 gives a quick payoff, but when the obstacles are complex, the more conservative approach of Bug1 often yields better performance.

Choset-79066 book February 22, 2005 17:34

2.2 Tangent Bug

23

2.2 Tangent Bug

Tangent Bug [216] serves as an improvement to the Bug2 algorithm in that it determines a shorter path to the goal using a range sensor with a 360 degree inﬁnite orientation resolution. Sometimes orientation is called azimuth. We model this range sensor with the raw distance function ρ : R2 × S1 → R. Consider a point robot situated at x ∈ R2 with rays radially emanating from it. For each θ ∈ S1, the value ρ(x, θ) is the distance to the closest obstacle along the ray from x at an angle θ . More formally,

(2.3)

ρ(x, θ ) = min d(x, x + λ[cos θ, sin θ ]T ),
λ∈[0, ∞]
such that x + λ[cos θ, sin θ ]T ∈ WOi .
i

Note that there are inﬁnitely many θ ∈ S1 and hence the inﬁnite resolution. This

assumption is approximated with a ﬁnite number of range sensors situated along the

circumference of a circular mobile robot which we have modeled as a point.

Since real sensors have limited range, we deﬁne the saturated raw distance function, denoted ρR : R2 × S1 → R, which takes on the same values as ρ when the obstacle is within sensing range, and has a value of inﬁnity when the ray lengths are greater

than the sensing range, R, meaning that the obstacles are outside the sensing range.

More formally,

ρR(x, θ) =

ρ(x, θ), ∞,

if ρ(x, θ ) < R otherwise.

The Tangent Bug planner assumes that the robot can detect discontinuities in ρR as depicted in ﬁgure 2.5. For a ﬁxed x ∈ R2, an interval of continuity is deﬁned to be a connected set of points x + ρ(x, θ )[cos θ, sin θ ]T on the boundary of the free space where ρR(x, θ ) is ﬁnite and continuous with respect to θ .
The endpoints of these intervals occur where ρR(x, θ ) loses continuity, either as a result of one obstacle blocking another or the sensor reaching its range limit. The endpoints are denoted Oi . Figure 2.6 contains an example where ρR loses continuity. The points O1, O2, O3, O5, O6, O7, and O8 correspond to losses of continuity associated with obstacles blocking other portions of Wfree; note the rays are tangent to the obstacles here. The point O4 is a discontinuity because the obstacle boundary falls out of range of the sensor. The sets of points on the boundary of the free space
between O1 and O2, O3 and O4, O5 and O6, O7 and O8 are the intervals of continuity. Just like the other Bugs, Tangent Bug iterates between two behaviors: motion-
to-goal and boundary-following. However, these behaviors are different than in the
Bug1 and Bug2 approaches. Although motion-to-goal directs the robot to the goal,

Choset-79066 book February 22, 2005 17:34

24

2 Bug Algorithms

WO4

WO5
x

WO3 WO2

WO1

Figure 2.5 The thin lines are values of the raw distance function, ρR(x, θ ), for a ﬁxed x ∈ R2, and the thick lines indicate discontinuities, which arise either because an obstacle occludes another or the sensing range is reached. Note that the segments terminating in free space represent inﬁnitely long rays.
this behavior may have a phase where the robot follows the boundary. Likewise, the boundary-following behavior may have a phase where the robot does not follow the boundary.
The robot initially invokes the motion-to-goal behavior, which itself has two parts. First, the robot moves in a straight line toward the goal until it senses an obstacle R units away and directly between it and the goal. This means that a line segment connecting the robot and goal must intersect an interval of continuity. For example, in ﬁgure 2.7, WO2 is within sensing range, but does not block the goal, but WO1 does. When the robot initially senses an obstacle, the circle of radius R becomes tangent to the obstacle. Immediately after, this tangent point splits into two Oi ’s, which are the endpoints of the interval. If the obstacle is in front of the robot, then this interval intersects the segment connecting the robot and the goal.
The robot then moves toward the Oi that maximally decreases a heuristic distance to the goal. An example of a heuristic distance is the sum d(x, Oi ) +d( Oi , qgoal). (The heuristic distance can be more complicated when factoring in available information

Choset-79066 book February 22, 2005 17:34

2.2 Tangent Bug

25

qgoal

O2 O3

x

O4

O8

O5

O1

O6

O7

Figure 2.6 The points of discontinuity of ρR(x, θ ) correspond to points Oi on the obstacles. The thick solid curves represent connected components of the range of ρR(x, θ ), i.e., the intervals of continuity. In this example, the robot, to the best of its sensing range, believes there is a straight-line path to the goal.
qgoal
O2 WO1
O1 O3
O4 WO2

Figure 2.7 The vertical represents the path of the robot and the dotted circle its sensing range. Currently, the robot is located at the “top” of the line segment. The points Oi represent the points of discontinuity of the saturated raw distance function. Note that the robot passes by WO2.

Choset-79066 book February 22, 2005 17:34

26 O1

2 Bug Algorithms O1

WO1

x

qgoal

O2

O3

WO2

WO1

x

O2

O3

WO2

qgoal

O4

O4

Figure 2.8 (Left) The planner selects O2 as a subgoal for the robot. (Right) The planner selects O4 as a subgoal for the robot. Note the line segment between O4 and qgoal cuts through the obstacle.

with regard to the obstacles.) In ﬁgure 2.8 (left), the robot sees WO1 and drives to O2 because i = 2 minimizes d(x, Oi ) + d( Oi , qgoal). When the robot is located at x, it cannot know that WO2 blocks the path from O2 to the goal. In ﬁgure 2.8 (right), when the robot is located at x but the goal is different, it has enough sensor information to conclude that WO2 indeed blocks a path from O2 to the goal, and therefore drives toward O4. So, even though driving toward O2 may initially minimize d(x, Oi ) + d( Oi , qgoal) more than driving toward O4, the planner effectively assigns an inﬁnite cost to d( O2, qgoal) because it has enough information to conclude that any path through O2 will be suboptimal.
The set {Oi } is continuously updated as the robot moves toward a particular Oi , which can be seen in ﬁgure 2.9. When t = 1, the robot has not sensed the obstacle, hence the robot moves toward the goal. When t = 2, the robot initially senses the obstacle, depicted by a thick solid curve. The robot continues to move toward the goal, but off to the side of the obstacle heading toward the discontinuity in ρ. For t = 3 and t = 4, the robot senses more of the obstacle and continues to decrease distance toward the goal while hugging the boundary.
The robot undergoes the motion-to-goal behavior until it can no longer decrease the heuristic distance to the goal. Put differently, it ﬁnds a point that is like a local minimum of d(·, Oi ) + d( Oi , qgoal) restricted to the path that motion-to-goal dictates.
When the robot switches to boundary-following, it ﬁnds the point M on the sensed portion of the obstacle which has the shortest distance on the obstacle to the goal. Note that if the sensor range is zero, then M is the same as the hit point from the Bug1 and Bug2 algorithms. This sensed obstacle is also called the followed obstacle. We make a distinction between the followed obstacle and the blocking obstacle. Let x be

Choset-79066 book February 22, 2005 17:34

2.2 Tangent Bug

27

t =1

t =2

t =4

t =4

Figure 2.9 Demonstration of motion-to-goal behavior for a robot with a ﬁnite sensor range moving toward a goal which is “above” the light gray obstacle.

WO1

qgoal M

WO2

Figure 2.10 The workspace is the same as in ﬁgure 2.7. The solid and dashed segments represent the path generated by motion-to-goal and the dotted path represents the boundaryfollowing path. Note that M is the “local minimum” point.
the current position of the robot. The blocking obstacle is the closest obstacle within sensor range that intersects the segment (1 − λ)x + λqgoal ∀λ ∈ [0, 1]. Initially, the blocking obstacle and the followed obstacle are the same.
Now the robot moves in the same direction as if it were in the motion-to-goal behavior. It continuously moves toward the Oi on the followed obstacle in the chosen direction (ﬁgure 2.10). While undergoing this motion, the planner also updates two values: dfollowed and dreach. The value dfollowed is the shortest distance between the boundary which had been sensed and the goal. Let be all of the points within

Choset-79066 book February 22, 2005 17:34

28

2 Bug Algorithms

line of sight of x with range R that are on the followed obstacle WO f , i.e., = {y ∈ ∂WO f : λx + (1 − λ) y ∈ Qfree ∀λ ∈ [0, 1]}. The value dreach is the
distance between the goal and the closest point on the followed obstacle that is within line of sight of the robot, i.e.,

dreach

=

min
c∈

d (qgoal ,

c).

When dreach < dfollowed, the robot terminates the boundary-following behavior. Let T be the point where a circle centered at x of radius R intersects the segment
that connects x and qgoal. This is the point on the periphery of the sensing range that is closest to the goal when the robot is located at x. Starting with x = qstart and dleave = d(qstart, qgoal), see algorithm 3.

Algorithm 3 Tangent Bug Algorithm

Input: A point robot with a range sensor

Output: A path to the qgoal or a conclusion no such path exists

1: while True do

2: repeat

3:

Continuously move toward the point n ∈ {T, Oi } which minimizes d(x, n) +

d(n, qgoal)

4: until

the goal is encountered or

The direction that minimizes d(x, n) + d(n, qgoal) begins to increase d(x, qgoal), i.e., the robot detects a “local minimum” of d(·, qgoal).

5: Chose a boundary following direction which continues in the same direction as the

most recent motion-to-goal direction.

6: repeat

7:

Continuously update dreach, dfollowed, and {Oi }.

8:

Continuously moves toward n ∈ {Oi } that is in the chosen boundary direction.

9: until

The goal is reached.

The robot completes a cycle around the obstacle in which case the goal cannot be achieved.

dreach < dfollowed 10: end while

Choset-79066 book February 22, 2005 17:34

2.2 Tangent Bug

29

L3

qstart

H1 D1

H2 D2

M3 H3

M4 H4

L4 qgoal

Figure 2.11 The path generated by Tangent Bug with zero sensor range. The dashed lines correspond to the motion-to-goal behavior and the dotted lines correspond to boundary-following.

L3

H1 qstart

D1

H2

sw3 M3

D2

H3

L4 sw 4 H4 M4
qgoal

Figure 2.12 Path generated by Tangent Bug with ﬁnite sensor range. The dashed lines correspond to the motion-to-goal behavior and the dotted lines correspond to boundary-following. The dashed-dotted circles correspond to the sensor range of the robot.
See ﬁgures 2.11, 2.12 for example runs. Figure 2.11 contains a path for a robot with zero sensor range. Here the robot invokes a motion-to-goal behavior until it encounters the ﬁrst obstacle at hit point H1. Unlike Bug1 and Bug2, encountering a hit point does not change the behavior mode for the robot. The robot continues with the motion-to-goal behavior by turning right and following the boundary of the ﬁrst obstacle. The robot turned right because that direction minimized its heuristic distance to the goal. The robot departs this boundary at a depart point D1. The robot

Choset-79066 book February 22, 2005 17:34
30

2 Bug Algorithms

S

H1

T

D1

H2

D2

H3

d3

Figure 2.13 Path generated by Tangent Bug with inﬁnite sensor range. The dashed-lines correspond to the motion-to-goal behavior and there is no boundary-following.

continues with the motion-to-goal behavior, maneuvering around a second obstacle, until it encounters the third obstacle at H3. The robot turns left and continues to invoke the motion-to-goal behavior until it reaches M3, a minimum point. Now, the planner invokes the boundary-following behavior until the robot reaches L3. Note that since we have zero sensing range, dreach is the distance between the robot and the goal. The procedure continues until the robot reaches the goal. Only at Mi and Li does the robot switch between behaviors. Figures 2.12, 2.13 contain examples where the robot has a ﬁnite and inﬁninte sensing ranges, respectively.

2.3 Implementation
Essentially, the bug algorithms have two behaviors: drive toward a point and follow an obstacle. The ﬁrst behavior is simply a form of gradient descent of d(·, n) where n is either qgoal or an Oi . The second behavior, boundary-following, presents a challenge because the obstacle boundary is not known a priori. Therefore, the robot planner must rely on sensor information to determine the path. However, we must concede that the full path to the goal will not be determined from one sensor reading: the sensing range of the robot may be limited and the robot may not be able to “see” the entire world from one vantage point. So, the robot planner has to be incremental. We must determine ﬁrst what information the robot requires and then where the robot should move to acquire more information. This is indeed the challenge of sensor-based planning. Ideally, we would like this approach to be reactive with sensory information

Choset-79066 book February 22, 2005 17:34

2.3 Implementation

31

feeding into a simple algorithm that outputs translational and rotational velocity for the robot.
There are three questions: What information does the robot require to circumnavigate the obstacle? How does the robot infer this information from its sensor data? How does the robot use this information to determine (locally) a path?
2.3.1 What Information: The Tangent Line
If the obstacle were ﬂat, such as a long wall in a corridor, then following the obstacle is trivial: simply move parallel to the obstacle. This is readily implemented using a sensing system that can determine the obstacle’s surface normal n(x), and hence a direction parallel to its surface. However, the world is not necessarily populated with ﬂat obstacles; many have nonzero curvature. The robot can follow a path that is consistently orthogonal to the surface normal; this direction can be written as n(x)⊥ and the resulting path satisﬁes c˙(t) = v where v is a basis vector in (n (c (t)))⊥. The sign of v is based on the “previous” direction of c˙.
Consistently determining the surface normal can be quite challenging and therefore for implementation, we can assume that obstacles are “locally ﬂat.” This means the sensing system determines the surface normal, the robot moves orthogonal to this normal for a short distance, and then the process repeats. In a sense, the robot determines the sequence of short straight-line segments to follow, based on sensor information.
This ﬂat line, loosely speaking, is the tangent (ﬁgure 2.14). It is a linear approximation of the curve at the point where the tangent intersects the curve. The tangent

Offset Curve

Tangent

WOi W*

x

D(x)

Figure 2.14 The solid curve is the offset curve. The dashed line represents the tangent to the offset curve at x.

Choset-79066 book February 22, 2005 17:34

32

2 Bug Algorithms

can also be viewed as a ﬁrst-order approximation to the function that describes the

curve. Let c : [0, 1] → Wfree be the function that deﬁnes a path. Let x = c(s0) for

a

s0

∈

[0, 1].

The tangent

at

x

is

dc ds

s=s0 . The tangent space

can

be

viewed

as a

line

whose basis vector is

dc ds

s=s0 , i.e.,

α

dc ds

s=s0

α∈R

.

2.3.2 How to Infer Information with Sensors: Distance and Gradient
The next step is to infer the tangent from sensor data. Instead of thinking of the robot as a point in the plane, let’s think of it as a circular base which has a ﬁne array of tactile sensors radially distributed along its circumference (ﬁgure 2.15). When the robot contacts an obstacle, the direction from the contacted sensor to the robot’s center approximates the surface normal. With this information, the robot can determine a sequence of tangents to follow the obstacle.
Unfortunately, using a tactile sensor to prescribe a path requires the robot to collide with obstacles, which endangers the obstacles and the robot. Instead, the robot should follow a path at a safe distance W∗ ∈ R from the nearest obstacle. Such a path is called

Tactile Ring

Robot

n(t)

Obstacle Figure 2.15 A ﬁne-resolution tactile sensor.

Choset-79066 book February 22, 2005 17:34

2.3 Implementation

33

WO4

D(x) Robot
x

WO3

WO1

WO2

Figure 2.16 The global minimum of the rays determines the distance to the closest obstacle; the gradient points in a direction away from the obstacle along the ray.

an offset curve [381]. Let D(x) be the distance from x to the closest obstacle, i.e.,

(2.4) D(x) = minc∈ i WOi d(x, c).

To measure this distance with a mobile robot equipped with an onboard range sensing

ring, we use the raw distance function again. However, instead of looking for dis-

continuities, we look for the global minimum. In other words, D(x) = mins ρ(x, s)

(ﬁgure 2.16).

We will need to use the gradient of distance. In general, the gradient is a vector

that points in the direction that maximally increases the value of a function. See

appendix C.5 for more details. Typically, the ith component of the gradient vector is

the partial derivative of the function with respect to its ith coordinate. In the plane,

∇ D(x)

=

[

∂

D(x ∂ x1

)

∂

D(x ∂ x2

)

]T

which

points

in

the

direction

that

increases

distance

the

most. Finally, the gradient is the unit direction associated with the smallest value of

the raw distance function. Since the raw distance function seemingly approximates a

sensing system with individual range sensing elements radially distributed around the

perimeter of the robot, an algorithm deﬁned in terms of D can often be implemented

using realistic sensors.

There are many choices for range sensors; here, we investigate the use of ultrasonic

sensors (ﬁgure 2.17), which are commonly found on mobile robots. Conventional

ultrasonic sensors measure distance using time of ﬂight. When the speed of sound

Choset-79066 book February 22, 2005 17:34
34

2 Bug Algorithms

Figure 2.17 The disk on the right is the standard Polaroid ultrasonic transducer found on many mobile robots; the circuitry on the left drives the transducer.

Figure 2.18 Beam pattern for the Polaroid transducer.

in air is constant, the time that the ultrasound requires to leave the transducer, strike

an obstacle, and return is proportional to the distance to the point of reﬂection on

the obstacle [113]. This obstacle, however, can be located anywhere along the angu-

lar spread of the sonar sensor’s beam pattern (ﬁgure 2.18). Therefore, the distance

information that sonars provide is fairly accurate in depth, but not in azimuth. The

beam pattern can be approximated with a cone (ﬁgure 2.19). For the commonly used

Polaroid transducer, the arcbase is 22.5 degrees. When the reading of the sensor is d,

the

point

of

reﬂection

can

be

anywhere

along

the

arc

base

of

length

2π d22.5 360

.

Choset-79066 book February 22, 2005 17:34

2.3 Implementation

35

Obstacle d
Point Sensor

Sensor Measurement Axis Beam Pattern
Robot

Figure 2.19 Centerline model.

Initially, assume that the echo originates from the center of the sonar cone. We acknowledge that this is a naive model, and we term this the centerline model (ﬁgure 2.19). The ultrasonic sensor with the smallest reading approximates the global minimum of the raw distance function, and hence D(x). The direction that this sensor is facing approximates the negated gradient −∇ D(x) because this sensor faces the closest obstacle. The tangent is then the line orthogonal to the direction associated with the smallest sensor reading.

2.3.3

How to Process Sensor Information: Continuation Methods
The tangent to the offset curve is (∇ D(x))⊥, the line orthogonal to ∇ D(x) (ﬁgure 2.14). The vector ∇ D(x) points in the direction that maximally increases distance; likewise, the vector −∇ D(x) points in the direction that maximally decreases distance; they both point along the same line, but in opposite directions. Therefore, the vector (∇ D(x))⊥ points in the direction that locally maintains distance; it is perpendicular to both ∇ D(x) and −∇ D(x). This would be the tangent of the offset curve which maintains distance to the nearby obstacle.
Another way to see why (∇ D(x))⊥ is the tangent is to look at the deﬁnition of the offset curve. For a safety distance W∗, we can deﬁne the offset curve implicitly as the set of points where G(x) = D(x) − W∗ maps to zero. The set of nonzero points (or vectors) that map to zero is called the null space of a map. For a curve implicitly deﬁned by G, the tangent space at a point x is the null space of DG(x), the Jacobian of G [410]. In general, the i, jth component of the Jacobian matrix is the partial derivative of the ith component function with respect to the jth coordinate and thus the Jacobian

Choset-79066 book February 22, 2005 17:34

36

2 Bug Algorithms

is a mapping between tangent spaces. Since in this case, G is a real-valued function (i = 1), the Jacobian is just a row vector D D(x). Here, we are reusing the symbol D. The reader is forced to use context to determine if D means distance or differential.
In Euclidean spaces, the ith component of a single-row Jacobian equals the ith component of the gradient and thus ∇ D(x) = ( D D(x))T . Therefore, since the tangent space is the null space of D D(x), the tangent for boundary-following in the plane is the line orthogonal to ∇ D(x), i.e., (∇ D(x))⊥, and can be derived from sensor information.
Using distance information, the robot can determine the tangent direction to the offset curve. If the obstacles are ﬂat, then the offset curve is also ﬂat, and simply following the tangent is sufﬁcient to follow the boundary of an unknown obstacle. Consider, instead, an obstacle with curvature. We can, however, assume that the obstacle is locally ﬂat. The robot can then move along the tangent for a short distance, but since the obstacle has curvature, the robot will not follow the offset curve, i.e., it will “fall off” of the offset curve. To reaccess the offset curve, the robot moves either toward or away from the obstacle until it reaches the safety distance W∗. In doing so, the robot is moving along a line deﬁned by ∇ D(x), which can be derived from sensor information.
Essentially, the robot is performing a numerical procedure of prediction and correction. The robot uses the tangent to locally predict the shape of the offset curve and then invokes a correction procedure once the tangent approximation is not valid. Note that the robot does not explicitly trace the path but instead “hovers” around it, resulting in a sampling of the path, not the path itself (ﬁgure 2.20).
A numerical tracing procedure can be posed as one which traces the roots of the expression G(x) = 0, where in this case G(x) = D(x) − W∗. Numerical curvetracing techniques rest on the implicit function theorem [9, 232, 307] which locally deﬁnes a curve that is implicitly deﬁned by a map G : Y × R → Y . Speciﬁcally, the roots of G locally deﬁne a curve parameterized by λ ∈ R. See appendix D for a formal deﬁnition.

Figure 2.20 The dashed line is the actual path, but the robot follows the thin black lines, predicting and correcting along the path. The black circles are samples along the path.

Choset-79066 book February 22, 2005 17:34

2.3 Implementation

37

For boundary following at a safety distance W∗, the function G( y, λ) = D( y, λ) − W∗ implicitly deﬁnes the offset curve. Note that the λ-coordinate corresponds to a tangent direction and the y-coordinates to the line or hyperplane orthogonal to the tangent. Let Y denote this hyperplane and DY G be the matrix formed by taking the derivative of G(x) = D(x) − W∗ = 0 with respect to the y-coordinates. It takes the form DY G(x) = DY D(x) where DY denotes the differential with respect to the y-coordinates. If DY G( y, λ) is surjective at x = (λ, y)T , then the implicit function theorem states that the roots of G( y, λ) locally deﬁne a curve that follows the boundary at a distance W∗ as λ is varied, i.e., y(λ).
By numerically tracing the roots of G, we can locally construct a path. While there are a number of curve-tracing techniques [232], let us consider an adaptation of a common predictor-corrector scheme. Assume that the robot is located at a point x which is a ﬁxed distance W∗ away from the boundary. The robot takes a “small” step,
λ, in the λ-direction (i.e., the tangent to the local path). In general, this prediction step takes the robot off the offset path. Next, a correction method is used to bring the robot back onto the offset path. If λ is small, then the local path will intersect a correcting plane, which is a plane orthogonal to the λ-direction at a distance λ away from the origin.
The correction step ﬁnds the location where the offset path intersects the correcting plane and is an application of the Newton convergence theorem [232]. See appendix D.2 for a more formal deﬁnition of this theorem. The Newton convergence theorem also requires that DY G( y, λ) be full rank at every ( y, λ) in a neighborhood of the offset path. This is true because for G(x) = D(x) − W∗, [0 DY G( y, λ)]T = DG( y, λ). Since DG( y, λ) is full rank, so must be DY G( y, λ) on the offset curve. Since the set of nonsingular matrices is an open set, we know there is a neighborhood around each ( y, λ) in the offset path where DG( y, λ) is full rank and hence we can use the iterative Newton method to implement the corrector step. If yh and λh are the hth estimates of y and λ, the h + 1st iteration is deﬁned as
(2.5) yh+1 = yh − ( DY G)−1 G( yh, λh),
where DY G is evaluated at ( yh, λh). Note that since we are working in a Euclidean space, we can determine DY G solely from distance gradient, and hence, sensor information.

Problems
1. Prove that D(x) is the global minimum of ρ(x, s) with respect to s. 2. What are the tradeoffs between the Bug1 and Bug2 algorithms?

Choset-79066 book February 22, 2005 17:34

38

2 Bug Algorithms

3. Extend the Bug1 and Bug2 algorithms to a two-link manipulator.
4. What is the difference between the Tangent Bug algorithm with zero range detector and Bug2? Draw examples.
5. What are the differences between the path in ﬁgure 2.11 and the paths that Bug1 and Bug2 would have generated?
6. The Bug algorithms also assume the planner knows the location of the goal and the robot has perfect positioning. Redesign one of the Bug algorithms to relax the assumption of perfect positioning. Feel free to introduce a new type of “reasonable” sensor (not a highresolution Global Positioning System).
7. In the Bug1 algorithm, prove or disprove that the robot does not encounter any obstacle that does not intersect the disk of radius d(qstart, qgoal) centered at qgoal.
8. What assumptions do the Bug1, Bug2, and Tangent Bug algorithms make on robot localization, both in position and orientation?
9. Prove the completeness of the Tangent Bug algorithm.
10. Adapt the Tangent Bug algorithm so that it has a limited ﬁeld of view sensor, i.e., it does not have a 360 degree ﬁeld of view range sensor.
11. Write out DY G for boundary following in the planar case. 12. Let G1(x) = D(x) + 1 and let G2(x) = D(x) + 2. Why are their Jacobians the same? 13. Let G(x, y) = y3 + y − x2. Write out a y as a function of x in an interval about the origin
for the curve deﬁned by G(x, y) = 0.

