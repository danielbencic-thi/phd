2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) September 24–28, 2017, Vancouver, BC, Canada

Search-based Motion Planning for Quadrotors using Linear Quadratic Minimum Time Control
Sikang Liu, Nikolay Atanasov, Kartik Mohta, and Vijay Kumar

Abstract— In this work, we propose a search-based planning method to compute dynamically feasible trajectories for a quadrotor ﬂying in an obstacle-cluttered environment. Our approach searches for smooth, minimum-time trajectories by exploring the map using a set of short-duration motion primitives. The primitives are generated by solving an optimal control problem and induce a ﬁnite lattice discretization on the state space which can be explored using a graph-search algorithm. The proposed approach is able to generate resolution-complete (i.e., optimal in the discretized space), safe, dynamically feasibility trajectories efﬁciently by exploiting the explicit solution of a Linear Quadratic Minimum Time problem. It does not assume a hovering initial condition and, hence, is suitable for fast online re-planning while the robot is moving. Quadrotor navigation with online re-planning is demonstrated using the proposed approach in simulation and physical experiments and comparisons with trajectory generation based on state-of-art quadratic programming are presented.

Fig. 1: Taking the quadrotor dynamics into account is important for obtaining a smooth trajectory (magenta) while ﬂying at non-zero velocity towards a goal (red triangle). In contrast, existing methods generate a trajectory (red dashed curve) from a shortest path that ignores the system dynamics. Instead of relying on a prior shortest path, the approach proposed in this paper plans globally-optimal trajectories based on time and control efforts.

I. INTRODUCTION
Smooth trajectories obtained by minimizing jerk or snap have been widely used to control differentially ﬂat dynamical systems such as quadrotors [1], [2], [3]. These trajectories are represented via time-parameterized polynomials, which converts the trajectory generation problem into one of ﬁnding polynomial coefﬁcients that satisfy certain constraints. Recent work exploring time-optimal trajectory generation includes [4], [5]. If additionally, obstacle avoidance is added as a consideration, the trajectory generation problem becomes more challenging. While mixed integer optimization techniques [6], [7] handle collisions reliably, they suffer from high computational costs. Recent work demonstrated practical application of quadratic programming [8], [9], [10], [11] to derive collision-free trajectories in real-time. These methods separate the trajectory generation problem in two parts: (i) planning a collision-free geometric path and (ii) optimizing it locally to obtain a dynamically-feasible timeparametrized trajectory. In this way, one can solve for a locally optimal trajectory with respect to a given time allocation. However, the prior geometric path restricts the generated trajectory to be inside a given homology class which may not contain a globally optimal (or even feasible) trajectory (Fig. 1).
This paper proposes an approach for global trajectory optimization that obtains collision-free, dynamically-feasible, minimum-time, smooth trajectories in real time. Instead of
This work is supported in part by ARL # W911NF-08-2-0004, DARPA # HR001151626/HR0011516850, ARO # W911NF-13-1-0350, and ONR # N00014-07-1-0829. The authors are with the GRASP Laboratory, University of Pennsylvania. Email: {sikang, atanasov, kmohta, kumar}@seas.upenn.edu

using a geometric path as a prior, our approach explores the space of trajectories using a set of short-duration motion primitives generated by solving an optimal control problem. We prove that the primitives induce a ﬁnite lattice discretization on the state space, which can in turn be explored using a graph-search algorithm. It is well-known that the graph search in high-dimensional state spaces is not computationally efﬁcient because there are many states to be explored. However, with the help of a tight lower bound (heuristic) on the optimal cost we can inform and signiﬁcantly accelerate the search. The main contribution of this paper can be concluded as:
1) generation of motion primitives that convert an optimal control problem to graph search
2) a search heuristic(s) based on the explicit solution of a Linear Quadratic Minimum Time problem
In contrast with previous works based on motion primitives like [12], [13], [14], our approach does not require a big precomputed look-up table to ﬁnd connections between different graph nodes. To reduce the run time, we propose to plan a trajectory in a lower dimension state space and reﬁne a ﬁnal trajectory that is executable by quadrotors through an unconstrained quadratic programming. We also show that our method generates smoother trajectories compared to the traditional path-based trajectory generation approaches. We demonstrate that our approach can be used for online replanning during fast quadrotor navigation in various cluttered environments. The the code used in this work is open sourced on https://github.com/sikang/motion_ primitive_library.

978-1-5386-2682-5/17/$31.00 ©2017 IEEE

2872

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

II. PROBLEM FORMULATION

Let x(t) ∈ X ⊂ R3n be a dynamical system state, consisting of 3-D position and its (n − 1) derivatives (velocity, acceleration, jerk, etc.). Let X free ⊂ X denote
free region of the state space that, in addition to capturing the obstacle-free positions Pfree, also speciﬁes constraints Dfree on the system’s dynamics, i.e., maximum velocity
vmax, acceleration amax, and higher order derivatives in each axis. Note that Pfree is bounded by the size of the map that we are planning in. Thus, X free := Pfree × Dfree = Pfree × [−vmax, vmax]3 × [−amax, amax]3 × . . .. Denote the obstacle region as X obs := X \ X free.
As described in [15] and many other related works, the
differential ﬂatness of quadrotor systems allow us to con-
struct control inputs from 1-D time-parametrized polynomial
trajectories speciﬁed independently in each of the three
position axes. Thus, we consider polynomial state trajectories x(t) := [pD(t)T, p˙D(t)T, . . . , p(Dn−1)(t)T]T, where

pD(t) :=

K

tk dk k!

=

tK dK K!

+

. . . + d1t + d0

∈

R3

(1)

k=0

and D := [d0, . . . , dK ] ∈ R3×(K+1). To simplify the

notation, we acceleration

denote by a(t)

the :=

sp¨yTDs(tet)m, ’jservkelboycitjy(tb)y:=v(t.p.).TD:=(t)p˙,TDe(ttc).,,

and drop the subscript D where convenient. Polynomial tra-

jectories of the form Eq. (1) can be generated by considering a linear time-invariant dynamical system p(Dn)(t) = u(t), where the control input is u(t) ∈ U := [−umax, umax]3 ⊂ R3. In state space form, we obtain a system as

x˙ = Ax + Bu

0 I3 0 · · · 0 

0

0 0 I3 · · · 0 

0

A

=

  

...

... ... ...

...

  

,

B

=

  

...

  

(2)

0 · · · · · ·

0

I3

 

 

0

 

0 ··· ··· 0 0

I3

We are interested in planning state trajectories that are collision-free, respect the constraints on the dynamics, and are minimum-time and smooth. We deﬁne the smoothness or effort of a trajectory as the square L2-norm of the control input u(t):

J(D) :=

T
u(t) 2 dt =

T

p(Dn)(t)

2
dt

(3)

0

0

and consider the following problem.

Problem 1. Given an initial state x0 ∈ X free and a goal region X goal ⊂ X free, ﬁnd a polynomial trajectory parametrization D ∈ R3×(K+1) and a time T ≥ 0 such
that:

min J(D) + ρT
D,T

s.t. x˙ (t) = Ax(t) + Bu(t), ∀ t ∈ [0, T ]

(4)

x(0) = x0, x(T ) ∈ X goal

x(t) ∈ X free, u(t) ∈ U , ∀ t ∈ [0, T ]

(a) T = 4, J = 19. (b) T = 4, J = 48. (c) T = 7, J = 5.
Fig. 2: Three trajectories start from x(0) to x(T ). Blue and green rays indicate the magnitude of velocity and acceleration along trajectories respectively. If the effort J is disregarded, i.e. ρ → ∞ in Eq. (4), trajectories (a) and (b) have equivalent cost of T = 4. If the time T is not considered, i.e. ρ = 0, trajectory (c) become optimal. Since we are interested in low-effort trajectories, ρ should not be inﬁnite (so that (a) is preferable to (b)) but it should still be large enough to prioritize fast trajectories. Thus, in this comparison, (a) is preferable to both (b) and (c).

where the parameter ρ ≥ 0 determines the relative importance of the trajectory duration T versus its smoothness J.
In the remainder, we denote the optimal cost from an initial state x0 to a goal region X goal by C∗ x0, X goal . The reason for choosing such an objective function is illustrated in Fig. 2. This problem is a Linear Quadratic MinimumTime problem [16] with state constraints, x(t) ∈ X free, and input constraints, u(t) ∈ U. As the derivation in Sec. IIID shows, if we drop the constraints x(t) ∈ X free, u(t) ∈ U, the optimal solution can be obtained via Pontryagin’s minimum principle [16], [17] and the optimal choice of polynomial degree is K = 2n − 1. The main challenge is the introduction of the constraints x(t) ∈ X free, u(t) ∈ U . In this paper, we show that these safety constraints can be handled by converting the problem to a deterministic shortest path problem [18, Ch.2] with a 3n dimensional state space X and a 3 dimensional control space U. Since the control space U is always 3 dimensional, a searchbased planning algorithm such as A∗ [19] that discretizes U using motion primitives is efﬁcient and resolution-complete (i.e., it can compute the optimal trajectory in the discretized space in ﬁnite-time, unlike sampling-based planners such as RRT [20], [21]).

III. OPTIMAL TRAJECTORY PLANNING

A. Motion Primitives

First, we discuss the construction of motion primitives for

the system in Eq. (2) that will allow us to convert Problem 1

from an optimal control problem to a graph-search problem.

Instead of using the control set U, we consider a lattice

discretization [22] UM := {u1, . . . , uM } ⊂ U , where each

control um ∈ R3 vector will deﬁne a motion of short duration

for the system. One way to obtain the discretization UM is

to choose a number of samples µ ∈ Z+ along each axis

[0, umax],

which

deﬁnes

a

discretization

step

du

:=

umax µ

and results in M = (2µ + 1)3 motion primitives. Given an

initial state x0 := [pT0 , v0T, aT0 , . . .]T, we generate a motion

primitive of duration τ > 0 that applies a constant control

2873

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

input u(t) ≡ um ∈ UM for t ∈ [0, τ ] so that:

u(t)

=

p(Dn)(t)

=

K −n

tk

dk+n k!

≡

um.

k=0

The control input being constant, implies that all coefﬁcients that involve time need to be identically zero, i.e.:

d(n+1):K = 0 =⇒ um = dn

Integrating the control expression u(t) = um with an initial condition x0 results in

tn

t2

pD(t) = um n! + . . . + a0 2 + v0t + p0

or, equivalently, the resulting trajectory of the linear timeinvariant system in Eq. (2) is:

x(t) = eAt x0 +
F (t)

t
eA(t−σ)Bdσ um
0
G(t)

An example of the resulting system trajectories is given in Fig. 3. Since both the duration τ and the control input um are

Algorithm 1 Given s ∈ S and a motion primitive set UM with duration τ , ﬁnd the states R(s) that are reachable from s in one step and their associated costs C(s).

1: function GETSUCCESSORS(s, UM , τ )

2: R(s) ← ∅, C(s) ← ∅

3: for all um ∈ UM do

4:

em(t) ← F (t)s + G(t)um, t ∈ [0, τ ]

5:

if em(t) ⊂ X free then

6:

sm ← em(τ )

7:

R(s) ← R(s) ∪ {sm}

8:

C(s) ← C(s) ∪ { um 2 + ρ τ }

9: return R(s), C(s)

We use Algorithm 1 to explore the free state space X free and build the connected graph: in line 4, the primitive is calculated using the fully deﬁned state s and a control input um given the constant time τ ; line 5 checks the feasibility of the primitive, this step will be further discussed in Section. III-E; in line 6, we evaluate the end state of a valid primitive and add it to the set of successors of the current node; in the meanwhile, we estimate the edge cost from the corresponding primitive. After checking through all the primitives in the ﬁnite control input set, we add the nodes in successor set R(s) to the graph, and we continue expanding until we reach the goal region.

(a) Discretized Acceleration. (b) Discretized Jerk.
Fig. 3: Example of 9 planar motion primitives from initial state x0 for an acceleration-controlled (n = 2) system (left) and a jerk-controlled (n = 3) system (right). The black arrow indicates correpsonding control input. The red boundary shows the feasible region for the end states (red squares), which is induced by the control limit umax. The initial velocity and acceleration are v0 = [1, 0, 0]T and a0 = [0, 1, 0]T (only for the right ﬁgure).
ﬁxed, the cost of the motion primitive according to Eq. (4) is um 2 + ρ τ
B. Induced Space Discretization
Proposition 1. The motion primitives deﬁned in the previous section induce a discretization on the state space X .
Proof. See App. A.
This discretization of the state space allows us to construct a graph representation of the reachable system states by starting at x0 and applying all primitives to obtain the M possible states after a duration of τ (see Fig. 3 and Alg. 1). Applying all possible primitives to each of the M states again, will result in M 2 possible states at time 2τ . Since the free space X free is bounded and discretized, the set of reachable states S is ﬁnite.
This deﬁnes a graph G(S, E), where S is the discrete set of reachable system states and E is the set of edges that connect states in the graph, each deﬁned by a motion primitive e := (um, τ ). Let s0 be the state corresponding to x0.

Proposition 2. The motion primitive uij ∈ UM which connects two consecutive states si, sj ∈ S with sj = F (τ )si + G(τ )uij is optimal according to the cost function in Eq. (4).
Proof. See App. B.

C. Deterministic Shortest Trajectory
Given the set of motion primitives UM and the induced space discretization discussed in the previous section, we can re-formulate Problem 1 as a graph-search problem. This can be done by introducing additional constraints that stipulate that the control input u(t) in Eq.(4) is piecewise-constant over intervals of duration τ . More precisely, we introduce an additional variable N ∈ Z+, such that T = N τ , and uk ∈ UM for k = 0, . . . , N − 1 and a constraint in Eq. (4):

N −1

u(t) =

uk1{t∈[kτ,(k+1)τ )}

k=0

that forces the control trajectory to be a composition of the motion primitives in UM . This leads to the following deterministic shortest path problem [18, Ch.2].
Problem 2. Given an initial state x0 ∈ X free, a goal region X goal ⊂ X free, and a ﬁnite set of motion primitives UM with duration τ > 0, choose a sequence of motion primitives

2874

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

u0:N−1 of length N such that:

N −1

min
N ,u0:N −1

uk 2 + ρN τ
k=0

s.t. xk(t˜) = F (t˜)sk + G(t˜)uk ⊂ X free, t˜ ∈ [0, τ ]

xk(t˜) ⊂ X free ∀ k ∈ {0, . . . , N − 1}, t˜ ∈ [0, τ ] (5)

sk+1 = xk(τ ), ∀ k ∈ {0, . . . , N − 1}

s0 = x0, sN ∈ X goal

uk ∈ UM , ∀ k ∈ {0, . . . , N − 1}

The optimal cost of Problem 2 is an upper bound to the optimal cost of Problem 1 because Problem 2 is just a constrained version of Problem 1. However, this reformulation to discrete control and state-spaces enables an efﬁcient solution. Such problems can be solved via searchbased [23], [19] or sampling-based [20], [21], [24] motion planning algorithms. Since only the former guarantees ﬁnitetime (sub-)optimality, we use an A∗ method and focus on the design of an accurate, consistent heuristic and efﬁcient, guaranteed collision checking methods in following subsections.

D. Heuristic Function Design

Devising an efﬁcient graph search for solving Problem 2

requires an approximation of the optimal cost function, i.e., a heuristic function, that is admissible1, informative (i.e.,

provides a tight approximation of the optimal cost), and consistent2 (i.e., can be inﬂated in order to obtain solutions

with bounded suboptimality very efﬁciently [19]). Since by

construction, the optimal cost of Problem 2 is bounded below

by the optimal cost of Problem 1, we can obtain a good

heuristic function by solving a relaxed version of Problem 1.

Our idea is to replace constraints in Eq. (4) that are difﬁcult to satisfy, namely, x(t) ∈ X free and u(t) ∈ U , with a

constraint on the time T . In this section, we show that

such a relaxation of Problem 1 can be solved optimally and

efﬁciently.

1) Minimum Time Heuristic: Intuitively, the constraints
on maximum velocity, acceleration, jerk, etc. due to X obs and U induce a lower bound T¯ on the minimum achievable time

in (4). For example, since the system’s maximum velocity

is bounded by vmax along each axis, the minimum time for

reaching the closest state xf in the goal region X goal is

bounded below by T¯v :=

. pf −p0 ∞
vmax

Similarly,

since

the

system’s maximum acceleration is bounded by amax, the

state xf := [pTf , vfT]T cannot be reached faster than:

min
T¯a ,a(t)

T¯a

s.t. a(t) ≤ amax, ∀ t ∈ [0, T ]

p(0) = p0, v(0) = v0 p(T¯a) = pf , v(T¯a) = vf

1A heuristic function h is admissible if it underestimates the optimal cost-to-go from x0, i.e., 0 ≤ h(x0) ≤ C∗ x0, X goal , ∀x0 ∈ X .
2A heuristic function h is consistent if it satisﬁes the triangle inequality, i.e., h(x0) ≤ C∗(x0, {x1}) + h(x1), ∀x0, x1 ∈ X .

The above is a minimum-time (Brachistochrone) optimal
control problem with input constraints, which may be dif-
ﬁcult to solve directly in 3-D [25] but can be solved
in closed-form along individual axes [17, Ch.5] to obtain lower bounds T¯ax, T¯ay, T¯az. This procedure can be continued for the constraint on jerk jmax and those on higher-order
derivatives but the problems become more complicated to
solve and the computed times are less likely to provide
better bounds the previous ones. Hence, we can deﬁne a lower bound on the minimum achievable time via T¯ := max{T¯v, T¯ax, T¯ay, T¯az, T¯j, . . .} but for simplicity we use the easily computable but less tight bound T¯ = T¯v.
Hence, to ﬁnd a heuristic function, we relax Problem 1 by replacing the state and input constraints, x(t) ∈ X free and u(t) ∈ U , with the lower bound T ≥ T¯v:

min J(D) + ρT
D,T

s.t. x˙ (t) = Ax(t) + Bu(t), ∀t ∈ [0, T ]

(6)

x(0) = x0, x(T ) ∈ X goal

T ≥ T¯

Since J(D) ≥ 0, a straight-forward way to obtain a lowerbound on the optimal cost is:
C∗ x0, X goal = J (D∗) + ρT ∗ ≥ ρT¯v

Hence, given nodes s0, sf ∈ S in the discretized space, the following is an admissible heuristic function:

h1(s0) = ρT¯v

=

ρ

pf − p0 vmax

∞

(7)

for Problem 2. It is easy to see that it is also consistent due to the triangle inequality for distances.
2) Linear Quadratic Minimum Time: While the minimum-time heuristic is very easy to compute and takes velocity constraints into account, it is not a very tight lower bound on the optimal cost in Eq. (5) because it disregards the control effort. The reason is that instead of solving Eq. (6), we simply found a lower bound in the previous subsection. An important observation is that after removing the constraints x(t) ∈ X free and u(t) ∈ U , the relaxed problem Eq. (6) is in fact the classical Linear Quadratic Minimum-Time Problem [16]. The optimal solution to Eq. (6) can be obtained from [16, Thm.2.1] with a minor modiﬁcation introducing the additional constraint on time T ≥ T¯.

Proposition 3. Let xf ∈ X goal be a ﬁxed ﬁnal state and

deﬁne δT := xf − eAT x0 and the controllability Gramian

WT Eq.

:= (6)

T 0

eAtBBTeATtdt.

is either the lower

Then, the bound T¯

optimal time T or the solution

in of

following equation:

d −
dT

δTT WT−1δT

= 2xTf ATWT−1δT + δTTWT−1BBTWT−1δT = ρ (8)

The optimal control is:

u∗(t) := BTeAT(T −t)WT−1δT

(9)

2875

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

While the optimal cost is:

h2(x0) = δTTWT−1δT + ρT

(10)

The polynomial coefﬁcients D ∈ R3×(2n) in Eq. (1) are:

d0:(n−1) = x0,

dn:(2n−1) = δTT WT−TeAT H T

where H ∈ R(3n)×(3n) with Hij =

(−1)j , 0,

i=j .
i=j

Thus, the optimal cost h2(x0) obtained in Prop. 3 is a better heuristic for Problem 2 than h1 because h2 takes the control efforts into account. It is also admissible by construction because the optimal cost of Problem 2 is lower

bounded by the optimal cost of Problem 1, which in turn is lower bounded by h2(x0). Below, we give examples of the results in Prop. 3 for several practical cases with a given T .
a) Velocity Control: Let n = 1 so that X ⊂ R3 is position space and U is velocity space. Then, the optimal
solution to Eq. (6) according to Prop. 3 is:

1 d1 = T (pf − p0)

x∗(t) = d1t + p0, u∗(t) = d1

C∗ = 1 T

pf − p0

2 + ρT

b) Acceleration Control: Let n = 2 so that X ⊂ R6 is position-velocity space and U is acceleration space. Then, the optimal solution to Eq. (6) according to Prop. 3 is:

d3 d2

=

−

12 T3

6

T2

6

T2

−

2 T

pf − p0 − v0T vf − v0

x∗(t) =

d3 6

t3

+

d2 2

t2

+

v0t

+

x0

d3 2

t2

+

d2t

+

v0

, u∗(t) = d3t + d2

C∗ =

12

pf − p0 T3

2

−

12(v0

+

vf ) · T2

(pf

−

p0) +

4( v0

2 + v0 · v1 +

v1

2) + ρT

T

Here the optimal cost C∗ turns out to be a polynomial

function of T , we are able to derive the optimal T ∗ by

minimizing C∗(T ) as

T ∗ = arg min C∗(T )
T
s.t. T ≥ T¯

the solution of which is the positive real root of C∗(T ) = 0. Furthermore, the optimal cost is C∗ = C∗(T ∗).

E. Collision Checking
For a calculated edge e(t) = [p(t)T, v(t)T, a(t)T, ...]T in Alg. 1, we need to check if e(t) ⊂ X free for t ∈ [0, τ ]. We check collisions in the geometric space Pfree ⊂ R3 separately from enforcing the dynamic constraints Dfree ⊂ R3(n−1). The edge e(t) is valid only if its geometric shape p(t) ⊂ Pfree and derivatives (v(t), a(t), ...) ⊂ Dfree, i.e.,

v ∞ ≤ vmax, ∀t ∈ [0, τ ] (v, a, ...) ⊂ Dfree ⇔ a ∞ ≤ amax, ∀t ∈ [0, τ ] (11)
...

Since the derivatives v, a, ... are polynomials, we calculate their extrema within the time period [0, τ ] to compare with maximum bounds on velocity, acceleration, etc. For n ≤ 3, the order of these polynomials is less than 5, which means we can easily solve for the extrema in closed form.
The more challenging part is checking collisions in Pfree. In this work, we model P as an Occupancy Grid Map. Other representations such as a Polyhedral Map are also possible but these are usually hard to obtain from real-world sensor data [9], [26] and out of the scope of the discussion in this paper. Let P := {p(ti) | ti ∈ [0, τ ], i = 0, . . . , I} be a set of positions that the system traverses along the trajectory p(t). To ensure a collision-free trajectory, we just need to show that p(ti) ∈ Pfree for all i ∈ {0, . . . , I}. Given a polynomial p(t), t ∈ [0, τ ], the positions p(ti) are sampled by deﬁning:

i

τ

ti

:=

τ I

such that

I vmax ≥ R.

(12)

Here R is the occupancy grid resolution. The condition ensures that the maximum distance between two consecutive samples will not exceed the map resolution. It is an approximation, since it can miss cells that are traversed by p(t) with a portion of the curve within the cell shorter than R, but it prevents the trajectory from hitting obstacles.

IV. TRAJECTORY REFINEMENT
A trapezoid velocity proﬁle is widely used to describe the robot following a path, in which the robot is assumed to move as a particle that exactly tracks the path with deﬁned velocity function. This model gives the so-called time allocation for a large group of trajectory optimization approaches described in [1], [8], [9], [10] and [11]. However, this approximation is naive and the resulting trajectory signiﬁcantly deforms from the given path since the modeled particle is not obeying the expected dynamics.
In above section, we proposed the complete solution for planning a trajectory that is valid in control space. The resulting trajectory gives not only the collision-free path, but also the time for reaching those waypoints. Thus, we are able to use it as a prior to generate a smoother trajectory in higher dimension for controlling the actual robot. The reﬁned trajectory x∗(t) is derived from solving an unconstrained QP with given initial and end states s0, sg and the intermediate waypoints pk, k ∈ {0, . . . , N − 1}.

N −1
min
D k=0

τk 0

p(Dnk)(t)

2
dt

s.t. x0(0) = s0, xN−1(τN−1) = sg

(13)

xk+1(0) = xk(τk), k ∈ {0, . . . , N − 2}

pDk(τk) = pk, k ∈ {0, . . . , N − 1}

The time for each trajectory segment τk is also given from the prior trajectory. The solution for Eq. (13) is proposed in [1]. We ignore the mathematical details in this section and only show the trajectory reﬁnement results in Fig. 4.

2876

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

(a) T = 8.5.

(b) T = 8.5, J = 296.6.

to solve for the real roots of a polynomial, but it reveals the lower bound of the cost regarding system’s dynamics and thus it is a tighter underestimation of the actual cost. Here we compare the performance of the algorithm with respect to the two heuristics h1, h2. As a reference, by setting the heuristic function to zero changes the algorithm into Dijkstra search. Fig. 5 visualizes the expanded nodes while searching towards the goal from a state with initial velocity 3m/s in positive vertical direction.

(a) Dijkstra. Tp = (b) A∗ with h1. Tp = (c) A∗ with h2. Tp = 0.16s, Np = 2707 0.064s, Np = 1282 0.016s, Np = 376

(c) T = 10, J = 14.0.

(d) T = 10, J = 21.3.

Fig. 5: Generated trajectories using different heuristics. The expanded nodes (small dots) are colored by the corresponding cost value of the heuristic function. Grey nodes have zero heuristic value, high cost nodes are colored red while low cost nodes are colored green. Tp and Np shows the time for planning and number of expanded nodes respectively.

(e) T = 12, J = 11.3.

(f) T = 12, J = 13.6.

Fig. 4: Trajectories planned from start s to goal g with initial velocity (4m/s). The blue/green lines show the speed/acceleration along trajectories respectively and the red points are the intermediate waypoints. (a) shows the shortest path. The time is allocated using the trapezoid velocity proﬁle for generating min-jerk trajectory in (b). The resulting trajectory has a large cost for efforts J. (c) shows the trajectory planned using acceleration-controlled system. In this case, the acceleration is not continuous. In (d), we reﬁne using a min-jerk trajectory which has continuous and smooth acceleration. (e) shows the trajectory planned using jerk-controlled system. The acceleration is continuous but not smooth. In (f), the reﬁned minjerk trajectory has continuous and smooth acceleration.

We can see that the Minimum Cost Heuristic h2 makes the searching faster as it expands less nodes without loss of optimality. However, when it comes to the system with higher dimension, calculating h2 becomes harder as one can not analytically ﬁnd the roots for a polynomial with order greater than 4. As claimed in Sec. III-D, when the maximum velocity is low, h1 is efﬁcient enough for any dynamic system.
B. Run Time Analysis
To evaluate the computational efﬁciency of the algorithm, we record the run time of generating hundreds of trajectories (Fig. 6) using either acceleration-controlled or jerk-controlled system in both 2-D and 3-D environments. Table I shows the time it takes for each system. We can see that planning in 3-D takes more time than in 2-D; also, planning in jerk space is much slower (10 times) than in acceleration space.

It needs to be notiﬁed that even though the reﬁnement step produces a smoother trajectory, the reﬁned trajectory might be unsafe and infeasible.
V. EXPERIMENTAL RESULTS
A. Heuristic Function
We proposed two different heuristics in Sec. III-D: denote the ﬁrst one that estimates the minimum time using the max speed constraint as h1; denote the other one estimates the minimum cost function using the dynamic constraints as h2. The heuristic h1 is easier to compute, but it fails to take in to account of the system’s dynamics; the heuristic h2 requires

(a) 2-D Planning.

(b) 3-D Planning.

Fig. 6: Trajectories generated to sampled goals (small red balls). For 2-D case, we use 9 primitives while for 3-D case, the number is 27.

2877

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

TABLE I: Trajectory Generation Run Time

Map Time(s) Accel-controlled Jerk-controlled

Avg

0.016

0.147

2-D Std

0.015

0.282

Max

0.086

2.13

Avg

0.094

2.98

3-D Std

0.155

3.78

Max

0.515

9.50

C. Re-planning and Comparisons
Receding Horizon Control (RHC) has been widely used for navigating an aerial vehicle in unknown environments [27], the frequently re-planning process allows the robot to keep moving with limited sensing range until it reaches the goal region. In this section, we show results of our navigation system that builds on the RHC framework with the proposed trajectory generation method. As a comparison, we also set up the system that utilizes the prior planned path as the guide for trajectory generation. To demonstrate the fully autonomous collision avoidance on a quadrotor, we use the AscTec Pelican platform with a Hokuyo laser range-ﬁnder. We run state estimation and obstacle detection (mapping) as described in [28] on an onboard Intel NUC-i7 computer. Fig. 7 shows the performance of using these two approaches to avoid an obstacle by re-planning at the circle position where the desired speed is non-zero. The traditional pathbased approach in Fig. 7(b) leads to a sharp turn while our approach generates a smoother trajectory shown in Fig. 7(c).
Fig. 8 shows the results in simulation where we set up a longer obstacle-cluttered corridor for testing. The re-planning is triggered constantly at 3Hz and the maximum speed is set to be 3m/s. Our method generates a better overall trajectory compared to the traditional method as it avoids sharp turns when avoiding obstacles.

(a) Experiment environment.
(b) Re-plan with path-based approach.
(c) Re-plan with our method. Fig. 7: Pelican experiments using different trajectory generation pipelines. The robot is initially following a trajectory (blue curve) and needs to re-plan at the end of this prior trajectory (circled) to go to the goal (red triangle). The state from which the robot re-plans is non-static and the speed is 2m/s in positive vertical direction. (b) shows the result of using traditional path-based trajectory generation method, the shortest path (purple line segments in the left ﬁgure) leads to the ﬁnal trajectory (yellow curve in the righ ﬁgure); (c) shows the result of using our trajectory generation method, the shortest trajectory (purple curve in the left ﬁgure) leads to the smoother ﬁnal trajectory (yellow curve in the righ ﬁgure).

VI. CONCLUSION
Search-based planning is well-known to be inefﬁcient for high dimensional planning due to the large number of nodes to expand. Even though lattice search techniques with motion primitives have been explored for ground vehicles, it is still a hard problem to consider the system’s dynamics in planning phase. Using ideas from optimal control, we propose a solution that plan optimal trajectories in high dimensional spaces within a reasonable time. The experimental results reveal the success of using it as the foundation for a safe and fast navigation system for a quadrotor. The deterministic optimal trajectory helps in reducing errors in state estimation and control, saving system energy and making robot’s motion predictable. We believe the basic approach proposed in this paper is valuable for planning optimal trajectories for any system that is differential ﬂat, moreover, this generic framework can be integrated with other path planning technique like sampling-based methods to generate trajectories.
APPENDIX A
Proof of Prop. 1. Given an initial state x0 and a sequence of k inputs, u1, . . . , uk, are applied each for time τ . The ﬁnal

(a) Simulation Environment.

(b) Path-based approach.

(c) Our method.

Fig. 8: Re-planning with RHC in simulation using different trajecotry generation pipelines. The robot starts from the left (circled) and the goal is at the right side of the map (red triangle). Blue curves show the traversed trajectory. (b) shows the re-planning processes using traditional path-based trajectory generation method. (c) shows the re-planning processes using proposed method in this paper. We can see that the overall trajectories in (c) is smoother than in (b).

2878

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

state after applying the k inputs is given by,

[5] J. Jamieson and J. Biggs, “Near minimum-time trajectories for

k−1
x(kτ ) = F k(τ )x0 + F i(τ )G(τ )uk−i

i=0

  I3 kτ I3 ···

(kτ )n−1 (n−1)!

I3

quadrotor uavs in complex environments,” in IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), 2016, pp. 1550–1555. [6] D. Mellinger, A. Kushleyev, and V. Kumar, “Mixed-integer quadratic program trajectory generation for heterogeneous quadrotor teams,” in Proceedings of the 2012 IEEE International Conference on Robotics and Automation (ICRA), 2012.

F

k (τ

)

=

   

0
...

I3
...

 ···

(kτ )n−2 (n−2)!

I3



...

...

 

0 ··· I3 kτ I3

0 ··· 0

I3



[(i+1)n −in ]

τn n!

I3



 [ ]  (i+1)n−1−in−1

τ n−1 (n−1)!

I3

F

i(τ

)G(τ

)

=

 



...

  



[ ] (i+1)2−i2

τ2 2!

I3



τ I3

Our discretized inputs are of the form ui = duκi where

[7] R. Deits and R. Tedrake, “Efﬁcient mixed-integer planning for uavs in cluttered environments,” in Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), 2015.
[8] C. Richter, A. Bry, and N. Roy, “Polynomial trajectory planning for aggressive quadrotor ﬂight in dense indoor environments,” in Robotics Research. Springer, 2016, pp. 649–666.
[9] S. Liu, M. Watterson, S. Tang, and V. Kumar, “High speed navigation for quadrotors with limited onboard sensing,” in 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2016.
[10] S. Liu, M. Watterson, K. Mohta, K. Sun, S. Bhattacharya, C. J. Taylor, and V. Kumar, “Planning dynamically feasible trajectories for quadrotors using safe ﬂight corridors in 3-d complex environments,” IEEE Robotics and Automation Letters, vol. 2, no. 3, pp. 1688–1695, July 2017.

κ ∈ Z3 leading to x(kτ ) being of the form



x(kτ

)

=

F

k (τ

)x0

+

 

(



( ) k−1 i=0

[(i+1)n

−in

]κk−i

du

τn n!



k−1
[ ] )  i=0

(i+1)n−1 −in−1

κk−i

du

τ n−1 (n−1)!

...

 

( ) k−1 i=0

κk−i

du τ

[11] J. Chen, T. Liu, and S. Shen, “Online generation of collision-free trajectories for quadrotor ﬂight in unknown cluttered environments,” in 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2016, pp. 1476–1483.
[12] M. Likhachev and D. Ferguson, “Planning long dynamically feasible maneuvers for autonomous vehicles,” The International Journal of Robotics Research, vol. 28, no. 8, pp. 933–945, 2009.
[13] B. MacAllister, J. Butzke, A. Kushleyev, H. Pandey, and M. Likhachev,

Thus we can see that each term in the expression for x(kτ ) is a variable integer times a constant which means that our state

“Path planning for non-circular micro aerial vehicles in constrained environments,” in Robotics and Automation (ICRA), 2013 IEEE International Conference on. IEEE, 2013, pp. 3933–3940.

space is discretized due to discretization of the inputs.

[14] M. Pivtoraiko, D. Mellinger, and V. Kumar, “Incremental microuav motion replanning for exploring unknown environments,” in

APPENDIX B

Proceedings of the 2013 IEEE International Conference on Robotics and Automation (ICRA), 2013, pp. 2452–2458.

Proof of Prop. 2. Since the trajectory connecting si and sj is collision-free by construction of the graph G (see Alg. 1), the optimal control from si to sj according to the cost

[15] D. W. Mellinger, “Trajectory generation and control for quadrotors,” Ph.D. dissertation, University of Pennsylvania, 2012.
[16] E. Verriest and F. Lewis, “On the linear quadratic minimum-time problem,” IEEE Transactions on Automatic Control, vol. 36, no. 7,

function in (4) has the form prescribed by Prop. 3. In detail

pp. 859–863, 1991.

[17] F. Lewis and V. Syrmos, Optimal control. John Wiley & Sons, 1995.

δτ = sj − F (τ )si = G(τ )uij

[18] D. Bertsekas, Dynamic Programming and Optimal Control. Athena Scientiﬁc, 1995.

and the optimal control is:

[19] M. Likhachev, G. Gordon, and S. Thrun, “ARA* : Anytime A* with Provable Bounds on Sub-Optimality,” in Advances in Neural

u∗(t) = BTeAT(τ−t)Wτ δτ

Information Processing Systems, 2004, pp. 767–774. [20] S. M. Lavalle, “Rapidly-exploring random trees: A new tool for path

τ

−1 τ

planning,” Tech. Rep., 1998.

= BTeAT(τ −t)

eAsBBTeATsds
0

0

eAsdsBuij

[21]

S. Karaman and E. Frazzoli, “Sampling-based algorithms for optimal motion planning,” The International Journal of Robotics Research,

vol. 30, no. 7, pp. 846–894, 2011.

Since only the bottom 3 × 3 block of B is non-zero and [22] M. Pivtoraiko, R. A. Knepper, and A. Kelly, “Differentially constrained

since the matrix eAT(τ−t)

τ 0

eAsBBTeATsds

−1

τ 0

eAsds

mobile robot motion planning in state lattices,” Journal of Field Robotics, vol. 26, no. 3, pp. 308–333, 2009.

has its bottom-right 3 × 3 block equal to I3×3, we get:

BTeAT(τ −t)

τ

−1 τ

eAsBBTeATsds

eAsdsB = I3×3

0

0

[23] P. E. Hart, N. J. Nilsson, and B. Raphael, “A formal basis for the heuristic determination of minimum cost paths,” IEEE Transactions on Systems Science and Cybernetics, vol. 4, no. 2, pp. 100–107, 1968.
[24] O. Arslan and P. Tsiotras, “Use of relaxation methods in samplingbased algorithms for optimal motion planning,” in IEEE Int. Conf. on

which implies that u∗(t) ≡ uij.

Robotics and Automation (ICRA). IEEE, 2013, pp. 2421–2428. [25] D. Feng and B. Krogh, “Acceleration-constrained time-optimal control

REFERENCES

in n dimensions,” IEEE Transactions on Automatic Control, vol. 31, no. 10, pp. 955–958, 1986.

[1] D. Mellinger and V. Kumar, “Minimum snap trajectory generation and control for quadrotors,” in Proceedings of the 2011 IEEE International Conference on Robotics and Automation (ICRA), 2011.
[2] M. Hehn and R. D’Andrea, “Quadrocopter trajectory generation and control,” IFAC Proceedings Volumes, vol. 44, no. 1, 2011.
[3] M. Mueller, M. Hehn, and R. D’Andrea, “A computationally efﬁcient motion primitive for quadrocopter trajectory generation,” IEEE Trans. on Robotics (T-RO), vol. 31, no. 6, pp. 1294–1310, 2015.
[4] Y. Bouktir, M. Haddad, and T. Chettibi, “Trajectory planning for a

[26] R. Deits and R. Tedrake, “Computing large convex regions of obstaclefree space through semideﬁnite programming,” in Algorithmic Foundations of Robotics XI. Springer, 2015, pp. 109–124.
[27] J. Bellingham, A. Richards, and J. P. How, “Receding horizon control of autonomous aerial vehicles,” in Proceedings of the 2002 American Control Conference (ACC), vol. 5, 2002, pp. 3741–3746.
[28] S. Shen, N. Michael, and V. Kumar, “Autonomous indoor 3d exploration with a micro-aerial vehicle,” in IEEE International Conference on Robotics and Automation (ICRA), May 2012, pp. 9–15.

quadrotor helicopter,” in 16th Mediterranean Conference on Control

and Automation, 2008.

2879

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on June 08,2022 at 09:54:08 UTC from IEEE Xplore. Restrictions apply.

