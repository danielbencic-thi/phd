ADVANCES IN APPLIED MATHFMATICS 4,298-35 1 ( 1983)
On the “Piano Movers” Problem. II. General Techniques for Computing Topological
Properties of Real Algebraic Manifolds*
JACOBT. SCHWARTZ
Computer Science Department, Courant Institute of Mathematical Sciences,New York University, New York New York 10003
AND
MICHA SHARIR
Department of Mathematical Sciences, Tel Aviv Universily, Tel Aviv, Israel
This paper continues the discussion, begun in J. Schwartz and M. Sharir [ Comm. Pure Appl. Math., in press], of the following problem, which arises in robotics: Given a collection of bodies B, which may be hinged, i.e., may allow internal motion around various joints, and given a region bounded by a collection of polyhedral or other simple walls, decide whether or not there exists a continuous motion connecting two given positions and orientations of the whole collection of bodies. We show that this problem can be handled by appropriate refinements of methods introduced by A. Tarski [“A Decision Method for Elementary Algebra and Geometry,” 2nd ed., Univ. of Calif. Press, Berkeley, 19511 and G. Collins [in “Second GI Conference on Automata Theory and Formal Languages,” Lecture Notes in Computer Science, Vol. 33, pp. 134-183, Springer-Verlag, Berlin, 19751, which lead to algorithms for this problem which are polynomial in the geometric complexity of the problem for each fixed number of degrees of freedom (but exponential in the number of degrees of freedom). Our method, which is also related to a technique outlined by J. Reif [in “Proceedings, 20th Symposium on the Foundations of Computer Science,” pp. 421-427, 19791, also gives a general (but not polynomial time) procedure for calculating all of the homology groups of an arbitrary real algebraic variety. Various algorithmic issues concerning computations with algebraic numbers, which are required in the algorithms presented in this paper, are also reviewed.
*Work on this paper has been supported in part by the Office of Naval Research Contract NOOOl4-75-C-0571; work by the second author has also been supported in part by the Bat-Sheva Fund of Israel.
298 0196-8858,‘83 $7.50
Copyright 0 1983 by Academic Press. Inc. All rights of reproduction in any form reserved.

THE “PIANO MOVERS” PROBLEM

299

0. INTRODUCTION

The “Piano Movers” problem (see [l-5]) is that of finding a continuous motion which will take a given body or bodies B from a given initial position to a desired final position, but which is subject to certain geometric constraints during the motion. These constraints forbid the bodies to come in contact with certain obstacles or “walls,” or to collide with each other. These walls can be curved, and the full collection of walls is not required to be connected (see Fig. 1). The problem that we set out to solve is: Given two configurations (i.e., positions and orientations of all subparts) of the bodies B in which none of these bodies touches any walls, and in which none of the bodies B collide, find a continuous wall- and collision-avoiding motion of all the B between these two configurations, or establish that no such motion exists.
This paper will present a general, though not very efficient, method for deciding on the existence of such a path (and for constructing such a path if its exists). Specifically, we will show that this problem can be handled by a variant of Tarski’s famous algorithm [6] for deciding statements in the quantified elementary theory of real numbers. Our approach is related to that outlined in an interesting paper of Reif [l], and makes essential use of technical devices introduced by Collins [7] and reviewed by Amon [S]. As we shall see, these techniques also allow explicit, constructive calculation of

FIG. 1. An instanceof our caseof the “piano movers” problem.The positions drawn in full are the initial and final positions of B; the intermediatedotted positions describe a possible motion of B between the initial and final positions.

300

SCHWARTZ AND SHARIR

the homology groups of an arbitrary real algebraic variety. In particular, the connectivity of such a variety can be calculated easily.
The paper is organized as follows. In Section 1 we begin to formulate the general mover’s problem in which we are interested, as an abstract computational problem in algebraic topology. The algebraic machinery required to handle this problem is then developed in Section 2. The results obtained in this section can be used to calculate topological properties of algebraic varieties more general than those required for the solution of the mover’s problem, and Section 2 also outlines some procedures for these calculations. Applications of the general theory of Section 2 to the mover’s problem are then given in Section 3, yielding an algorithm which solves this problem in time polynomial in the number of geometric constraints on the motion of the body B, provided that the set of forbidden configurations for the body B is closed.
For the sake of completeness and clarity, we include a simple proof of the Collins construction on which our algorithms are based. This is given in Appendix A. Appendix B reviews various efficient techniques, some new, for exact calculations with algebraic numbers; such calculations appear repeatedly in our algorithms. Finally, Appendix C gives a technical details concerning the computations required to obtain the topological structure of the Collins decomposition. Note, however, that these, possibly very expensive, computations are not required for the simpler task of determining the connectivity of the space of free configurations of the body B.

1. AN ALGEBRAIC FORMULATION OF THE GENERAL MOVER’S PROBLEM
In this section we reformulate the general motion-planning problem in abstract algebraic terms, and reduce it to the problem of decomposing certain algebraic varieties into their connected components. A solution to this abstract problem is then developed in subsequent sections.
Like Reif, whose work is to be presented more fully in a forthcoming paper, we study the space of all collision-free positions of one or more hinged bodies B. We assume each body B to consist of a finite number of rigid compact subparts B,, B,,. . . , each bounded by various algebraic surfaces. These subparts can be connected to each other by various types of attachments, including the following:
(a) A point X on one part B, can be fastened to a point Y on another part B2, in a manner which requires X and Y to be coincident but does not otherwise constrain the relative orientations of B, and B,.

THE “PIANO

MOVERS”

PROBLEM

301

(b) The connection between X on B, and Y on B, can be a “hinge,” i.e., can constrain B, to revolve around an axis V fixed in the frame of B,.
(c) The connection between B, and B, can permit B, to slide, or to slide and rotate, along an axis I/ fixed in the frame of B,.
Various other forms of affixment might be envisaged and can be treated in much the same way that we will treat the more common fastenings (a-c). As noted above, we are willing to consider any number of disjoint hinged bodies of this kind, which are to move in a coordinated fashion throughout an empty space bounded by a finite collection of walls, which can themselves be arbitrary algebraic surfaces. We can regard the walls as part of the given system of bodies, with the additional properties that (a) they need not be compact; and (b) they are constrained not to move at all.
Since we intend to proceed algebraically in what follows, our first task is to set up an appropriate algebraic parametrization of a superspace of the set of all allowed positions of the hinged body B. It is convenient to proceed as follows. The rotation group is a smooth 3-dimensional algebraic submanifold of the 9-dimensional Euclidean space of 3 by 3 real matrices. If B = B, is a single rigid body, we describe its position by giving a Euclidean motion T which takes B from some standard position to its given position. This transformation TX = Ru + X0 is defined by a pair [X0, R] consisting of a point X0 in 3-dimensional Euclidean space E3 and of a 3 by 3 rotation matrix R, and can therefore be regarded as a point in a smooth six-dimensional algebraic submanifold G of 12-dimensional Euclidean space E12.
Next suppose that B is hinged, and that a second part B2 of B is attached to B,, say for the sake of definiteness in the manner (a). Then we can describe the overall position of the two parts B,, B, of B as follows. As above, the position of B, is described by a Euclidean motion T which takes B, from a standard position to its actual position. By applying the inverse T-’ of T to both B, and B,, we put B, into its standard position, and B, into a position which attaches a fixed one of its points X2 to a point fixed on B,. This position of B2 is therefore defined by giving a Euclidean transformation T2 such that T2X2 = X2. It is plain that the set of these transformations is in l- 1 correspondence with the set of rotation matrices R,. Hence the overall position of B, and B, can be represented by a pair [T, R2], which once again varies over a smooth algebraic submanifold G, of a higherdimensional Euclidean space E.
If instead B, is connected to B, in the manner (b), then much the same remarks apply, except that in this case the rotation matrix R, must satisfy R,V = V for a certain 3-dimensional vector V. If B, can slide along an axis U fixed in B, but not rotate, its position is defined by a single real parameter u which defines the position of B2 along this axis, etc. In all cases, the overall position of B, and B2 is described by a pair [T,, T2] of Euclidean

302

SCHWARTZ AND SHARIR

motions, the first unconstrained, the second confined to some subgroup of the full Euclidean group. In all cases the allowed pairs form a smooth algebraic submanifold G, of some Euclidean space.
We can proceed similarly even if B consists of many parts hinged together in various ways. Suppose, for example, that B2 is connected to B, , and that a third part B, of B is connected to B,. Then as above the overall position of B, and B2 is defined by a pair [T,, T2] of Euclidean transformations. T, maps B, from its standard to its actual position, and T,T, maps B2 from its standard to its actual position. If we apply the inverse of T,T, to B,, we put it into a position in which it is attached to a fixed point or axis of B, in one of the manners (a-c). Hence the actual position of B3 is defined by a third Euclidean transformation T3, belonging to a group of motions of one of the types we have already considered, and the mapping T,T2T3 takes B, from its standard to its actual position.
These considerations make it clear that, irrespective of the manner in which the parts of a hinged body are connected together, the overall position of all its parts can always be defined by a point belonging to a smooth algebraic manifold G lying in a Euclidean space of some appropriate dimension.
Of course, the preceding considerations ignore all restrictions on the position of the parts of the bodies B imposed by the condition that none of these parts must collide. This point will be handled in Section 3 below, after the necessary algebraic machinery is introduced and developed in Section 2, which now follows.

2. TARSKI SENTENCER AND SETS; THE COLLINS DECOMPOSITION
By a Tut-ski sentence we mean a sentence, possibly containing free variables, which can be formulated in the decidable quantified language studied by Tarski [6]. In this language, variables designate real numbers and are quantified over the set of all reals. The operators allowed in the language are +, -, *, and /, designating the usual real arithmetic operators. The allowed comparators are = , * , > , < , 2 , < , all of which have their standard meanings. In addition quantifiers and Boolean connectives are allowed.
A Tarski sentence Q(x,,..., x,) containing exactly n free variables defines a subset of n-dimensional Euclidean space E”, namely,

Ep = ([x,,. . . , x,1: Q(x,,. . . , x,)}.

(1)

Sets of this form will be called Tarski sets (also known as semi-algebraic

THE “PIANO MOVERS” PROBLEM

303

sets); the Q occurring in (1) is called the defining formuh of C,. By a result given in the cited paper of Tat-ski, every Tarski set has a quantifier-free defining formula. A useful constructive proof of this result, involving a penetrating analysis of the geometric structure of Tarski sets, is given by Collins [7] (see also Arnon [S]), and we will base our analysis of the general mover’s problem on Collins’ results, which substantially improve Tarski’s earlier work. We will also prove certain topological properties of the “cells” appearing in Collins’ work, and will use these topological improvements to show that many standard topological properties (i.e., all the homology groups) of any algebraic variety are effectively calculable.
Using terminology slightly different from ours, Collins gives the following definitions and theorems:

DEFINITION 1. For any subset X of Euclidean space, a decomposition of X is a finite collection K of disjoint connected subsets Y of X whose union is X. Such a decomposition is a Tarski decomposition if each such subset Y is a Tarski set.

In what follows, E’ will denote the Euclidean space of r dimensions.

DEFINITION 2. A cylindrical algebraic decomposition of E’ is defined as follows. For r = 1 such a decomposition is just a partitioning of E1 into a finite set of algebraic numbers and into the finite and infinite open intervals bounded by these numbers. For r > 1, a cylindrical algebraic decomposition of E’ is a decomposition K obtained recursively from some cylindrical algebraic decomposition K’ of E’- ’ as follows. Regard E’ as the Cartesian product of E’- ’ and E’, and accordingly represent each point p of E r as a pair [x, y] with x E E’- ’ and y E E’. Then K must be defined in terms of K’ and an auxiliary polynomial P = P(x, y) with rational coefficients, in the following way.

(i) For each c E K’, let c X E’ designate the cylinder over c, i.e., the set of all [x, y] such that x E c.
(ii) For each c E K’ there must exist an integer n, such that for each
x E c there are exactly n distinct real roots f,(x),. . . ,f,(x) of P(x, y)
(regarded as a polynomial in y), and these roots must vary continuously with x. We suppose in what follows that these roots have been enumerated in ascending order. Then each one of the cells of K which intersects c x E’ must have one of the following forms:

@.a) {Ix, ~1: x E c, Y <f,(x)>
(ii.b) {[x, J;(x)]: x E C}

(lower semi-infinite

“segment” of c X E’ ). (“section” of c X E’).

304

SCHWARTZ AND SHARIR

(ii.4 (Ix, rl: x E c,h<x> < Y <h+,(x)>

(“segment”

(ii.@{ix, rl: x E c,f,(x) < Y>
(upper semi-infinite “segment”

of c x E’). of c X E’).

All these cells are said to have c as their base cell in K’; K’ is said to be the base decomposition, and P the base polynomial, of K. It is convenient to put &(x) = - cc and f,+,(x) = + cc, and then to designate the cells (ii.a), (iib), (ii.c), and (ii.d) as co*,ci, CT, and cz, respectively.
It obviously follows by induction that each of the sets constituting a cylindrical algebraic decomposition K of E’ is topologically equivalent to an open cell of some dimension k G r. We will therefore refer to the elements c E K as the (open) Collins cells of the decomposition K.

DEFINITION

3. Let S be a set of functions of r variables, and K a

cylindrical algebraic decomposition of E ‘. Then K is said to be S-invariant

if, for each c in K and each f in S, one of the following conditions holds

uniformly for x E c: either

(a) f (x) = 0 for all x E c; or (b) f(x) -C 0 for all x E c; or (c)f(x) > 0 for all x E c.

DEFINITION 4. A point p E E’ is algebraic if each of its coordinates is a real algebraic number. A defining polynomial for p is a polynomial with rational coefficients whose set of roots includes all the coordinates of p.

THEOREM 1 (Collins). Given any finite set S of polynomials with rational coefficients in r variables, we can effectively construct an S-invariant cylindrical algebraic decomposition K of Er into Tarski sets such that each c E K contains an algebraic point. Moreover, defining polynomials for all these algebraic points, and quantifier-free defining formulae for each of the sets c E K, can also be constructed effectively.
The proof of Collins’ Theorem, which is not difficult, will be reviewed in Appendix A below. .
In what follows we will find it useful to sharpen Collins’ results in certain topological respects. For this, we have to impose an additional requirement on the decomposition; in certain unfavorable orientations of E’, this condition can be false. However, as we shall show below, one can always restore this extra property by an appropriate rotation of the r-Euclidean space, and such a rotation can be easily calculated. This requirement is stated in the following:

THE "PIANO MOVERS" PROBLEM

305

DEFINITION 5. A Collins decomposition K is said to be well-based if the following condition holds. Let K’ be the base decomposition and P(b, x) the base polynomial of K. Then we require that P(b, x) should not be identically zero for any b E E’- ‘. Moreover, we require that this same condition apply recursively to the base decomposition K’.
EXAMPLE. Consider the polynomial
P(x, y, z) = (x” + y2)z + (x2 - Y2)

in 3-dimensional space E3. Then, since P(O,O, z) vanishes identically, no P-invariant Collins decomposition of E3 whose final step projects E3 onto E * in the z-direction is well-based.
For the correctness of the topological assertions that we are about to make, it is essential that the decomposition K be well-based. Later we shall see how to rotate the given Euclidean space so as to make the decomposition well-based. For the moment we assume a well-based decomposition K, and show that it has certain useful topological properties.
LEMMA 1. Let c E K. Then the closure of c is a union of cells of K.
Proof To establish the lemma, we will use induction on the dimension r, and prove the following stronger
CLAIM. Let r 2 1, and let K be a Collins decomposition of E’. Then the closure of each cell in K is a union of cells of K. Moreover, for each cell c of K, each point z in the boundary of c, and each E > 0, the open e-ball about z contains a (relative) neighborhood U of z in c U {z} such that U - {z} is a connected subset of c.

Proof of claim. Our claim holds trivially for r = 1. Assume r > 1. With no loss of generality assume that c has either the form

c = c;* = {[b, x]: b E c’,fj(b) < x <fi+,(b)), or

c = c’ = {[b,l;(b)]:
J

b E c’},

for some c’ E K’ = the base decomposition of K. In either case the closure of c obviously contains c itself, and, in case (l), also the two “sections” cj and c;+, bounding c from above and from below, all of which are of course cells in K. Any other point in the closure of c must be of the form [b, x], where b belongs to the boundary of c’, and where x,(b) G x Q x2(b); here we write

x,(b) = liminf h(b’)
b’sc’,W+b

and x2(b) = limsup fk(b’),
b’ec’.b’-+b

306

SCHWARTZ AND SHARIR

where k = j + 1 in case (l), k = j in case (2). Note that
liminf f(r) XES, X-y
designates the smallest limit off(x) for any sequence yi of points of the set s for which y, + y, and similarly for lim sup. Conversely, any such point clearly belongs to the closure of c. Let e be the set of all such points. By our induction hypothesis, the boundary of c’ is a union of cells in K’. Let c” E K’ be a cell of this boundary. Note that x,(b) and x1(b) either are roots of P or are - cc or + cc. We will show that these functions are (equal if k = j, and) continuous in the entire closure of c, and hence are continuous for b E c” (here we give the extended real axis R*, including the points - cc, + co, its standard topology, which makes R* homeomorphic to the compact unit interval [ - 1, + 11.)
The asserted continuity is an easy consequence of the following auxiliary lemma.
LEMMA 2. Let c’ E K’ be as aboue, and let fj(b) denote the jth root of P(b, 0) for b E c’. Then there exists a unique continuous extension (in the sense of the extended topolog of R*) of 4. to the entire closure of the cell c’. Moreover, this extension, which we will also denote by fi, is either infinite or else a root of P.
It will be shown below that Lemma 2 follows inductively from our other assertions. Assume for the moment that this has been proved. It then follows that the set
K(c”) = {[b, x]: b E c”, x,(b) d x Q x2(b))

must be a union of cells in K. We can show this, and even provide a more explicit characterization of these cells, as follows. Let c’ E K’ be as above, and let fi(b) be the jth root (of m distinct real roots) of P(b,. ) over c’. Let c” E K’ be any cell in the boundary of c’. Use the same symbol fi(b) to denote the continuous extension of fi to b E c” which exists by Lemma 2. Then it follows from Lemma 2 that, for b E c”, fj(b) is (either - cc or + cc or) one of the M roots of P over c”. In either case we can write&(b) = FJ( b), where FJ is the Jth root of P over c” (by our convention, this also includes the extreme cases J = 0, M + 1); note that J is independent of b, because the roots FJ are isolated and J: varies continuously over c”. Define a mapping
p(c’, c”): {O..m + l} + {O..M + l}
by putting p(c’, c”)(j) = J if&(b) = F,(b) for some, hence for all b E c”.

THE “PIANO

MOVERS”

PROBLEM

307

Then the assertion we need to prove is contained in the following somewhat more detailed

LEMMA 3. Let c’ E K’ be as above. Then the cells of K which intersect the closure of the cell cj are c; itself, and all cells of the form c;‘, where c” is contained in the closure of c’ and p(c’, c”)(j) = J. The cells of K which
intersect the closure of cj* are c;* itself, the two sections cj and cj+ ,, and all cells of the form c;‘, c;I*, c;‘+ ,, c;‘+*,, . . . , cz, where c” is contained in the closure of c’, p(c’, c”)(j) = J, and p(c’, c”)( j + 1) = L. Moreover, all of these cells are contained in the closure of c; (resp. c;*).

Proof: We prove only the second assertion, the first being even simpler.

As noted in the paragraph immediately preceding the statement of Lemma

2, the closure of cJ* consists of cj*, c;, cj’+ ,, and of the union of all the sets

K(c”) where c” ranges over all the cells contained in the boundary of c’. By

Lemma 2, and by the remarks preceding the present lemma, we have

x,( 6) = F’(b), x2(b) = F’(b), for b E c”, where J, L are as in the state-

ment of the present lemma. Thus K(c”) is the union of all the cells

c;‘,..., ci. It is then clear that all these cells, together with CJand c;+ 1, are

the only cells which can intersect (and hence be contained in) the closure of

cl*

Q.E.D.

J *

We can now complete the proof of Lemma 1. Indeed, the first part of the

claim to be proved is now immediate from Lemma 3. To prove the second

part, let c, c’, [b, x] E %,and let Ebe as in the claim. Let d, d’, be the base

cells of c, c’ respectively. Then either c = dj for some j or c = d; for some j.

Assume first that c = dj, for some j. Project the e-ball U about [b, x] onto

a subset U’ of E r-‘. By inductive hypothesis, U’ contains a relative

neighborhood I” of b in d + {x} such that V - {x} is connected. The

continuity of fi(b) implies that for sufficiently small I” the set {[b, f,(b)]:

b E I”) is a connected neighborhood of [b, x] in c + {[b, x]} which is

contained in U.

Next consider the case where c = dj*. Let J, L be as in Lemma 3, and let

0 < (Y< 1 be such that x = cuF,(b) + (1 - a)F’(b). Obtain U’, v’ as in the

preceding paragraph, and consider the set

V= {[a,/3h(a) + (1 -B)h+,(a)]:aE

v,OGPG 1, ID-al <s>.

Note that V is relatively open in c. It also follows from the (uniform)

continuity of 4 and rj+ , over V’ that if V’, 6 are both sufficiently small, V

will be a connected (relative) neighborhood of [b, x] in c + {[b, x]} which is

contained in U.

Thus both assertions of our claim continue to hold in r dimensions,

completing the inductive proof of Lemma 1.

Q.E.D.

308

SCHWARTZ AND SHARIR

Next we return to finish the proof of Lemma 2, which will complete our whole interlocking set of inductions.
Proof of Lemma- 2. We give the extended real axis R* the metric topology of the compact unit interval [ - 1, + l] (which is homeomorphic to R*) and write the distance function in R* as d(x, y). It is sufficient to prove that fi is uniformly continuous on any bounded subset of c’. Suppose the contrary. Then there exist S > 0 and two sequences b,, bi E c’, such that both sequences converge to a point b, on the boundary of c’, but for all n we have d( h( b,,), h( bh)) > 8. By inductive hypothesis, for each integer m there exists a (relative) neighborhood N, of b,, in c’ + {b,} which is contained in the (l/m)-ball about b, in E ‘-I, and such that iv,,, - (b,,} is connected. For all m > 1 define sets
R, = {[by l;(b)]: b E Nm- V+,J),

and let R denote the intersection of the closures of these sets. R is obviously

a compact set. We claim that it is connected. To see this we first observe

that each of the sets R, is connected, being the image of the comrected set

%I - (b,} under the continuous function b + [b, h(b)]. Next suppose that R is not connected. Then there exist two disjoint open sets U, V such that R

is contained in the union of U and V and intersects both U, V. But this

implies that for sufficiently large m, R, is also contained in the union of U

and V, for otherwise there would exist a sequence z,, such that z, E R, -

U - V for all m, which, by compactness, must converge to some z E R - U

- V, which is impossible. Since R, is connected, we can assume with no

loss of generality that R, is contained in U for all sufficiently large m. But

then R must also be contained in U, a contradiction which proves that R is

connected. Since the projection of R into E ‘- ’ consists of the single point

b,, R must be a vertical straight segment, all of whose points are obviously

roots of P(b,, 0). However, since we have assumed that K is well-based,

there are only finitely many such roots, and so R must consist of a single

point [b,, x]. Hence this point is the common limit of both sequences

{[b,, h(b,,)]}, {[b;, &(bA)]), which is impossible. This shows that fj is uni-

formly continuous over bounded subsets of c’, and hence admits a unique

continuous extension to the entire closure of c’.

Q.E.D.

Remark. Lemma 2 is false if the decomposition is not well-based. Indeed consider the example given earlier. It is easily seen that {[O,O]} is a base cell. Hence, if c is a 2-dimensional base cell c containing [O,O] in its boundary, the single zero of P(x, y, *) for [x, y] E c can never admit a continuous extension to [0, 01.
Lemma 2 has several consequences, which collectively show that a wellbased Collins decomposition is free of local pathology.

THE 'LPIANO MOVERS" PROBLEM

309

COROLLARY. Assume K is well-based. Let c E K’, and let c’ be a boundary cell of c. L.et g,(b) denote the k th root of P( b, .) for b E c’. For each b E c’ let J(b) denote the set of a/f indices j such that g,(b) is the limit of some sequence J.( b;), as b,!,E c approaches b. Then J(b) is a constant depending only on c’, but not on the particular point b E c’.
LEMMA 4. Let c e K, and let c’ E K be a boundary cell of c. Then for each point z E c and each point z’ E c’ there exists a continuous path connecting z to z’, which, except for its endpoint z’, lies wholly in c.
Proof. Proceed by induction on r. Let d, d’ be the base cells of c, c’ respectively. Let z = [b, x], z’ = [b’, x], where b E d, b’ E d’. If d = d’, then c = d,! for some j, and c’ is its top or bottom face. Assume c’ to be the bottom face dj of c; then the desired curve is constructed as follows. Let q‘(t) be a curve contained in d which connects b with b’ (the recursive construction of Collins cells makes it quite easy to construct such a curve explicitly). Next let 0 < (Y< 1 be such that
x = ah(b) + (1 - ++,(b)-
Then the desired curve q(t) is simply [q’(t), q*(t)], where
4*(t)= Ml - t) + tlfihm) + LO- al - t)l~+MtN~
Ogt<l.
Otherwise, d * d’, and by inductive hypothesis there exists a continuous curve q(t), t E [0, l] such that q(0) = b, q(1) = b’, and q(t) E d for all t < 1. First suppose that c’ is a section
<[a7a(a)] : a E d’),
where g,(a) is the kth root of P(a, -) over d’, and that c is a section
{[a,h(a)]:aEd},

where 4 is the jth root of P(a, -) over d. Extending fj continuously to the whole closure of d, so that &(a) = g,(a) for a E d’, the curve we want is simply

PW = [4(t)7 fjM))]Y

t E 10911.

The other possible cases, i.e., those in which one or both of c and c’ is a

“segment” rather than a section, can be handled in essentially the same

manner; we leave details to the reader.

Q.E.D.

310

SCHWARTZ AND SHARIR

Next we quote some standard definitions and results concerning finite cell complexes and their (singular) homology groups; see Cooke and Finney [9].
DEFINITION 6. A decomposition of a compact topological space S into finitely many disjoint sets (ci> is called a cell complex if
(a) Each ci is homeomorphic to an open unit ball of some dimension d,, which we call the dimension of ci.
(b) For each integer dimension d, the union S, of all the sets ci of dimension Q d is closed.
(c) Each cell ci of dimension di is open in the relative topology of Sd,. (d) For each cell ci of dimension di, there exists a continuous mapping f. of the unit closed ball B of dimension di onto the closure ci of ci, which maps the interior of B homeomorphically onto ci.
DEFINITION 7. The cell complex {ci} of the preceding definition is said to be regular if each of the mappings fi is a homeomorphism of the closed ball B of dimension di onto the closure of the corresponding cell ci.
THEOREM 2. The collection of compact cells of a (well-based) Collins decompositionof E’ forms a regular cell complex.
We will, as usual, prove this theorem by induction on the dimension r, for which purpose the following easy lemma will be useful.
LEMMA 5. Let B be the closed unit ball in E’, and let f and g be two continuousreal functions on B suchthat g(b) < f(b) for each b in the interior of B. Put
B* = {[b,x]: b E B,g(b) 6 x <f(b)}.
Then B* is homeomorphicto the closedunit ball B, of Eri ‘.
Proof By shifting and contracting B* along the x-axis we can assume that g(b) = -f(b), and that f(b) < l/2 for all b E B. For each b f 0 in B, let B(b) = b/lb], so that 0 is continuous for all b * 0. Put r(b) = (1 f *Wb)))“*, and then let T map the point [b, x] of B* to

[bdb), ~(1 - lbl*r*(b))“*/f(b)].
(If ]b] = 1 and f (b) = 0, then put T(b, x) = [b, 01.) Since br( b) is continuous for all b, and since f(b) f 0 for ]b] < 1, this mapping is plainly continuous for all [b, x] E B* such that ]b] < 1. T is also continuous when ]b] = 1. This is plain for each b such that ]b] = 1 and f(b) > 0; on the other hand, if f(b) = 0, then since Ix’/f (b’) I < 1 for [b’, x’] E B*, it follows that T[ b’, x’] + [b, 0] as [b’, x’] --, [b, 0] from within B*. Moreover,

THE “PIANO MOVERS” PROBLEM

311

T is l-l on B*. Indeed, if T[b, x] = T[b’, x’] then plainly e(6) = 0(V), so

that r(b) = r(V), and hence b = b’, x = x’. Since T is continuous and l-l

on the compact set B*, it is a homeomorphism on B*.

It is easily seen that the range T( B*) is the set B+ of points [a, JJ] in the

closed unit ball ]al2 + y2 < 1 which satisfy the condition Iat d r(a).

The boundary of B+ then consists of all points [a, y] which either lie on the

boundary of the closed unit ball B, of E’+ ’ and satisfy ]a ] < r(a), or else

are interior points of B, such that [al = r(a). It then follows that the

boundary of B+ has the property that each ray from the origin meets it in

exactly one point. Hence B+ is a star-shaped compact set, and it follows

from Lemma 6 below that B+, and hence also B*, is homeomorphic to the

closed unit ball B, .

Q.E.D.

LEMMA 6. Let A be a compact set in E’ which contains the origin 0 of E’ in its interior, and which is star-shaped relative to 0 (i.e., each ray from 0 intersects the boundary A’ of A in exactly one point.) Then A is homeomorphic to the closed unit ball B of E’.

Proof. This is well known, but to prove it let 8 designate an arbitrary point on the boundary of B, and let r(e) be the length of the straight ray from 0 to A’. Then, since each such ray intersects A’ in exactly one point, r(f?) obviously varies continuously with 8. The desired homeomorphism simply maps each nonzero b E B to br( 0( b)), where B(b) = b/I bl . Q.E.D.

Proof of Theorem 2. Suppose that Theorem 2 has been proven for a

Collins decomposition K’ of E’, and let K be a Collins decomposition of

E’+ ’ with base decomposition K’. Then any cell of K has the form of either

cj or cy for some c E K’, and for some integerj. In the case of a section cell

cj = ([b, h(b)] : b E c}, we can simply note that, since fi is continuous on

the closure C of c, the projection of cj to c extends to a homeomorphism of

the closure of cj with F, which, by inductive assumption, is homeomorphic to

a closed unit ball B of an appropriate dimension. Finally, using the same

homeomorphism of C with B, the case of a segment cell cJ* is covered by

Lemma 5.

Q.E.D.

DEFINITION 8. If c and c’ are Collins cells belonging to a decomposition K, and if c’ is contained in the closure of c, then we say that c’ is a face of c.

We continue our analysis by quoting another standard definition from Cooke and Finney [9].

DEFINITION

8. Given the finite regular cell complex K, an incidence

function (Y on K is a function assigning one of the integers { - 1, 0, + 1) to

each pair c, c’ of cells of K, which satisfies the following conditions:

312

SCHWARTZ AND SHARIR

(i) (Y(c, c’) * 0 iff c’ belongs to the boundary of c and has dimension exactly one less than the dimension of c.
(ii) If c is of dimension 1, and the two O-dimensional cells (i.e., discrete points) constituting the endpoints of c are c, and c2, we have a(c, c,) + a(c, c*) = 0.
(iii) If c” belongs to the boundary of a cell c of dimension d, and has dimension exactly d - 2, then

&x(c, c’)a(c’, c”) = 0, c’

where the sum extends over all cells c’ of dimension d - 1 whose closures are subsets of c- and supersets of the closure of c”. (It is well known (see, e.g., Cooke and Finney [9]) that for any c, c” there are precisely two cells c’ of this kind, if the cell complex is regular.)
Every regular cell complex A admits an incidence function, and by a standard result proved at length in the cited work of Cooke and Finney, any such incidence function can be used to compute the homology groups of A in a purely combinatorial manner. For the Collins cell decompositions which we consider, incidence functions are easy to define; we simply proceed inductively on the dimension, and use a variant of the standard “Cartesian product rule.” More specifically, suppose that K and K’ are as in the proof of Theorem 2 above, and that an incidence function a’ has already been defined for the cells of K’. Extend this to the cells of K by putting
(a) cw(cj,cj) = (~‘(c, c’), if c’ belongs to the boundary of c and
P(C,c’>(j) = J;
(b) clr(cj*,c/) = - 1, (Y(c;, cj+,) = + 1;
(c) a(cj*, CL*) = - a’(c, c’), i f c’ belongs to the boundary of c and P(C, c’)(j) < k < P(C, c’)(j + 1);
and putting a(a, b) = 0 in all other cases. It follows immediately from Lemma 3 that the function a defined this way satisfies condition (i) of Definition 8. It is trivial to verify that (x also satisfies condition (ii) of that definition.
Next we verify that (Ysatisfies condition (iii) of Definition 8. Let c E K be an s-dimensional cell, and let c” be an (s - 2)-dimensional cell contained in the boundary of c. Let d, d” be the base cells of c, c”, respectively. Several cases are possible:
(i) Suppose c = dj for somej. Then it follows from Lemma 3 that c” must have the form d;‘. Furthermore any (s - I)-dimensional face c’ of c which contains c” in its boundary must be of the form d;, for some

THE “PIANO MOVERS” PROBLEM

313

(s - I)-dimensional face d’ E K’ of d which contains d” in its boundary and is such that p(d, d’)(j) = L and p(d’, d”)(L) = J. Then, by (a) above and by induction hypothesis, we have

$a(,, c’)a(c’, c”) = ga’(d, d’)a’(d’, d”) = 0.

(ii) Next suppose that c = d/*. Then d must be (s - I)-dimensional. Once more Lemma 3 implies that c” either is an (s - 2)-dimensional face of dj or dj+ i (both of which are (s - I)-dimensional), or c” is d;l where d” is (s - 2)-dimensional, or c” is d;l* where d” is (s - 3)-dimensional. The first case is a special case of the second one, so we begin by assuming that the second case holds. Then it follows that d” is a face of d, and that p(d, d”)(j) = J G k Q L = p(d, d”)( j + 1). Assume first that k lies strictly between J and L; then the only possible cells c’ that ‘come between’ c and c” are dL_ ,* and dL*. Hence, in this case, clause (b) of our definition of the incidence function (Yimplies
Ca(c, c’)a(c’, c”)

= a(d;, d;-,*)a(d;-,*,

d;l) + a(dT, d;l*)a(d;*, d;)

= -a’(d, d”) - (- 1 + 1) = 0.

Next suppose that k = J < L. Then the possible c’ are the lower face dj of c and the cell d;‘*, and so we have

&(c, c’)a(c’, c”)

= a(d;, d/)a(d,, d;) + a(dj*, d;‘*)a(d;‘*, d;‘)
= (- 1) . a’(d, d”) + (-a’(d, d”)) . (- 1) = 0.
A similar analysis covers the case J < L = k. Suppose finally that k = J = L. Then the possible c’ are just the upper and lower faces d, and d,, , of c, and once again it is easy to verify (iii).
Next consider the case in which d” is an (s - 3)-dimensional cell, and C II -- d;*. It is easily seen that in this case the only possible intermediate cells c’ are of the form d;*, where d’ is a cell in K’ intermediate between d and d”, and
p(d, d’)(j) = J, d I -c J2 = p(d, d’)( j + 1);
p(d’, d”)(f) = L , < k < L, = p(d’, d”)(l= 1).
However, it readily follows from Lemma 3 that for each intermediate cell d’

314

SCHWARTZ AND SHARIR

there exists exactly one 1 satisfying these inequalities. Hence, by inductive hypothesis, we have

y,, c’)a(c’, c”) = G( -cd(d, d’))( -a’(d’, d”)) = 0

Thus condition (iii) is established in all cases, so (Yis indeed an incidence function for K.
Since an incidence function for the cells of a Collins decomposition can be defined in this straightforward combinatorial manner, and since the homology groups of any finite regular cell complex can be computed combinatorially from such an incidence function, it follows that the homology groups can be computed by a purely finite procedure once we know what (d - 1)-cells are faces of each given d-cell. A technique for determining this, which is based on Lemma 3 and its corollary, will be described below. Assuming this, we have the following result:
THEOREM 3. For each j, the (singular) homology group H,.(V) of the real
algebraic variety V defined by any set II of polynomial equations P(x,, . . . , x,) = 0 with rational coefficients, can be computed in a purely rational manner from the coefficients of the polynomials P.
In particular, since V is a regular cell complex the number of connected components of V can be formed simply by tracing sequences of cells which are faces of each other.
Collins gives estimates (which we reconstruct in Appendix A below) for the complexity of his cell decomposition procedure; in what follows we shall extend these to estimates of the work needed to determine whether one Collins cell c’ is a face of another cell c, in the special case in which the dimension of c is the same as the dimension of the space E’ being decomposed. This will show that the connectivity analysis required to solve the general movers problem can be performed in time polynomial in the total degree of the set II of polynomials (but exponential in the numer r of variables appearing in these polynomials.) Appendix C discusses the more difficult adjacency analysis in case c has a lower dimension than r. At the present moment we do not know whether this more complex task can also be handled also in polynomial time.
To complete the foregoing arguments we still need to show how a well-based Collins decomposition can be defined for any algebraic variety. Let P be an r-variate polynomial, for which we wish to construct a P-invariant Collins decomposition of E’. Following Hironaka [lo], we define a good direction to be a unit vector v (i.e., a point in the unit sphere S of E’) such that P does not vanish identically on any line parallel to v. A simple technique for constructing a good direction, which is given by Lazard

THE “PIANO MOVERS” PROBLEM

31.5

[ll], is as follows. Let Q(x,,. . . , xr) be the homogeneous part of P of highest degree = n. If o is a direction on which Q does not vanish (i.e., Q(u) * 0), then v is a good direction for P. Indeed, for any x E E’ and for sufficiently large real t, P(x + tu) behaves asymptotically as Q(fu) = f”Q(u) * 0. By an easy lemma of Schwartz [12], if c > 1, then the number of integer points in a cube of side I > cn at which Q vanishes is at most c- ‘I’. Taking c substantially larger than 1, a good direction 2)can be found quite rapidly simply by picking a u at random from such a cube, testing the condition Q(u) f 0, and repeating the choice until a v satisfying this condition is found. Once having found such a o, we rotate E’ so that o becomes the r th axis, and we begin the Collins construction by projecting in the direction of 0. As will be seen in Appendix A, this recursive construction generates a new polynomial Q in the remaining (r - 1) variables from P and u; Q plays exactly the same role for the required base decomposition of E’- ’ that P plays for the decomposition of E’. This observation allows us to apply the above way of finding a good direction recursively, and in this way we build a well-based Collins decomposition.
Remark. The result of Hironaka [lo] which asserts the triangulability of real algebraic varieties, follows immediately from what has gone before. Note also that the fact that the cells of a Collins decomposition form a regular cell complex was anticipated by Professor P. Kahn of Cornell in a 1978 letter to Collins. See [ 131.
To use the Collins cell decomposition associated with a set of polynomials to analyze the connectivity of a space defined by algebraic equalities and inequalities, we must tackle the problem of deciding when a Collins cell c’ of dimension d - 1 forms part of the boundary of a d-dimensional Collins cell c. In analyzing this question, we shall first handle the relatively simple case in which c is of maximal dimension, i.e., is of the same dimension as the Euclidean space E’ which is being decomposed; this is all that is needed for the “movers problem” proper (see Section 3 for details). As usual, we proceed by induction on the dimension r; i.e., suppose that the decomposition K of E’ being considered has the base decomposition K', and that for each (r - 2)-dimensional cell c’ of K’ we know the two (r - I)-dimensional cells c, and c2 of K’ of whose boundary c’ forms part. We will also suppose that for each cell c E K’ considered, an algebraic point p(c) belonging to c is known, and that whenever c’ forms part of the boundary of c, a vector v pointing from p(c’) into c, i.e., a vector z, such that p(c’) + 60 E c for all sufficiently small 6 is known. We will shortly note that it is easy to carry the construction of such vectors forward inductively.
Any r-dimensional cell in E’ must have the form c,? for some (r - l)dimensional cell c E K’, and then, by Lemma 3, the (r - 1)-dimensional cells lying in the boundary of CT are its top and bottom cells cj and cj+ ,,

316

SCHWARTZ AND SHARIR

together with all cells of the form c;*, where c’ belongs to the boundary of c

and where p(c, c’)(j) Q J -c p(c, c’)(j + 1). The vector [O,. . . , 0, - l] (resp.

10,. . . J 0, + 11) points from cj+, (resp. from ci) into CT. Moreover, if

V- iv ,,..., v,-,]pointsfromanx

E c’intoc, then[v ,,..., v,-,,O]points

from c;* into CT if the former is part of the boundary of the latter. Hence it

is trivial to carry the necessary vectors v forward, and the boundary

determination problem presently under consideration reduces to that of

calculating the map p(c, c’) for an (r - I)-dimensional cell c and an

(r - 2)-dimensional cell c’ of K’.

To make this calculation, we begin by observing that the corollary to

Lemma 2 implies that to compute p it suffices to compute, for each root

f,(b) over c’, the number k of roots of P into which h( 6) splits as b moves

slightly into c. Moreover, we can make this calculation for an arbitrary

b E c’.

Given b = p(c’), and the vector v which points from b into c, the points

b’ = b + tv will lie in c for sufficiently small positive values of t. Moreover,

the bivariate polynomial

Q(x, y) = P(b + xv> fi(b) +I’>

has coefficients which are algebraic since they depend algebraically on the (algebraic) coordinates of b, and this polynomial vanishes at the origin [0, 01. Let x vary in a sufficiently small interval (0, x0], and for each such x define the polynomial
R,(Y) = Qk Y>-
As is well known (see, e.g., Van der Waerden [14, Ch. l]), for sufficiently small x all the roots y of R,(y) which lie near the origin are expressible by fractional power series of the form

y = c,x I/k + czXW + . . .
= C,X”k + o(x”k),
where k < n = the degree of R, as a polynomial in y. Thus, if we substitute x”+ ’ for x and if we let x be small enough, it follows that each root y of Rx.+ I(*) lying near the origin must belong to the interval [ -x, x], because the sum of the above fractional power series is O(X(“+‘/~)) = o(x). It’ therefore suffices to determine the number N of zeroes of R = R,.+I in the neighborhood [-x, x] of 0. To find N, we can use the Sturm technique (see Appendix B for a review of Sturm sequences), that is, compute the Sturm sequence of R at x and at - x, and then N is S( - x) - S(x), where S(a) is

THE “PIANO MOVERS” PROBLEM

317

the number of sign changes in that sequence evaluated at a. (The Sturm sequence is obtained as the remainder sequence of R and its y-derivative R’.) Since R and R’ depend polynomially on the parameter x, extra care must be taken to ensure that, as this sequence is being calculated by repeated divisions, no leading coefficient of any of the polynomials in that sequence vanishes for the values of x that we consider (if such a term did vanish, subsequent divisions might involve completely different polynomials). However, since all these coefficients of R are polynomials in X, and since there are only finitely many such coefficients, none of their zeroes will belong to the open interval (0, x0], if x,, is chosen to be small enough.
Therefore we can find the number N of roots in which we are interested by calculating the Sturm sequence

of Rx.+, as a sequence of polynomials in y with coefficients which are rational functions in x; and since we can multiply all those coefficients by a common denominator, we can even assume that these coefficients are polynomials in x. After calculating the polynomials (l), we must find their signs at the points -x and x, for x small enough. If we substitute y = x in the sequence (l), we obtain a sequence of polynomials Go(x), . . . , Gk(x) in x, the signs of whose members are to be computed for x positive and sufficiently close to 0; and an exactly similar statement holds if we substitute -x fory. Let G(x) be any one of these polynomials; then the sign of G(x) is either the sign of the coefficient in G of the nonzero term of the smallest degree, or, if all the terms of G vanish, is 0. This gives us N, i.e., the number of roots into which h(b) splits as b moves into c. As already observed, by collecting these numbers for all the roots fi( b) of P for b E c’, and by using Lemma 3 in a straightforward manner, we can reconstruct the map P(C, 0.
The analysis required to determine when a Collins cell c’ of dimension k - 1 is a face of a cell c of dimension k < r is somewhat more difficult, for which reasons we prefer to present it in Appendix C below. Note that several two- and three-dimensional cases of the results proved in this section were established by Arnon [8]. Lemma 1 of this section is related in this way to Amon’s Corollary 3.3.25 and Theorem 3.4.11, Lemma 2 to his Theorem 3.6.16, and Lemma 3 to his Theorems 3.3.8 and 3.3.14.
3. A GENERAL ALGORITHM FOR THE PATH-PLANNING PROBLEM
As noted previously, the position of one of the hinged bodies B we consider is always described by a point Tin a smooth algebraic manifold G,

318

SCHWARTZ AND SHARIR

and the set of points occupied by a particular rigid part Bi of B is the range on Bi of a Euclidean transformation q whose coefficients can be expressed as polynomials in the components of T. We assume that each part Bi of each of our bodies is a compact Tarski set, and moreover that each face, edge, or
other significant feature of such a part Bi is also a compact Tarski set (the walls, however, are not assumed to be compact but merely closed Tarski sets). The set F of forbidden configurations for the body B is then defined as follows. First we note that if Bi and Bj are two parts of B which are hinged together in any of the ways specified above, then there exist some
face or other closed feature B,! (resp. BJ of Bi (resp. Bj) which always touch each other. Any other touch between Bi and Bj at a point outside B; or B,! is then considered to be forbidden (in particular, if Bi and Bj are not directly
hinged to each other, then it is forbidden for them to intersect at all). This defines a set F, of points of G which represent forbidden configurations of B, and we define F to be the closure of Fo. F clearly constitutes a closed Tarski set, and hence a real closed semi-algebraic subset of G. (All this
continues to apply in cases involving several disconnected, independently moving bodies, some of which can represent (immobile) walls.) Our pathplanning problem is therefore that of deciding whether or not two points of G - F belong to the same component of G - F, where F is a real closed semi-algebraic subset of G, and, if so, to construct a path that connects
these points in G - F. (Note: If F is not required to be closed, the problem is still decidable, but the technique we are about to present may become less efficient; additional comment on this point is found below.)
To show how to decide this question, we can proceed as follows. Let Q be a quantifier-free defining formula for the set F of forbidden positions. Since the condition a > b (resp. a > b) can be written as a - b > 0 (resp. a - b > 0 or a - b = 0), etc., we can suppose without loss of generality
that Q is a boolean combination of clauses P > 0 and P = 0, P designating some arbitrary polynomial in the appropriate number r of variables. Let S designate the set of all polynomials appearing in Q or as defining equations
of the manifold G, and use Collins’ theorem to construct an S-invariant cylindrical algebraic decomposition K of E’. Then it is clear that G, F, and G - F are all unions of collections of cells c E K.
It follows from the general topological results presented in the preceding section that two points p and q of G - F can be connected by a continuous arc in G - F if and only if there exists a chain c,, . . . , ck of cells of G - F such that p E c,, q E ck, and such that for eachj, either cj+, is a face of cj, having one dimension less than that of cj, or vice versa. (This follows from well-known properties of the homology group H,,(G - F); see, e.g., [9].) Note that the recursive construction of the Collins cells gives us an effective
way of connecting any two points in the same cell by a continuous arc lying wholly within that cell, while Lemma 4 gives us an equally explicit way of

THE “PIANO MOVERS” PROBLEM

319

constructing an arc from any point p in a cell c’ forming part of the boundary of another cell c to any point q E c.
All in all, therefore, the results we have proved concerning the Collins decomposition give us a constructive way of determining whether the two given points p and q belong to the same (arcwise connected) component of G - F, and of finding a smooth arc connecting them when they do.
If F is not assumed to be closed, then to check for the existence of a chain of cells connecting the given points we may need to employ the more costly test for adjacency of Collins cells of arbitrary dimension described in Appendix C. At present we do not know whether this test can be carried out in time polynomial in the geometric complexity of the problem. By making the technical assumption that F is a closed subset of G we avoid this difficulty, since then connectivity in G - F can be determined by following chains of cells of codimension at most 1. To see this, assume for the moment that G can be represented as a whole Euclidean space E k for some k (we will explain shortly how such a representation can be constructed). Then, if F is closed it follows that G - F is a smooth manifold of dimension k in Ek, so that no submanifold of G - F of dimension k - 2 or less can disconnect any connected component of G - F (for this well-known fact see, e.g., Lemma 1.9 of [5]). Hence in this case two points in G - F are connected to one another if and only if the two cells containing them can be connected by a chain of cells all of which are either k-dimensional or (k - l)dimensional. This can be done using the relatively efficient “maximal dimension” adjacency testing method presented at the end of the preceding section.
To see that G can be represented in this manner, first note that by the general discussion of the algebraic representation of a collection of hinged bodies given in Section 1, G can be represented as the Cartesian product of a finite number of spaces, each of which is either a full Euclidean space Ek, or a rotation group of dimension 1, 2, or 3. These groups can in turn be represented as the circle S’, the 2dimensional sphere S*, and the 3-dimensional sphere S3, respectively, with the third representation being doublevalued, i.e., each rotation in 3-space is represented by two antipodal points in S3 (for more details concerning this representation, see, e.g., [15]). Moreover, with the exception of one point, S* and S3 can be mapped algebraically onto E* and E3 respectively by appropriate stereographic projections. Omission of the exceptional points of one or more such stereographic mappings will not affect the connectivity of the open manifold in which we are interested since the points omitted all lie on submanifolds of G of codimension at least 2. Therefore, with no loss of generality, we can assume that G is represented as a product of a Euclidean space Ek by a finite number of circles S’. Each such circle can be mapped algebraically (with the exception of one point) onto a line by a stereographic projection,

320

SCHWARTZ AND SHARIR

but here the omitted point can affect the connectivity of the resulting image of G - F. To overcome this small technical difficulty, assume first that only one circle is involved, i.e., G = Ek X S’. Map S’ onto a line R, by projecting it from a point X, E S’, and also onto another line R, from another point X,. We then obtain two distinct representations G, and G, of
G, and can construct corresponding Collins decompositions K, and K, for each of them. Next we can analyze the connectivity of G, (resp. G2) by constructing an appropriate connectivity graph CG, (resp. CG,) in the
simplified manner described above, and finally we can merge these graphs into one graph by adding edges which connect a cell cl E CG, to a cell c2 E CG, whenever c, and c2 have a common point of G - F (this property
of cells can be checked for easily if we take care to include the equation defining the subspace Ek x {X,} (resp. Ek X {Xl}) among the algebraic equations from which K, (resp. X2) is generated). The connectivity of
G - F can then be determined by analyzing chains of edges in this merged graph. Cases in which G is the product of E k by more than one circle can be handled in a similar manner.

Note. Another minor technical point to be noted is that the representation of the full 3-dimensional rotation group as S3 is bivalent, so that a path
between two specified rotations R, and R, of some subpart Bi of B can correspond either to a path between a point 5, E S3 representing R, and a similar point t2 representing R, or to a path between El and -t2. Thus in order to determine whether R, and R, can be connected we have to check
for the existence of one of several paths. Once a well-based Collins decomposition has been constructed, the
connectivity analysis can proceed, as already noted, via a simple search through the connectivity graph whose nodes represent the Collins cells of highest dimension, and whose edges indicate cell adjacency. The computation cost of such an analysis is plainly linear in the size of the Collins
decomposition. Collins has shown (see also Appendix A below) that the number of cells in a cell decomposition K is 0((2n)3’+’ * m”), where m is the number of polynomials defining the sets G and F, and where n is the maximum degree of any one such polynomial. Note that n is related to the degree of any single geometric constraint, and that r is related to the number of degrees of freedom of the bodies B. If we fix r, it follows that the number of cells in K, as well as the number of adjacent pairs of cells, is polynomial in m and n, i.e., in the geometric complexity of the problem, that is, in the number of different walls, faces, and other features of the system B of bodies, and in their algebraic degrees. Moreover, the time required to construct the Collins decomposition, and to test for adjacency of cells of maximal dimension, can also be shown to involve a number of operations on algebraic numbers which is also polynomial in m and n. As is

THE "PIANO MOVERS" PROBLEM

321

well known (see Appendix B for details), each such operation can be accomplished in time polynomial in the degree of the polynomials defining these algebraic numbers. Taking all this into account, we obtain the following result:

THEOREM 4. The mouer ‘s problem for (algebraic) bodies having a fixed number of degrees of freedom whose set of forbidden configurations is closed can be solved in time polynomial in the number of geometric constraints present in the problem.

Remarks. (1) The computational cost of our solution of the movers problem is still exponential in the number of degrees of freedom of the bodies B. That this complexity growth is probably inherent is indicated by a theorem of Reif [l], which asserts that the mover’s problem for a robot B with many jointed arms (all free to rotate around a common axis) is PSPACE-complete.
(2) A comparison of Theorem 4 and the discussion preceding it with the more elaborate technique used in [5] to solve certain 2-dimensional cases of the motion-planning problem efficiently reveals a significant similarity between the two approaches. In both approaches the free space of configurations of B is partitioned into cells, and these cells are comected to each other whenever they are physically adjacent to each other. This imposes a combinatorial graph structure on these cells, whose connected components reflect the connected components of G - F. Moreover, in both cases these cells are constructed recursively by adding one dimension at a time. Also, the cells appearing in [5] can be shown to consist each of a finite union of Collins cells in the associated decomposition. We will not pursue these observations in this paper, but they will reappear in a subsequent report on efficient algorithms for other special cases of the mover’s problem.

APPENDIX

A: THE COLLINS DECOMPOSITION-AUXILIARY REMARKS

In this appendix we review the construction which leads to the proof of Collins’ Theorem 1, and add various auxiliary observations. We begin with the following remark. Let Pb(z) be a polynomial of fixed degree n whose complex coefficients depend continuously on a parameter b which varies in some connected set S. Suppose that the number of distinct roots of Pb(z) is independent of b. Then these roots vary continuously with b. This follows immediately from the fact that the unique root p of Pb lying in any small circle C can be expressed by a quotient of Cauchy integrals over this circle.

322

SCHWARTZ

More specifically we have

AND SHARIR

Next suppose that the polynomial Pb also has real coefficients for each
value of b. Then the number m of real roots of Pb is also independent of b, and for eachj d m thejth largest real root of Pbdepends continuously on b. To establish this, let S, be the set of points b for which there exist exactly k real roots. Take a point b, in S,, let rl . . . r, be the distinct complex roots of Pb,, with rl . . . rk real and the remaining roots nonreal. Draw disjoint small
circlesCi,j = l... I, around these roots. Then for b sufficiently near b,, each of those circles will contain exactly one of the roots of Pb, and each root of Pb will lie in one such circle. Since complex roots of Pb must occur in conjugate pairs, it follows that (if they are sufficiently small) the circles
c ,,. . . , C,, and only these, contain real roots of Pb, which proves our assertion.
Next, suppose, in addition to the assumptions made above, that Rb(x) is
a second polynomial with real coefficients depending continuously on b E S, and that for each b E S all the zeroes of R, are contained in the set of zeroes of Pb. Then for each j, R, is nonzero and of constant sign in the open interval Ij(b) between the jth and the (j + 1)st largest real zeroes of Pb, and arguing by continuity and from the connectedness of S it is clear
that the sign of R, on the interval Ij(b) is independent of b. A simple variant of the Collins technique, sufficient for our purposes, but
a bit less efficient than the one developed by Collins, can be described as follows. Assume that we are given a (finite) collection { P,(b, x)} of poly-
nomials in k + 1 variables whose coefficients are all rational. (We continue to suppose that b designates a vector of k real variables, and that x designates the last of the k + 1 variables on which Pi depends; accordingly, we will treat the multivariate polynomials Pi as polynomials in x with coefficients belonging to the ring of rational polynomials in the k other variables b.) Let P denote the product of all these polynomials. We can then construct a family of polynomials {Q(b)} in the k variables b with the property that for each (connected) k-dimensional set S over which each of the polynomials Q(b) maintains a constant sign (zero, positive or negative), the number of distinct zeroes of P(b, .) is constant. Suppose for the moment that this has been done. Then the preceding remarks imply that the distinct real roots of P(b, 0) over each such set S can be enumerated from smallest to largest so that for each j the j th root fi( b) varies continuously over S. On the other hand, once the family (Q(b)) has been formed, we can partition Ek into connected sign-invariant subsets S by a recursive application of the Collins technique to the collection {Q(b)). The complexity of the

THE “PIANO

MOVERS”

PROBLEM

323

total procedure then depends on the number of polynomials Q needed to ensure the invariance of the number of distinct real roots of P over each connected set on which they maintain a constant sign, and on their maximal degree.
To construct the required polynomials Q, we have only to use the following well-known observation: Let P’ denote the x-derivative of P, and let R = GCD(P, P’). Let n be the degree of P, and m be the degree of R. Then P has n - m distinct roots. Hence it suffices to introduce enough polynomials Q(b) to ensure that the degrees of P and R are constant on any connected set on which the Q’s are sign-invariant.
To do this we first recall some facts concerning resultants and subresultants of polynomials; for which see Brown and Traub [ 161: Let A(x) and B(x) be two polynomials in x, having degrees a and b, respectively. Fix any j 2 0, and consider the equation

A(x)tgx) = B(x)l$(x)

(*I

in two polynomials q., 5, having degrees b - j - 1 and a - j - 1, respectively. The unique factorization theorem for polynomials implies that ( * ) has a nonzero solution if and only if A and B havej + 1 common roots. By expanding (*) in terms of the coefficients of q and 5, we obtain a system of a + b - j linear equations in a + b - 2j unknowns. We prefer to reduce this system to a square system, to which end we use the following observation. Suppose that we already know that ( * ) admits a nonzero solution for all i = 0, . . . , j - 1, so that A and B have at least j common roots. Replace (* ) by the weaker condition

A(x)l$(x) -B(x)?(x)

= c,(x),

(**)

where Cj( x) is an arbitrary polynomial whose degree is at most j - 1. This system mvolves exactly as many equations as unknowns, so that Eq. ( * * )
then has a nonzero solution if and only if #j( A, B) = 0, where \c;.(A, B) is the determinant of the (a + b - 2j) x (a + b - 2j) matrix of the homogeneous system of linear equations representing the condition that highest (a + b - 2j) powers of x in the left-hand side of ( * * ) have zero coefficients. (The determinant Ic;.(A, B) is known as thejth principal subresultant coefficient of A and B; qo(A, B) is the resultant of these polynomials. See Brown and Traub, op. cit., for more details.) If qj( A, B) * 0, then (* *), and hence also ( * ), has only trivial solutions, so that A and B have exactlyj roots in common. On the other hand, if #j(A, B) = 0, then there exist I?$, 5, and Cj satisfying (* * ). However, we already know that A and B have at least j roots in common. Hence Cj(x) must be divisible by their product. But since Cj(x) is of degree at mostj - 1, it must be identically 0, so that q

324

SCHWARTZ AND SHARIR

and 5 also satisfy ( * ), and so have at least j + 1 roots in common. Thus, given the two polynomials A and B, we can determine exactly how many roots they have in common by computing $J~C;.(AB,) for increasing j until qj(A, B) becomes nonzero. This establishes the following:
LEMMA 1. The number of common roots of two polynomials A(x) and B(x) is j, where j is the smallest integer such that #j(A, B) * 0.
In particular, the degree of the polynomial R(b, x) introduced above is the least j such that rG;.(P, P’) * 0. Note also that the process just described depends on the knowledge of the degree of A and B (more precisely, on the maximal degree of A and B). Hence if A and B also depend on some parameter b (as does happen in the case in which we are interested), these degrees may vary if the leading coefficients of these polynomials become zero. All these considerations lead us to the following:
LEMMA 2. Let P(b, x) be of degree n in x. For each j = 1,. . . , n let P,(b, x) denote the sum of terms of P whose degree in x is < j, and let Qj(b) denote the leading coefficient of q. Also let Rj,(b) = I,!J,($ pi), for k = 0 , . . . , j - 2. Let M be the collection of all polynomials Qj(b) and Rj,(b). Then on each connected set S on which all polynomials in M maintain a constant sign, the number of distinct real roots of P( b, *) is constant.
To bound the computational cost of all this, let Q*(b) denote the product of all nonzero polynomials in M. Then the degree of Q*, as a polynomial in any of the components y of b, is easily seen to be 0(dn3), where d is the degree of P in y. Indeed this product involves 0( n2) polynomials, which are determinants of matrices of size 2n X 2n at most, each element of which is of degree d in y.
Using the preceding remarks, the Collins decomposition can be built up in the following recursive manner. Let S = {P,(b, x)} be any set of polynomials in k + 1 variables whose coefficients are all rational. Let P be the product of all the nonzero Pi, and let Q(b) be the product of all nonzero polynomials appearing in Lemma 2. Applying Collins’ construction recursively, let K be a Q-invariant cylindrical algebraic decomposition of the Euclidean space Ek. Let c be any one of the cells of K. Then Lemma 2 implies that the number of distinct real roots of P( b, a) remains constant as b varies in c. Hence, if f,(b),. . . , f,(b) designate the real roots of P over c in ascending order, then all the functions fi( b) are continuous in b for b E c, and the collection of sets (ii.a)-(ii.d) of Section 2 partition the cylinder c X E’ in such a way so that the collection of all these sets over all base sets c E K defines an S-invariant (k + I)-dimensional cylindrical algebraic decomposition.
Remark. Using the technique for selecting a good direction described in Section 2 we can reduce M somewhat. Let R denote the homogeneous

THE “PIANO MOVERS” PROBLEM

325

portion of P of highest degree 1. Rotating axes, we can ensure that R has a nonzero term involving x’. In this case M need only include Q, and the subresultants Rlk, so that Q* will be of degree dl at most.
We omit the somewhat more refined argument, given by Collins, which shows how to find effectively quantifier-free defining formulae for the cells of the Collins decomposition.
As noted by Amon [8], it is easy to write a Tarski statement which asserts
that y is the j th real root of P in ascending order. This is simply

P(Y) = 08t(3Y,,...,Yj-,)I

X(Y, <Y2&Y, <Y,&*-~Yj-,<Yj-l

&P(y,) = o&c*** &P(yj-,) = O&Yj-, <Y

&(Vx)(P(x)

<O&x <y =q

x((x=y,

vx=y,v

-.-vx=y,J).

(1)

Collins also notes that it is easy to find an algebraic point in each cell in the decomposition K, in the following recursive way. Let K’ be the base decomposition of K. Proceeding recursively, obtain such a point for each c’ E K’. Let b E c E K be such a point. Then the points

[c,Y1 - ll,[c, Y, + 11, [c,Yj], j= l,m**m, 9

1 Yj + Yj+ 1

[ C,

2

’

j=l

,..., m - 1,

are all algebraic and there is one such point in each cell intersecting c x E’.

EXAMPLE. We illustrate the technique described above by finding a P-invariant decomposition of the 2-dimensional plane, where

P(x, y) = x3 + y3 - 3xy

(This is one of the examples analyzed by Amon [ 171.) We begin by
projecting E2 onto E’ in the y-direction. Since the leading coefficient of P (as a polynomial in y) is constant, in the first step of the Collins decomposition it is sufficient to construct the following polynomials in x (we delete the common factors of their coefficients):

&(P, P,) = x6 - 4x3, +,(p, p,> = x. Moreover, since the second polynomial is a factor of the first, only Q(x) = Jl,,

326

SCHWARTZ AND SHARIR

need be retained. The real roots of Q are 0 and 4’i3, so that the base
decomposition K' of the decomposition we seek has 5 cells, namely,

co*= (-cqo), Cl = Ro, cy = (0,41'3), c* = {4"3}, c; = (41'3, +a).

Next we determine how many distinct real roots P(x, Y) (as a polynomial in y) has over each of these cells. To do this we compute the Sturm sequence
of P and P,,(see Appendix B below for a review of Sturm sequences), which
is
A)(Y) = Y3 - 3XY + x3,
f,(Y) = Y2 - x9
h(Y) = 2XY - x3,
f3(y) = 4x - x4.
From this sequence one easily finds out that P( X, .) has one root over c&
one root over c,, three roots over c:, two roots over c2, and one root over ct. Since the decomposition we have considered is well-based, it is a regular
cell complex, and its topology will be completely determined once the p maps on its base cells are found. The maps p can be computed by using the technique described in Section 2. Omitting details, one finds that the map p(cG, c,) maps 1 to 1; the map p(cf, c,) maps all three roots 1,2,3 to 1; the map p(c:, c2) maps the two upper roots 2,3 to the upper root 2, and the lower root 1 to the lower root 1; and, finally, the map p(cz, c2) maps the single root 1 to 1.

APPENDIX

B: ON EXACT S~OLIC COMPUTATIONS WITH ALGEBRAIC NUMBERS

This appendix addresses the problem of how to perform the exact calculations with algebraic numbers required for the algorithms described in this paper, for which numerical approximate solutions may not be acceptable, since such calculations may lead to incorrect conclusions, e.g., in comparing approximate quantities we may wind up putting them in an order which is different from the order of the original numbers, if these

THE “PIANO MOVERS” PROBLEM

327

numbers are very close to each other. Of course, the algorithms to be described will never be able to give an “exact” value of an algebraic number. Nevertheless they can be used whenever an answer to some discrete query involving algebraic numbers is needed, as in the Collins decomposition related technique sketched in this paper.
This kind of problem, i.e., how to perform exact calculations involving algebraic numbers, has been studied by many authors (see [18-211). In this appendix we will review the methods used to perform calculations of this kind, describe various improvements of techniques that have appeared in the literature, and present a few additional techniques.
In the following discussion, we ignore all those (possibly substantial) computational costs which can (and will) arise from the growth in size of the integers with which the algorithms to be described must deal; that is, we will measure cost by assigning each operation on integers (and hence each elementary operation on rational numbers) a nominal cost of 1. (Note, however, that much prior research has concentrated on obtaining more realistic cost estimates for such algorithms, taking into account the possible growth of coefficients during certain operations on polynomials, such as computation of the GCD of two polynomials, the Sturm sequence of a polynomial, the sequence of derivatives of a polynomial, etc. (see [16, 19, 201. These more refined estimates have shown that the extra cost incurred in such operations is still polynomial in the degree and the size of the coefficients of the polynomial(s) involved. Our significantly more optimistic cost measure is like the one used by Aho, Hopcroft, and Ullman [22].)
Some of the results presented below rely on the weak but useful lower bound on the smallest possible distance between two distinct real roots of a polynomial. This is the content of the result of Mahler [23] (see also Mignotte [24]) which the following definition and theorem summarize.
DEFINITION 1. (a) Let P be a polynomial over the complex field. Then ]PI is defined to be the sum of the absolute values of all the coefficients of P.
(b) The squurefree part P* of P is the quotient of P by the greatest common divisor GCD(P, P’) of P and its derivative P’.
As already observed, P* and P have exactly the same roots, but all the roots of P* are simple. If P = P*, i.e., if P has simple roots only, then P is said to be squarefree. With the significant reservation noted above the squarefree part of a polynomial P of degree n can be calculated in time 0( n log2n) by using fast techniques for the required GCD computation and division steps; see Aho, Hopcroft, and Ullman [23, Ch. 81.
THEOREM 1 (Mahler). The minimum distance between two distinct roots of
a squarefree polynomial P of degree n with integer coefficients is bounded

328 below by

SCHWARTZ AND SHARIR

Theorem 1 is important in what follows, since it guarantees that sufficiently precise approximate calculations with algebraic numbers (of the type to be considered below) will yield entirely precise results. However, in most of the following algorithms we will not have to compute the roots of a polynomial P to such a high degree of accuracy, unless roots of P actually happen to be that close to one another.
DEFINITION 2. (a) Let P be a squarefree polynomial of degree n with integer coefficients. Then a P-isolating interval for a real root r of P is an interval with rational endpoints, which contains r in its interior, but does
not contain any other root of P.
(b) Let P be as in (a). A P-separation of the real line is a partition of R into a union of disjoint P-isolating intervals.
Theorem 1 yields a lower bound on the size of a maximal P-isolating interval for a root of P. However, assuming that the roots of P are randomly distributed, the size of P-isolating intervals can be expected to be much larger than A(n, IPI).
Following a convenient convention, we can represent an algebraic number x by a pair consisting of a squarefree polynomial with integer coefficients having x as a root and of a P-isolating interval for x. To proceed in this way, it is obviously important to be able to find isolating intervals for all the real roots of a squarefree P (i.e., to find a P-separation of the real line) rapidly. This root isolation problem is considered by Heindel [19], Akritas [18], and Collins and Loos [20]. Akritas describes an isolation technique based upon systematic binary searching using the Descartes rule of signs, which he indicates can solve this problem for a polynomial P of degree n in time 0( n’). (However, the details of his efficiency estimate are not entirely clear.) The estimates of Heindel and of Collins and Loos give the bound 0( nl” + n710g3]PI), which is also polynomial in n and 1PI, although with a relatively high exponent. Below we will sketch a rootisolation algorithm, essentially an improved variant of the older technique suggested by Heindel [19], which uses a Sturm sequence-based technique and can accomplish root isolation using O(n310g n) arithmetic operations (in our cost measure) in the worst case, but on the average will require only O(n210g2 n) such operations.
We begin by reviewing the beautiful classical theory of Sturm sequences (see Marden [25], p. 130ff.), which gives a very useful way of handling several of the problems that concern us. Let P be a univariate polynomial,

THE “PIANO MOVERS” PROBLEM

329

and let P’ be its derivative. The Sturm sequence of P is a sequence {fi} of polynomials such that f0 = P, f, = P’, and such that for each i > 1, -fi is the remainder obtained by dividing fiP2 by fi- ,. For this sequence there plainly exists a sequence of quotient polynomials Qi-, (with rational coefficients) such that
fi-2 = Qi-Ifi-1 -A, i> 1,

where the degree of fi is strictly smaller than that of fi- ,. Since P is assumed
to be squarefree, this process must terminate with some constant function
fk. The Sturm sequence has the property that, for any interval [a, b], the
number of roots of P in this interval is S(a) - S(b), where S(x) is the number of sign changes in the sequence [ fo(x), f,(x),. . . , fk(x)].
Next we describe a fast procedure for the computation of the Sturm sequence of a given polynomial P of degree n. At a first glance it might seem that this task will require time at least O(n*), since that many coefficients appear in the polynomials constituting this sequence. However,
by representing the sequence in a more economical way, we can reduce this time to O(n log*n). To do this, we note that the degree of Qi is the difference of the degrees of fi- , and fi. Thus if m, denotes the degree of the quotient Qi, i = l,..., k - 1, the sum of all the mi’s is n. Hence we can
represent the Sturm sequence by the sequence [ fo(x), f,(x), Q,(x), . . . , Qk _ ,(x)1, which involves only O(n) coefficients. Once this representation is
available, we can use it to evaluate the whole Sturm sequence at any given x, as well as the number of sign changes in the Sturm sequence, in time O(n).
To do this, we first compute fo(x), f,(x), and Q,(x) for i = 1,. . . , k - 1 (which requires total time O(n)). Then, using the “backward formulae”

h(x) = Qi(x)h-l(x) -fi-z(x),

i = 2,. . . , k,

the Sturm functions can be evaluated at x in O(n) additional time. For this more efficient evaluation, we simply need all the quotient
polynomials Qi. Up to a sign change, these are exactly the quotients obtained during calculation of the GCD of P and P’. To compute all these
quotients efficiently, we can use the fast polynomial GCD procedure described in [22, Ch. 81. This procedure works as follows. Let a(x), b(x) be two polynomials of degree 4 n. Let the remainder sequence {I;(x)} and the quotient sequence {qi(x)} of a(x) and b(x) be defined so that r,,(x) = u(x),
r,(x) = b(x), ri-l(x) = qi(x)ri(x) + ‘i+,(X), i > 1, and deg(ri+,(x)) < deg(r,(x)). For each i there exists a polynomial 2 X 2 matrix Mi such that

330

SCHWARTZ AND SHARIR

Furthermore, each Mi is the product of matrices of the form

The fast GCD algorithm first computes the two middle elements Q(X) and 5 + ,(x) in the remainder sequence, and then calls itself recursively with 9 (x) and q+ ,(x) to process their remainder sequence, which of course coincides with the rest of the remainder sequence of a and b. To find 5 and q+ ,, the algorithm uses another recursive procedure HGCD which computes the matrix Mj. This second procedure uses the fact (see [22, Lemmas 8.6 and 8.71) that all the quotients qi(x), i < j, depend only on the most significant half of the polynomials CLand b. HGCD thus discards the least significant halves of a and b, thereby obtaining polynomials a’ and b’ of degree at most n/2; it then calls itself recursively to compute the two middle elements 5, and ‘it+, among the first j elements in the remainder sequence of a’ and b’, during which process it also calculates the matrix Mj,. The quotient q,,(x) and the matrix Nj, are then calculated, after which HGCD calls itself once more with 7, and q,+, as parameters to compute the product L of the matricesNjP+,,..., Nj. The matrix Mj is then computed as Mj, . Nj, - L, and recursively returned. This description should make it plain that the algorithm sketched computes all quotients qi(x) appearing in the quotient sequence of u(x) and b(x). With minor modifications, it can therefore be used to obtain the desired efficient representation of the Sturm sequence of a given polynomial. Since the fast GCD algorithm runs in time O(n log2n), this is also the time required for the calculation of the Sturm sequence.
This gives us the following:
THEOREM 2. The number of distinct real zeroes of a polynomial with rational coefficients of degree n, lying in any given interval [a, b], can be found in O(n) arithmetic operations, after preprocessing which requires 0( n log*n) arithmetic operations.
We can now describe a root-isolation procedure as follows. We first compute the Sturm sequence of the given polynomial P, in the manner just described. Next we find an upper bound b and a lower bound u such that all real roots of P lie in the interval [a, b]. For example (see [25]), we can take

b= -u=max 1 +F:i=O,...,

n-l

”

where pi is the coefficient of the ith power of x in P. Let N = S(b) - S(u) denote the number of distinct real roots of P. We perform a binary search of the interval I = [a, b] to find a point c E [a, b] which separates it into two subintervals each containing at least one root of P. It follows from

THE “PIANO

MOVERS”

PROBLEM

331

Mahler’s theorem that such a point will be found after at most 0( n log n) bisections of I, at each of which we have to evaluate S, so that to find c will take O(n210g n) steps. (However, assuming random distribution of the roots of P, the expected number of required bisections will be O(log n), so that c will be found on the average after O(n log2n) steps.) We then apply the same process to each of the intervals [a, c] and [b, c], and continue in this manner until isolating intervals for all the roots of P have been found. Obviously only N < n intervals will have to be processed, so that the whole procedure requires O(n310gn) steps in the worst case, and O(n210g2n) steps on the average; note that these time bounds also dominate the time required for the initial computation of the Sturm sequence.
An alternative, and possibly more attractive, technique for root isolation has been described by Collins and Loos [20], and is based on Newton’s approximation technique. Their technique proceeds inductively by first obtaining root-separating intervals for the derivative of P, making sure that none of these intervals contains a root of the second derivative of P. On any interval in the complement of the union of these intervals P’ has constant sign, so that it is trivial to check whether such an interval contains a root of P. On any of the P’-isolating intervals I, P is either convex or concave throughout I. Hence Newton’s technique will converge (very rapidly) to a root of P in I if such a root exists. This enables one to partition I rapidly into P-isolating intervals which do not contain a zero of P’, thus allowing iteration of the process. More details can be found in [20].
Once any root-isolation procedure is available, we can use it to perform various exact computations in algebraic numbers. Before describing efficient procedures for such computations, we first note a simple but useful generalization of Sturm’s theorem. Specifically, let A(x) and B(x) be two given polynomials, where A is squarefree. Form the generalized Sturm sequence of A and B (which, up to sign changes, coincides with the remainder sequence of A and B) as follows. Put fO(x) = A(x), f,(x) = B(x), and, for each i> 1,

so that the last element in this sequence will be the GCD of A and B. Let
S(x) denote the number of sign changes in the sequence &(x), . . . , f,Jx)]. As in the case of standard Sturm sequences, it is easy to see that each time we cross a zero of some function L(x), i > 1, S(x) remains unchanged. However, each time we cross a zero x0 of f0 = A from left to right, S(x) decreases by sign(d’(xO) B(x,)). (It is easy to check that this statement remains true even if x0 is a zero of B(x).) Hence, in any given interval
Ia, bl,
S(a) - S(b) = zsign(d’(x)B(x)),

332

SCHWARTZ AND SHARIR

where the summation extends over all distinct roots of A lying in (a, 6). (In the case of a standard Sturm sequence, B(x) = A’(x), so that the above sum is equal to the number of distinct real roots of A in (a, b).)
In particular, if the interval (a, b) is known to contain just one root r of A(X), then S(a) - S(b) is 0, 1, or - 1, depending on the signs of A’( r ) and
B(r). Since A has been assumed to be squarefree, the sign of A’(r) is easily calculable from the signs of A(u) and A(b). Hence the sign of B(r) can also be calculated. That is, given an algebraic number r, represented as the ith
root of a squarefree polynomial A, for which an A-separation of the real line is available, and another polynomial B, we can find the sign of B(r). (Note that (an efficient representation of) the generalized Sturm sequence can be
computed and evaluated using precisely the same techniques prescribed for standard Sturm sequences.) This technique improves that described by Rump [21].
This generalized Sturm technique is applicable to a variety of other problems. For example, we can use it to determine the multiplicity of the real roots of a given polynomial P. To do this, we first compute the squarefree part P* of P, and then isolate the real roots of P* (i.e., the distinct real roots of P). For each root r of P, we use the above
procedure to determine sign P’(r). If this is nonzero, then r is a simple root. Otherwise r has multiplicity 2 at least; we then repeat our procedure to find the sign of P”(r), and so on, until a nonzero sign is obtained, from which the multiplicity of r is immediately calculable. Using this technique, the multiplicities of all real roots of a polynomial of degree n can be found in time O(n210g2n) (assuming that a P-separation is available). Indeed, the
total number of roots is n, and to determine each multiplicity, an 0( n log2n) procedure is applied.
A very similar procedure can be used to compare two real algebraic
numbers a and b, given as roots of the squarefree polynomials P and Q, respectively. To do this, obtain a P-separation and a Q-separation of the real axis, and merge them into one partitioning. Let Z = [c, d] be a P-isolating interval for a, and let J = [e, f] be a Q-isolating interval for b. If Z and J are disjoint, then the manner in which a and b compare is immediately obvious. Suppose then that Z and J intersect. Several cases can arise; we will treat only the case in which c < e c d -Cf, since the other cases can be handled in a similar manner. Since P is squarefree, and since (c, d) contains only one root of P, P(c) and P(d) have different signs. By evaluating the sign of P(e) we can determine whether a lies in the subinterval (c, e) or in the subinterval (e, d) of I. If a lies in (c, e) then we must have a < b. Similarly, if b lies in (d, f) we also have a -C b. In the remaining case, both a and b (but no other root of P or Q) must lie in the interval (e, d). Using the generalized Sturm technique explained above, we can compute the sign of P(b), and this shows at once how a and b compare. As

THE “PIANO

MOVERS”

PROBLEM

333

before, this procedure takes 0( n log2n) time, where n is the maximal degree of P and Q, provided that P- and Q-separations of the real axis are
available. Similar procedures can be used to perform various other exact computa-
tions with algebraic numbers. Suppose, for example, that we need to
compare the sum (or product) of two algebraic numbers a and b to a third such number. One can of course compute a polynomial R(x) having a + b (or ab) as a root. However, it may be undesirable to do this since this can generate a polynomial whose degree is deg(A) . deg( B) (where A(x) (resp. B(x)) is a polynomial having a (resp. b) as a root), and repeated computa-
tions of this sort may result in polynomials of extremely large degrees. To avoid this problem, a recursive symbolic representation of algebraic numbers might be more advantageous: We can specify an algebraic number r either as a polynomial A( r,, . . . , rk) in k other algebraic numbers, or as a root of a polynomial B(x), whose coefficients are algebraic numbers r,, . . . ,
rk; where each of these numbers is in turn represented in this same fashion, until numbers explicitly representable by polynomials with rational coeffi-
cients are finally reached. Such semi-symbolic representations can be used to perform computations of the kind discussed above. Consider the typical problem of determining the sign of an algebraic number r specified in this recursive fashion. Suppose to be specific that r is specified as a polynomial A(r,,..., rk). Let B(rk) = 0 be an equation for rk, and isolate rk as a root of B. Then use the technique explained above to determine the sign of 4r t, . . . , rk), which we regard as a polynomial in rk with coefficients which are algebraic. This will require that we determine the sign of various polynomials in r,, . . . , r,- ,, which we can do by using the same technique recursively.

Fast Algorithms for the Computation of Principal Subresultant Coefficients
Schwartz [ 121 (see also Moenck [26]) describes a variant of the fast GCD algorithm described above which computes the resultant of two polynomials having degrees Q n in O(n log*n) time. Since the Collins decomposition technique involves numerous calculations of resultants and subresultants, it is of interest to note that the algorithm described in [12] can be generalized in a straightforward manner to yield a rather similar fast procedure for the computation of subresultants as well. For the convenience of the reader we will describe the necessary modifications in full detail.
First we recall the definition of a principal subresultant coefficient. Let
A(x) = a,xm + a,,-,xm-’ + ... + a,,

334

SCHWARTZ AND SHARIR

and
B(x) = b,,” + b”-,x”-’ + *** + b,
be two polynomials of degrees m and n, respectively. For 0 Q j d min( m, n), the jth principal subresultant coefficient qi(A, B) of A and B is the (m + n - 2j) x (m + n - 2j) determinant ’

0 0 *-bn 4-1 0 bn bn-,
0 0

%-n+j+

I

. ..

. ..

. . .

am

. ..

.. .

bn-m+j+ 1

. . .

. ..

4l

a2j-n+l a2j-n+2

ai
* * * &j-m+ 1 . . . &j-m+2

. ..

!i

the first n - j rows of which involve coefficients of A, and the last m - j rows of which involve coefficients of B. (Here we use the convention that ai = 0 if i < 0.) As noted earlier, this is precisely the determinant of the linear transformation

T: [u(x), v(x)] + (A(x)U(x) + B(x)%))/x’,
where U is a polynomial of degree n - j - 1, I’ is a polynomial of degree m - j - 1, and where, as usual, the remainder after the indicated division is discarded. Ifj = 0, #j(A, B) is just the resultant of A and B.
Let Q be the quotient obtained by dividing B by A, and let R = B mod A be the corresponding remainder. Suppose that n 2 m, and let k < n - m. By subtracting an appropriate upper row from each lower row in ( * ) we see that tij(A, B) = rC;.(A, B - xkA). Using this last formula repeatedly, it follows that, if both sides of the following equation are considered as (m + n - 2j) x (m + n - 2j) determinants, we have
#j(A, B) = qj(A, Bmod A).

Moreover, expanding the second determinant by minors of the first n - m + 1 rows, we obtain

#j(A, B) = L(A)“-“+‘qj(A,

Bmod A),

where L(A) denotes the leading coefficient of A, and where the determinant

THE “PIANO MOVERS” PROBLEM

335

on the right-hand side is now an (2m - 1 - 2j) X (2m - 1 - 2j) determinant. However, since the remainder B mod A can be of any degree k lower than m, a more appropriate reduction is

#j(A, B) = L(A)“-‘#j(A,

Bmod A)

(1)

where this time #j(A, Bmod A) is an (m + k - 2j) X (m + k - 2j) determinant. To rewrite this in the symmetric form which covers the case m >, n, first note that

$j(A, B) = (-1) (m-j)(n-j)#j(B, A).

(2)

Hence, if m 2 n, and if k is the degree of A mod B, we have

$,(A, B) = (-l)‘“-“‘m-k’L(B)m-k~j(Amod

B, B).

(3)

Finally, if j = m Q n, then

#j(A, B) = L(A)“-“.

(4)

It is also appropriate to put

+$(A, B) = 0.

(5)

if min(m, n) -Cj. Note that the last equality is consistent with the reduction formulae (1) given above, in the sense that #j( A, B) = 0 if either deg(Amod B) <j or deg(Bmod A) <j.
The technique for resultant calculation given in [12] depends only on the
identities (l)-(5) and hence can be adapted to the calculation of principal subresultant coefficients. Fleshing out this summary remark, we shall now present an efficient technique for the simultaneous calculation of all subresultants of a given pair of polynomials P and Q. To this end, we make the following definition.

DEFINITION

3. Let a pair of polynomials w = [P, Q] of degree d, d’

with coefficients in a field F be given, and let d = max(d, d’). Write

P mod Q for the remainder of P upon division by Q. Then the RQ-sequence

RQ(w) of w is the sequence t;, i = d, d - 1,. . . , 0, of quadruples

ti = [[Pi, Qi], ai, bi> Mi],
defined as follows:
(1) Pi, Qi are polynomials, ai is a quantity of F, bi is always + 1 or - 1, and Mi is a 2 x 2 matrix of polynomials with coefficients in F.
(2) t, = [[P, Q], 1, 1, I], where I is the 2 X 2 identity matrix.

336

SCHWARTZ AND SHARIR

(3) max(deg(Pi), deg(Q,)) 2 i 2 min(deg(Pi), deg( Qi)) for i > 0. (4a) If min(deg(Pi), deg(Q,)) < i, then tieI = ti; (4b) Otherwise, if deg(P,) = i, then (dropping remainders in all polynomial divisions) we have
ti-l = [[Pi, Qimod pi], aiei, bifi, nisi],
where n = deg(Qi), k = deg(Q,mod Pi), fi = 1, e, = L(Pi)“-k, and

Ni= [ -h,/p, if];

(4~) Otherwise deg( Qi) = i, and then
ti-1 = [[P,modQi, Qi], aiei, bif,, N,M~],
where m = deg(P,), k = deg(Pimod Q,),

ei = (( - l)iL(Qi))“-“, f, = (-l)“+, and

The following lemma generalizes Lemma 3 of [12].
LEMMA 3. Let w = [P, Q], ti, etc., be as in the preceding definition. Then the sequence RQ( w) has the following properties:
(i) [Pi, Qil = Mi[P, Ql-
(ii) deg(M,) Q d - max(deg(P,),deg(Q,)) G d - i. (iii) For each i d d and each 0 d j d min(deg(Pi), deg(Q,)), Gj(P, Q) = a,tJj(Pj, Qi) if j is even, and Gj(P, Q) = a,bi#j(Pi, Qi) ifj is odd.
ProoJ All this is clear for i = d. A step from ti to tie, via (4a) of the preceding definition clearly preserves the validity of (i)-(iii). Now suppose that rule (4b) applies to the step from tj to t,-,. Property (i) is clearly preserved. Moreover,

deg(Mi-1)

Q deg(Qi) - deg(Pi) + deg(M;) G deg( Qi) - deg( pi) + d - deg( Qi)
= d - deg( Pi) = d - max(deg(Pi-,),deg(Qi-,)).

THE “PIANO MOVERS” PROBLEM

337

Concerning (iii), it follows by (1) and (2) that

if j is even, and similarly if j is odd. Suppose finally that (4c) is used to obtain ti from lie ,. Again, property (i)
is clearly preserved, and property (ii) follows by an argument symmetric to the one used above, in which Pi and Qi are interchanged. Concerning (iii), using (1) and (3) we obtain, assumingj is even,

= ((-lIi'(Qi))

@eg(Pi)-deg(PQ,,))mod
* J/(P,modQi, Qi)

and similarly ifj is odd. This proves the lemma.

Q.E.D.

LEMMA 4. bt w = [P, Q], w* = [P*, Q*] be two pairs of polynomials. Suppose that max(deg( P), deg( Q), deg( P*), deg( Q*)) = d, and suppose that the terms of order not less than d - 2i in P, Q agree with the corresponding terms in P*, Q*. Then the first i + 1 terms of the sequence RQ(w) = [fd, t&,,--- ] have precisely the same components ai, bi, Mi as the corresponding terms a:, b:, h4: of the sequence RQ(w*) = [t$, t$- ,, . . . 1.

Proof. Except for the equality of b, and bf, the proof is completely

identical to that of Lemma 4 of [ 121. The equality of bi and br is also an

easy consequence of that same proof.

Q.E.D.

Lemmas 3 and 4 justify the following principal subresultant calculation algorithm, whose underlying idea is to compute the terms ai, bi, and Mi by
stepping through the sequence [r,] by steps of increasing length, each of length double that of the preceding step. Lemma 4 implies that each of these steps can use polynomials of substantially lower degree than that of the original polynomials. However, as soon as we have calculated ai, bi, and Mi for some i 6 d for which j = deg(Pi) 6 deg(Q,), we can get 1c;.(P, Q) directly. Indeed, using (4) and Lemma 3(iii), we have

I1;(f’, Q) = ai+j(P,, Qi)
= ai . L(pi)(deg(QJ-j),

if j is even, and similarly if j is odd (and of course analogous formulae are

338

SCHWARTZ AND SHARIR

available if i = deg(Q,) < deg( Pi).) Note that if li * tit then ~n(deg(Ci), deg(Qi)) * min(deg( Pi,), deg(Q,,)), so that for each j either there exists no i for which j = min(deg(Pi, Qi), or the i’s for which this equality holds all have the same value ti, and hence the above formula defines Itj unambiguously. Observe finally that, by (5), all qj which do not appear in the above formula for any value of i are 0.
In view of these comments, the algorithm proceeds as follows. Initialize four static lists, AL, BL, CL, and DL to the null list each.
(1) Call an auxiliary routine HSBRSL(P, Q, 0), with final parameter I = 0. This routine will build up the first half of the RQ-sequence [ti], for
d 2 i > d/2 = d’, and will return the quantities ed’, fd,, and Md’.
(2) Compute [Pa, Q&l = Mdf[Pd, Qdl.
(3) Let m = deg(P,,), n = deg(Q,,). If m < n then append the quanti-
ties ed,, fdr, L(P,,)“-“, m respectively to the end of the four lists
AL, BL, CL, DL. Similarly, if m >/ n then append the quantities
ed’yfd’, L(Q&)“-“, n, to the end of these four respective lists.
(4) Call the whole procedure recursively, passing Pd’, Q# to it as inputs to complete the construction of the whole sequence.

The subprocedure HSBRSL( P, Q, /) required is rather similar to the auxiliary procedure HGCD used in the fast polynomial GCD algorithm in [22]. It consists of the following steps.
(1) Discard the least significant half of the coefficients of P and Q; that is, let P = P*xk + P’, Q = Q*xk + Q’, where k = max(deg(P), deg(Q))/2, and where deg( P’), deg(Q’) < k.
(2) Apply HSBRSL to P*, Q*, and 1 + k, to obtain ek’, fkl, and Mk, for
k’ = 3k/2 (by Lemma 4, these are the same as the corresponding quantities associated with the original P and Q).
(3) COInpUte [Pk’, &] = ikfkf[P9 Q]. (4) As in step (3) of the main procedure, let m = deg( Pk,), n = deg(Qk,). If m d n then append the quantities ek’, fk’, L(Pkr)“-“, m + 1, to the end of the four lists AL, BL, CL, DL respectively. Similarly, if m > n then append the quantities eke,fkt, L(Qk,)“-“, n + I, to the end of these four respective lists. (5) Let Pkp = Pk*,xk” + P”, Qk, = Q$xk” + Q”, where k” = k/2, and where deg( P”), deg( Q”) c k”. (6) Call HSBRSL with PC, Qj$, and I + k”, to obtain e:, fz, and Mz.
(7) Return e:, fk*, and Mk* * &fk’.
When the algorithm just sketched has terminated, we can perform one final

THE "PIANO MOVERS" PROBLEM

339

scan through the lists AL, BL, CL, and DL, to accumulate the scalar quantities a, by bi by repeated multiplication of the ei’s and the h’s, respectively. Using the following technique we can also calculate all the principal subresultant coefficients Gj. For each iteration step k, let yk, mk be
the k th components of CL and DL, respectively, and let uk- i and b,- , be the product of all preceding components in the lists AL and BL, respectively. If mk is even, put

and if mk is odd, put

At the end of this final iteration, all remaining undefined subresultants are
set to 0. The computational cost of the procedure just sketched is evidently the
same as the original procedure given in [12]. To estimate this cost we note that multiplication and division of polynomials of order m can be accom-
plished in time O(m log m). During each call to the subprocedure HSBRSL(P, Q, I) that we have just described polynomials of order at most
m = maNdeg(P), d&Q)) need to be multiplied and divided (at steps (3)
and (7)). The total time T(m) required to apply HSBRSL to two polynomials of degree m therefore satisfies T(2m) = 2T( m) + 0( m log m) and hence
has the bound T(m) = O(m log*m). Similar considerations show that the time used by the main procedure to build up the RQ-sequence has the same bound, so that this estimate also bounds the time required to calculate all the subresultants of two polynomials of maximal degree m.

APPENDIX

C: ADJACENCY OF COLLINS CELLS OF GENERAL DIMENSION

In this appendix we complete our calculation of Collins cell adjacency by considering cells whose dimension is less than that of the whole space E’
being decomposed. The problem here is to determine when a Collins cell c’ of dimension k - 1 is a face of a cell c of dimension k < r. Our approach will again be based upon consideration of the base decomposition K’ of K.
However, the present case is somewhat more complex than the case k = r considered previously, and this makes it necessary to use a bit more (largely classical) machinery drawn from the theory of algebraic curves. Accordingly, we recall the following definitions and lemmas, for which see Keller [27, Ch. 51.

340
DEFINITION
form

SCHWARTZ AND SHARIR
1. (a) A fractional (La went) series is a formal series of the

y(x) = E aix’/o

0)

i=m

whose coefficients are complex numbers, and in which D is an integer. Such a series is said to be convergent if it converges in the neighborhood of x = 0. Note that we allow m to be negative. The series (1) is said to be truncated if it contains only finitely many terms.
@I If a, * 0, then m/D is called the lkading exponent of the series y. (c) If the leading exponent e of the series (1) satisfies e > k (resp. e > k), we will writey = 0(x“) (resp.y = o(x~)).

It is easily seen that the standard definitions of addition, multiplication, etc., for power series make the collection of all fractional series into a field. This statement, like many others made in the next few paragraphs, is true irrespective of whether we consider convergent fractional series only, or allow arbitrary, nonconvergent series, and treat operations on them in a purely formal manner. Moreover, this statement remains true even if the coefficients of the series (1) are required to lie in some subfield of the complex numbers.
In what follows we will designate the field of fractional power series by
Fr.

LEMMA 1 (see [27, Ch. VI). The field of fractional series with complex (or with algebraic) coefficients is algebraically closed.

Thus if P(y) = any’ + . . . + a, is a polynomial in y with coefficients in the field Fr and if a, f 0, P can be factored as

P(Y) = a,(r - r,)... (y - r,),
where r,,..., r” are themselves fractional series, namely, the roots of P(y) = 0.
In what follows we will need to work in purely finite manner with fractional series representing the roots of various polynomials. Our ability to do so without ambiguity will rest upon various extensions of the following simple lemmas, which are also noted by Kung and Traub [28].
LEMMA 2. Let P(x, y) be a polynomial with complex coefficients in two variables, of total degree d > 0. Let its degree n in y be nonzero, and suppose that, when regarded as a polynomial P,.. y) in y, P has no factor in common with its y-derivative P:(y) and has a leading coefficient a,(x) which is not

THE “PIANO MOVERS” PROBLEM

341

zero for x = 0. Regard P,(y) as a polynomial in y with coefficients in Fr, and let rl(x),. . . , r,,(x) be its roots (which are elements of Fr). Then
(a) If I;(x) - q(x) = O(X~(*~-~)), then i =j.
(b) We cannot have Pi(ri(x)) = o(xd(*“-‘)) for any root r;(x).
Prooj: Consider the discriminant D(x) of the polynomial P,(y), i.e., D = Res(P,, Pi) is the resultant of P, and Pi. This is a polynomial of degree d(2n - 1) in x, and since P, and Pi have no factor in common it is nonzero. Hence D(x) = o(x~(*~-‘)) is impossible. By well-known identities (see [29, Sections 30 and 31]),

(3)

and also

D(X) = IIIPi(I;:(x>). i*j

Since the leading coefficient of y in P,(y) does not vanish at x = 0, it is

easy to see (by substitution) that no fractional series r(x) with negative

leading exponent can satisfy P,.(r(x)) = 0. Hence I;:(x) = O(1) for all i, and

therefore if assertion (a) of our lemma were violated, (3) would imply that

D(x) = o(x d(2n- ‘)), which is impossible. If we use (4) instead of (3) in this

argument, (b) follows in the same way.

Q.E.D.

LEMMA 3. Let P,.(y) = a,(x)y” + a,-l(x)y”-l

+ ... + a,(x) be a

polynomial in y, of degree n, with coefficients in Fr, and suppose that a,,(x)

does not vanish at x = 0. Let k 2 1, and let y,, = C~X’/~ be an element of Fr

such that P,(y,(x)) = O(xnk). Then there exists a root r,(x) of P,(y) = 0

such that yO(x) - ri(x) = 0(x“).

Proof. Factor P,(y) in the manner (2). Then it is plain that if y0 - ri has

leading exponent less than k for all i, the leading exponent of P,.. y,,(x))

must be less than nk, contradicting our assumption.

Q.E.D.

Lemma 3 asserts that any power series y,, which comes close enough to making P,( yO) equal to zero must lie quite close to a root of P,. It is also
worth noting that if P,.. y) has no repeated roots, then, once P,( yO) has been made small enough, any desired number of coefficients of a root of P,(y) = 0 can be calculated rapidly from the coefficients of y, by purely rational operations. A technique for calculating fractional power series which approximate each of the roots of P,(y) near x = 0 to an arbitrary degree of precision is described by Kung and Traub [28]. Their technique first uses the Newton’s polygon method to obtain an initial (truncated) fractional series approximation for each of the roots of P,, and then uses a

342

SCHWARTZ AND SHARIR

variant of Newton iteration (similar to that described by Lipson [30]) to extend each of these series to an arbitrary degree of precision. Kung and Traub give a complexity bound of O( nN log N) for their procedure, where n is the y-degree of the polynomial P,, and where N is the number of terms sought in each fractional series. This bound holds asymptotically if n is held fixed and N increases, but it ignores the cost of applying the Newton polygon procedure (which indeed is independent of N) in order to obtain the initial collection of terms required to ensure convergence of Newton’s approximation method. At present our best estimates of this cost are still exponential, leading us to pose the following:
Open problem. Given a polynomial P(x, y) with complex coefficients, of y-degree n and total degree d, does there exist a procedure for calculating truncated fractional series approximations for each of the roots of P(x, y) (regarded as a polynomial in y) near x = 0 up to terms of order 0( xdc2+ I)), in time polynomial in n and d?
As will become clear from the subsequent discussion, an affirmative answer to this problem would imply that adjacency of Collins cells of general dimension, and hence also the homology groups of any algebraic variety, can be calculated in time polynomial in the number and the maximal degree of polynomials defining a Collins decomposition (or an algebraic variety).
At any rate, once these fractional power series are available, we can use them to determine the adjacency of Collins cells. It is worth explaining what is involved by commenting briefly on the special case r = 3. Let K’ be the 2-dimensional base decomposition of a well-based Collins decomposition K of E3 whose base polynomial is P(x, y, z). Let c be a l-dimensional curved cell in K’, and let c’ = [xc, ~a] E K be an endpoint of c. Let Q(x, y) be the base polynomial of K’. It follows from the preceding discussion that in the vicinity of c’ the curve c can be specified uniquely by a truncated fractional series y(x) which approximates the corresponding root of Q(x, y) near (x,,, ya). If enough leading terms of this fractional series are known, then, to determine the number of roots of P(x, y, *) into which a given root z0 of P(x,, ya, z) = 0 splits as we move from (x0, y,,) into c, we can substitute the curvey(x) fory in P, thus obtaining a polynomial R,(z) = P(x, y(x), z) in z with coefficients in Fr. Then, using a Sturm-based technique of the sort described in Appendix B, we can determine the number of roots of R, into which z,, splits for sufficiently small positive x. We can also compute truncated fractional series approximating each of these roots, and this enables us to carry the same form of analysis inductively to cases involving more than three variables.
However, several technical difficulties must be overcome in following this conceptual approach. First of all, Lemma 2 is not immediately applicable to

THE -PIANO MOVERS" PROBLEM

343

R,, since the coefficients of R, are not simply polynomial but he in Fr; moreover R, need not be squarefree. This makes it a little harder to state how many terms of a fractional series suffice to characterize a root of R,. z) uniquely. Also, the truncated fractional series y(x) gives only an approximate representation of the root of Q which traverses the curve c, and at first glance it is not clear how many terms need be included in y(x) to guarantee that the analysis we have outlined will carry forward inductively.
To overcome these purely technical difficulties, it is useful to consider systems of polynomial equations in several variables having the form specified in the following definition.
DEFINITION 2. (a) A triangular manic systemof polynomial equations is a system

p,(x,,x*,..., XJ = 0
of polynomial equations of total degrees d,, . . . , d, with complex coefficients, whose jth equation involves the variables x,, . . . , “j only, and which, regarded as a polynomial in xj with coefficients polynomral in the remaining variables, has a constant leadmg term. The sequence d,, . . . , d, is the degree sequence of the triangular system (5).
(b) Given the triangular monk system (5) its resultant system is the sequence
&(x,9 x*)9 R~(x,,xj), .... Rn(xl,xn) (6)
of bivariate polynomials defined as follows. R, is simply P2. R, is obtained from P3 and Pz by regarding them both as polynomials in the variable x2 and forming their resultant. More generally, to form Rj(x,, xi) proceed as follows: Regard Pj(x,, . . . , xj) and P,- ,(x,, . . . , xj- ,) as polynomials in xj- ,, and form their resultant, thus obtaining a polynomial Q,(x,, . . . , xjd2, xj) from which the variable xi-, has been eliminated. Then form the resultant Q, of Q, and Pjv2 (as polynomials in xjP2), obtaining a polynomial from which both variables xi-* and xj-, have been eliminated. Continue repeatedly in this way, thus finally obtaining the desired polynomial Rj = Qjm2, from which all variables but x, and xj will have been eliminated.
(c) The sequence a,, . . . , S,,of degrees of the resultant polynomials (6) is called the resultant degreesequenceof the triangular system (5).

344

SCHWARTZ AND SHARIR

DEFINITION 3. (a) A solution curve of the triangular manic system (5) is a continuous vector-valued function f(t) = [ f2( t), . . . , f,(t)] with complex components defined for all sufficiently small nonnegative values of the parameter t, such that for allj = 2,. . . , n we have Pj(t, f2(t),. . . , h(t)) = 0.
(b) Let 5 and f be as in (a), let d = [d2,. . . , d,] be a sequence of rational numbers, and let (Y= [(Ye,. . . , a,] be a sequence of truncated fractional series in the variable t, such that oj contains terms of order 0( tdj)
at most. Then a is said to be an order d descriptor of the solution curve f if
f, - oj = O(tdj) for allj = 2,..., n. Our aim is to generalize Lemmas 2 and 3 to general triangular monk
systems of more than two variables. For this, we need the following straightforward technical lemma, whose main purpose is to enable us to bound the order of finite descriptions of solution curves of (5) needed to characterize such a solution uniquely.
LEMMA 4. As in Definition 3, let P2,. . . , P,, be a triangular manic system andlet R2,..., R, be its resultant sequence. Then each Rj can be factored as

where A, R;, and RJ are all polynomials in their respective variables, and where Rj is the squarefree part of Rj (regarded as a polynomial in xj) represented by a polynomial whose coefficients (which are polynomials in x,) have no common factor. Moreover, we can arrange this factorization so that
the leading coefficient C(x,) of RT does not vanish at x, = 0.
Proof As in Definition 2, regard Pj(x,, . . . , xi) and pi- ,(x1,. . . , xi- ,) as polynomials in xj-, with polynomial coefficients, and form their resultant Q,. If we use the fact that Pi-, is monk in xi- i, it follows from the fundamental theorem of resultant theory that a tuple [x,, . . . , xj-*, xj] is a solution of the system P, = P2 = - * * = q- 2 = Q, = 0 of equations if and only if there exists an xi-, such that [xi,. . . , xi-*, xj- ,, xi] is a solution of the system Pi = 0, i = 2,. . . , j. Arguing repeatedly in this way, we see that [x,, xi] is a solution of the equation Rj(x,, xj) = 0 if and only if there exist Xl,..., xj- , such that [x,, x2,. . . , xj]isazeroofPif0ralli=2,...,j.0n the other hand, it follows since each Pi is monk that all the solutions of the system Pi = 0, i = 2,..., j which lie over a small neighborhood of the point x, = 0 remain bounded. Thus all the solutions of Rj(x,, xi) = 0 over such a neighborhood have the same property.
Next regard Rj as a polynomial in xj, take its (xj - ) derivative Rj, form T’ = GCD(Rj, RJ), and use it to factor Rj as Rj = TOT’. These are polynomials in xi with coefficients rational in x, but then by multiplying through by an appropriate polynomial C(x,) we can write CR, = S’S’, where now So and S’ have coefficients which are polynomials in x,. Since

THE “PIANO MOVERS" PROBLEM

345

the ring of polynomials in two variables is a unique factorization domain, every prime factor of C divides one of the polynomials on the right, which is to say, divides all its coefficients. This remark allows us to divide through by all these prime factors, and if we then collect all common factors of the coefficients of R” and R’ in A(x,), we arrive at the factorization (7).
It is now clear that all the solutions [x1, xj] of RT = 0 which lie over a sufficiently small neighborhood of x , = 0 have second components xj which remain bounded. By Lemma 1, these solutions T,(x,),. . . , TV can be written as fractional power series C,,,,+X,X;/~, and since they remain bounded near x, = 0 none of these fractional series contain any term with negative exponents. Suppose that the leading coefficient a,(~,) of Ry vanishes at x, = 0. Then since R/” can be factored as

R~(x,,Xj)= a,(X,)n(Xj - ri<X,>),

it would follow that all the coefficients of R; vanish at x, = 0. But then x,

would be a common factor of all coefficients of Ry, contrary to the way in

which Ry has been defined.

Q.E.D.

COROLLARY. Let thepolynomials I$ j = 2,. . . , n form a triangular manic system, and let the resultant degree sequenceof this triangular system be f&Y.. -9 S”]. Put
d= [6,(26, - l),..., 6,,(2S, - l)].

Then any two solution curves f(t), g(t) of this triangular system which have
identical order d descriptors are identically equal for all sufficiently small nonnegative values of t.
Proof Let R, be the resultant system of the triangular system 5. Arguing as in the proof of Lemma 4, we can conclude that the components f, off satisfy Rj(x, h(x)) = 0, and similarly for the components of g. Our assertion is therefore an immediate consequence of Lemmas 2 and 4. Q.E.D.

DEFINITION 4. Let q. and Sj be as in the preceding corollary, let d = [d,,..., d,] be the degree sequence of the pi, and define d* = maj,2...,,d2d3 * * . djaj(2Sj - 1). Put d;” = d*/(d, . . . d,) for j = 2, .: . , n (so that d; is a decreasing sequence of positive rational numbers). Suppose that for j = 2,..., n aj(x) is a truncated fractional series such that there exist auxiliary truncated fractional series a;(x) (all of whose exponents can be assumed to be < d:) such that pi(x, a:(x),. . . , a;(x)) = O(xdY-l) and aj(x) - a;(x) = O(xd;). Then a = [a2,. . . , a,,] is called an adequate descriptor for a solution of the triangular system P2 = . . . = P,, = 0 of equations.

346

SCHWARTZ AND SHARIR

LEMMA 5. Let d, d*, and 6 be as in the preceding definition. Given any adequate descriptor a = [ a2,. . . , a,,] for a solution of the triangular system (5), then for all sufficiently small t there exists a solution f(t) = [ f2( t ), . . . , f,( t )] of the system Pj(t, f2(t),. ..,fi(t)) = 0,j = 2,. . ., n such that

fi(t) - ai = O(tsj(*‘j-I)).

(8)

Prooj Use the notations of Definition 4. We proceed by induction on j to establish the existence of a solution curve f = [f2,. . . , f,] which satisfies the formula

h(t) - ai = O(tdy),

(8’)

forj = 2,..., n. By definition of the d; it is plain that (8’) implies (8). The base casej = 2 for our induction is immediate from Lemma 3. Suppose that we have already shown the existence of f2( t), . . . , fi- ,( t) such that
pict, f*(t),. ** 3fi( t)) = 0 for i = 2,. . . , j - 1, and such that (8’) holds for all such i. As in Definition 4, there exist auxiliary fractional series a;(t) such that Pj(t, a,(t),. . . , aj(t)) = 0(&l) and at(t) - ai = O(td:) < O(tdT-l) (since the dr are decreasing). Thus by (8’) we have at(t) - fi(t) = 0( t d;- I), from which we see immediately that

p,(t, f*(t) ,..., h-,(t), a;(t)) = O(t”;-I).

Hence by Lemma 3 there exists a root fi(t) of this same equation such that

fi(t) - a;(t) = O(t(dT-l/dj)) = O(td;) for small t, from which (8’) is plainly

seen to hold forj too.

Q.E.D.

COROLLARY. Let$f = [f2 ,..., f,],anda = [a2 ,..., a,]beasinLemma 5. Suppose that all the polynomials 5. have real coefficients. Then fj is real if and only if all the nonzero coefficients appearing in aj are real.

Proof Since all Pj are real, the whole situation being considered is

invariant under complex conjugation. Thus the curve f = [f,, . . . , f”] is also

a solution curve of the system Pi, and z = [E2,. . . , Zn] is an adequate

descriptor for j. It is plain from Definition 3 and from the corollary to

Lemma 4 that f = f if and only if a = Z, from which the present corollary is

immediate.

Q.E.D.

Our preparation is now sufficient for computations of the topological relationships which interest us to be feasible. The following definition takes the next step in this direction.

THE “PIANO MOVERS” PROBLEM

341

DEFINITION 5. Let K be a Collins decomposition of the Euclidean space E r, let c be a d-dimensional cell in K, and let c’ E K be a (d - I)-dimensional face of c. Then an incidence curne for the pair c, c’ is a triple consisting of
(i) a triangular manic system P2,. . . , P,,, of m polynomials with real algebraic coefficients,
(ii) a continuous solution curve f(t) = [f,(t), fi(t), . . . , f,(t)], all of whose components are real, such that f(t) E c for all sufficiently small nonnegative t, and such that f(0) E c’ [all constant components of the vector f must be algebraic numbers, and its nonconstant components J;,w,. *. 9h,(t), which for convenience we shall write in left-to-right order as g,(t),..., g,(t), must satisfy q(g,(t) ,..., g,(t)) = 0 for j = 2,..., m; moreover, g,(t) must have the form g,(t) = t + 2, where 5 is an algebraic number];
(iii) an adequate descriptor (Yfor the solution g,, . . . , g, of the triangular manic system P2 = - - . = P,,, = 0 [This (finite) descriptor will be used to represent the nonconstant components of the curve f in finite terms in a unique manner].

Our aim is to carry such a family of incidence curves through the whole

inductive construction of the Collins decomposition, and at each stage to

use them to determine which (d - I)-dimensional cells c’ are faces of a

given d-dimensional cell c. To this end, let K be a well-based decomposition

of E’, and let K’ be the base decomposition of K. Suppose inductively that

for each cell b of K’ and each of its faces 6’ of one less dimension an

incidence curve for the pair b, b’ is available. Let c be a d-dimensional cell

of K, and let c’ be one of its faces. Then, by Lemma 3 of Section 2, either

c=bT forsomebEK’andc’=bjorc’=bj+,,orc=bj*

andc’=b;

where b’ is a (d - 2)-dimensional face of (the (d - l)-dimensional) cell b,

or c = bj and c’ ,= bJ where 6’ is a (d - 1)-dimensional face of (the

d-dimensional) cell b.

Let P(x,,..., xr) be the base polynomial of K; since K is well-based, the

leading coefficient of P (regarded as a polynomial in x,) is constant. If

c = by and c’ = cj, then we can take [[,, . . . , S,- ,] to be any algebraic point

in b, and then if 5; is the jth root of P({,,. . . , lr-,, x,) we can put

f(f) = IS,,..., lr;- ,, 5; + t], thereby defining an incidence curve. Of course, an entirely similar construction yields an incidence curve for the pair

bj*v bj+ 1’

Next suppose that c = b: and c’ = b;*, where b’ is a (d - 2)-dimensional
face of b. Let f’ = [f,(t) ,..., f,- ,( f )] be an incidence curve for the pair

b, b’, let g,(t) = 3 + t, g2(t),. . . , g,,,(t) be the nonconstant components of this curve, enumerated in left-to-right order, and let P2,. . . , P,,, be the

associated triangular manic system of polynomials. Put Sj = l;(O) for j =

348

SCHWARTZ AND SHARIR

1,***, r - 1, so that the point 2 = [[, , . . . , [,- ,] is an algebraic point in b’. Let P be as in the preceding paragraph, let TJ be the Jth real root of

fYl ,,...,Sr-l,Y)=O(

or a sufficiently small rational number if J = 0), and

let q’ be the (J + 1)st root of this same equation (or a sufficiently large

rational number if this equation has only J real roots). Put [, = i(n + q’),

mdf(t) = [f,(t),..., f,- I(t), [,I. This is plainly an incidence curve for the pair c, c’, whose nonconstant components are plainly the same as those of

f’. We have an adequate descriptor for the nonconstant components off’,
and plainly this can also serve as an adequate descriptor for f.

Finally, suppose that c = bj and c’ = b;, where b’ is a (d - l)-dimensional

face of b. Again, let f’(t) = [f,(t) ,..., f,-,(t)],[P2 ,..., Pm-,], and a’ =

[a 2,. . . , a,- ,] be an incidence curve for the pair b, b’. As in Definition 5, let g,,..., g,,-, be the nonconstant components off’, so that g,(t) = t + 5

where 3 is algebraic, and put a,(t) = t + 5 for convenience. Extend the

truncated fractional series gi, j = 2,. . . , m - 1 to series a? such that

gj - a? = O(tD), where D WIU be chosen below. Let P be the same base

polynomial as in the two preceding paragraphs, let d be its degree, and let

P* be the polynomial obtained from P by replacing each variable xi in it for

which fi(t) = Sj is an algebraic constant by lj. Clearly, the degree of P* is at

most d. Having P*, we can then find all distinct real roots y,, . . . , yI of the

equation P*( a,(O), . . . , a,- ,(O), y) = 0 and arrange these solutions in in-

creasing order. By Lemma 2 of Section 2, these roots are in l-l correspon-

dence with the sequence of “section” cells b; of K whose base cell is b’.

Next, for each such yk, we can find all the fractional series solutions of the

manic equation P*( a:(t), . . . , a:- ,(t), y) = 0 whose constant term is y,;

all terms of these series up to those of order to must be constructed. Let

a(t) designate any one of the truncated fractional series constructed in this

way. Since gj - a? = O(tD) for j = 1,. . . , m - 1, we have P*( g,(t), . . . ,

g,- ,(t), a(t)) = 0( tD) and thus by Lemma 3 there exists a solution g of

p*(g,(t),..., g,-,(t), g(t)) = 0 such that a(t) - g(t) = O(tDid). Append

the polynomial P* to the triangular monk system P2,. . . , Pmpl, thus

obtaining a larger system P2,. . . , P,,,, and let R,,. . . , R, and S,,. . . , 8, be

respectively the resultant system and the resultant degree sequence of this

extended system. Arguing as in the first paragraph of the proof of Lemma 4,

we see that R,(g,(t), g(r)) = R,(t + {, g(t)) = 0. Hence if we choose

D = da,,, (26, - 1) it follows by Lemma 2 that this equation, together with

the truncated fractional series a and the relationship g - a = O(tDid),

determine g uniquely, and in particular (arguing as in the proof of the

corollary to Lemma 5) that g is real for t 2 0 if and only if all the

coefficients of the fractional series a are real.

Dropping all those fractional series a which involve any nonreal coeffi-

cient, we can then go on to append any of the remaining a to al,. . . , a,- ,,

thereby obtaining an adequate descriptor for the nonconstant components

THE “PIANO MOVERS" PROBLEM

349

of the curvef= [f,,..., f,- r, g], where g is the unique (real) solution of R,(t + {, g(r)) represented by a. Let us agree to compare any two fractional series b(t), y(t) with real coefficients by comparing coefficients of like terms lexicographically; this is equivalent to agreeing that /I Q y if /I?(t) d y(t) for all sufficiently small nonnegative f. Then it is plain that for each yk the real solutions of P*(g,(t),..., g,-,(t), g(t)) = 0 are in l-l ordered correspondence with the truncated fractional series a which we retain and which satisfy a(0) = y,. The number of such series is therefore the number of distinct real roots into which the root y, of P(f,, . . . , {,- ,, y) = 0 splits as f’(t) moves from the point f’(0) = [l,,. . . , S,-,] of b’ to immediately neighboring points inside b. The sequences P2,. . . , P,,- ,, P*, g13.m*,g,-l,g, and q,..., q,-I, (Yclearly define incidence curves for all pairs of cells having the form bj, b;, such that the latter is part of the boundary of the former.
This finishes our inductive construction of incidence curves, and also shows how the information on root splitting needed to determine the mappings p( b, b’), defined in the paragraph preceding Lemma 3 of Section 2, can be calculated; so that description of a technique for testing the adjacency of Collins cells of general dimension is now complete.
Remark. Given two Collins cells and Tarski sentences defining each of them, we can easily write a quantified Tarski sentence which is true if and only if they are adjacent. Thus in principle we can obtain an adjacency-testing algorithm using standard decision procedures for Tarski sentences. However, since the number of quantified variables required to define adjacency of Collins cells in this way can be large (compare, e.g., the explicit Tarski sentence defining a Collins cell given at the end of Appendix A), this technique will probably be much less efficient than that described in the present appendix.

ACKNOWLEDGMENT
The authors would like to thank Professor Dennis Amon, Purdue University, for his generous help during the preparation of this paper.
REFERENCES
1. J. REIF, Complexity of the mover’s problem and generalizations, in Proceedings, 20th Symposium on the Foundations of Computer Science, pp. 421-427, 1979.
2. T. LOZANO-PEREZAND M. WESLEY,An algorithm for planning collision-free paths among polyhedral obstacles. Comm. ACM 22 (1979), 560-570.
3. M. B. IGNAT’YEV, F. M. KULAKOV, AND A. M. POKROVSKIY,“Robot Manipulator Control Algorithms,” Rep. No. JPRS 597 17, NTIS, Springfield, Va., 1973.

350

SCHWARTZ

AND SHARIR

4. S. UDUPA, “Collision Detection and Avoidance in Computer-Controlled Manipulators,” Ph.D. dissertation, California Institute of Technology, Pasadena, 1977.
5. J. SCHWARTZ AND M. SHARIR, On the “piano-movers” problem. I. The case of a two-dimensional rigid polygonal body moving amidst polygonal barriers, Computer Science Tech. Rep. 39, Courant Institute, New York University, Comm. Pure Appl. Math., in press.
6. A. TARSKI, “A Decision Method for Elementary Algebra and Geometry,” 2nd ed. rev., Univ. of California Press, Berkeley, 1951.
7. G. COLLINS, Quantifier elimination for real closed fields by cylindrical algebraic decomposition, in “Second GI Conference on Automata Theory and Formal Languages,” Lecture Notes in Computer Science, Vol. 33, pp. 134-183, Springer-Verlag, Berlin.
8. D. S. ARNON, “Algorithms for the Geometry of Semi-algebraic Sets,” Tech. Rep. 436, Computer Science Department, University of Wisconsin, Madison.
9. G. E. COOKE AND R. L. FINNEY, “Homology of Cell Complexes,” Mathematical Notes, Princeton Univ. Press, Princeton, N.J., 1967.
IO. H. HIRONAKA, Triangulations of algebraic sets,in “Proceedings, Symposia in Pure Math,” Vol. 29, pp. 165-185, Amer. Math. Sot., Providence, R.I., 1975.
I 1. D. LAZARD, Algebre lineaire sur K [ X,, . . , X,,] et elimination, Bull. Sot. Math. France 105 (1977), 165-190.
12. J. T. SCHWARTZ,Fast probabilistic algorithms for verification of polynomial identities, J. Assoc. Comput. Mach. 27 (1980), 701-717.
13. P. KAHN, Counting Types of Rigid Frameworks, Invent. Math. 55 (1979), 297-308. 14. B. L. VAN DERWAERDEN,“Algebra,” 5th ed., Springer, Berlin, 1960. 15. W. R. HAMILTON, “Elements of Quatemions,” Chelsea, New York, 1969. 16. W. S. BROWN AND J. F. TRAUB, On Euclid’s algorithm and the theory of subresultants, J.
Assoc. Comput. Much. 118 (1971), 505-514. 17. D. S. ARNON, “Automatic Analysis of Real Algebraic Curves,” Tech. Rep., Computer
Science Department, Purdue University (see also ACM S&sum Bull. 15, No. 4 (1981), 3-9). 18. A. G. AKIUTAS, The fastest exact algorithm for the isolation of the real roots of a
polynomial equation, in “Computing,” Vol. 24, pp. 299-3 13, 1980. 19. L. E. HEINDEL, Integer arithmetic algorithms for polynomial real zero determination, J.
Assoc. Comput. Much. 22 (1971), 533-549. 20. G. E. COLLINS AND R. Loos, Polynomial real root isolation by differentiation, in
SYMSAC 76 (Proceedings, 1976 ACM Symposium on Symbolic and Algebraic Computations, Yorktown Heights, N.Y.), pp. 15-25, 1976. 21. S. RUMP, On the sign of a real algebraic number, in SYMSAC 76 (Proceedings, 1976 ACM Symposium on Symbolic and Algebraic Computations, Yorktown Heights, N.Y.), pp. 238-241, 1976. 22. A. AI-IO, J. HOPCROFT,AND J. ULLMAN, “The Design and Analysis of Computer Algorithms,” Addison-Wesley, Reading, Mass., 1974. 23. K. MAHLER, An inequality for the discriminant of a polynomial, Michigan Math. J. 11 (1964), 257-262. 24. M. MIGNOTTE, Some problems about polynomials, in SYMSAC 76 (Proceedings 1976 ACM Symposium on Symbolic and Algebraic Computations, Yorktown Heights, N.Y.), pp. 227-228, 1976. 25. M. MARDEN, “The Geometry of Zeroes of a Polynomial in a Complex Variable,” Mathematical Surveys, Vol. 3, Amer. Math. Sot., Providence, R.I., 1949. 26. R. MOENCK, “Studies in Fast Algebraic Algorithms,” Ph.D. dissertation, University of Toronto. 27. 0. H. KELLER, “Vorlesungen Uber Algebraische Geometrie.” Akademische Verlagsgescllschaft, Geest & Portig, Leipzig.

THE “PIANO

MOVERS”

PROBLEM

351

28. H. T. KUNG AND J. F. TRAUB, All algebraic functions can be computed fast, J. Assoc.
Comput. Mach. 25 (1978), 245-260.
29. B. L. VAN DER WAERDEN, “Einfuhrung in die Algebra&he Geometric,” Springer, Berlin,
1939.
30. J. LIPSON, Newton’s method: A great algebraic algorithm, in “SYMSAC 76 (Proceedings, ACM Symposium on Symbolic and Algebraic Computations, Yorktown Heights, N.Y.), pp. 260-270, 1976.
31. P. J. COHEN, Decision procedures for real and p-adic fields, Comm. Pure Appl. Math. 22 (1969), 131-151.

