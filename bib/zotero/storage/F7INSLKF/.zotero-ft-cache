2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Macau, China, November 4-8, 2019

Fast Motion Planning via Free C-space Estimation Based on Deep Neural Network
Xiang Li1, Qixin Cao2, Mingjing Sun3, Ganggang Yang4

Abstract— This paper presents a novel learning-based method for fast motion planning in high-dimensional spaces. A deep neural network is designed to predict the free conﬁguration space rapidly given the environment point cloud. With a generated roadmap as an approximate view of the free C-space, LazyPRM is applied to ﬁnd and check the path with A* search. Due to the application of LazyPRM, the presented method can preserve probabilistic completeness and asymptotic optimality. The new algorithm is tested on a 3-DOF robot arm and a 6-DOF UR3 robot to plan in randomly generated obstacle environments. Results indicate that compared to planners including PRM, RRT*, RRT-connect and the original LazyPRM, our method is of the lowest time consumption and relatively short path length, showing good performance on both planning speed and path quality.
I. INTRODUCTION
Motion planning algorithms aim to generate collision-free motions for complex bodies from a start to a goal position among a collection of static obstacles [1]. These algorithms are widely used in robot navigation, robotic surgery and robotic manipulation.
Sampling-based planners are very popular methods for solving motion planning problems and can guarantee probabilistic completeness and asymptotic optimality. The acceleration of sampling-based motion planning is one optimization direction that researchers focus on [2] [3] [4] . Faster planning speed can be beneﬁcial for variable environments, speciﬁcally for robots working in changing environments or robot arms on a moving platform that can change their positions. Recent work shows that using environment data to set up a heuristic single-query planner can increase planning speed [5].
The key idea of sampling-based planners is to exploit the free C-space by sampling and collision checking between the robot and the environment. This is because an explicit representation of the obstacles in the conﬁguration space may result in an excessive computational burden in high dimensions, and in environments described by a large number of obstacles [6]. Neural networks can perform well when ﬁtting complex functions and might be helpful to predict the free C-space with the information of the obstacles.
This paper presents a novel learning-based method to accelerate sampling-based motion planning. A deep neural network is designed to estimate the free C-space from the point cloud of an environment. Figure 1 shows a prediction
1,3,4 Master students of School of Mechanical Engineering, Shanghai Jiao Tong University. lixiang3.1416@qq.com, {smj 1024,yanggang}@sjtu.edu.cn
2 Professor of School of Mechanical Engineering, Shanghai Jiao Tong University. qxcao@sjtu.edu.cn

1 1

0

0

-

-

0

0

0

--

2

3

0 --
3 2

Fig. 1. Free C-space predicted by deep neural network for a 3-DOF robot arm in an obstacle environment. Left is the ground truth roadmap vertices and on the right is the prediction. The input of the network is the point cloud of the environment and the output is a set of robot conﬁgurations indicating the C-free.

of the free C-space of a 3-DOF robot arm in an obstacle environment. PointNet [7] is adopted in our network for point cloud processing. A roadmap vertex set is generated directly by the DNN with Earth Moving Distance (EMD) as the loss of the network to maintain the unordered feature of the graph vertices. Then the output vertices are rewired, and paths are found by A* search algorithm. LazyPRM [8] is applied to reduce the number of collision checking and to ensure probabilistic completeness and asymptotic optimality. The roadmap need only to be generated once in each different environment, and can be used for multiple planning problems in the same environment, making our multi-query planner suitable for mobile manipulators where the robot arm often faces different environments and may need to perform multiple tasks in the same environment.
The algorithm is tested on a 3-DOF robot arm and a 6-DOF UR3 robot to plan in randomly generated obstacle environments. Results indicate that compared to planners including PRM, RRT*, RRT-connect and original LazyPRM from OMPL [9], averagely, with a well-generated roadmap from the network, our algorithm can ﬁnd a relatively lowcost path for the planning problem in the least time.
This paper begins with the background of sampling-based planning. Section II then shows the classical sampling-based planners and previous work for sampling-based fast planning and learning-based planning. In Section IV we describe our method in detail. Experiments are shown in Section V. Finally Section VI concludes this paper.

978-1-7281-4004-9/19/$31.00 ©2019 IEEE

3542

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

II. RELATED WORK
A. Sampling-based motion planning
Sampling-based planners are one of the main categories of robot motion planning algorithms. Instead of providing the exact geometric model of the C-space, sampling-based planners try to describe the C-space by sampling and checking whether these sampled robot conﬁgurations collide with the obstacles. In this way, sampling-based planners can solve the planning problem in a more computationally efﬁcient way. The exchange of the computational efﬁciency is that sampling-based planners provide a weaker, but still interesting, form of completeness: probabilistic completeness, which means if a solution path exists, the planner will eventually ﬁnd it [1].
Sampling-based planners can be mainly divided into two classes: single-query planners and multi-query planners. Rapidly-exploring random tree (RRT) algorithm [10] is the main representative of single-query planners. This algorithm solves a planning problem by trying to grow a tree from start conﬁguration to the goal. Its bidirectional derivative RRT-connect [11] is famous for its fast speed and another derivative RRT* [12] can solve motion planning problems with asymptotic optimality. Multi-query planners can plan faster than single-query planners with a precise pre-generated roadmap, but lose this advantage in new environments. The probabilistic roadmap (PRM) method [13] is a representative of the multi-query planners. Its asymptotic optimal derivative is PRM* [12]. Another derivative of PRM, LazyPRM [8], can reduce the planning time using lazy collision checking.
B. Fast motion planning
Various research has been done to accelerate motion planning, mainly for robots working in unstable environments, speciﬁcally, a robot in an environment with moving obstacles or the robot arm is being moved, for example, a mobile manipulator. One main approach was to modify the algorithms to re-use information to efﬁciently update motion paths when the environment changes [14]. Paper [2] presented Dynamic Roadmap (DRM) algorithm, which accelerates planning speed by workspace discretization and using pre-generated collision checking data, and was able to do real-time planning in changing environments [3]. However, this algorithm cannot guarantee completeness because the workspace needs to be discretized into cells for fast collision checking, and will face difﬁculty while approving accuracy since the number of cells to check increases with the reciprocal of the third power of cell size. The method in [4] proposed another solution that can guarantee probabilistic completeness. LazyPRM was adopted as the planner of this method planning with a pre-generated roadmap and online estimation of vertex collide possibility. But collision checking results in the same environment are needed to set up a precise model, and the prediction model can lose effectiveness in a new environment.
Recent years, machine learning technologies have been widely concerned in robotics and were adopted to accelerate

robot motion planning. Paper [15] tried to optimize the sampler by clustering-based unsupervised region identiﬁcation with a small roadmap and was able to apply different sampling strategies according to the feature of the region. Another method, Lightning Framework [16], tried to reduce computation time by learning from experience. This framework consists of two main modules running in parallel, a planning-from-scratch module, and a module retrieves and repairs paths stored in a path library. However, the path library may not perform well for new environments where obstacles change a lot. Recent work in paper [17] used conditional variational autoencoder to accelerate the planning process by non-uniform sampling strategies that favor sampling in regions where an optimal solution might lie. The network is trained for a speciﬁc environment so that this method is not able to address motion planning problems in different environments. Another recent work, [5], presented a deeply informed approach for the sampler to predict the well-optimized results generated by RRT* with the data of the environment given in the form of a point cloud. However, the deep sampler can only produce one sample under each condition, leading to running neural network forward propagation multiple times in solving one problem. Its performance is highly related to the training quality of the sampler; therefore, the performance of the whole algorithm is sensitive to the quality of the dataset. Since RRT* is an asymptotic optimal planner and may cost much time to get well-optimized and each environment in the dataset need several generated paths, this algorithm might suffer from the difﬁculty of dataset generation.
III. PROBLEM FORMULATION
The goal of this work is to ﬁnd a relatively low cost solution for motion planning problems in a short time in different environments. The formulation of the motion-planning problem follows as presented by Karaman and Frazzoli [6]. Let X = (0, 1)d be the conﬁguration space, where d ∈ N , d ≥ 2. Let Xobs be the obstacle region, such that X \Xobs is an open set, and denote the obstacle-free space as Xfree = cl(X \Xobs), where cl(·) denotes the closure of a set. The initial condition xinit is an element of Xfree, and the goal region Xgoal is an open subset of Xfree. A path planning problem is deﬁned by a triplet (Xfree, xinit, Xgoal).
Problem 1 (Feasible path planning) Given a path planning problem (Xfree, xinit, Xgoal), ﬁnd a feasible path σ : [0, 1] → Xfree such that σ(0) = xinit and σ(1) ∈ cl(Xgoal), if one exists. If no such path exists, report failure.
Let a set of all feasible paths be denoted as Σ. Let a cost function c(·) computes a summation of Euclidean distances between all the consecutive states in a path Σ.
Problem 2 (Optimal path planning) Given a path planning problem (Xfree, xinit, Xgoal) and a cost function c : Σ → R≥0, ﬁnd a feasible path σ∗ such that c(σ∗) = min{c(σ) : σ is f easible}. If no such path exists, report failure.

3543

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

1024 1024 FC Dropout 1024 FC Dropout m x d FC
mxd

nx3 1024 mxd

PointNet

MLP

input points

environment feature

output vertices

Fig. 2. Architecture of the roadmap generation network.

environment feature

multilayer perceptron (MLP)

output vertices

Fig. 4. Architecture of the multilayer perceptron module.

nx3 1 x1x64 CONV
n x 64 1 x1x 64 CONV
n x 64 1 x1x64 CONV
n x 64 1 x1x128 CONV
n x 128 1 x1x1024 CONV

n x 1024

input points

PointNet

environment feature

max pooling 1 x 1024

Fig. 3. Architecture of PointNet (vanilla) [7].

IV. ALGORITHM IMPLEMENTATION
In this section, we present our algorithm, including a deep neural network that can generate C-space roadmap vertices for different environments to accelerate motion planning and a planner that can utilize the results of the roadmap generation network (RGN). This section also includes speciﬁc information about the generation of training dataset.
A. Network architecture
Our network consists of two parts: the ﬁrst part to extract features of the environment point cloud and the second to generate vertices from the features to build a C-space roadmap (Figure 2).
In the ﬁrst part of our network, PointNet [7] is used to extract features of the environment point cloud that can be obtained from 3-D sensors (Figure 3). PointNet is an architecture that can effectively process unordered point sets by extracting point features through convolutional layers and aggregating information from all the points through a maxpooling layer. It is a simple but highly efﬁcient and effective architecture originally created for object classiﬁcation, part segmentation and scene semantic parsing. In order to use this architecture to solve motion planning problems, the simplest version of PointNet, the vanilla version (without point cloud transformation layers) is used for higher performance. This part of network consumes a n × 3 data matrix where n is the number of input points and outputs a 1 × 1024 vector as the feature of the environment point cloud.
The second part of the network aims to reconstruct the Cspace roadmap from the feature of the environment point cloud. A multilayer perceptron (MLP) is applied in the structure with ReLU activation function. The layer number of the MLP will be further discussed in later sections. Each fully-connected layer is followed by a dropout layer (Figure 4). The input of this part of the network is the 1 × 1024 feature vector generated by PointNet. The output is a m × d matrix where d is the dimension of the C-space and m is the number of output roadmap vertices.

The Earth Mover’s Distance (EMD) [18] between the vertices of dataset roadmap and the reconstructed roadmap is adopted as the loss of the network. EMD is the solution of a transportation problem and is deﬁned as the least cost that one set transforms to the other. For two equally sized subsets S1 ⊆ Rd; S2 ⊆ Rd, their EMD is deﬁned by

dEMD(S1, S2) = min

x − φ(x) 2

φ:S1→S2 x∈S1

where φ is a bijection [19]. The EMD distance is symmetrical among all points in the set and can be easily adopted to highdimensional spaces, which is suitable for our application. In our method, the distance between two conﬁgurations is set a weighted Euclidean distance with coefﬁcients differ among joints.

B. Dataset generation
In order to train the proposed network, the needed dataset includes different environment point clouds and the corresponding roadmap vertices. The obstacle environment is generated randomly from four kinds of basic 3D objects (sphere, cube, ring and cylinder) (Figure 6). Points are only placed on the surface of the objects to simulate real data collected from 3-D cameras. This can also be more computational efﬁcient while enhancing accuracy because in this case number of voxels to check increases with the reciprocal of only the second power of voxel size. The number of each kind of object in one environment is random and each object is transformed by a random homogeneous transformation matrix. Points too far away that will deﬁnitely not collide with the robot are removed. Then, for computation efﬁciency, the point cloud is processed by a PCL VoxelGrid ﬁlter. After all the process, the number of points varies from approximately 5000 to 40000. Considering the balance of a smaller neural network for higher performance and enough points for roadmap prediction accuracy, 16384 (=214) points are selected randomly in each piece of data. Points may be selected repeatedly when there are not enough in one point cloud; our network can handle repeated points well since the same points will not affect the feature that came out from a max-pooling layer.
After creating the obstacle point cloud, a roadmap in Cspace is generated for this environment. As planning in open C-space regions is not the bottleneck of motion planning, a novel algorithm is presented for roadmap dataset generation (Algorithm 1) to bias samples to complex regions. Our roadmap generator starts with an empty vertex set V and

3544

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

Algorithm 1: Roadmap dataset generator

1 V ← ∅; E ← ∅; t ← 0;

2 Start timing on t;

3 while t < tmax do

4 xrand ← RandomV alidSample()

5 Xnear ← N eighbor(V, xrand, Nneighbor);

6 Xconnectable ← CheckM otion(xrand, Xnear)

7 if size(Xconnectable) > sizemin then

8

continue;

9 else if SameComponent(Xconnectable) then

10

continue;

11 else if InterConnectable(Xconnectable) then

12

continue;

13 else

14

AddV ertex(xrand, V, E)

15 return V ;

an empty edge set E, and generate time is limited for each environment. While not running out of time, a sampler ﬁrst tries to sample a valid robot conﬁguration xrand. Then a neighbor ﬁnding function N eighbor(·) would give the Nneighbor nearest vertices of xrand in V , this result is stored in Xnear. Then, the direct path from xrand to every vertex in Xnear is tested by the collision checking function CheckM otion(·) and connectable vertices are stored in Xconnectable. After this, three conditions are checked sequentially and xrand would be added to the graph if any condition is satisﬁed. The order of the three judgements is determined by computational cost, from low to high. The ﬁrst condition is the vertex number in Xconnectable. Small vertex number in Xconnectable means that many of near neighbors cannot be reached directly by xrand, the C-space near xrand is complexed and new vertices are needed. Checking the size of Xconnectable is quick since it is represented in one array in our algorithm. The second condition is whether all the vertices in Xconnectable belong to the same component of the graph. Vertices that can reach each other through edges are deﬁned in the same component. xrand will be added to the graph if it can connect different components. The judgement of this condition would only need to check the existing data. The third condition to check is whether all vertices in Xconnectable can directly reach each other. This condition also indicates the region complexity near xrand. The computational cost is high because collision checking is needed in this process. When the time meets the limit, the program stops adding new conﬁgurations to the roadmap, all the vertices in V are stored together with the environment point cloud as a piece of data.
C. Planner for the generated roadmap
During online planning, the roadmap generation network generates a roadmap vertex set according to the environment data, then a planner is applied to ﬁnd a path for the motion

planning problem.
The planner we used is based on LazyPRM [8], a PRMbased motion planner that can reduce the planning time using lazy collision checking. At the start, the roadmap vertices generated by the neural network are loaded and wired to near vertices to build an original roadmap, the graph G. Then the start conﬁguration xstart and goal conﬁguration xgoal are added into G for initialization. During each loop, the planner checks whether xstart and xgoal belong to the same component. If so, an A* searcher will rapidly search the shortest path for the problem. The path found is then collision checked and the invalid vertices and edges of the path are removed. If xstart and xgoal belong to different components, a new vertex will be added to help solve the planning problem.
Except for the roadmap loaded at the beginning, the algorithm is the same with the LazyPRM [8] planner and can guarantee probabilistic completeness and asymptotic optimality as LazyPRM does. The application of A* algorithm gave our planner a feature that the originally found paths are relatively low-cost paths and this can contribute to good path quality.

Algorithm 2: Roadmap planner (xstart, xgoal)

1 G ← LoadRoadmap(); t ← 0; path ← ∅

2 AddV ertex(xstart, G)

3 AddV ertex(xgoal, G)

4 Start timing on t;

5 while t < tmax do

6 while SameComponent(xstart, xgoal) do

7

pathtmp = A∗(xstart, xgoal, G)

8

if pathtmp is collision-free then

9

path = pathtmp

10

else

11

remove invalid vertices and edges in

pathtmp

12 if path = ∅ then

13

break;

14 xrand ← RandomV alidSample() 15 AddV ertex(xrand, G)

16 while t < tmax do

17 xrand ← RandomV alidSample()

18 AddV ertex(xrand, G)

19 if found valid solution shorter than path then

20

update path;

21 if path = ∅ then 22 return path;
23 else 24 return failure;

3545

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

1

0

-

0

0

--

2

3

1

0

-

0

0

--

2

3

Fig. 5. Validation loss of RGN with different MLP layer numbers for the 3-DOF robot.

1

0

-

0

0

--

2

3

1

0

-

0

0

--

2

3

1

0

1

0

-

0

0

--

2

3

-

0

0

--

2

3

Fig. 6. Validation loss of RGN with different MLP layer numbers for UR3.

Fig. 8. Examples of C-free prediction for a 3-DOF robot in different environments, ground truth on the left.

Fig. 7. The tested 3-DOF Robot Arm.
V. EXPERIMENTAL EVALUATION
After algorithm implementation, experiments are performed on a 3-DOF robot arm and a 6-DOF UR3 robot arm.
Our network is trained with an NVIDIA GTX1080Ti GPU. The optimizer is Adam and the batch size is 16. The number of input points is 16384 and number of output vertices is 2048. In our dataset generation, tmax is set 3 minutes for each roadmap, Nneighbor is 10 and sizemin is 2. Our dataset contains over 20000 environment-roadmap pairs for the 3DOF robot and over 14000 for UR3. The ratio between training data and validation data is 3 : 1. The testing software platform is ROS kinetic with Moveit! framework on Ubuntu 16.04.
To ﬁnd a better structure of the MLP module (Figure 4),

validation loss of networks with different numbers of fullyconnected layers are evaluated during the training process (Figure 5, Figure 6). All the networks achieve convergence after 200 epochs of training. For both robots, the ﬁnal validation loss of the corresponding networks reaches the lowest with three fully-connected layers, which are the adopted network structures during the following tests.
The forward propagation time of the network is around 30ms. For performance enhancement, only a subset of the output vertices are used for roadmap generation; this number is 256. Loading and wiring these vertices takes less than 5ms. During this test, our method is compared to four typical sampling-based planners (PRM, LazyPRM, RRT* and RRT-connect) and a LazyPRM planner loading a randomly generated roadmap. All the planners above are probabilistic complete so that with enough time all the planners can ﬁnd a solution if the problem is solvable. In our experiment, the planning time is set to 5 seconds and we only process data from problems that all planners can solve within the time limit. Each planner is measured by the planning speed and the cost of the found paths. For precise comparison, the planning time is measured by the time of solution() function in OMPL framework to remove the time of ROS data transmission and preparation. For our method, the path length measured is the ﬁrst found valid path. For RRT*,

3546

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

Fig. 9. UR3 robot being tested in random obstacle environments.
TABLE I PERFORMANCE OF PLANNERS ON THE 3-DOF ROBOT

Average planning time (normalized to average) Average RSD of planning time (%)
Average path cost (normalized to lowest) Average RSD of path cost (%)

Our Method 0.35 27.75 1.29 3.31

LazyPRM(random roadmap) 0.40 29.50 1.39 4.62

PRM 1.81 59.15 1.52 15.08

LazyPRM 0.90 67.49 1.59 19.28

RRT-connect 0.59 52.35 2.27 29.09

RRT* 1.95 62.33 1.00 1.22

TABLE II PERFORMANCE OF PLANNERS ON 6-DOF UR3 ROBOT

Average planning time (normalized to average) Average RSD of planning time (%)
Average path cost (normalized to lowest) Average RSD of path cost (%)

Our Method 0.34 27.48 1.27 2.30

LazyPRM(random roadmap) 0.52 31.52 1.55 6.68

PRM 1.54 61.23 1.42 16.39

LazyPRM 0.84 74.36 1.70 24.30

RRT-connect 0.71 60.62 2.07 27.68

RRT* 2.05 63.16 1.00 3.65

especially, the planning time is the time when the ﬁrst path is found and the cost is from the ﬁnal path as an indicator of the lowest cost, for the ﬁnal result of RRT* should have been optimized for a long time. For multi-query planners, speciﬁcally PRM and LazyPRM, which can plan with pregenerated roadmaps as our method does, extra time (50ms, not included during comparison) is given for setting up a valid roadmap to make the comparison fair; the roadmaps keep the same for the same environment. All the planners above are from the Open Motion Planning Library (OMPL) [9] with default parameters. Environments and the startgoal conﬁguration pairs are randomly generated in real-time (Figure 9). For each robot, results from over 1200 valid planning problems in over 400 environments are collected.
A. Experiment on a 3-DOF Robot Arm
The algorithm is tested on a designed 3-DOF robot arm (Figure 7) ﬁrstly as a preliminary experiment. Its C-space is of low dimensions and is easy visualized in a 3D space in the form of 3-D point clouds (Figure 8). The visualized results from the validation dataset show that our neural network can successfully predict the main structure of the free C-space. The blurry of the detailed structures indicates that there is still room for improvements. Then the vertices generated by

the GPU are rewired and the planner starts planning. The result of the 3-DOF robot experiment is shown in
Table I. The performance of a planner in each problem is measured ﬁve times, then the average and the relative standard deviation (RSD) is calculated. After this, the average performance on the same problem of different planners is normalized to build an overall evaluation, planning time normalized to the average among all planners and path cost to the lowest. Compared to other planning algorithms, our method is of the fastest speed on average. The RSD of the planning time of the same problem shows the time stability of the planners, in which our method reached the lowest average value among all the planners to be of the most steady time performance. In the comparison of path cost, our method can plan relatively short paths, closer to the well-optimized paths generated by RRT* than any other algorithm compared. In conclusion, our method performs well in both planning speed and path quality with high stability in the 3-DOF arm test.
B. Experiment on UR3
UR3 is a typical 6-DOF robot arm. The experiment held over UR3 is to show the performance of our method in highdimensional motion planning problems. Figure 6 shows the validation loss during network training. The network loss

3547

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

decreases slower than in 3-DOF test, but can also converge after 200 epochs.
Comparison between our method and other planners in the UR3 test is shown in Table II. Our method showed a signiﬁcant advantage over other compared planners in high-dimensional planning problems. The result is generally similar to the 3-DOF robot experiment: our algorithm can averagely ﬁnd a relatively short path in the least time and have excellent stability on time cost and path length.
VI. CONCLUSIONS
This paper presents a novel approach to accelerate robot motion planning in variable environments. A neural network is designed to predict the free C-space according to the point cloud of the environment. LazyPRM is adopted as the search and check policy to ensure probabilistic completeness and asymptotic optimality. The roadmap can be used multiple times within the same environment and can be generated through GPU in a very short time, making this multiquery planner remarkably suitable for robot arms in mobile manipulator systems, where the arm often faces different environments and may need to perform multiple tasks in the same environment. In our test, compared to existing planning algorithms including PRM, LazyPRM, RRT* and RRT-connect from OMPL, our method is of the fastest speed, relatively low path cost and the most steady time performance in both low and high dimensional C-spaces.
Future work may include further optimization of the structure of the roadmap generation network. The dataset generation algorithm may also be optimized: more targeted dataset environments for speciﬁc tasks and more efﬁcient dataset C-space roadmaps for solving motion planning problems.
REFERENCES
[1] B. Siciliano and O. Khatib, Springer handbook of robotics. Springer, 2016.
[2] P. Leven and S. Hutchinson, “A framework for real-time path planning in changing environments,” The International Journal of Robotics Research, vol. 21, no. 12, pp. 999–1030, 2002.
[3] T. Kunz, U. Reiser, M. Stilman, and A. Verl, “Real-time path planning for a robot arm in changing environments,” in 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, Oct 2010, pp. 5906–5911.
[8] R. Bohlin and L. E. Kavraki, “Path planning using lazy prm,” in Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), vol. 1, April 2000, pp. 521–528 vol.1.

[4] M. Pomaˆrlan and I. A. S¸ ucan, “Motion planning for manipulators in dynamically changing environments using real-time mapping of free workspace,” in 2013 IEEE 14th International Symposium on Computational Intelligence and Informatics (CINTI), Nov 2013, pp. 483–487.
[5] A. H. Qureshi and M. C. Yip, “Deeply informed neural sampling for robot motion planning,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Oct 2018, pp. 6582–6588.
[6] S. Karaman and E. Frazzoli, “Sampling-based algorithms for optimal motion planning,” The International Journal of Robotics Research, vol. 30, no. 7, pp. 846–894, 2011.
[7] R. Q. Charles, H. Su, M. Kaichun, and L. J. Guibas, “Pointnet: Deep learning on point sets for 3d classiﬁcation and segmentation,” in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017, pp. 77–85.
[9] I. A. S¸ ucan, M. Moll, and L. E. Kavraki, “The Open Motion Planning Library,” IEEE Robotics & Automation Magazine, vol. 19, no. 4, pp. 72–82, December 2012, http://ompl.kavrakilab.org.
[10] S. M. Lavalle, “Rapidly-exploring random trees: A new tool for path planning,” Tech. Rep., 1998.
[11] J. J. Kuffner and S. M. LaValle, “Rrt-connect: An efﬁcient approach to single-query path planning,” in Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), vol. 2, April 2000, pp. 995–1001 vol.2.
[12] S. Karaman and E. Frazzoli, “Sampling-based algorithms for optimal motion planning,” The International Journal of Robotics Research, vol. 30, no. 7, pp. 846–894, 2011.
[13] L. E. Kavraki, P. Svestka, J. . Latombe, and M. H. Overmars, “Probabilistic roadmaps for path planning in high-dimensional conﬁguration spaces,” IEEE Transactions on Robotics and Automation, vol. 12, no. 4, pp. 566–580, Aug 1996.
[14] A. Short, Z. Pan, N. Larkin, and S. van Duin, “Recent progress on sampling based dynamic motion planning algorithms,” in 2016 IEEE International Conference on Advanced Intelligent Mechatronics (AIM). IEEE, 2016, pp. 1305–1311.
[15] L. Tapia, S. Thomas, B. Boyd, and N. M. Amato, “An unsupervised adaptive strategy for constructing probabilistic roadmaps,” in 2009 IEEE International Conference on Robotics and Automation, May 2009, pp. 4037–4044.
[16] D. Berenson, P. Abbeel, and K. Goldberg, “A robot path planning framework that learns from experience,” in 2012 IEEE International Conference on Robotics and Automation, May 2012, pp. 3671–3678.
[17] B. Ichter, J. Harrison, and M. Pavone, “Learning sampling distributions for robot motion planning,” in 2018 IEEE International Conference on Robotics and Automation (ICRA), May 2018, pp. 7087–7094.
[18] Y. Rubner, C. Tomasi, and L. J. Guibas, “The earth mover’s distance as a metric for image retrieval,” International Journal of Computer Vision, vol. 40, no. 2, pp. 99–121, Nov 2000.
[19] P. Achlioptas, O. Diamanti, I. Mitliagkas, and L. Guibas, “Learning representations and generative models for 3d point clouds,” arXiv preprint arXiv:1707.02392, 2017.

3548 Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on July 08,2022 at 15:53:34 UTC from IEEE Xplore. Restrictions apply.

