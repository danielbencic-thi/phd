Mechanisms and Machine Science
Giuseppe Carbone Fernando Gomez-Bravo Editors
Motion and Operation Planning of Robotic Systems
Background and Practical Approaches

Mechanisms and Machine Science
Volume 29
Series editor Marco Ceccarelli, Cassino, Italy

More information about this series at http://www.springer.com/series/8779

Giuseppe Carbone • Fernando Gomez-Bravo
Editors
Motion and Operation Planning of Robotic Systems
Background and Practical Approaches
123

Editors Giuseppe Carbone University of Cassino Cassino, Frosinone Italy

Fernando Gomez-Bravo Engineering School University of Huelva La Rábida, Huelva Spain

ISSN 2211-0984

ISSN 2211-0992 (electronic)

Mechanisms and Machine Science

ISBN 978-3-319-14704-8

ISBN 978-3-319-14705-5 (eBook)

DOI 10.1007/978-3-319-14705-5

Library of Congress Control Number: 2015932073

Springer Cham Heidelberg New York Dordrecht London © Springer International Publishing Switzerland 2015 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made.

Printed on acid-free paper

Springer International Publishing AG Switzerland is part of Springer Science+Business Media (www.springer.com)

Preface

Robot motion planning and its applications have attracted the attention of the robotic community along the last decades. This book is an attempt to address this wide topic with a multidisciplinary approach. While other publications focus on describing the theoretical basis of robot motion, this work pays special attention to explain the fundamentals through real applications. Thus, it represents a perfect combination for studying this topic along with other theoretical books.
Each chapter has been authored by an expert or a team of experts in a speciﬁc area spanning from the mechanics of machinery to control theory, informatics, mechatronics. Chapters have been divided into ﬁve parts. The ﬁrst one aims to give a theoretical background. Then, Parts II–V discuss the main speciﬁc issues for a proper path planning of different types of robots such as robotic manipulators, wheeled robots, legged robots, cooperation and coordination of multiple aerial or underwater robots.
This book project can be foreseen as a reference for young professionals/ researchers to overview the most signiﬁcant aspects in the ﬁeld of path planning. Given the wideness of the topic, this book can be considered as a ﬁrst edition and, as Editors, we shall be pleased to consider additional contents/suggestions for a future edition.
We wish to acknowledge all the authors and expert blind reviewers for their signiﬁcant contributions to this project. Also acknowledged is the professional assistance by the staff of Springer Science+Business Media that have supported this project with their help and advice in the preparation of the book.
Last but not least we are indebted to our families. Without their patience and understanding it would not have been possible for us to work on this book.

January 2015

Giuseppe Carbone Fernando Gomez-Bravo

v

Contents
Part I Theoretical Background Path Planning and Trajectory Planning Algorithms: A General Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 Alessandro Gasparetto, Paolo Boscariol, Albano Lanzutti and Renato Vidoni Off-Line and On-Line Trajectory Planning . . . . . . . . . . . . . . . . . . . . . 29 Zvi Shiller Open Architecture for Vision-Based Robot Motion Planning and Control. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 Theodor Borangiu, Florin Anton and Silvia Anton Grasping and Manipulation of Unknown Objects Based on Visual and Tactile Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 Robert Haschke
Part II Motion Planning of Robotic Manipulators Obstacle Avoidance with Industrial Robots. . . . . . . . . . . . . . . . . . . . . 113 T. Petrič, A. Gams, N. Likar and L. Žlajpah Path Planning Kinematics Simulation of CNC Machine Tools Based on Parallel Manipulators . . . . . . . . . . . . . . . . . . . . . . . . 147 Luc Rolland Planning Automatic Surgical Tasks for a Robot Assistant . . . . . . . . . . 193 Enrique Bauzano Nuñez, Belen Estebanez Campos, Isabel Garcia Morales and Victor F. Muñoz Martinez
vii

viii

Contents

Part III Motion and Operation Planning for Wheeled Robots

Motion Planning Using Fast Marching Squared Method . . . . . . . . . . . 223 S. Garrido, L. Moreno and Javier V. Gómez

Motion Planning of Large Scale Vehicles for Remote Material Transportation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249 Alberto Vale and Isabel Ribeiro

Car-Like Robot Manoeuvre Generation . . . . . . . . . . . . . . . . . . . . . . . 293 F. Gomez-Bravo

Vehicle Autonomy Using Cooperative Perception for Mobility-on-Demand Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331 Seong-Woo Kim, Tirthankar Bandyopadhyay, Baoxing Qin, Zhuang Jie Chong, Wei Liu, Xiaotong Shen, Scott Pendleton, James Guo Ming Fu, Marcelo H. Ang Jr., Emilio Frazzoli and Daniela Rus

Motion Planning of a Spherical Mobile Robot. . . . . . . . . . . . . . . . . . . 361 Qiang Zhan

Part IV Motion Planning for Legged Robots
A Minimum Jerk-Impedance Controller for Planning Stable and Safe Walking Patterns of Biped Robots . . . . . . . . . . . . . . . . . . . . 385 Amira Aloulou and Olfa Boubaker
Online Walking Pattern Generation Using FFT for Humanoid Robots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417 Kenji Hashimoto, Hideki Kondo, Hun-Ok Lim and Atsuo Takanishi
Hexapod Walking Robot Locomotion . . . . . . . . . . . . . . . . . . . . . . . . . 439 Franco Tedeschi and Giuseppe Carbone

Part V Robot Cooperation and Interaction
Distributed Cooperation of Multiple UAVs for Area Monitoring Missions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 471 José J. Acevedo, Begoña C. Arrue, Iván Maza and Anibal Ollero

Contents

ix

Robotic Manipulation Within the Underwater Mission Planning Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 495 Javier Pérez, Jorge Sales, Antonio Peñalver, J. Javier Fernández, Pedro J. Sanz, Juan C. García, Jose V. Martí, Raul Marín and David Fornas

Erratum to: Motion and Operation Planning of Robotic Systems. . . . . E1 Giuseppe Carbone and Fernando Gomez-Bravo

Part I
Theoretical Background

Path Planning and Trajectory Planning Algorithms: A General Overview
Alessandro Gasparetto, Paolo Boscariol, Albano Lanzutti and Renato Vidoni

Abstract Path planning and trajectory planning are crucial issues in the ﬁeld of Robotics and, more generally, in the ﬁeld of Automation. Indeed, the trend for robots and automatic machines is to operate at increasingly high speed, in order to achieve shorter production times. The high operating speed may hinder the accuracy and repeatability of the robot motion, since extreme performances are required from the actuators and the control system. Therefore, particular care should be put in generating a trajectory that could be executed at high speed, but at the same time harmless for the robot, in terms of avoiding excessive accelerations of the actuators and vibrations of the mechanical structure. Such a trajectory is deﬁned as smooth. For such reasons, path planning and trajectory planning algorithms assume an increasing signiﬁcance in robotics. Path planning algorithms generate a geometric path, from an initial to a ﬁnal point, passing through pre-deﬁned via-points, either in the joint space or in the operating space of the robot, while trajectory planning algorithms take a given geometric path and endow it with the time information. Trajectory planning algorithms are crucial in Robotics, because deﬁning the times of passage at the via-points inﬂuences not only the kinematic properties of the motion, but also the dynamic ones. Namely, the inertial forces (and torques), to which the robot is subjected, depend on the accelerations along the trajectory, while the vibrations of its mechanical structure are basically determined by the values of the jerk (i.e. the derivative of the acceleration). Path planning algorithms are usually divided according to the methodologies used to generate the geometric path, namely:

A. Gasparetto (B) · P. Boscariol
DIEGM – Dipartimento di Ingegneria Elettrica Gestionale E Meccanica, University of Udine, Via Delle Scienze, 206, 33100 Udine, UD, Italy e-mail: alessandro.gasparetto@uniud.it
A. Lanzutti MBP, Via Toscanini, 48/B, 46043 Castiglione Delle Stiviere, MN, Italy
R. Vidoni Faculty of Science and Technology, Free University of Bozen-Bolzano Piazza Università, 39100 Bolzano, Italy

© Springer International Publishing Switzerland 2015

3

G. Carbone and F. Gomez-Bravo (eds.), Motion and Operation Planning

of Robotic Systems, Mechanisms and Machine Science 29,

DOI 10.1007/978-3-319-14705-5_1

4

A. Gasparetto et al.

• roadmap techniques • cell decomposition algorithms • artiﬁcial potential methods.
The algorithms for trajectory planning are usually named by the function that is optimized, namely:
• minimum time • minimum energy • minimum jerk.
Examples of hybrid algorithms, which optimize more than a single function, are also found in the scientiﬁc literature. In this chapter, the general problem of path planning and trajectory planning will be addressed, and an extended overview of the algorithms belonging to the categories mentioned above will be carried out, with references to the numerous contributions to this ﬁeld.
Keywords Path planning · Trajectory planning · Roadmap · Cell decomposition · Artiﬁcial potential · Minimum time · Minimum energy · Minimum jerk

1 Introduction
Human activity in many sectors is nowadays supported or substituted by robots, which range from standard robots for industrial applications to autonomous robots for complex tasks, such as space exploration. Indeed, the great versatility and ﬂexibility of robots allows them to be employed in different sectors, to perform even very diverse tasks. Referring to the industrial environment, a robot can be deﬁned [78] as a mechanical structure made of several rigid bodies (links) connected one to another by means of joints. Within the robot, it is possible to identify a structure that implements mobility, a wrist which provides dexterity, and an end-effector which performs the task given to the robot.
Regardless of the speciﬁc mechanical structure, in all types of applications a generic task is achieved by a robot by imposing a speciﬁc motion to the end-effector. This motion may be free or bound: the former case applies if the end-effector does not have a physical interaction with the environment, while the latter case applies if the end effector interacts with the environment by exchanging forces and/or torques.
The input of the control system of the robot is generally given by the law of motion, which is generated by a dedicated module for motion planning. Such motion planning module can operate off-line, by using a knowledge of the robot and the environment which is given a priori, or can operate on-line: in this case, suitable sensors must be employed to monitor the robot motion and enable the control system to adjust the movements in real time.
Ultimately, controlling the robot means determining the forces and torques that the actuators must develop at the joints, so as to ensure that the reference trajectories

Path Planning and Trajectory Planning Algorithms: A General Overview

5

are properly followed. However, this problem turns out to be very complex, because a robot is an articulated structure, so the motion of a single link arm affects the other links. Mathematically, this is expressed by the fact that the dynamic equations of a robot (with the exception of Cartesian structures), contain some terms due to the coupling effects between different links.
In most cases, robot controllers are based on closed loops, driven by the error between the reference and the actual position, which allows to achieve the accuracy required to the robot in executing the planned trajectory. In the case that, during a manipulation task, there is contact between the end-effector and the environment, the control problem is further complicated because not only the motion, but also the forces exchanged in the interaction should be monitored and controlled.
In this chapter, we will focus on the path planning and trajectory planning problems, which constitute the two main parts of the general motion planning problem. The interest for such topics is dramatically increasing, because operations at high speed are required to robots in the modern automatic systems; hence, smooth motions should be planned (where smooth means that such motions must avoid excessive values of accelerations of the actuators, as well as vibrations of the mechanical structure).
Many algorithms have been proposed, both for path planning and for trajectory planning, in the scientiﬁc literature of the robotic domain. The aim of this chapter is to provide a general overview of such algorithms, which have been subdivided into suitable categories.

2 Path Planning
Path planning is a merely geometric matter, because it is deﬁned as the generation of a geometric path, with no mention of any speciﬁed time law. On the other hand, trajectory planning consists in assigning a time law to the geometric path. In most cases, path planning precedes trajectory planning; however, these two phases are not necessarily distinct; for instance, if point-to-point trajectories are considered (i.e. only the initial and ﬁnal positions are speciﬁed), the two problems may be solved at the same time.
In this section the analysis of available works in literature deals with the case of systems without non-holonomic constraints.
Different types of paths are possible, depending on the speciﬁc case. For instance, for industrial manipulators, the standard path is usually deﬁned by the geometry of the task, which is deﬁned in a static way. In more advanced applications, or for robots operating in dynamic environments, some extra features, such as the need for automatic obstacle avoidance, may be added.
In applications of advanced robotics, the problem of path planning is deﬁnitely very challenging, especially for robots characterized by a large degree of autonomy or for robots that must operate in hostile environments (space, underwater, nuclear, military, etc.).

6

A. Gasparetto et al.

The deﬁnition of the path planning problem is very straightforward: “ﬁnd a collision-free motion between an initial (start) and a ﬁnal conﬁguration (goal) within a speciﬁed environment”. The simplest situation is when the path is to be planned in a static and known environment; however, more generally, the path planning problem can be formulated for any robotic system subject to kinematic constraints, in a dynamic and unknown environment.
Much work can be found the robotic literature, dealing with path planning. The ﬁrst deﬁnitions and algorithms date back to the 1970s. In [57] a complete overview of the path planning techniques can be found. An overview of many techniques cited in this work can be found also in the classic book [23] or in the recent book [48]. Other useful reviews of path planning techniques are [49, 55].
Some basic deﬁnitions are needed to introduce the path planning problem, namely: the conﬁguration space (C-space), the space of free conﬁgurations (C-free) and the obstacles’ representation in the C-space (C-obs).
The conﬁguration space is the space of all possible robot conﬁgurations, where a conﬁguration q is the speciﬁcation of position and orientation of the robot A with respect to a ﬁxed reference frame FW . Referring to Fig. 1, the C-space of the robot A is R3, since the conﬁguration of A is speciﬁed by the origin of FA with respect to FW , and by its orientation.
For an articulated robot (Fig. 2), the C-space is given by its joint space (in this case, R2). The C-obs is given by the image of the obstacles in the C-space, and the C-free is deﬁned as {C-space—C-obs}.
Path planning algorithms are usually divided in three categories, according to the methodologies used to generate the geometric path, namely:
• roadmap techniques • cell decomposition algorithms • artiﬁcial potential methods.

Fig. 1 Mobile robot in a 2-dimensional space with obstacles

Path Planning and Trajectory Planning Algorithms: A General Overview

7

360

270

Cobs

q start

β

180

β

C free

α

90

qgoal

0

45 α 90

135 180

Fig. 2 C-space, C-free and C-obs for an articulated robot with two joints

2.1 Roadmap Techniques
The roadmap techniques are based upon the reduction of the N-dimensional conﬁguration space to a set of one-dimensional paths to search, possibly on a graph.
In other words, this approach maps the free space connectivity into a system of one-dimensional curves (the roadmap) in the C-free space or in its closure. The roadmap R thus obtained contains a set of paths: hence, the path planning consists in linking the initial and ﬁnal conﬁgurations to R. In this way a feasible path between the two conﬁgurations is found.
It is very natural to associate a graph to the roadmap and to deﬁne some optimality index (e.g. the Euclidean length): the graph can then be searched in order to get the optimal solution to the path planning problem (in most cases, this is represented by the shortest path).
Figure 3 represents the so-called visibility graph, i.e. the graph whose nodes are the vertices of all the obstacles in the conﬁguration space. Searching the graph would lead to get the shortest Euclidean path in the C-space. The nodes of the graphs indicate point locations, while edges represents visible connections between the nodes. Grey areas indicate obstacles to be avoided. The concept of visibility graph, which represents a milestone in the literature related to path planning, was introduced by Lozano-Pérez [63, 64].
Another kind of roadmap algorithms are those based on Voronoi diagrams, which are deﬁned as a way to divide the space into regions having the following characteristic: given a set of points { p1, . . . pn}, each point belonging to the ith region is closer to pi than to any other p j = pi . This approach is dual to that based on the visibility graph, because the Voronoi diagrams enable one to obtain a path lying at the maximum distance from the obstacles, whereas the visibility graph generates a path that passes as close as possible to the obstacle vertices.

8

A. Gasparetto et al.

Fig. 3 Visibility graph
Figure 4 shows some path generated by using Voronoi diagrams. The three squares in the diagram represents obstacles, while the blue lines are the set of points equidistant from at least two obstacles. Therefore the paths deﬁned with this technique are designed to be as far away as possible from nearby obstacles. Examples of path planning algorithms may be found in [15, 35, 84].
2.2 Cell Decomposition Methods
According to the cell decomposition methods, the free space of the robot is subdivided into several regions, called cells, in such a way that a path between any two conﬁgurations lying in the same cell is straightforward to generate. It is then natural to deﬁne a so-called connectivity graph, which represents the adjacency relations between cells. Namely, the nodes of the graph represent the cells extracted from the free space, and there is an arch between two nodes are connected if and only if the corresponding cells are adjacent. The path planning problem is, again, turned into a graph searching problem, and can therefore be solved using graph-searching techniques.
Figure 5 illustrates the procedure described above, which is named exact cell decomposition technique, because the union of the cell represents exactly the free space. In some cases, an exact computation of the free space is not possible or convenient. Approximate cell decomposition methods must therefore be employed. Figure 6 shows how these techniques work:

Path Planning and Trajectory Planning Algorithms: A General Overview

9

Fig. 4 Paths resulting from Voronoi diagrams
• the whole C-space (assumed 2-dimensional) is divided into four cells; • the algorithm checks if each cell is completely empty, completely full or mixed
(such words obviously refer to the occupancy by the obstacles); • each mixed cell is in turn divided into four subcells, and the algorithm is recursively
applied to check the status of every subcell and recursively divide each mixed subcell into four sub-subcells.
The graph that may be naturally associated to the approximate cell decomposition is a tree, named quadtree for 2-dimensional spaces (Fig. 7), octree for 3-dimensional spaces (Fig. 8), 16-tree for 4-dimensional spaces, and so forth.
2.3 Artiﬁcial Potential Methods
The artiﬁcial potential methodologies are a different approach to the path planning problem. The basic idea is to consider the robot in the conﬁguration space as a moving point subject to a potential ﬁeld generated by the goal conﬁguration and the obstacles in the C-space: namely, the target conﬁguration produces an attractive potential, while the obstacles generate a repulsive potential. The sum of these two contribution is the total potential, which can be seen as an artiﬁcial force applied

10

A. Gasparetto et al.

Fig. 5 Exact cell decomposition: a subdivision of space into numbered polygons, b connectivity graph, c regions to be crossed, d path
Fig. 6 Approximate cell decomposition
to the robot, aimed at approaching the goal and avoiding the obstacles. Thus, given any conﬁguration during the robot motion, the next conﬁguration can be determined by the direction of the artiﬁcial force to which the robot is subjected. This normally represents the most promising direction of motion in terms of free path. An example of the application of the artiﬁcial potential method is shown in Fig. 9.
The artiﬁcial potential method was originally conceived by Khatib [50] and further developed by Volpe [91, 92]. Such a technique can ﬁnd applications in many ﬁelds, because it can be successfully implemented online, thus moving the obstacle avoidance problem from the higher (and slower) level of path planners to the lower (and faster) level of online motion controllers. This implies that the good features of the artiﬁcial potential methods, especially the reactivity to environment changes,

Path Planning and Trajectory Planning Algorithms: A General Overview

11

Fig. 7 Quadtree

Mixed cell Full cell Empty cell

Fig. 8 Octree

Mixed cell Full cell Empty cell

duly detected by the robot sensors, enable the robot controller to manage unexpected workspace changes in a fast way.
However, the artiﬁcial potential methods are intrinsically affected by a major problem, namely the presence of local minima, where the robot may ﬁnd itself trapped. In order to overcome this problem, several solutions have been proposed: for instance, using potential functions which do not have local minima [25, 26, 51, 53]. Such functions are called navigation functions.
In [39, 42] alternative applications of the artiﬁcial potential method are presented. Another approach to solve the path planning problem is found in [5], where a special kind of planners, named RPP (Random Path Planners), is proposed: local minima are avoided by combining the concepts of artiﬁcial potential ﬁeld with random search techniques. Albeit with some limitations, RPP proved to be able to solve path planning problems for robots with a high number of degrees of freedom, with reasonable computation times. Other examples of RPP can be found in [18–21].

12

A. Gasparetto et al.

Fig. 9 The artiﬁcial potential method
2.4 Alternative Approaches to Path Planning
A possible alternative approach, which had remarkable results in very complex path planning problems, is given by the Probabilistic Roadmap Planners (PRM). It is a technique which employs probabilistic algorithms, such as random sampling, to build the roadmap. The most important advantage of PRM is that their complexity do not strictly depend on the complexity of the environment and on the dimension of the conﬁgurations space. The basic idea is to consider a graph where the nodes are given by a set of random conﬁgurations in the C-free. A local planner can then try to connect these conﬁgurations by means of a path: if a path is found, a new node is added to the graph. In this way the graph reﬂects the connectivity of the C-free. In order to ﬁnd a path between two conﬁgurations, these conﬁgurations are added to the graph, then a graph search is performed in order to ﬁnd a feasible path. Given the probabilistic nature of the algorithm, post-processing is often necessary to improve the quality of the path. PRM algorithms have been successfully applied to robotic manipulators with up to 16 degrees of freedom. Examples of PRM can be found in [1, 24, 45, 66].
There are some examples [29, 34] of path planners that take into account kinematic and dynamic constraints of the robot, in addition to the pure geometric problem of obstacles avoidance. This problem is referred to as kinodynamic motion planning. Kinodynamic and nonholonomic motion planning can be handled by the Rapidlyexploring Random Tree (RRT) method [58]. This method allows to search nonconvex high-dimensional spaces by randomly building a space-ﬁlling tree.
Another important version of the general problem is given by path planning in presence of mobile obstacles. As it can be easily understood, this kind of problem

Path Planning and Trajectory Planning Algorithms: A General Overview

13

results very complex with respect to the basic version. This approach is used, for instance, in [32, 33].
A general overview of the path planning problem can be found in [54] and in [43], where the most important results achieved in the ﬁeld of path planning, including PRM and RPP techniques, are reported. In [43] it is claimed that all the methodologies that have proven to be practically usable for path planning are based on a discretization of the conﬁguration space. There are two crucial requirements in order to ensure an efﬁcient implementation of path planning methodologies, namely: the efﬁciency of collision detection algorithms and the efﬁciency of graph searching techniques.

3 Trajectory Planning
Solving the trajectory planning problem means generating the reference inputs for the control system of the robot, so as to ensure that the desired motion is performed. Usually, the algorithm employed for trajectory planning takes as inputs the path generated by the path planner, as well as the kinematic and dynamic constraints of the robot. The output of the trajectory planning module is given by the trajectory of the joints, or of the end-effector, in form of a sequence of values of position, velocity and acceleration.
The geometric path is normally deﬁned in the operating space of the robot, because the task to be performed, as well as the obstacles to avoid, are described in the operating space more naturally than in the joint space. Thus, planning the trajectory in the operative space means generating a sequence of values that specify the position and orientation that the end-effector of the robot must assume at every time interval. Planning the trajectory in the operating space is usually done when the motion follows a path with speciﬁc geometric characteristics deﬁned in the operating space; in this case, the path can be speciﬁed in an exact form (i.e. taking the original path), or in an approximate form, by allocating some path points and connecting them by means of polynomial sequences. However, in most cases the trajectory is planned in the joint space of the robot because, since the control action on the manipulator is made on the joints, planning in the operating space requires a kinematic inversion to transform the end-effector position and orientation values into the joint values.
In order to plan a trajectory in the joint space, ﬁrst a sequence of via-points should be extracted from the desired end-effector path, then a kinematic inversion is to be performed to get the corresponding values of the robot joints. The trajectory is then generated in the joint space by means of interpolation functions, taking into account the kinematic and dynamic limits imposed to the robot joints (in terms of position, velocity, acceleration and jerk). Normally, this way of planning the trajectory can also avoid the problems involved in moving near singular conﬁgurations, and can efﬁciently deal with the possible presence of redundant degrees of mobility. The main drawback of planning a trajectory in the joint space is given by the fact that the execution of a motion planned in the joint space is not so straightforward to predict in the operative space, due to the nonlinearities introduced by the direct

14

A. Gasparetto et al.

kinematics. However, no matter if the trajectory is planned in the operating space or in the joint space, it is crucial that the laws of motion resulting from the planning do not generate forces and torques at the joints that are not compatible with the given constraints: in this way the possibility of exciting mechanical resonance modes can be greatly reduced. For this reason, the planning algorithms must output smooth trajectories, i.e. trajectories represented by a curve whose derivatives are continuous up to a certain order. In particular, it is highly desirable to ensure the continuity of the accelerations of the joints, in order to get trajectories with a limited jerk, because limiting the jerk is crucial in order to reduce the vibrations induced to the robot (which may lead to considerable wear of the mechanical structure), as well as to avoid the excitation of the resonance frequencies of the robot. The vibrations caused by non-smooth trajectories may seriously damage the actuators and degrade the tracking performance of the trajectory. Furthermore, low-jerk trajectories can be executed faster and with a higher accuracy as demonstrated in [6]. In addition, there are some applications where abrupt motions can jeopardize the quality of the work or constitute a risk to the human operators working near the robot.
In order to classify the different trajectory planning methodologies into categories, it is useful to consider that a trajectory is usually planned after some optimality criterion has been set. The most signiﬁcant optimality criteria that can be found in the literature are:
• minimum execution time; • minimum energy (or actuator effort); • minimum jerk.
In addition to the above, hybrid optimality criteria have been proposed, such as, for instance, time-energy optimal trajectory planning. With respect to the minimum energy criterion, a short clariﬁcation is necessary. In most of the cases related with trajectory planning, the term “energy” does not correspond to a physical quantity measured in Joules, but it is deﬁned as the integral of squared torques: in other words, it measures the effort of the robot actuators. However, in the robotic literature it is possible to ﬁnd also trajectory planning algorithms where the optimality index is “energy” in its strict meaning. Actually, this is not really a problem, because in the electric motors used on the robots, the torque can be assumed proportional to the current, so there is a correlation between the actuators’ effort and the energy required to the system.

3.1 Minimum Execution Time Algorithms
The optimality criterion based on minimum execution time was the ﬁrst to be considered in trajectory planning, because short execution times are strictly related to high productivity in automatized production plants in industrial environments. Thus, no wonder that many papers can be found, in the robotic literature, proposing

Path Planning and Trajectory Planning Algorithms: A General Overview

15

trajectory planning algorithms aimed at minimizing the performance index given by the execution time.
The algorithms described in [7, 80] are deﬁned in the position-velocity phase plane. The basic idea of these algorithms is to write the dynamic equation of manipulator in a parametric form using the curvilinear abscissa s of the path as the independent parameter. The curvilinear abscissa s (path parameter) and its derivative s pseudo-velocity) constitute the state of the system, while the second derivative of s (i.e. the pseudo-acceleration s ) is chosen as the control variable. In this way, it is possible to transform the constraints given by the nonlinear robot dynamics, as well as the constraints on the actuators, into constraints on the control variable depending from the state of the system. For every point on the path, the maximum admissible value for the pseudo-velocity of the end-effector is determined from the constraints; it is then possible to build in the position-velocity phase plane (i.e. in the (s, s ) plane), a velocity limit curve (VLC). The optimal trajectory is then computed by ﬁnding the admissible control that yields, for each point of the path, the maximum velocity that does not exceed the limit curve. The solution turns out to be in the form of a curve (named switching curve) in the phase plane.
An alternative approach to minimum time trajectory planning consists in using dynamic programming techniques, such as those described in [2, 81]. The basic idea is to take the state space and discretize it by building a grid of points (called state points). On the basis of the limits set on velocity, acceleration and jerk, it is possible to associate to each point the set of the subsequent admissible state points, and to deﬁne the cost of each possible solution by considering the time needed for the motion. This cost is deﬁned by assuming a constant value of acceleration for each step. Finally, an algorithm based on dynamic programming generates the minimum time trajectory. Compared with the phase plane methods, the dynamic programming methods do not require the parameterization of the path and enables to choose an arbitrary performance index. Therefore, such algorithms may be used as a general technique for trajectory optimization. On the other hand, the phase plane approach turns out to be very efﬁcient in terms of computational load; moreover, it may also be used for on-line trajectory planning, as in [28, 67].
A model-based approach is used to maximize the speed of industrial robots by obtaining the minimum-time trajectories that satisfy various constraints commonly given in the application of industrial robots in [52]. Conventional trajectory patterns, such as trapezoidal velocity proﬁles and cubic polynomial functions.
The algorithms described above produce trajectories with discontinuous accelerations and joint torques, because the dynamic models used consider the robot members as perfectly rigid and do not take into account the actuator dynamics. Neglecting the link ﬂexibility and the actuator dynamics normally leads to some undesired effects. First, in reality the robot actuators cannot generate discontinuous torques: this causes the joint motion to be delayed with respect to the reference trajectory. This accuracy in trajectory following is thus greatly reduced, and the tracking controller has to be often activated during the execution of the trajectory. Moreover, each switching of the actuators may cause the so-called chatter phenomenon, i.e. high frequency oscillations inducing vibrations of the mechanical structure of the robot. This obviously

16

A. Gasparetto et al.

results in wearing of the mechanical components and in a decrease of the accuracy in trajectory following. Again, the tracking controller is activated more frequently and the actuators are further stressed. Another undesired effect resulting from an inaccurate model is that, since the time-optimal control requires saturation of at least one robot actuator at any time instant, it is impossible for the controller to correct the tracking errors arising from disturbances or modelling errors.
In [26, 27] a possible solution to these kind of problems is proposed: in these works, the phase plane method is used, together with a limitation set on the torque variations (actuator jerks). The proposed algorithm takes the pseudo-jerk, deﬁned as the third derivative of the curvilinear abscissa, as the control variable: a dynamic equation of the third order is thus obtained. The experimental results presented in [26] show that, if some upper bound is set on the pseudo-jerk, time-optimal trajectories can be practically obtained by simply employing a conventional PID controller. This proves the correlation between accuracy in trajectory following and low values of jerk.
A different way to limit the torque variations is to consider in the objective function not only the execution time, but also an energy contribution: for instance in [79] the integral of squared torques along the whole trajectory is taken into account. The experimental results presented in [79] show that the increase of the overall motion time is compensated by a greater accuracy in trajectory following, even if conventional PD controllers are used. This results in a reduction of actuator stresses, with obvious advantages in the total lifetime of the electro-mechanical components of the robot.
It is possible to approach the problem of minimum-time trajectory planning by deﬁning a priori the primitives of the motion, i.e. the curves that deﬁne the trajectory in the joint space. Such curves must be smooth functions, so that the control signals and, consequently, the torque signals at the actuators, result also smooth functions. The most common situation is that in which the path is speciﬁed using a limited number of via-points: the solution is then given by spline interpolation. In the literature, several methodologies are proposed to compute time-optimal trajectories for robot manipulators based on optimization of splines, whose order may be three (cubic splines) or higher. The main differences among these techniques are:
• the type of constraints considered (either kinematic or dynamic); • the algorithm used to compute the optimal trajectory; • the possibility to extend the optimization problem, by taking into account other
optimization criteria, in addition to the minimum time.
The distinction based on the type of constraints can be considered the most important. It can be extended to any type of trajectory planning algorithm, so that the two categories of kinematic trajectory planning and dynamic trajectory planning can be deﬁned. The kinematic trajectory planning algorithms take as their input upper (sometimes also lower) bounds on velocity, acceleration and jerk. In most cases such bounds are considered constant. The dynamic trajectory planning algorithms consider the dynamic model of the robot and deﬁne an optimization problem taking into account dynamic constraints, such as bounds on the actuator torques, or on

Path Planning and Trajectory Planning Algorithms: A General Overview

17

the actuator jerks, deﬁned as the variation of the torques. In some cases kinematic constraint (typically the velocity) are also considered. Both approaches have pros and cons: the kinematic trajectory planning has its main advantage in the simplicity and in the lower computational load; on the other hand, the dynamic trajectory planning features a better capacity to use the robot actuators. In other words, the kinematic methods are based on a simpliﬁed computational model that yields a non-optimal use of the robot actuators, although in most cases reasonably good trajectories are planned. Dynamic methods are based on a more accurate model and therefore produce better solutions, but at the cost of a heavier computational load, since they have to deal with non-trivial issues, such as identiﬁcation of the dynamic parameters of the robot, or the efﬁciency in implementing efﬁcient algorithms to solve the robot dynamic equations.
An interesting example of an algorithm based on the inverse dynamic of a parallel robot is given by [17]. In this work, a multi-objective optimisation problem is formulated and a dedicated genetic algorithm is employed to ﬁnd an optimal trajectory based upon spline functions.
Splines function are therefore used as trajectory primitives in order to ensure the continuity of the acceleration. Another example can be found in [59], where a nonlinear optimization problem is set, namely the computation of the value of the time intervals between the via-points, so as to minimize the total execution time of the trajectory subject to kinematic constraints. The technique is based upon an unconstrained optimization algorithm named FPS (Flexible Polyhedron Search), in combination with an algorithm called FSC (Feasible Solution Converter), which converts the solutions that are not physically feasible (i.e. that are not compatible with the kinematic constraints) into feasible ones, by implementing a suitable time scaling of the trajectory generated by the FPS algorithm. In [93], the same optimization algorithm presented in [59] is used, but instead of cubic splines, cubic B-splines are taken as primitives of motion.
The algorithms described above produce a local optimal solution, while other minimum-time trajectory planning methods output a global optimal solution. Piazzi and Visioli use interval analysis to calculate a minimum-time trajectory subject to kinematic constraints at the joints. Such kinematic constraints are on the maximum value of velocity, acceleration and jerk. In [71] they extend the results already presented in [71, 72]. The simulations presented in [71] showed an improvement of 18 % of the total execution time with respect to the results yielded by a local optimization algorithm.
In [40, 41] a global optimization method is presented, which combines a stochastic technique, such as a genetic algorithm, with a deterministic procedure based on interval analysis. The proposed technique can be applied to solve general global optimization problems where semi-inﬁnite constraints are deﬁned. In [40] this algorithm is applied to the problem of minimum-time trajectory planning with speciﬁc kinematic and dynamic constraints: namely, the trajectories, represented by cubic splines, are subject to restrictions on the maximum actuator torques, as well as on the linear and angular velocities of the end-effector in the operating space. It is remarkable

18

A. Gasparetto et al.

that, differently from usual, in [40] the velocity constraint is not imposed in the joint space, but in the operating space of the end-effector.
A composition of polynomial functions of different orders are used in [11, 12] to obtain jerk continuity along a trajectory planned from a set of pre-deﬁned via-points, obtaining a global minimum time solution.
Another example of minimum-time trajectory planning for robotic manipulators can be found in [16]. In this case the objective function is made of two terms: the ﬁrst term takes the squared values of the optimization variables (i.e. of the time intervals between the via-points), while the second term is the sum of the squared accelerations computed at the via- points. The introduction of this second term has the effect of increasing the trajectory smoothness with respect to a pure minimum-time approach. The optimization is performed by using the DFP (Davidon-Fletcher-Powell) algorithm, which does not consider the kinematic bounds, therefore performing an unconstrained minimization. The solution obtained by means of the DFP algorithm is then subjected to a procedure of time-scaling, until the more restrictive kinematic bound has been saturated. The resulting trajectory, although respecting the limits on velocity, acceleration and jerk, is sub-optimal with respect to time.
In [30] a technique for determining time-optimal path-constrained trajectories subject to velocity, acceleration and jerk constraints, acting on both the robot actuators and on the task to be executed, is presented. The solution of the optimization problem is based upon a hybrid optimization strategy, which takes into account the path description, the kinematic model of the robot and constraints deﬁned by the user. The resulting trajectories are optimal with respect to time, but not with respect to smoothness.
In the work [60] a combination of spline functions up to the seventh order are used together to achieve minimum time solutions with velocities, acceleration and jerk bounds. Other examples of minimum-time algorithms subject to kinematic constraints may be found in [31, 49, 85, 86, 89]. In [74] the minimum-time trajectory problem is solved under kinematic and dynamic constraints, i.e. teorque, power, jerk and energy, taking into account both the robot dynamics and the obstacle presence.

3.2 Minimum Energy Algorithms
As already remarked, the minimum-time trajectory planning algorithms received a lot of consideration in the robotic literature, mainly because of the strong industrial interest to reduce the length of the production cycles. However, the minimum-time optimization criterion is not the only one that can be considered: other criteria are deﬁnitely more suitable for different needs and requirements.
The trajectory planning based on energetic criteria is interesting under many aspects. On one hand, it generates smooth trajectories which are easier to track, and reduce the stresses induced to the actuators and to the mechanical structure of the robot. On the other hand, this optimization criterion enables one to better comply with energy saving requirements, which are driven not only by mere economic

Path Planning and Trajectory Planning Algorithms: A General Overview

19

considerations, but may be imposed by speciﬁc applications in which the energy source is limited by technical factors, such as robotic applications for outer space, for underwater exploration or for military tasks.
A classical example of minimum-energy trajectory planning algorithm is contained in [65], where a trajectory is optimized with respect to energy taking into account constraints on the motion of the end-effector, as well as the physical limits of the joints. The proposed objective function is the integral of squared torques. The trajectories are expressed by cubic B-splines and, by exploiting some property of the convex hull, it is possible to transform the joint limits into some limits set on the optimization parameter, which are the control points of the B-splines. The resulting motion thus minimizes the effort of the actuators.
In [2, 79] some techniques for optimal trajectories planning, with respect to energy and time, are described: the function to optimize is made of two terms, the ﬁrst related to the execution time, the second related to the energy consumption. Such algorithms are intended to reduce the stresses of the actuators and to facilitate the trajectory tracking. In [79], the integral of the squared torques along the trajectory is considered in the objective function, while in [2] the function of total energy is considered.
Other examples of optimized trajectories, with respect to energy as well as to time, are presented in [75–77, 90, 95]. In [75] the Authors consider a trajectory parameterized by cubic splines, subject to kinematic constraints set on the maximum value of velocity, acceleration and jerk, and to dynamic constraint given by the maximum torque applicable to the joints. In [76] the same Authors consider a trajectory parameterized by cubic B-splines, where the physical limits of the joints are added to the torque and kinematic constraints. The objective function includes also an additional term (penalty function), in order to avoid mobile obstacles expressed as spherical or hyperspherical safety zones. In [77], two strategies for ofﬂine 3-dimensional optimal trajectory planning of industrial robots, in presence of ﬁxed obstacles, are presented. In [90], a nonlinear change of variables is employed to convert the time-energy optimal trajectory planning problem into a convex control problem based on only one state variable. In [95], a methodology based on the minimization of an objective function which considers both the total execution time and the total energy spent along the whole trajectory is presented; the via-points of the trajectory are interpolated by means of cubic splines. Kinematic and dynamic constraints, in terms of upper bounds on velocity, acceleration, jerk and input forces and torques are also considered. It is worth noting that in algorithms such as the one presented in [79] the energy term is added in order to produce trajectories which result slower but smoother with respect to those generated by minimum-time trajectory planning algorithms; on the other hand, in approaches such as the one presented in [76] the objective function is primarily designed to minimize the energy and to plan trajectories with no regard to the execution time.
Recently, due to the development and installation of energy recovery and redistribution devices in robotic systems, the minimum-energy topic has gained new interest among the research community, e.g. [44, 68].

20
3.3 Minimum Jerk Algorithms

A. Gasparetto et al.

The importance of generating trajectories that do not impose discontinuities of the actuator torques at the robot joints has already been remarked; for instance, in [26] and in [27] this result is obtained by imposing upper bounds to the rate of change of the actuator torques. However, this kind of approach requires the computation of the third order dynamics of the robot.
An alternative method to obtain smooth proﬁles of the actuator torques is based on the idea of limiting the jerk, deﬁned as the time derivative of the acceleration. Indeed, the torque variations depend upon the dominant term of the matrix of inertia multiplied by the vector of the joint jerk. Thus, some trajectory planning methods take the jerk as the variable to be minimized, in order to obtain smooth trajectories. The minimization of the jerk yields positive results, such as: reduction of the error during the trajectory tracking phase, reduction of the excitation of resonance frequencies, reduction of the stresses induced to the mechanical structure of the robot and to the actuators.
This results in a natural and coordinated motion: indeed, some studies suggest that the movements of the human arm satisfy an optimization criterion based upon the minimization of the jerk, or of the torque variations [82]. The minimum-jerk trajectory planning for robotic manipulators are an example of optimization based on physical criteria which mimic the human ability to produce natural movements [8].
In [56] the analytical solution of a trajectory planning problem for a point-to-point path, based on a minimum-jerk optimization criterion, is presented. The optimization, performed by applying Pontryagin’s principle, involves two objective functions, namely: the maximum absolute value of jerk (minimax approach) and the time integral of the squared jerk.
In some cases, the total execution time of the trajectory is not imposed, so it can be chosen so as to comply with the kinematic limits on velocity and acceleration. However, most of the minimum-jerk algorithms that can be found in the robotic literature consider an execution time imposed a priori.
In [82], the integral of the squared jerk is minimized along the executed trajectory. In order to have a trajectory with a smooth start and stop, the values of velocity, acceleration and jerk are set to zero at the ﬁrst and at the last via-points. The proposed algorithm is based upon a stochastic optimization technique performed by means of neural networks. The algorithm does not ensure the exact interpolation of intermediate nodes, but allows a tolerance, which can be set by tuning appropriate weights. This does not constitute a problem in cases where the exact interpolation is not needed, but just the passage in the neighbourhood of the via-points is required. The main limitation of this technique is that the resulting trajectories are not analytical functions, but are numerically deﬁned.
Another approach is contained in [83], where the interpolation of the via-points is performed by means a trigonometric spline, thus ensuring the continuity of the jerk. The algorithm assumes that the time interval between the via-points is known and constant, and takes as input the values for the velocity, the acceleration and the

Path Planning and Trajectory Planning Algorithms: A General Overview

21

jerk, at the ﬁrst and at the last via-points (such values are typically all set to zero). There are some advantages in using trigonometric splines to interpolate the trajectory via-points, for instance the property of locality: namely, if a via-point is changed, it is not necessary to recalculate the whole trajectory, but only the two splines that are connected to the via-point need to be recomputed. This property allows fast computation, thus making it possible to implement obstacle avoidance procedures in real time. The most signiﬁcant aspect, in terms of trajectory optimization, is that parameterizing the trajectory allows some degrees of freedom, namely those given by the values of the ﬁrst three derivatives (velocity, acceleration and jerk) at the intermediate via-points. Such values can be adjusted in order to minimize an objective function, such as the time integral of the squared jerk. The optimization presented in [83] is not bounded, since no kinematic limits are imposed, and yields a closed form solution, thus not requiring iterative minimization procedures.
In [70, 73] an algorithm based on interval analysis is presented. This technique seeks the minimum of the maximum absolute value of the jerk along a trajectory whose execution time is imposed a priori. It is therefore a so-called minimax approach bounded on the trajectory execution time. The trajectories primitives are cubic splines and the intervals between the via-points are computed, so as to obtain the lowest maximum absolute jerk value. In [70] the Authors present a comparison with the method based on trigonometric splines [83], reporting the highest values of the jerk, of the torques and of the torque variations. The simulation, which calculates the robot dynamics using the MatLabTM Robotics Toolbox, highlights the efﬁciency of the minimax algorithm with respect to other approaches.

3.4 Hybrid Optimization Approaches
Optimal trajectory planning with respect to time, energy and jerk has been discussed in the foregoing. Hybrid optimization approaches have also been proposed in the robotic literature. For instance, in order to get the advantages of the jerk reduction while executing fast trajectories, hybrid time-jerk optimal techniques are proposed, for instance [9, 11, 36–38, 46, 69]. These algorithms differ from the primitives used to interpolate the path, or from the optimization procedures implemented.
In [9, 11, 36–38] a minimum time-jerk trajectory planning technique is described, based upon two algorithms aimed at the minimization of an objective function, which is designed so as to ensure fastness in execution and smoothness of the trajectory at the same time. Such an objective function is composed of a term which is proportional to the total execution time and of a term which is proportional to the integral of the squared jerk along the path. The proposed algorithm enables one to deﬁne constraints on the robot motion before the execution of the trajectory. The constraints are expressed in form of upper bounds on the velocity, acceleration and jerk values

22

A. Gasparetto et al.

of all robot joints. In this way, any physical limitation of the real robot can be taken into account when planning the trajectory. Unlike most jerk-minimization methods, this technique does not ask for an a priori setting of the total execution time.
In [61, 62], the methodology is extended by taking into account also the power consumption of the actuators and physical limits of the joints. In this way, the technique becomes a time-jerk-energy planning algorithm.
Several objectives are taken into account in the work [51]: in particular minimum elctrical and kinematic energy, minimum time and maximum maniuplability are obtained with the solution of a single optimization problem.
Minimum effort trajectories planned trough model-based approaches are presented in [10, 14]. The ﬁrst one includes bounds on jerk, while second one has bounded joint speed. The work [13] introduces the novel topic of robustness in trajectory planning algorithms. Such approach allows to increase the tolerance of the resulting trajectory to the inevitable mismatches between the dynamic model used for the planning and the actual robot dynamics.
The problem of ﬁnding minimum time-effort trajectories for motor-driven parallel platform manipulators, subject to the constraints imposed by the kinematics and dynamics of the manipulator structure is the topic of the paper [21]. Computational efﬁciency is obtained trough a hybrid scheme comprising the particle swarm optimization method and the local conjugate gradient method. Also in [22] a constrained multi-objective genetic algorithm (MOGA) based technique is proposed to address this problem for a general motor-driven parallel kinematic manipulator. The planning process is composed of searching for a motion ensuring the accomplishment of the assigned task, minimizing the traverse time, and expended energy subject to various constraints imposed by the associated kinematics and dynamics of the manipulator.
All the trajectory planning methods introduced above are applicable to rigid link robot, with either serial or parallel kinematic conﬁgurations. However, it is worthwhile to mention that also cable-driven robots application are gaining a growing interest in robotics. Among the advantages brought by this class of manipulators, low overall mass and high stiffness make them very advantageous in many applications. On the other hand, the fact that they often require to use actuation redundancy and that they operation must avoid cable interference [94], has led to the development of trajectory planning algorithms speciﬁcally designed for them. The work [87] presents a method to compute trajectories for underconstrained parallel robot that ensures positive and bounded cable tension, while in [88] a similar procedure is also experimentally validated. A detailed study of the dynamics of cable-driven parallel robot is reported in [47], as a tool for developing accurate path planning algorithms. The time-optimality of trajectories designed for cable-driven robot is the topic covered in the works [3, 4].

Path Planning and Trajectory Planning Algorithms: A General Overview

23

4 Conclusions

In this paper, the fundamental problems of path planning and trajectory planning in Robotics have been addressed. An overview of the most signiﬁcant methods, that can be found in the robotic literature to generate collision-free paths, has been presented. Then, the problem of ﬁnding an optimal trajectory given a planned path has been discussed and the most signiﬁcant approaches have been described.

References
1. Amato NM, Wu Y (1996) A randomized roadmap method for path and manipulation planning. In: Proceedings of the 1996 IEEE international conference on robotics and automation, pp 113–120
2. Balkan T (1998) A dynamic programming approach to optimal control of robotic manipulators. Mech Res Commun 25(2):225–230
3. Bamdad M (2013) Time-energy optimal trajectory planning of cable-suspended manipulators. Cable-driven parallel robots. Springer, Berlin, pp 41–51
4. Barnett E, Gosselin C (2013) Time-optimal trajectory planning of cable-driven parallel mechanisms for fully-speciﬁed paths with g1 discontinuities. In: ASME 2013 international design engineering technical conferences and computers and information in engineering conference. American Society of Mechanical Engineers
5. Barraquand J, Latombe JC (1991) Robot motion planning: a distributed representation approach. Int J Robot Res 10(6):628–649
6. Barre PJ, Bearee R, Borne P, Dumetz E (2005) Inﬂuence of a jerk controlled movement law on the vibratory behaviour of high-dynamics systems. J Intell Robot Syst 42(3):275–293
7. Bobrow JE, Dubowsky S, Gibson JS (1985) Time-optimal control of robotic manipulators along speciﬁed paths. Int J Robot Res 4(3):554–561
8. Bobrow JE, Martin BJ, Sohl G, Wang EC, Kim J (2001) Optimal robot motion for physical criteria. J Robot Syst 18(12):785–795
9. Boscariol P, Gasparetto A, Lanzutti A, Vidoni R, Zanotto V (2011) Experimental validation of minimum time-jerk algorithms for industrial robots. J Intell Robot Syst 64(2):197–219
10. Boscariol P, Gasparetto A (2013) Model-based trajectory planning for ﬂexible link mechanisms with bounded jerk. Robot Comput Integr Manuf 29(4):90–99
11. Boscariol P, Gasparetto A, Vidoni R (2012) Jerk-continous trajectories for cyclic tasks. In: Proceedings of the ASME 2012 international design engineering technical conferences (IDETC), pp 1–10
12. Boscariol P, Gasparetto A, Vidoni R (2012) Planning continuous-jerk trajectories for industrial manipulators. In: Proceedings of the ESDA 2012 11th biennial conference on engineering system design and analysis, pp 1–10
13. Boscariol P, Gasparetto A, Vidoni R (2013) Robust trajectory planning for ﬂexible robots. In: Proceedings of the 2013 ECCOMAS multibody dynamics conference, pp 293–294
14. Boscariol P, Gasparetto A, Vidoni R, Romano A (2013) A model-based trajectory planning approach for ﬂexible-link mechanisms. In: Proceedings of the ICM 2013—IEEE international conference on mechatronics, pp 1–6
15. Canny J, Donald B (1988) Simpliﬁed voronoi diagrams. Discret Comput Geom 3(1):219–236 16. Cao B, Dodds GI (1994) Time-optimal and smooth constrained path planning for robot manip-
ulators. In: Proceedings of the 1994 IEEE international conference on robotics and automation, pp 1853–1858 17. Carbone G, Ceccarelli M, Oliveira PJ, Saramago SF, Carvalho JCM (2008) An optimum path planning for Cassino parallel manipulator by using inverse dynamics. Robotica 26(2):229–239

24

A. Gasparetto et al.

18. Caselli S, Reggiani M (2000) ERPP: an experience-based randomized path planner. In: Proceedings of the ICRA’00—IEEE international conference on robotics and automation, pp 1002– 1008
19. Caselli S, Reggiani M, Rocchi R (2001) Heuristic methods for randomized path planning in potential ﬁelds. In: Proceedings of the 2001 IEEE international symposium on computational intelligence in robotics and automation, pp 426–431
20. Caselli S, Reggiani M, Sbravati R (2002) Parallel path planning with multiple evasion strategies. In: Proceedings of the ICRA’02—IEEE international conference on robotics and automation, pp 260–266
21. Chen CT, Liao TT (2011) A hybrid strategy for the time-and energy-efﬁcient trajectory planning of parallel platform manipulators. Robot Comput-Integr Manuf 27(1):72–81
22. Chen CT, Pham HV (2012) Trajectory planning in parallel kinematic manipulators using a constrained multi-objective evolutionary algorithm. Nonlinear Dyn 67(2):1669–1681
23. Choset HM, Lynch KM, Hutchinson S, Kantor GA, Burgard W, Kavraki LE, Thrun S (2005) Principles of robot motion: theory, algorithms, and implementation. MIT Press, Cambridge
24. Clark CM, Rock S (2001) Randomized motion planning for groups of nonholonomic robots. In: Proceedings of the 6th international symposium on artiﬁcial intelligence, robotics and automation in space, pp 1–8
25. Connolly CI, Burns JB (1990) Path planning using Laplace’s equation. In: Proceedings of the 1985 IEEE international conference on robotics and automation, pp 2102–2106
26. Constantinescu D (1998) Smooth time optimal trajectory planning for industrial manipulators. Ph.D. Thesis, The University of British Columbia, 1998
27. Constantinescu D, Croft EA (2000) Smooth and time-optimal trajectory planning for industrial manipulators along speciﬁed paths. J Robot Syst 17(5):233–249
28. Croft EA, Benhabib B, Fenton RG (1995) Near time-optimal robot motion planning for on-line applications. J Robot Syst 12(8):553–567
29. Donald BR, Xavier PG (1990) Provably good approximation algorithms for optimal kinodynamic planning for Cartesian robots and open chain manipulators. In: Proceedings of the sixth annual symposium on computational geometry, pp 290–300
30. Dong J, Ferreira PM, Stori JA (2007) Feed-rate optimization with jerk constraints for generating minimum-time trajectories. Int J Mach Tools Manuf 47(12–13):1941–1955
31. Dongmei X, Daokui Q, Fang X (2006) Path constrained time-optimal robot control. In: Proceedings of the international conference on robotics and biomimetics, pp 1095–1100
32. Fiorini P, Shiller Z (1996) Time optimal trajectory planning in dynamic environments. In: Proceedings of the 1996 IEEE international conference on robotics and automation, pp 1553– 1558
33. Fraichard T (1999) Trajectory planning in a dynamic workspace: a state-time space approach. Adv Robot 13(1):74–94
34. Fraichard T, Laugier C (1993) Dynamic trajectory planning, path-velocity decomposition and adjacent paths. In: Proceedings of the 1993 international joint conference on artiﬁcial intelligence, pp 1592–1597
35. Garrido S, Moreno L, Lima PU (2011) Robot formation motion planning using fast marching. Robot Auton Syst 59(9):675–683
36. Gasparetto A, Zanotto V (2007) A new method for smooth trajectory planning of robot manipulators. Mech Mach Theor 42(4):455–471
37. Gasparetto A, Zanotto V (2008) A technique for time-jerk optimal planning of robot trajectories. Robot Comput-Integr Manuf 24(3):415–426
38. Gasparetto A, Lanzutti A, Vidoni R, Zanotto V (2012) Experimental validation and comparative analysis of optimal time-jerk algorithms for trajectory planning. Robot Comput-Integr Manuf 28(2):164–181
39. Ge SS, Cui YJ (2000) New potential functions for mobile robot path planning. IEEE Trans Robot Autom 16(5):615–620
40. Guarino Lo Bianco C (2001a) A semi-inﬁnite optimization approach to optimal spline trajectory planning of mechanical manipulators. In: Goberna MA, Lopez MA (eds) Semi-inﬁnite programming: recent advances. Springer, pp 271–297

Path Planning and Trajectory Planning Algorithms: A General Overview

25

41. Guarino Lo Bianco C, Piazzi A (2001b) A hybrid algorithm for inﬁnitely constrained optimization. Int J Syst Sci 32(1):91–102
42. Guldner J, Utkin VI (1995) Sliding mode control for gradient tracking and robot navigation using artiﬁcial potential ﬁelds. IEEE Trans Robot Autom 11(2):247–254
43. Gupta K, Del Pobil AP (1998) Practical motion planning in robotics: current approaches and future directions. Wiley
44. Hansen C, Oltjen J, Meike D, Ortmaier T (2012) Enhanced approach for energy-efﬁcient trajectory generation of industrial robots. In: Proceedings of the 2012 IEEE international conference on automation science and engineering (CASE 2012), pp 1–7
45. Hsu D, Kindel R, Latombe JC, Rock S (2002) Randomized kinodynamic motion planning with moving obstacles. Int J Robot Res 21(3):233–255
46. Huang P, Xu Y, Liang B (2006) Global minimum-jerk trajectory planning of space manipulator. Int J Control, Autom Syst 4(4):405–413
47. Ismail M, Samir L, Romdhane L (2013) Dynamic in path planning of a cable driven robot. Design and modeling of mechanical systems. Springer, Berlin, pp 11–18
48. Jing XJ (2008) Edited by. Motion planning, InTech 49. Kazemi M, Gupta K, Mehrandezh M (2010) Path-planning for visual servoing: a review and
issues. Visual servoing via advanced numerical methods. Springer, London, pp 189–207 50. Khatib O (1985) Real-time obstacle avoidance for manipulators and mobile robots. In: Pro-
ceedings of the 1985 IEEE international conference on robotics and automation, pp 500–505 51. Kim JO, Khosla PK (1992) Real-time obstacle avoidance using harmonic potential functions.
IEEE Trans Robot Autom 8(3):338–349 52. Kim J, Kim SR, Kim SJ, Kim DH (2010) A practical approach for minimum-time trajectory
planning for industrial robots. Ind Robot: Int J 37(1):51–61 53. Koditschek DE (1992) Exact robot navigation using artiﬁcial potential functions. IEEE Trans
Robot Autom 8(5):501–518 54. Kumar V, Zefran M, Ostrowski JP (1999) Motion planning and control of robots. In: Nof
Shimon Y (ed) Handbook of industrial robotics, 2nd edn, vol 2. Wiley 55. Kunchev V, Jain L, Ivancevic V, Finn A (2006) Path planning and obstacle avoidance for
autonomous mobile robots: a review. Knowledge-based intelligent information and engineering systems. Springer, Berlin, pp 537–544 56. Kyriakopoulos KJ, Saridis GN (1988) Minimum jerk path generation. In: Proceedings of the 1988 IEEE international conference on robotics and automation, pp 364–369 57. Latombe JC (1991) Robot motion planning. Kluwer 58. LaValle SM (2006) Planning algorithms. Cambridge University Press 59. Lin CS, Chang PR, Luh JYS (1983) Formulation and optimization of cubic polynomial joint trajectories for industrial robots. IEEE Trans Autom Control 28(12):1066–1073 60. Liu H, Lai X, Wu W (2013) Time-optimal and jerk-continuous trajectory planning for robot manipulators with kinematic constraints. Robot Comput-Integr Manuf 29(2):309–317 61. Lombai F, Szederkenyi G (2008) Trajectory tracking control of a 6-degree-of-freedom robot arm using nonlinear optimization. In: Proceedings of the 10th IEEE international workshop on advanced motion control, pp 655–660 62. Lombai F, Szederkenyi G (2009) Throwing motion generation using nonlinear optimization on a 6-degree-of-freedom robot manipulator. In: Proceedings of the 2009 IEEE international conference on mechatronics, pp 1–6 63. Lozano-Pérez T, Wesley MA (1979) An algorithm for planning collision-free paths among polyhedral obstacles. Commun ACM 22(10):560–570 64. Lozano-Perez T (1983) Spatial planning: a conﬁguration space approach. IEEE Trans Comput 100(2):108–120 65. Martin BJ, Bobrow JE (1999) Minimum effort motions for open chain manipulators with task-dependent end-effector constraints. Int J Robot Res 18(2):213–224 66. Nissoux C, Simon T, Latombe JC (1999) Visibility based probabilistic roadmaps. In: Proceedings of the 1999 IEEE international conference on intelligent robots and systems, pp 1316–1321

26

A. Gasparetto et al.

67. Pardo-Castellote G, Cannon RH (1996) Proximate time-optimal algorithm for on-line path parameterization and modiﬁcation. In: Proceedings of the 1996 IEEE international conference on robotics and automation, pp 1539–1546
68. Pellicciari M, Berselli G, Leali F, Vergnano A (2013) A method for reducing the energy consumption of pick-and-place industrial robots. Mechatronics 23(3):326–334
69. Petrinec K, Kovacic Z (2007) Trajectory planning algorithm based on the continuity of jerk. In: Proceedings of the 2007 Mediterranean conference on control and automation, pp 1–5
70. Piazzi A, Visioli A (2000) Global minimum-jerk trajectory planning of robot manipulators. IEEE Trans Ind Electron 47(1):140–149
71. Piazzi A, Visioli A (1997b) A cutting-plane algorithm for minimum-time trajectory planning of industrial robots. In: Proceedings of the 36th Conference on decision and control, pp 1216–1218
72. Piazzi A, Visioli A (1997a) A global optimization approach to trajectory planning for industrial robots, In: Proceedings of the 1997 IEEE-RSJ international conference on intelligent robots and systems, pp 1553–1559
73. Piazzi A, Visioli A (1997c) An interval algorithm for minimum-jerk trajectory planning of robot manipulators. In: Proceedings of the 36th Conference on decision and control, pp 1924–1927
74. Rubio F, Valero F, Sunyer J, Cuadrado J (2012) Optimal time trajectories for industrial robots with torque, power, jerk and energy consumed constraints. Ind Robot Int J 39(1):92–100
75. Saramago SFP, Steffen V Jr (1998) Optimization of the trajectory planning of robot manipulators tacking into account the dynamics of the system. Mech Mach Theory 33(7):883–894
76. Saramago SFP, Steffen V Jr (2000) Optimal trajectory planning of robot manipulators in the presence of moving obstacles. Mech Mach Theory 35(8):1079–1094
77. Saravan R, Ramabalan R, Balamurugan C (2009) Evolutionary multi-criteria trajectory modeling of industrial robots in the presence of obstacles. Eng Appl Artif Intell 22(2):329–342
78. Sciavicco L, Siciliano B, Villani L, Oriolo G (2009) Robotics. Modelling, planning and control. Springer, London
79. Shiller Z (1996) Time-energy optimal control of articulated systems with geometric path constraints. J Dyn Syst Meas Control 118:139–143
80. Shin KG, McKay ND (1985) Minimum-time control of robotic manipulators with geometric path constraints. IEEE Trans Autom Control 30(6):531–541
81. Shin KG, McKay ND (1986) A Dynamic programming approach to trajectory planning of robotic manipulators. IEEE Trans Autom Control 31(6):491–500
82. Simon D (1993) The application of neural networks to optimal robot trajectory planning. Robot Auton Syst 11(1):23–34
83. Simon D, Isik C (1993) A trigonometric trajectory generator for robotic arms. Int J Control 57(3):505–517
84. Takahashi O, Schilling RJ (1989) Motion planning in a plane using generalized Voronoi diagrams. IEEE Trans Robot Autom 5(2):143–150
85. Tangpattanakul P, Meesomboon A, Artrit P (2010) Optimal trajectory of robot manipulator using harmony search algorithms. Recent advances in harmony search algorithm. Springer, Berlin, pp 23–36
86. Tangpattanakul P, Artrit P (2009) Minimum-time trajectory of robot manipulator using harmony search algorithm. In: Proceedings of the IEEE 6th international conference on ECTI-CON 2009, pp 354–357
87. Trevisani A (2010) Underconstrained planar cable-direct-driven robots: a trajectory planning method ensuring positive and bounded cable tensions. Mechatronics 20(1):113–127
88. Trevisani A (2013) Experimental validation of a trajectory planning approach avoiding cable slackness and excessive tension in underconstrained translational planar cable-driven robots. Cable-driven parallel robots. Springer, Berlin, pp 23–29
89. Van Dijk NJM, Van de Wouw N, Nijmeijer H, Pancras WCM (2007) Path-constrained motion planning for robotics based on kinematic constraints. In: Proceedings of the ASME 2007 international design engineering technical conference and computers and information in engineering conference, pp 1–10

Path Planning and Trajectory Planning Algorithms: A General Overview

27

90. Verscheure D, Demeulenaere B, Swevers J, De Schutter J, Diehl M (2008) Time-energy optimal path tracking for robots: a numerically efﬁcient optimization approach. In: Proceedings of the 10th international workshop on advanced motion control, pp 727–732
91. Volpe RA (1990) Real and artiﬁcial forces in the control of manipulators: theory and experiments. The Robotics Institute, Carnegie Mellon University, Pittsburgh, 1990
92. Volpe RA, Khosla PK (1990) Manipulator control with superquadric artiﬁcial potential functions: theory and experiments. IEEE Trans Syst, Man, Cybern 20(6):1423–1436
93. Wang CH, Horng JG (1990) Constrained minimum-time path planning for robot manipulators via virtual knots of the cubic B-spline functions. IEEE Trans Autom Control 35(5):573–577
94. Williams RL, Gallina P (2002) Planar cable-direct-driven robots: design for wrench exertion. J Intell Robot Syst 35(2):203–219
95. Xu H, Zhuang J, Wang S, Zhu Z (2009) Global time-energy optimal planning of robot trajectories. In: Proceedings of the international conference on mechatronics and automation, pp 4034–4039

Off-Line and On-Line Trajectory Planning
Zvi Shiller

Abstract The basic problem of motion planning is to select a path, or trajectory, from a given initial state to a destination state, while avoiding collisions with known static and moving obstacles. Ideally, it is desirable that the trajectory to the goal be computed online, during motion, to allow the robot react to changes in the environment, to a moving target, and to errors encountered during motion. However, the inherent difﬁculty in solving this problem, which stems from the high dimensionality of the search space, the geometric and kinematic properties of the obstacles, the cost function to be optimized, and the robot’s kinematic and dynamic model, may hinder a sufﬁciently fast solution to be computed online, given reasonable computational resources. As a result, existing work on motion planning can be classiﬁed into offline and on-line planning. Off-line planners compute the entire path or trajectory to the goal before motion begins, whereas on-line planners generate the trajectory to the goal incrementally, during motion. This chapter reviews the main approaches to off-line and on-line planning, and presents one solution for each.
Keywords Motion planning · Trajectrory optimization · Online planning

1 Introduction

One of the basic problems in robotics is that of motion planning, which attempts to move a robot from a given initial state to a destination state, while avoiding collisions with known static and moving obstacles. We distinguish between a path and a trajectory: a path italic represents a sequence of positions, deﬁned in the robot’s conﬁguration space, which is the space of all positions, or conﬁgurations, that the robot can achieve [1]. A trajectory italic can be viewed as a path with a velocity proﬁle along it, deﬁned in the higher dimensional state space, where every point deﬁnes a position, or a conﬁguration, and the velocity vector at that point. Thus, path

Z. Shiller (B)
Department of Mechanical Engineering and Mechatronics, Ariel University, Ariel, Israel
e-mail: shiller@ariel.ac.il

© Springer International Publishing Switzerland 2015

29

G. Carbone and F. Gomez-Bravo (eds.), Motion and Operation Planning

of Robotic Systems, Mechanisms and Machine Science 29,

DOI 10.1007/978-3-319-14705-5_2

30

Z. Shiller

planning solves a geometric, or kinematic, problem, whereas trajectory planning solves a dynamic problem [1]. In this chapter, we will focus on trajectory italic planning.
Generally, it is desirable that the trajectory to the goal be computed online, during motion, to allow the robot to react to changes in the environment to a moving target, and to errors encountered during motion. However, the inherent difﬁculty in solving this problem, which stems from the high dimensionality of the search space, the geometric nature of the obstacles, the cost function to be optimized, and the robot’s kinematic and dynamic model, prevents it from being solved sufﬁciently fast to be done online, given reasonable computational resources. As a result, two branches of research have emerged in the area of motion planning: off-line planning, where the trajectory to the goal is computed before motion begins, and on-line planning where the trajectory to the goal is computed incrementally during motion. We thus associate off-line with the computation of the entire trajectory to the goal, and on-line with incremental planning, regardless of the computational resources available for the planning process.
Another distinction between off-line and on-line planners is that the former may produce globally optimal solutions if the environment is fully known, whereas the latter is locally optimal at best. The challenges in off-line planning are therefore: optimality (local and global), completeness (will a solution be found if one exists), and overall computational complexity. The challenges in online planning are: completeness (is the planner guaranteed to reach the goal if a solution exists), computational complexity at each step, and optimality (how far is a solution from the optimal and is it bounded by an upper limit).
Off-line planners are most useful for repeatable tasks in static environments where optimality is essential, as is the case in many industrial applications. On-line planners are required in applications where the target states are determined on the ﬂy, obstacles are discovered during motion, the environment is changing during motion, the computation time required for a global solution delays the task execution, or simply as an alternative to a computationally expensive off-line search [2].
The different nature of the two types of planners has resulted in distinct strategies to reaching the goal: the off-line planner takes generally a global view of the environment to select the optimal trajectory to the goal, whereas the on-line planner may select the next move based on a partial view of the environment. Both approaches were pursued at the early stages of the development of the ﬁeld of motion planning in the early 80s [3–6]. The main focus then was on path planning, with the goal of computing the shortest path from start to goal in the presence of static obstacles [3, 4, 6].
Focusing on the shortest path resulted in geometric planners that account for the geometry of the moving object and obstacles. While the computation of an obstaclefree path may solve many important problems in industrial settings, where the robot may move slowly, it is insufﬁcient, and almost useless, when the robot needs to move at reasonably high speeds, such as mobile robots moving through cluttered environments, and autonomous vehicles negotiating freeway trafﬁc. Furthermore, the computed geometric path is insufﬁcient to move the robot along the path unless

Off-Line and On-Line Trajectory Planning

31

some speed proﬁle along the path is speciﬁed. Selecting the speed proﬁle that can be followed without the robot deviating from the path requires knowledge of the robot dynamic behavior. This brings to focus the problem of trajectory planning, which was addressed using tools rooted in optimal control theory. The two ﬁelds of research, path planning and trajectory planning, were developed in parallel over the years until recently when geometric planners were extended to searching for trajectories in the state space [7, 8]. While the focus in this chapter is off-line and on-line trajectory planning, we begin the literature review with geometric planners.

1.1 Geometric Planners
The introduction of the conﬁguration space as the basic geometric motion planning tool [4, 9, 10] reduced the search for an obstacle-free path to computing a continuous path for a point from start to goal that avoids the forbidden regions representing the physical static obstacles. Being a geometric problem, most off-line planners are based on a geometric representation of the environment, through which a global search produces the shortest path to the goal. The geometric representations may consist of roadmaps or graphs that capture the topology of the free-space, generated e.g. by a Voronoi diagram, a visibility graph, a tangent graph [11, 12], or by cell decomposition [13]. Although each representation differs in the way it represents the free space, they all consist of a connected network of path segments that can be traversed from start to goal. The main computational effort in these planners is the representation of the free-space. This includes mapping of obstacles to the conﬁguration space and the initial construction of the roadmap. Once the roadmap was constructed, the search for the shortest path is done using standard graph search techniques such as Dijkstra’s search [14] or A* [15]. The remaining difﬁculties stem from the dimensionality of the search space and the number of edges (segments) in the roadmap. The main computational effort here is the construction of the roadmap.
An alternative approach to constructing roadmaps is to overlay a uniform grid over the search space and represent the entire space by an undirected graph [2]. Assigning high costs to edges that intersect obstacles, effectively separates between inaccessible nodes and nodes in the free space. As a result, this, like all approaches that are based on a discrete representation of the search space, is resolution complete, implying that at low grid resolutions one may miss paths that pass through tight spaces between obstacles. Increasing graph resolution would severely impact the computational complexity. Compared to the roadmap-based algorithms, the number of nodes for the uniform grid representation is much greater. However, this representation, which is quite general, is applicable to problems where obstacles are not clearly deﬁned, such as for mobile robots moving over rough terrain [16], as is demonstrated later in this chapter.
The increased interest in solving high dimensional problems, such as motion planning for humanoids or multi degrees-of-freedom arms, gave rise to a class of

32

Z. Shiller

sampling-based planners [17]. The most popular version of sampling-based planners is based on rapidly exploring random trees (RRT) [17–19]. They search the way to the goal by probing the conﬁguration space (can be also done in the workspace) and incrementally expanding a collision-free tree from an initial conﬁguration. Because the entire search is done “in the dark,” the planner attempts to reach unexplored parts of the search space, resulting eventually in a uniform coverage of the free space. The efﬁciency of these planners stems from the incomplete coverage of the free space and from terminating the search when the goal is ﬁrst reached. The solution found is feasible but not optimal in any way. RRT based planners may not produce optimal solutions even when exploring the entire search space [7, 20]. In addition, they inherently have difﬁculties with tight spaces. Nevertheless, the RRT algorithms were demonstrated for solving very complex problems [21].
An extension called RRT* was developed to asymptotically produce the optimal solution [7]. The asymptotic optimality was achieved by adding a lower bound estimate to the RRT search. Optimality is achieved iteratively at a great computational cost by running the algorithm repeatedly while reﬁning the solution until either exhausting the available computation time or reaching a desired level of optimality [7]. Despite the great promise, the RRT* algorithm was demonstrated in [7, 20] for the kinematic avoidance of very few planar and widely spaced obstacles, producing a smooth near-optimal solution after a large number of iterations (10,000). Solving a dynamic problem in a higher dimensional state space is expected to be much more challenging. Recently, a path generated by an RRT search was further optimized using a genetic algorithm to produce the shortest path for a hybrid manipulator with six degrees-of-freedom [22]. The idea of further optimizing paths that were generated by a geometric planner is similar in nature to the off-line planner presented here, except that the objective of the off-line planner is to produce a global optimal trajectory, not only the shortest path.
The sampling-based planners represent a paradigm shift in the motion planning community by (1) accepting probabilistic completeness, which is to say that the goal may not be reached in a ﬁnite time, (2) accepting any solution, not necessarily the optimal, and (3) abandoning the explicit geometric representation of the free conﬁguration space in terms of roadmaps or graphs. This is a signiﬁcant departure from the previous practices that evaluated motion planning algorithms for completeness and optimality.

1.2 Trajectory Planning (Off-Line)
The trajectory planning problem concerns the computation of robot motions that move the robot between two given states, while avoiding collision with obstacles, satisfying robot dynamics and actuator constraints, and usually minimizing some cost function, such as energy or time.
Early work on trajectory planning, from the 1960s to the 1980s, was rooted in the ﬁeld of optimal control theory, which provides powerful tools to characterize and

Off-Line and On-Line Trajectory Planning

33

generate optimal trajectories when high speed motion is desired [23]. The elegant necessary conditions, stated by the Pontryagin’s maximum principle, lead to the formulation of the optimal control problem as a two-point boundary value problem, and the development of algorithms that searched for the optimal control that generates the optimal trajectories [23]. For time optimization problems, it was shown that the time-optimal control is bang-bang. This in turn reduces the optimal control problem to a parameter optimization by iterating on the switching times between the maximal controls [24, 25].
The ﬁrst attempt to use these theories for robotics was by Khan and Roth [26], who computed the multi-axis time optimal trajectory for a linearized model of robot dynamics. Solving this problem for the full robot’s dynamic model was computationally very difﬁcult. The typically non-linear and coupled robot dynamics makes such solutions computationally extensive. Adding obstacles makes the computational challenge even harder.
One approach to reducing the complexity of the problem and facilitating a practical realization of time-optimal motion planning is to decouple the problem by representing robot motions by a path and a velocity proﬁle along the path. This decoupling allows reducing the trajectory planning problem to two smaller problems: (a) computing the optimal velocity proﬁle along a given path, and (b) searching for the optimal path in the n-dimensional conﬁguration space.
The time optimal velocity proﬁle along a speciﬁed path is computed using an efﬁcient algorithm, originally developed Bobrow, Shin and McCay and Pfeiifer [27–29], and later improved by Shiller and Lu [30] and Slotine and Yang [31]. Assuming a second order system, the solution to this problem was found to be bang-bang in the acceleration, that is, applying the maximum or minimum acceleration so as to maximize the velocity along the path. The switching times are computed efﬁciently to avoid crossing the velocity limit curve, which reﬂects the actuator constraints and the robot dynamics. This approach was later extended to computing time optimal velocity proﬁles along speciﬁed paths for nonlinear third order systems, subject to general jerk constraints [32].
The optimal path was computed using a nonlinear parameter optimization over path parameters, such as the control points of a cubic B spline [33, 34]. In each iteration of the optimization process, the optimal velocity proﬁle along the path is efﬁciently computed to produce the minimum time for that iteration. One advantage of this approach is that each iteration yields a feasible trajectory, albeit not necessarily optimal. The optimization can therefore be terminated at any time to yield an acceptable solution.
A similar approach, known as direct optimization, differential inclusion [35], and inverse dynamics optimization [36], was proposed by the aerospace community. Common to these methods is the direct search for the optimal trajectory as opposed to a search for the optimal control in the higher dimensional state and co-state spaces [23]. Attempts to solve the multi-axis problem using graph search techniques in the state space, solving the so called “kinodynamic” problem, did not yield practical solutions [37, 38].

34
1.3 Online Planning

Z. Shiller

Early on-line planners were developed to address the lack of apriori information about the environment. Called “sensor-based” algorithms, they navigate a point robot equipped with position and touch sensors among unknown obstacles to reach a global goal. A series of “bug” algorithms were developed, starting with the basic bug that navigates by circumventing the detected obstacle always clockwise or counterclockwise until reaching the straight line to the goal, then continuing along that line until either reaching the goal or hitting another obstacle [5]. Assuming long range vision sensors, the bug strategies were extended to the Tangent Bug algorithm, which follows the tangent line to the next obstacle that obstructs the straight line to the goal [39, 40]. It was shown that complete online navigation can be achieved with only a ﬁnite amount of memory [5, 41, 42].
Another approach to online motion planning is based on potential functions [43–45]. Representing the goal with an attractive potential, and the obstacles with repulsive potentials, the path is generated online by following the negative gradient of the potential function. While this approach is computationally efﬁcient and is suitable for on-line feedback control, it suffers from local minima, which may cause the path to terminate at a point other than the goal. This problem was overcome using harmonic potentials [43] and navigation functions [45]. These potentials, however, address only the obstacle avoidance problem with no concern for path optimality. Furthermore, the generation of the potential function is done off-line and may be time consuming.
A similar approach generates the shortest path by following the direction of steepest descent of a discretized distance function [46]. The main computational effort is in numerically computing the distance function, which is done off-line. The computation complexity increases rapidly with the number of obstacles and with grid resolution.
The potential functions used to guide the trajectory towards the goal resemble the value function, which is the solution to the Hamilton- Jacobi-Bellman (HJB) equation [47–49]. The HJB equation states a sufﬁcient condition of global optimality (unlike the Pontryagin Maximum Principle, which is only a necessary condition), and the value function represents the cost-to-go from any feasible state. The globally optimal trajectory is then generated by selecting the controls that minimize the time derivative of the value function. For time invariant systems, this amounts to following the negative gradient of the value function, which drives the system time-optimally to the goal from any initial state. This is similar to the potential ﬁeld method, except that the value function may be regarded as the “optimal” potential function.
Although the theoretical framework exists for deriving optimal feedback controllers, it is impractical to derive a time-optimal control law, using the HJB equation, for a typical obstacle avoidance problem that accounts for robot’s dynamics.
A recently developed online algorithm navigates towards the goal by optimally avoiding one obstacle at a time [50, 51]. This transforms the multi-obstacle problem with m obstacles to m simpler sub-problems with one obstacle each, thus reducing the size of the problem from exponential to linear in the number of obstacles.

Off-Line and On-Line Trajectory Planning

35

The incremental generation of the trajectories and the relatively low computational effort at each step make this algorithm an efﬁcient on-line alternative to the computationally expensive off-line planning, thus trading optimality for efﬁciency. This algorithm will be later discussed in this chapter.
This chapter is organized as follows: it starts with a formal problem statement of the motion planning problem, focusing on trajectory planning rather than on path planning. It continues with the theoretical solution for the optimization problem using the Hamilton Jacobi equation. It then describes an efﬁcient off-line planner and a very efﬁcient online planner. Both algorithms are demonstrated for a point robot moving at high speeds over rough terrain (the off-line planner) and through very cluttered environments (the online planner).

2 Problem Statement

In a typical motion planning problem, we wish to solve the following optimization problem:

tf

min L(x, u)dt

(1)

u0

subject to the system dynamics:

x˙ = f (x, u),

(2)

where x ∈ Rn is a point in the robots state space, and u ∈ Rm is a vector of actuator efforts, subject to the actuator constraints:

uimin ≤ ui ≤ uimax, i ∈ {1, . . . , m},

(3)

obstacle constraints:

g(x) ≥ 0; g ∈ Rk,

(4)

and the boundary conditions:

x(0) = x0; x(t f ) = x f ,

(5)

where k is the number of obstacles and t f is the ﬁnal time. If the objective function is time, i.e. L(x, u) = 1, then t f is free. We assume that the obstacles (4) do not overlap with each other and with the goal x f .
Problem (1) is a two point boundary value (TPBV) problem: of all trajectories that
satisfy the boundary conditions (5), select the one that minimizes the cost function (1)
and satisﬁes system dynamics (2), control constraints (3) and obstacle constraints (4).

36

Z. Shiller

The global optimal trajectory can be computed using the Hamilton-JacobiBellman (HJB) equation, which states a sufﬁcient condition for global optimality [47–49]. Denoting the set of obstacles as O:

O = {x : g(x) < 0},

(6)

The control u∗ that is the solution to problem (1), satisﬁes, on Rn − {x0} − O, the HJB equation:

min
u

{vt

(x

,

t

)

+

<

vx (x, t),

f (x, u) >}

= −L(x, u)

(7)

subject to (3) and (4), where v(x, t) is a C2 scalar function, satisfying

v(x0, t) = 0

(8)

v(x, t) > 0, x ∈/ x0

(9)

The subscripts x and t represent partial derivatives with respect to x and t, respectively, and < ·, · > denotes the inner product on Rn.
The scalar function v(x, t) is the value function [47, 48, 52], representing the
minimum cost-to-go to the origin (goal) from any given state. For an autonomous system (time-invariant) and for ﬁxed boundary conditions, vt = 0; assuming in addition that the cost function to be minimized is time (L(x, u) = 1), reduces (7) to:

min{<
u

vx (x),

f (x, u)

>}

=

−1

(10)

To satisfy (10), the projection of x˙ = f (x, u) on vx (x) must equal −1. It follows that the optimal control u∗ that minimizes (10) drives the optimal trajectory x˙∗(x, u) in the direction of the negative gradient, −vx (x), of the value function, as shown schematically in Fig. 1. This is similar to the trajectory generation by potential ﬁeld methods [43–45, 53], except that here the potential function is the value function. Since the value function has a unique minimum at the goal, trajectories generated by following the negative gradient of the value function are globally optimal and are guaranteed to reach the goal from any initial state.

Fig. 1 The optimal trajectory x˙∗(x, u∗) slides
opposite to the gradient
vx (x) of the value function

Value function

vx x

Goal

x• *

Off-Line and On-Line Trajectory Planning

37

The on-line planner for the multi-obstacle avoidance problem, described later in this chapter, can be viewed in the context of the value function as following the negative gradient of an approximate value function for this problem. It generates near-optimal trajectories by avoiding obstacles one at a time, or equivalently, by sequentially following the negative gradient of the return function for each obstacle avoidance problem. The trajectory is generated incrementally, permitting robot motion before the entire trajectory to the goal has been computed.
Obtaining an analytical expression for the value function is practically impossible for other than for very simple cases. Computing the value function numerically would require solving the optimization problem from every point in the state space. This is essentially the approach used in [46] for solving the shortest path problem.
A discrete version of the HJB equation is the basis for the Bellman’s Principle of Optimality and Dynamic Programming [54]. Dynamic programming is the optimization method used in most grid based optimizations, including the off-line optimization discussed next in this chapter.

3 Off-Line Planner
The off-line planner presented here computes the global time optimal trajectory between given boundary states in the presence of known static obstacles [2]. It combines a grid search in the conﬁguration space with a continuous local optimization. In lieu of an expensive search in the 2n dimensional state space for one (globally optimal) trajectory, this planner searches for many paths in the n dimensional conﬁguration space for an n degree of freedom robot. The reduction of the search to the conﬁguration space yields a signiﬁcant (exponential) computational gain compared to a full search in the state space. The complexity of this approach is exponential in the dimension of the conﬁguration space and linear in the number of nodes in the graph.

3.1 Summary of the Approach
This planner is based on a branch-and-bound search for the global optimal trajectory between given end states in a static environment. It assumes an efﬁcient mapping from a curve in the conﬁguration space to the optimal traversal time along that curve. This mapping allows us to search for the optimal trajectory in the lower dimensional conﬁguration space. We call the projection of the optimal trajectory on the conﬁguration space the optimal path.
The branch-and-bound search begins by reducing the inﬁnite set of paths between given end points to a ﬁnal set by representing the conﬁguration space by an undirected graph. The branch-and bound search then reduces this set to a small set of the most promising paths. The paths in the ﬁnal set are then pruned to retain the best path in each path-neighborhood. These paths are then optimized using a nonlinear parameter

38

Z. Shiller

optimization to further reduce motion time. This last step signiﬁcantly relaxes the grid resolution required for the initial search to ensure global optimality.
This process was proven to generate the global optimal trajectory in addition to producing a set of local minima [2]. The optimality of the solution depends on the number of paths selected in the ﬁrst step, grid resolution with respect to the distance between obstacles, and the ﬁdelity of the local optimization. This optimization was demonstrated for a six DOF manipulator moving in a cluttered environment [2] and for a mobile robot moving on general terrain [16].

3.2 The Graph Search
The purpose of the graph search is to efﬁciently produce a set of paths that explore all regions in the conﬁguration space and that may contain the optimal path. Obstacles are accounted for by setting high costs to edges that penetrate obstacles. For motion over rough terrain, obstacles are accounted for by considering their geometric shape and determining if the robot can safely traverse these obstacles, similarly to traversing other terrain features [16].
In the context of this algorithm, the optimal path is the one that can be traversed at the minimum time between given end points, subject to robot dynamics, and to control and obstacles constraints. Since metrics measured in the conﬁguration space are not good predictors for path optimality, it is necessary to consider a large number of paths to ensure that they contain at least one path in the neighborhood of the optimal path. By representing the conﬁguration space with a uniform grid, we reduce the inﬁnite number of obstacle-free paths to a ﬁnite set.
One approach to generating a large set of paths, using a graph search, is to use the k-best search by Dreyfus [55] to produce a set of shortest paths. It is similar to a shortest path search except that it effectively excludes the k − 1 best paths from the searched space while searching for the next kth best path. This allows us to sequentially generate the paths until some upper bound on the cost function, determined by the branch and bound search, is reached. The cost function may be path length, or some other function that produces a lower bound estimate of the optimal motion time along the path [2]. While this approach guarantees that the global and a few local minima (within grid resolution) are found, it has the drawback that it ﬁrst generates a large number of paths in the neighborhood of the best path (k = 1), usually in one homotopy class, before exploring other homotopy classes, as shown schematically in Fig. 2. A homotopy class contains all paths that can be continuously deformed into one another [1], as shown schematically in Fig. 3. Depending on grid resolution, using the k-best search may require a very large number of paths in order to cover the entire space. In addition, identifying a local minimum (that is not global optimal) is quite tedious. The difﬁculty arises from the regions of optimality not being easily quantiﬁed, and hence requiring that each new path be tested if it is in the neighborhood of any path generated so far. The large number of paths required by this approach thus imposes a high computational cost, ﬁrst with the k-best search, which is linear in k, and then in the pruning process, which is O(k log k).

Off-Line and On-Line Trajectory Planning Fig. 2 Near shortest paths found by the K shortest path algorithm tend to group around the shortest path
Fig. 3 Paths in one homotopy class

39 Goal

Start

Goal

Start

The pruning process consists of selecting the best (shortest in time or distance) of all paths in the initial set of paths, then discarding all paths that are within some tube of a predeﬁned diameter around the best path. The paths within a tube around the next best path are similarly discarded, and the process repeats until all paths in the initial set are either discarded or retained as the best path in their neighborhood. The pruning process thus reduces an initially large set of paths to a smaller set of promising paths, each is then locally optimized, as discussed later.
An alternative approach efﬁciently generates a large number of paths that cover the entire search space [56, 57] and can be easily reduced to the most promising path in each homotopy class, as shown schematically in Fig. 4. In two steps, each consisting of a shortest path search, it generates all shortest paths that pass through

Fig. 4 Paths of various homotopy classes

Goal

Start

40

Z. Shiller

each node in the graph. This allows an efﬁcient coverage of the entire free-space and the identiﬁcation of a few promising local minima in addition to the global optimal path .
This is essentially a single-pair search for n constrained paths through a graph with n nodes. It starts with a single-source search, such as Dijkstra’s [14], that generates the shortest path from the source s to the goal g (Fig. 5). The cost as,i stored at each node i is the cost from s to that node. Repeating this search from the goal g to s stores the cost bg,i at each node i (Fig. 6). Summing the two costs cs,g,i = as,i +bg,i yields the optimal cost cs,g,i for the path between s and g that passes through node i (Fig. 7).
If each local minimum represents a homotopy class, the computational cost of this approach is O(2) for the initial search, and on average O(m/ p log m/ p) for the pruning process, where m is the number of nodes and p is the number of homotopy classes generated by this search [57]. Compare to the k-best search, O(m) for the initial search and O(m log m) for pruning. This efﬁciency is achieved at the cost of generating only a subset of all possible local minima, but at a computational cost far smaller than the alternative.
Figure 8 shows a topographic surface that is to be traveresed from Start to Goal. The surface was ﬁrst tesselated by a unofrm grid, then the shortest paths through all nodes were computed using the algorithm discussed earlier [56, 57]. Color marking

Fig. 5 Shortest paths from

Goal

start to all nodes

Start

Fig. 6 Shortest paths from

Goal

goal to all nodes

Fig. 7 Shortest paths through via points

Start

Goal

Start

Off-Line and On-Line Trajectory Planning Fig. 8 A surface map

41
Goal

Start
Fig. 9 A color coded surface map. The color at each node represents the optimal cost for passing through that node
the nodes according to the cost of passing through each node produced the cost map shown in Fig. 9. The cost function for this case was a traversability measure, calculated by dividing distance by the maximum safe velocity along each segment along the graph [16]. Here, blue represents the lowest cost (global minimum), then yellow, green and red represent gradually increasing costs. The cost map clearly shows the traversability of each region, thus offering sub-optimal alternatives to the global optimal path, which is colored blue. The blue “river”, whose nodes all have the same (optimal) cost, might be wider in regions where the neigboring edges have identical costs. In such cases, the global optimal grid path may not be unique, which is a common artifact of the uniform discretization of the search space.
3.3 Branch and Bound Search
The goal of the branch-and-bound search is to efﬁciently reduce the initially large set of paths in each homotopy class to a smaller set that contains the local optimal path. This is done by dividing the initial set of paths into two smaller subsets: one that contains all paths having a lower bound estimate on their cost that is higher

42

Z. Shiller

than the lower bound estimate of all paths in the second subset. The second subset is discarded, and the process repeats by subdividing the remaining subset using a more accurate lower bound estimate. Repeating this process, using a series of gradually increasing lower bounds, thus reduces the initial large set of paths to a much smaller set of promising paths. The search is terminated when the last subset has been shown to contain no better solution than the one already at hand. The best solution found during this search is the optimal path [15]. The fastest among the local minima found in this process is the global optimal path.
In this search, the objective function is the minimum traveling time between the two end points, whereas the initial set consists of all feasible (collision-free) paths between the given end points. It remains to determine appropriate approximations of the cost function that are guaranteed to produce lower bounds on the traveling time along a given set of paths. The computational efﬁciency of this approach depends on the proper selection of the lower bound estimates at each step. The most conservative but efﬁcient approximations are used ﬁrst, when the number of path candidates is large, and the more accurate but computationally expensive are used last. The last test is the exact solution, which is the optimal traveling time along the path.
We use three lower bound estimates on the optimal motion time along a given path, each represented by a different velocity proﬁle: (1) maximum constant speed, (2) velocity limit, and (3) optimal velocity along the path. The cost estimate is computed by integrating the respective velocity proﬁle along the path.
Maximum Speed: The ﬁrst lower bound estimate, t1, assumes motion everywhere at the maximum speed the robot can reach. It can be the tip velocity reached by assuming no load speeds at all joints at the most stretched conﬁguration, or the maximum speed a mobile robot can reach on ﬂat terrain. Dividing the distance along each edge of the graph by the maximum speed produces a lower bound estimate, obtained by the summation:

t1 =

xi , vmax

(11)

where xi is the Euclidean distance of the ith segment along the path, and vmax is the maximum speed.
Having assigned a ﬁxed cost to all edges, the paths produced by the graph search are rated by a lower bound estimate on the optimal motion time along each path. Paths with lower bound estimates higher than the optimal motion time along some arbitrary path can be discarded early in the search process.

Velocity Limit: Once a path has been selected from the grid search, it is smoothed by cubic B splines, using the nodes of the graph along the path as control points. This eliminates the sharp corners produced by the grid segments. If the smoothed path penetrates an obstacle because of the rounded corners, it can be either discarded or kept for the next lower bound test. Eventually, the local optimization, discussed later, will divert the path away from the obstacle.

Off-Line and On-Line Trajectory Planning

43

Here we assume that the speed along the path follows the velocity limit curve s˙max(s), s being the distance parameter along the path, that accounts for robot dynamics, actuator constraints, and path curvature, at every point along the path [27–29, 32].
The lower bound t2 is obtained by the integral

t2 =

sf ds , 0 s˙max

(12)

The computation of the velocity limit and the optimal velocity proﬁle are brieﬂy discussed later.
The value t2 is a true lower bound and greater than t1 since the velocity limit curve represents the true upper limit for the velocity proﬁle along the path. This evaluation is computationally more demanding than the previous one but is less expensive than computing the time optimal velocity proﬁle. This lower bound takes into account the combined effects of robot dynamics, actuator constraints, and path geometry.
Optimal Velocity: This is the exact solution for the optimal motion time and an upper bound to the previous lower bounds. The optimal velocity proﬁle is always below the limit curve and at most tangent to the limit curve at a ﬁnite number of points [30]. The computation of the optimal velocity proﬁle is brieﬂy discussed next.

3.4 Time Optimal Motions Along Speciﬁed Paths
The optimal motion time along the path represents the exact cost function for the global search. It is computed using a well established algorithm [27–31, 58], which accounts for robot dynamics, actuator constraints, and path geometry. It is applicable to any fully actuated system such as industrial and mobile robots [16]. The algorithm will not be repeated here, referring the reader to the respective literature [27–31, 58].
Key to this algorithm is the mapping of system dynamics to path coordinates. This reduces the multi dimensional conﬁguration space, in which the robot operates, to a single degree-of-freedom system, where the distance and speed along the path, s, s˙, are its two states, and the tangential acceleration s¨ is its control input. The actuator constraints, coupled with path geometry, are mapped to constraints on s˙ and s¨, as shown schematically in Fig. 10 at some point s along the path. The boundary of the range of speeds and accelerations, FSA, represents states where at least one actuator reaches its limit. States outside of FSA are therefore dynamically infeasible.
At a given speed, the acceleration is bounded between its maximum and minimum values, as shown in Fig. 10. The speed s˙m, where the range of feasible accelerations reduces to a point, represents the highest speed at which the robot can still move along the prescribed path. Plotting s˙m along the path produces the velocity limit

44
Fig. 10 The range of feasible speeds and accelerations (FSA)

Z. Shiller S

FSA

Sm2 S 2

Fig. 11 Velocity limit curve and time optimal velocity proﬁle

s
Velocity Limit Curve

S1

S3

S2
Time optimal velocity profile

s

curve, as shown schematically in Fig. 11. It serves as the upper limit for any velocity proﬁle along the path, optimal or not. Crossing the velocity limit curve implies that the robot is moving at speeds that are not sustainable by the robot’s actuators or that it does not follow to prescribed path.
The time optimal velocity proﬁle is computed using “bang-bang” control, switching between maximum acceleration and maximum deceleration along the path. The switching times are selected so that the optimal velocity proﬁle avoids crossing the velocity limit curve [30], as shown schematically in Fig. 11. In the schematic example shown in Fig. 11, the time optimal velocity proﬁle is integrated from the initial point at zero speed, using the maximum acceleration. At some point s1 along the path, the acceleration is switched to the maximum deceleration until point s2, where the optimal velocity proﬁle is tangent to the velocity limit curve. From s2, the maximum acceleration is again integrated until some point s3, from where the maximum deceleration is used to reach the ﬁnal point at zero speed. The number of switches is usually odd for a 2nd order system, and it depends on the shape of the velocity limit curve, and the robot’s dynamic properties. This algorithm is computationally very fast and can be used to efﬁciently assign the optimal motion time to every path in the last set of paths of the branch and bound search.

Off-Line and On-Line Trajectory Planning

45

3.5 Local Optimization

The paths generated over the graph are forced to pass through the nodes of the graph deﬁned by the grid used to represent the search space. To relax the demands on the grid resolution, a local optimization is used to locally alter the path to further reduce motion time [33, 34]. The optimization problem is formulated as an unconstrained parameter optimization, using the control points of cubic B splines as the optimization variables, and the optimal motion time along the path as the cost function. Obstacles are represented by penalty functions that account for the distance between the robot and the obstacles. At each iteration of the local optimization, the optimal motion time along the current path is computed using the method discussed earlier in Sect. 3.4, and the control points are modiﬁed by the optimization algorithm so as to produce paths with gradually decreasing optimal motion times. This process repeats until the optimal motion time reaches a local minimum. This optimization is obviously local since the path cannot “jump” over obstacles.
To reduce computation time and improve the convergence of the local optimization, the number of control points is reduced by retaining only a few points for each straight line segment along the grid path. It is important to note that a small number of control points may not adequately represent the true optimal path, however, a large number of parameters may be computationally costly. The true optimum can be approached asymptotically by successively increasing the number of control points and repeating the local optimization.
The local optimization is used to optimize only a small number of promising paths, selected from the paths remaining after the branch and bound search. These paths are selected as the best in each homotopy class [57] or as the best in some deﬁned neighborhood of radius Dmax. The classiﬁcation of the paths into homotopy classes is discussed in [57] and will not be repeated here. The selection of the best path in each neighborhood is done by ﬁrst discarding all paths that are contained in a tube around the best path, each satisfying the inequality:

D = max|( pi (w) − p0(w)| < Dmax, w = [0, 1]; i = 1 . . . N ,

(13)

where p0(w) is a point along the best path in the neighborhood, with w being a normalized path distance, and pi (w) is a point along any path in the remaining set of N − 1 paths. This process is repeated for the next best path among the remaining
paths until only a few paths, representing distinct regions, remain.

3.6 Summary of the Off-Line Planner
The off-line planner that uses the K-best search, is summarized in the following pseudo code. In the following, “best path” refers to the path along which the optimal motion time or a lower bound estimate is the smallest of all paths in the given set.

46

Z. Shiller

Algorithm 1: Off-line planning Step 0: Initialize.
Receive the geometric description of the workspace, robot dynamics, actuator
constraints, dynamic and state constraints, current state x, target state x f ; Determine the robot maximum speed vmax for Eq. (11); Set an upper bound tup to be used to terminate the ﬁrst search; Set diameter R for path ﬁltering. Step 1: Generate a graph over the workspace
Assign cost, usually Euclidean distance, to all edges on the graph.
Assign high cost to edges that connect unreachable nodes. Step 2: Use the K-best search to generate the set P0 of shortest paths between the end points (the projections into the conﬁguration space of the current and target states). Stop the search when t1(K ) ≥ tup. Step 3: Smoothing.
Smooth all paths in P0 by B-splines, using the nodes along each path as control points. P1 is the set of K smoothed paths. Step 4: For all paths in P1, compute a lower bound estimate t2(i), i = 1, . . . , K , using (12). Step 5: Select the best path j: t2( j) = min{t2(i), i = 1, . . . , K }. Compute the optimal motion time t3( j); t3( j) serves as the next upper bound in the branch and bound search. Step 6: Move all paths in P1 that satisfy t2(i) ≤ t3( j), i = 1, . . . , K , to P2. Step 7: Compute the optimal motion time t3(i) for all paths in P2. Step 8: Pruning.
Select the best path in P2 and discard all paths that are inside a tube of radius R around that path, using (13); Move the best path to P3; Repeat for the next best path in P2 until P2 is empty. P3 now contains a small set of “good” paths. Step 9: Local optimization.
Submit all paths in P3 to a local optimization. The resulting paths form the set of local minima P4. Step 9: Global optimum.
The best path in P3 is the global optimal path, along which the optimal motion time is globally optimal.
STOP.

3.7 Example 1
Figure 12 shows the near-global time optimal trajectory, computed using the global optimization discussed here, for a vehicle moving over general terrain. For this example, the k-best search was used to generate the initial set of 500 paths, all shown in Fig. 13. The grid resolution was set low at 1 m between nodes for a 10 × 10 m terrain segment. The branch and bound search retained 22 best paths, each was smoothed by

Off-Line and On-Line Trajectory Planning

47

Fig. 12 A (near) global time optimal path over general terrain, generated by the global planner

Fig. 13 500 shortest paths generated over the uniform grid overlayed over the terrain

Fig. 14 22 best smoothed paths retained by the branch and bound search
a cubic B spline, as shown in Fig. 14. All 22 paths were locally optimized to further reduce motion time, and the best path, shown in Fig. 12, was selected as the global optimal solution. The time optimal velocity proﬁle along the best path is shown in Fig. 15. Also shown in Fig. 15 is the velocity limit curve. Note that the vehicle slows down before accelerating again to prevent it from reaching high speeds that would cause it to airborne over the bump in the upper part of the terrain segment. The effect of the bump on the vehicle speed is reﬂected in the drop of the velocity limit curve.

48

Z. Shiller

Fig. 15 The optimal

10

velocity proﬁle and the

9

velocity limit curve along the

8

time optimal path

7

S [m/s]

6

5

4

3

2

1

0

0

2

4

6

8

10

S [m]

The solution obtained is near global optimal due to the choices of the grid resolution and the termination condition of the local optimization.
Computation time depends on the number of paths generated in the graph search, the number of promising paths left for the local optimization, and the number of control points used to represent each path. The global planner was implemented in C and run on an Intel core-i7 3:4 GHz desktop computer. For example1, the global optimal path was computed in 20 s, most of which was spent on the local optimization of 22 paths.
The global optimization presented here is inherently off-line as it produces the complete solution to the goal. It combines a search for a set of the best paths in a grid in the conﬁguration space with a local path optimization. This combination allows to reduce the search to the lower dimensional conﬁguration space without compromising optimality. There are only few global planners that we can compare to, especially those computing time optimal trajectories [7, 37].
The solution produced by this planner is a global optimum if the grid is sufﬁciently small. The requirement on grid resolution is relaxed by assuming that the region of convergence around the optimal path is large compared to the grid size. Despite this approach being presented long ago, it is still computationally efﬁcient compared to more recent global optimizations [7, 37]. Lacking information on the use of RRT* to solving dynamic problems, it is difﬁcult to compare this popular approach to ours.

4 Online Planner
We now address the online time-optimal obstacle avoidance problem for robots moving in cluttered environments. Motivated by the observation that the effect of an obstacle on the value function (the global cost-to-go function) in (10) is local [51], we solve the multi-obstacle problem by avoiding obstacles one at a time. This

Off-Line and On-Line Trajectory Planning

49

is equivalent to approximating the value function of the multi-obstacle problem by switching between the value functions of the individual problems, each avoiding a single obstacle. Computationally, this transforms the multi-obstacle problem with m obstacles to m simpler sub-problems with one obstacle each, thus reducing the size of the problem from exponential to linear in the number of obstacles. As a result, this approach produces an on-line planner, i.e. the trajectory is generated incrementally, one step at a time, requiring a low computational effort at each step relative to the original, inherently off-line, problem.
While the approach of avoiding obstacles optimally one at a time applies to any robot dynamics, and convergence can be guaranteed for any obstacle shapes, we treat here a point mass robot in the plane and convex obstacles.
We begin with the optimal avoidance of one obstacle.

4.1 Optimal Avoidance of a Single Obstacle

The time optimal avoidance of a single obstacle in the plane is relatively simple. It can be computed using a global optimization [2], or by running a local optimization [34] twice (one for each side of the obstacle for a planar problem).
Consider the following point mass model:

x¨ = u1 ; |u1| ≤ 1

y¨ = u2 ; |u2| ≤ 1

(14)

where (x, y)T ∈ R2 and (u1, u2)T ∈ R2 represent the conﬁguration space variables and actuator efforts, respectively.
We ﬁrst derive the unconstrained trajectory, for states not affected by the presence of the obstacle.

4.1.1 The Unconstrained Trajectory

The unconstrained trajectory for the decoupled system (14) is determined by the minimum motion time of the slowest axis.
Consider ﬁrst a single axis, represented by the double integrator

x˙1 = x2

x˙2 = u ; |u| ≤ 1.

(15)

Using optimal control theory [23], it is easy to show that the time-optimal control for system (15) is bang-bang with at most one switch [50]. In the following, we denote x = (x1, x2) and x f = (x1 f , x2 f ).

50

Z. Shiller

The minimum time-to-go from any state x to x f can be computed analytically [59, 60]:

⎧t f (x, x f ) =

(16)

⎪⎪⎪⎨ −x2 − x2 f + 2

−x1 + x1 f

+

x22 2

+

x22 f 2

, if x

∈R

⎪⎪⎪⎩ x2 + x2 f + 2

+x1

− x1 f

+

x22 2

+

x22 f 2

, otherwise

where

R = {(x) | S1(x) > 0, S2(x) < 0},

(17)

and the switching curves S1(x), S2(x), shown in Fig. 16, are:

S1(x) = x22 − 2

x1

−

x1 f

+

x22 f 2

= 0,

S2(x) = x22 + 2

x1

−

x1 f

−

x22 f 2

= 0.

(18)

The switching time ts is [60]:

t⎧s(x, x f ) =

(19)

⎪⎪⎪⎨ −x2 +

−x1

+ x1 f

+

x22 2

+

x22 f 2

, if x

∈

R

⎪⎪⎪⎩ x2 +

+x1

−

x1 f

+

x22 2

+

x22 f 2

, otherwise

Fig. 16 Switching curves in the state space of a single axis

x2
u = -1 S2(x)

x0
R
0

xf x1

S1 (x) u = +1

Off-Line and On-Line Trajectory Planning

51

Equation (16) computes the optimal time-to-go from any given state. It is used to

determine the slowest axis of a multi axis system and set the motion time for the

slowest axis, as discussed later.

The time-optimal trajectory thus ﬁrst follows a parabola from the initial state to

the switching curve, then follows the switching curve to the target state, as shown

schematically in Fig. 16. Trajectories starting from initial states left of the switching

curves (region R in Fig. 16) begin with u = 1, and right of the switching curves

with u = −1. Trajectories starting from states on the switching curve follow the

switching curve to the target with no switch. The switching time is determined by

the initial and ﬁnal states.

Since the minimum time trajectory has only one switch (excluding trajectories

that emanate from initial states on the switching curves), reaching the target at a time

greater than the minimum time, t f , using bang-bang control, requires more than one

switch [50].

For the two axis system (15), each axis may reach the target at a different optimal

time. Obviously, the optimal time t f to reach the target is determined by the slow-

est axis. Assuming, without loss of generality, that the faster axis from any initial

state x0 = (x10, x20, y10, y20) to the target state x f is the y-axis, the time-optimal

trajectory is obtained by driving the x-axis optimally, and driving the y-axis so that

it reaches the target at the same ﬁnal time, t f .

The trajectory of the x-axis is unique since it is optimal and hence has only one

switch, whereas the trajectory of the y-axis is not optimal and hence has at least two switches.1 It follows that the time-optimal path between the end points is not unique.

The set of all time-optimal paths is bounded by two extremal paths, generated by the

extremal trajectories, which are in turn generated by the extremal controls, umax and

umin [50]:

⎧ ⎪⎨1 if t ∈ [0, ts1]

umax(t) = ⎪⎩−1 1

if t ∈ [ts1, ts2] if t ∈ [ts2, T ]

(20)

⎧

⎪⎨−1 if t ∈ [0, ts3]

umin(t) = ⎪⎩1−1

if t ∈ [ts3, ts4] if t ∈ [ts4, T ]

(21)

where T > t f is speciﬁed, and

ts1

=

1 2α

x1 f

− x10

+ 2αT

− x20T

−

T2 2

− α2

ts2 = ts1 + α

α = (T + x20 − x2 f ) ,

(22)

2

1The switching time of the slowest axis occurs when its trajectory reaches one of the switching curves given in (18).

52

Z. Shiller

1 ts3 = 2β

x1 f

−

x10

− 2βT

−

x20 T

+

T2 2

+ β2

ts4 = ts3 + β

β = (T − x20 + x2 f ) .

(23)

2

We call the two-switch trajectories the extremal trajectories. Note that if the optimal motion times of both axes are identical, then the time-optimal trajectory is unique.
The unconstrained trajectory of system (14) from any state x = (x1, x2, y1, y2) to the target state x f = (x1 f , x2 f , y1 f , y2 f ) is thus determined by the optimal motion time of the slowest axis. It can be used to drive the system as long as at least one extremal trajectory avoids the obstacle. Otherwise, the obstacle must be avoided using the constrained trajectory discussed next.

4.2 The Constrained Trajectory

The constrained trajectory is needed for points in the state-space from which all unconstrained time-optimal trajectories to the target intersect the obstacle. We refer to the set of such points as the Obstacle Shadow. In the kinematic case [51], the shadow corresponds to the shadow created behind the obstacle by a point light source at the target. The physical analogy for the dynamic problem is not as obvious.
The intersection of all the extremal time-optimal paths with the obstacle implies the intersection of all unconstrained optimal paths. It is therefore sufﬁcient to check if both extremal trajectories intersect the obstacle to conclude that an avoiding trajectory, with optimal motion time greater than the optimal motion time of each axis, should be computed. Since the motion times of both axes are non-optimal, and hence greater than the unconstrained time t f , it follows that both axes have at least two switches.
We compute the time optimal trajectory from x0 to x f that avoids the obstacle, numerically, using a line search over the traveling time, tc = t f + δ. The search terminates when the ﬁrst trajectory that reaches the goal without intersecting the obstacle is found. The computation of the constrained trajectory for one obstacle is, thus, obtained by solving the following minimization problem over the single parameter, δ:

tc(x0, x f , OB)

=

min
δ

t f (x0, x f ) + δ

(24)

such that there exists j = 1, . . . , 4 that satisﬁes:

xex, j (t) ∈ OB,

(25)

where t f (x0, x f ) is the unconstrained optimal time (16), and xex, j (t), t ∈ [0, t f + δ] represents the jth extremal trajectory. The four extremal trajectories xex, j (t)

Off-Line and On-Line Trajectory Planning

53

correspond to the four combinations of the initial controls of both axes: (1, 1), (−1, −1), (1, −1), (−1, 1). Although only two of these four trajectories are true extremals, it is simpler to test all four. It is sufﬁcient that only one extremal satisﬁes (25).

4.3 Multi-obstacle Avoidance
The optimal avoidance of one obstacle is relatively simple, and is hence suitable for on-line computation. We use it to solve the multi-obstacle problem by avoiding obstacles one at a time. Key to this approach is the selection of the current obstacle to be avoided at any given time, as discussed next.

4.4 The Current Obstacle

We select the current obstacle as the maximum cost obstacle, which takes the longest time to avoid from the current state x to the goal x f . Denoting tc(x, x f , OB( j)), j = [1, m] as the minimum time it takes to avoid obstacle OB( j) from x to x f , the current obstacle, k, maximizes tc:

tc(x, x f , OB(k)) ≥ tc(x, x f , OB( j)) for all j = 1, . . . , m.

(26)

The current obstacle is thus selected by ﬁrst determining all obstacles with shadows to the goal x f containing the current state x, then computing the constrained trajectories avoiding each obstacle to x f , and selecting the one with the longest motion time. If x does not lie in the shadow of any obstacle, then the cost of all obstacles equals to the unconstrained trajectory to the goal and none is selected to be avoided. One of the extremals of the set of unconstrained trajectories is then selected for navigation. The algorithm may switch between the extremals in case they collide with any obstacle, until either reaching the goal or entering the shadow of any obstacle, in which case the current obstacle is selected by (26).
Selecting at each step the obstacle with the highest cost to the goal produces a trajectory that is close to optimal, since the other obstacles have a smaller impact on the motion time to the goal, as is shown schematically in Fig. 17. In Fig. 17, the state x is in the shadows of obstacles 1 and 4. Of those, the trajectory avoiding OB(4), denoted X (x, x f , OB(4)), takes longer time than X (x, x f , OB(1)) (not shown). Hence OB(4) is selected as the current obstacle. Obviously, any solution to the goal must avoid obstacle 4. Hence, recognizing it early in the avoidance process increases the likelihood that the resulting trajectory will be close to optimal. The intersection of X (x, x f , OB(4)) with OB(1) will prompt a recursive process, discussed next.
While selecting the maximum cost obstacle is likely to result in near optimal trajectories, other selection criteria, such as the nearest obstacle (obstacle 1 in Fig. 17) may sufﬁce for convergence.

54 Fig. 17 Selecting the current obstacle from x to x f
xf

OB4

Current obstacle

Z. Shiller X(x,xf,OB(4))

OB3

OB1

x

OB2

Unconstrained extremals

4.5 The Avoidance Algorithm
The avoidance algorithm assumes convex and non-overlapping obstacles (in the conﬁguration space). It selects the current obstacle to be avoided, computes the time optimal trajectory that avoids that obstacle, selects an intermediate goal along that trajectory on the boundary of that obstacle, and attempts to reach that goal. It repeats the process recursively until reaching the closest intermediate goal.
Algorithm 2: Online Avoidance Step 0: Initialize. Receive current state x, target state x f ; Set i = 0, g(i) = x f ; Step 1: Determine the current obstacle, OB(k), from x to g(i). If k = 0 (x not in the shadow of any obstacle), go to Step 3. Compute the optimal trajectory avoiding OB(k) to g(i). Step 2: i = i + 1; Select an intermediate goal g(i) on the boundary of OBk along the trajectory that avoids OB(k) to g(i − 1). Check that the velocity at g(i) is not in the obstacle hole2 of any obstacle, consisting of infeasible states from which the obstacle is unavoidable. If it is, reduce speed at g(i) as needed. Go to Step 1. Step 3: Follow the optimal trajectory to g(i). Set x = g(i). If i = 0, STOP. i =i−1 Go to Step 1.
Algorithm 2 generates a series of intermediate goals until one is reachable by a time optimal trajectory without colliding with any obstacle. Each intermediate goal g(i) (i ≥ 1) is selected along the constrained trajectory xc(t) from the current state x to the current goal g(i − 1) at a point where xc(t) is tangent to the current obstacle OBk. Usually, there is just one such point. In case xc(t) follows the obstacle for some
2The obstacle hole is a subset of the obstacle shadow.

Off-Line and On-Line Trajectory Planning

55

distance, the point closest to the goal g(i − 1) is selected. When an intermediate goal is reached, a new avoidance problem is attempted from that intermediate goal to the next goal in the queue. Note that once an intermediate goal was reached, it is removed from the queue and a new goal may be assigned the same index i. The goals are added and removed from the queue while the trajectory gradually progresses to the ﬁnal goal x f = g(0). Remembering the intermediate goals generated during the process is key to the convergence of this algorithm, as discussed later.
Step 2 of Algorithm 2 selects the speed at the intermediate goal g(i) that is both safe and feasible. A safe velocity is one that does not penetrate any obstacle hole, from which the obstacle is unavoidable. To simplify the search for the safe velocity, we choose to reduce it to the maximum velocity at which the robot can circle the current obstacle at its maximum lateral acceleration (the acceleration normal to its direction of motion). Denoting this velocity as the curvature velocity, it is easily proven that the curvature velocity does not lie in the obstacle hole of any obstacle.
Deﬁnition 4.1 Curvature Velocity. The curvature velocity, vc, is deﬁned as:

vc = umax R

(27)

where umax is the maximum lateral acceleration, and R is the radius of the obstacle.
It remains to verify that the velocity at g(i) is reachable from the current state x. This is done by checking that a direct time optimal trajectory exists from x to g(i). A direct trajectory is one that does not include loops. In case the velocity at g(i) is too high, we scale it down until it is reachable from x; if the velocity at g(i) is too low, the current speed, which was set to the curvature velocity, can be reduced by circling the nearby obstacle at a decreasing speed. The curvature velocity (27) ensures that the obstacle can be circled to allow a safe reduction in speed when necessary. While this feature is necessary to ensure safety, it was not needed in any of the many cases tested by this algorithm.
The adjustment of speeds at the intermediate goals would ensure that any consecutive intermediate goals are connected by a feasible trajectory. This implies that a too high ﬁnal velocity may be compromised for the sake of safety. Similarly, not every initial velocity is feasible for the obstacle avoidance case, even if it does not penetrate any individual obstacle hole. The speed reduction at the intermediate goals to the curvature velocity is a conservative measure to ensure safety.

4.6 Convergence
Convergence implies that the algorithm can reach the target state from an arbitrary feasible state, in a ﬁnite time. Since we cannot a priory determine the feasibility of arbitrary initial and target velocities, convergence of Algorithm 2 can be proven under

56

Z. Shiller

the assumption of zero terminal speeds (the speeds at the initial and ﬁnal points), for convex obstacles that do not overlap with each other [50].
Algorithm 2 progresses incrementally towards the goal by moving through a sequence of intermediate goals. Every intermediate goal subdivides the trajectory to the goal into two smaller segments, and in fact breaks the avoidance problem into two smaller problems. Repeating this process recursively further reduces the avoidance problem until two consecutive intermediate goals are connected by an unconstrained trajectory. The motion time along each segment is ﬁnite since it is traversed at the minimum time. The number of such segments is bounded by the number of obstacles, which is assumed ﬁnite. It follows that the total travel time from start to goal is also ﬁnite, which proves convergence.

4.7 Optimality
The trajectory generated by Algorithm 2 is not necessarily optimal, since each step is only locally optimal. While the paths (the projection of the trajectory to the conﬁguration space) generated by Algorithm 2 are generally close to the time optimal paths computed by a global planner [16], as demonstrated next, the motion time along the on-line trajectory is higher than the global optimal motion time due to the curvature velocity (27) imposed at the intermediate goals.

4.8 Numerical Examples and Experiments
Algorithm 2 is demonstrated for a planar environment, consisting of 70 tightly spaced circular obstacles.
4.8.1 Example 2
This example shows an on-line trajectory that avoids 70 obstacles, from the initial state (x1, x2, y1, y2) = (10.46 m, 0.001 m/s, 58.26 m, 0.001 m/s) to the goal state (x1 f , x2 f , y1 f , y2 f ) = (52.55 m, 0 m/s, 7.33 m, 0 m/s), as shown in Fig. 18. The spacing between the dots represents the speed along the path.
The motion time along this trajectory is 35.2 s, with a top speed of 3.4 m/s and an average speed of 2.1 m/s. There were 12 intermediate goals generated for this case, shown as empty circles along the trajectory. The total computation time was 4.3 s, with a time step t of 0.1 s, and an average computation time of 11 ms per-step. The speed along the trajectory, as a function of distance traveled, is shown in Fig. 19. The oscillations in the speed proﬁle are due to the curvature velocity imposed at the intermediate goals.

Off-Line and On-Line Trajectory Planning

57

Fig. 18 Trajectory generated on-line in a tightly spaced environment with 70 circular obstacles for Example 2

60 Start
50 40

meter

30

20

10

Goal

0

0

10

20

30

40

50

60

meter

Fig. 19 Speed as a function of distance traveled along the online trajectory of Example 2

Speed [m/s]

3.5

3

2.5

2

1.5

1

0.5

0

0

10 20 30 40 50 60 70 80

Distance Traveled [m]

4.8.2 Experiment–Global Optimality
This experiment compares the online planner with the global planner [16] for the obstacle setup shown in Fig. 20 (48 obstacles).
Shown in Fig. 20 are the trajectories generated by the online planner and the global planner. The online and globally optimal paths have similar topologies as they pass between the same obstacles. The velocity proﬁles along both trajectories are shown in Fig. 21. The motion time along the online trajectory was 28.9 s over a total distance of 93.8 m, with an average speed of 3.2 m/s, compared to the global optimal motion time of 20.7 s over a total distance traveled of 99 m, and an average speed of 4.8 m/s. This difference is caused primarily by the reduction in speeds to the curvature velocities (27) at the intermediate goals.

58 Fig. 20 The trajectories generated by the global and online planners, among 48 obstacles
Fig. 21 Speed as a function of distance traveled for the online and global optimal trajectories

Speed [m/s]

meter

90 80 70 60 50 40 30 20 10
0 0

Goal

Z. Shiller

Online

Global

Start

20

40

60

80

100

meter

10

Global

8

Online

6

4

2

0

0

20

40

60

80

100

Distance Traveled [m]

Repeating this test for 50 randomly selected end points yielded similar results, with the average motion time of the online trajectories being 30.52 s, compared to the average optimal time of 22.63 s. The average path length of the online trajectories was 111.51 m, compared with 115.26 m for the optimal trajectories. Here too, the increase in the motion time despite the comparable path lengths is due to the imposed curvature velocity at the intermediate goals, which is determined by the obstacle size.

4.9 Computational Issues
The consideration of the obstacles one at a time reduces the original problem with m obstacles to m simpler sub-problems with one obstacle each.
The cost for this reduction is the loss of optimality, and the need to check at each time step if all obstacles intersect the unconstrained optimal path from the current state, and for those that do, solve the single obstacle problem. This may

Off-Line and On-Line Trajectory Planning

59

seem excessive, but the alternative (solving the original exponential problem) is much worse. Our approach generates the trajectory incrementally, unlike the original problem that requires a complete solution before making the ﬁrst move. In fact, for problems with many obstacles, such as in example 2 with 70 obstacles presented earlier, the on-line (heuristic) solution may be the only viable alternative.
Practically, it may not be necessary to consider all obstacles at all times, but instead consider only the obstacles within some radius of visibility around the robot. It would be then necessary to limit robot’s speed to the stopping speed at the boundary of its visibility range to ensure that it does not collide with an unforeseen obstacle.
To appreciate the computational advantage of this approach, we attempted to compare it to the performance of efﬁcient state-of-the-art algorithms. Currently, the most popular approach is the RRT planner, which rapidly explores a random tree to produce the ﬁrst feasible solution to the goal [17–19]. The solution found is not optimal in any way, and this class of algorithms is known to have inherent difﬁculties with tight spaces. Yet, RRT is currently considered as the fastest algorithm to connect between two points through cluttered environments.
We compared a kinematic version of our online algorithm to the RRT and RRT* planners for avoiding 70 tightly space obstacles, all running on similar computers [50]. Testing the algorithms for 100 randomly generated end points, the run time of the online algorithm was on average 0.5 ms, compared to 3.5 ms of the RRT planner, 7 times faster. However, the path lengths produced by the RRT planner were twice as long as those produced by the online planner, which were near global optimum. Attempting to optimize the paths using the RRT* planner took 0.5 s to reach the optimality levels of the online planner; this is 1,000 times slower than the online algorithm. These results demonstrate the sound efﬁciency, in both computation time and optimality, of the online planner presented here. This is not surprising as the online planner consistently executes locally optimal paths at each incremental step, as opposed to the sampling-based planners which essentially search for a solution in the dark.

5 Summary
Motion planning is one of the basic problems in robotics as very few robotic tasks do not involve motion. The main challenge in motion planning is to produce a trajectory that safely and efﬁciently moves the robot from one state to another while accounting for its dynamic behavior. It is also desirable that the motion plan reﬂects the changing nature of the task or of the environment. While this is obviously the ultimate goal, early works on motion planning in the 80s settled for much less by focusing on geometric path planning with no account for robot dynamics. The resulting algorithms were useful for determining the shortest path from start to goal, but were useless for moving the robot at other than very low speeds. To account for robot dynamics, optimal control theory, developed in the late 60s, was applied then to robotics but failed because of insufﬁcient computation power and the high sensitivity of the numerical

60

Z. Shiller

solutions to the initial guess. Like in many other endeavors, the solution emerged by solving a simpler problem.
The failure of the geometric algorithms to solve high dimensional problems gave rise to a class of sampling-based planners, with the goal of producing any feasible path in lieu of the shortest path expected by earlier work. The multi-dimensional optimal trajectory planning problem was eventually solved by ﬁrst computing the optimal velocity proﬁle along a given path. This lead to a local optimization of the path and eventually to a global planner that computes “good” initial guesses for the local optimization.
In this chapter, we reviewed the main approaches to off-line and on-line motion planning, and presented one solution for each with a focus on trajectory planning. It was shown that any motion planning problem can be theoretically solved using the Hamilton Jacobi Bellman (HJB) equation. If the return function is known or approximated, this approach offers an online solution. In its discrete form, the HJB equation leads to dynamic programming, which is the basis for the combinatorial optimizations used in off-line planning.
We presented an off-line planner that takes advantage of the efﬁcient computation of the optimal motion time along any path. The on-line planner presented converts the original problem of optimally avoiding many obstacles to many simpler problems, each avoiding optimally only one obstacle. The high correlation between the solutions of the on-line and off-line planners is not surprising since both planners are based on sound optimal control theories.
As the basic problem of trajectory planning is considered solved, and as computers are becoming more powerful, the remaining challenge rests with online planning that adapts or reacts to the changing nature of real life scenarios in the industry, in the home, and on the road.

References
1. Choset H, Lynch KM, Hutchinson S, Kantor GA, Burgard W, Kavraki LE, Thrun S (2005) Principles of robot motion: theory, algorithms, and implementations. MIT Press, Cambridge
2. Shiller Z, Dubowsky S (1991) On computing the global time optimal motions of robotic manipulators in the presence of obstacles. IEEE Trans Robot Autom 7(6):785–797
3. Canny JF (1988) The complexity of robot motion planning. MIT Press, Cambridge 4. Lozano-Perez T, Wesley MA (1979) An algorithm for planning collision-free paths among
polyhedral obstacles. Commun ACM 22(10):560–570 5. Lumelsky VJ, Stepanov A (1987) Path planning strategies for a point mobile automaton moving
amidst unknown obstacles of arbitrary shape. Algorithmica 2:403–430 6. Schwartz JT, Sharir M (1983) On the piano movers’ problem: the case of a two-dimensional
rigid polygonal body moving amidst polygonal barriers. Commun Pure Appl Math 36:345–398 7. Karaman S, Frazzoli E (2011) Sampling-based algorithms for optimal motion planning. Int J
Robot Res 30(7):846–894 8. Manor G, Rimon E (2013) Vc-method: high-speed navigation of a uniformly braking mobile
robot using position-velocity conﬁguration space. Auton Robot 34(4):295–309 9. Lozano-Perez T (1987) A simple motion planning algorithm for robotic manipulators. IEEE
Trans Robot Autom RA-3(3):224–238

Off-Line and On-Line Trajectory Planning

61

10. Wein R, van den Berg JP, Halperin D (2005) The visibility-Voronoi complex and its applications. In: Proceedings of 21st symposium on computational geometry, pp 63–72
11. Alexopolous C, Grifﬁn PM (1992) Path planning for a mobile robot. IEEE Trans Syst Man Cybern 22(2):318–322
12. Liu YH, Arimoto S (1992) Path planning using a tangent graph for mobile robots among polygonal and curved obstacles. Int J Robot Res 11(4):376–382
13. LaValle SM (2010) Motion planning: the essentials. IEEE Robot Autom Mag 110 14. Dijkstra EW (1959) A note on two problems in connexion with graphs. Numerische Mathematik
1:269–271 15. Papadimitriou CH, Steiglitz K (1982) Combinatorial optimization, algorithms and complexity.
Prentice-Hall, Englewood Cliffs 16. Shiller Z, Gwo YR (1991) Dynamic motion planning of autonomous vehicles. IEEE Trans
Robot Autom 7(2):241–249 17. Lavalle SM (1998) Rapidly-exploring random trees: a new tool for path planning. Technical
Report 98-11, Department of CS, Iowa State University 18. Hsu D, Latombe JC, Motwani R (1999) Path planning in expansive conﬁguration spaces. Int J
Comput Geom Appl 4:495–512 19. Mazer E, Ahuactzin JM, Bessiere P (1998) The Ariadnes clew algorithm. J Artif Intell 9:295–
316 20. Karaman S, Walter MR, Perez A, Frazzoli E, Teller S (2011) Anytime motion planning using
the rrt*. In: International conference on robotics and automation 21. Amato NM, Bayazit OB, Dale LK (2000) Choosing good distance metrics and local planners
for probabilistic roadmap methods. IEEE Trans Robot Autom 16(4):442–447 22. Gmez-Bravo F, Carbone G, Fortes JC (2012) Collision free trajectory planning for hybrid
manipulators. Mechatronics 22(6):836–851. Special Issue on Intelligent Mechatronics 23. Bryson AE, Ho YC (1969) Applied optimal control. Blaisdell Publishing Company, Cambridge 24. Kiriazov P, Marinov P (1985) A method for time-optimal control of dynamically constrained
manipulator. Theory and practice of robotics and manipulators. MIT Press, Cambridge, pp 169–178 25. Niv M, Auslander DM (1984) Optimal control of a robot with obstacles. In: Proceedings of American control conference (San Diego, CA), June 1984, pp 280–287 26. Khan ME, Roth B (1971) The near-minimum time control of open loop articulated kinematic chains. J Dyn Syst Meas Control 93(3):164–172 27. Bobrow JE, Dubowsky S, Gibson JS (1985) Time-optimal control of robotic manipulators. IJRR 4(3):3–17 28. Pfeiffer F, Johanni R (1987) A concept for manipulator trajectory planning. IEEE Trans Robot Autom RA-3(3):115–123 29. Shin KG, McKay ND (1985) Minimum-time control of robotic manipulators with geometric path constraints. IEEE Trans Autom Control AC-30(6):531–541 30. Shiller Z, Lu HH (1992) Computation of path constrained time-optimal motions with dynamic singularities. ASME J Dyn Syst Meas Control 14(1):34–40 31. Slotine JE, Yang HS (1989) Improving the efﬁciency of time optimal path following algorithms. IEEE Trans Robot Autom 5(1):118–124 32. Tarkiainen M, Shiller Z (1993) Time optimal motions of manipulators with actuator dynamics. In: Proceedings of 1993 IEEE international conference on robotics and automation, vol 2, pp 725–730 33. Bobrow JE (1988) Optimal robot path planning using the minimum time criterion. IEEE Trans Robot Autom 4(4):443–450 34. Shiller Z, Dubowsky S (1989) Time-optimal path-planning for robotic manipulators with obstacles, actuator, gripper and payload constraints. IJRR 8(6):3–18 35. Seywald H (1994) Trajectory optimization based on differential inclusion. J Guid, Control, Dyn 17(3):480–487 36. Bryson AE (1999) Dynamic optimization. Addison Wesley, New York

62

Z. Shiller

37. Donald B, Xavier P (1989) A provably good approximation algorithm for optimal-time trajectory planning. In: Proceedings of IEEE conference on robotics and automation, May 1989, pp 958–963
38. Sahar G, Hollerbach JM (1985) Planning of minimum-time trajectories for robot arms. In: Proceedings of IEEE international conference on robotics and automation (St. Louis, MO), March 1985, pp 751–758
39. Kamon I, Rimon E, Rivlin E (1998) Tangentbug: a range-sensor based navigation algorithm. Int J Robot Res 17(9):934–953
40. Laubach S, Burdick J, Matthies L (1998) A practical autonomous path-planner for the rocky7 prototype microrover. IEEE international conference on robotics and automation
41. Choset H, Burdick JW (1995) Sensor based planning, part ii: incremental construction of the generalized Voronoi graph. In: Proceedings of IEEE international conference on robotics and automation, ICRA’95, pp 1643–1649
42. Sankaranarayanan A, Vidyasagar M (1991) Path planning for moving a point object amidst unknown obstacles in a plane: the universal lower bound on worst case path lengths and a classiﬁcation of algorithms. In: Proceedings of IEEE international conference on robotics and automation, ICRA’91, pp 1734–1941
43. Connoly CI, Burns JB, Weiss R (1991) Path planning using Laplace’s equation. In: IEEE conference on robotics and automation, Cincinnati, OH, vol 1, pp 102–2106
44. Khatib O (1986) Real time obstacle avoidance for manipulators and mobile robots. Int J Robot Res 1:65–78
45. Rimon E, Koditschek DE (1992) Exact robot navigation using artiﬁcial potential functions. IEEE Trans Robot Autom 8:501–518
46. Jarvis R (1985) Collision-free trajectory planning using distance transforms. Trans Inst Eng Aust Mech Eng ME10(3):187–191
47. Athans M (1965) Optimal control: an introduction to the theory and it’s applications. Academic Press, New York
48. Cesari L (1983) Optimization—theory and applications: problems with ordinary differential equations. Springer, New York
49. Moskalenko AI (1967) Bellman equations for optimal processes with constraints on the phase coordinates. Autom Remote Control 4:1853–1864
50. Shiller Z, Sharma S, Stern I, Stern A (2013) On-line obstacle avoidance at high speeds. Int J Robot Res 32(9–10):1030–1047
51. Sundar S, Shiller Z (1997) Optimal obstacle avoidance based on sufﬁcient conditions of optimality. IEEE Trans Robot Autom 13(2):305–310
52. Lee EB, Markus L (1967) Foundations of optimal control theory. Wiley, New York 53. Koditschek DE, Rimon E (1990) Robot navigation functions on manifolds with boundary. Adv
Appl Math 11:412–442 54. Bellman R (1957) Dynamic programming. Princeton University Press, Princeton 55. Lawler EL (1976) Combinatorial optimization. Holt, Rinehart and Winston, New York 56. Fujita Y, Nakamura Y, Shiller Z (2003) Dual dijkstra search for paths with different topologies.
In: ICRA, pp 3359–3364 57. Shiller Z, Fujita Y, Ophir D, Nakamura Y (2004) Computing a set of local optimal paths through
cluttered environments and over open terrain. In: ICRA, pp 4759–4764 58. Pham QC (2013) Characterizing and addressing dynamic singularities in the time-optimal path
parameterization algorithm. In: 2013 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp 2357–2363 59. Dreyfus S (1965) Dynamic programming and the calculus of variations. Academic Press, New York 60. Sundar S (1995) Time-optimal obstacle avoidance for robotic manipulators. Doctoral Dissertation, Mechanical and Aerospace Engineering, University of California, Los Angeles, June 1995

Open Architecture for Vision-Based Robot Motion Planning and Control
Theodor Borangiu, Florin Anton and Silvia Anton

Abstract This chapter introduces a methodology for the vision-based motion control of robot manipulators. The motion control problem is decomposed into three computational stages: motion planning, trajectory generation and trajectory tracking. While the two latter activities are always executed in real time, motion is planned in traditional robot systems off line, by learning robot points or by using numerical output data from programs that plan minimal paths, avoid obstacles, etc. Guidance vision is introduced as an advanced motion control method, which provides ﬂexibility when integrating industrial robots in computer-controlled manufacturing structures. A dynamic look-and-move system architecture is discussed, as a robot-vision system which is closed at task level. An open architecture is proposed as implementing solution for vision-based scene management and robot guidance, which integrates any types of robot controllers and image processing libraries. The chapter also presents a motion control algorithm for robots which are required to pick objects randomly moving on conveyor belts. The algorithm for visual tracking of conveyor belts for “on–the-ﬂy” object grasping is partitioned in two stages: (i) visual planning of the instantaneous destination of the robot, (ii) dynamic re-planning of the robot’s destination while tracking the object moving on the conveyor belt. The ensemble [conveyor belt + actuator + sensor] is conﬁgured as a single-axis Cartesian robot, leading to a cooperation problem between robot manipulators subject to multitasking control. Experimental results are ﬁnally reported in what concerns the statistics of object locating errors and motion planning errors function of the size of the objects of the belt speed and of the light strobe.
Keywords Robot-vision system · Vision guided robot planning · Visual robot servoing · Joint-space trajectory planning

T. Borangiu (B) · F. Anton · S. Anton
Department of Automation and Applied Informatics,
University Politehnica of Bucharest, Bucharest, Romania
e-mail: theodor.borangiu@cimr.pub.ro

© Springer International Publishing Switzerland 2015

63

G. Carbone and F. Gomez-Bravo (eds.), Motion and Operation Planning

of Robotic Systems, Mechanisms and Machine Science 29,

DOI 10.1007/978-3-319-14705-5_3

64
1 Introduction

T. Borangiu et al.

The motion control problem refers to controlling the robot manipulator such that it follows a pre-planned path. The motion control problem is generally decomposed into three computational stages (Fig. 1): (1) Motion planning; (2) Trajectory generation; (3) Trajectory tracking [1].
In the motion planning stage, desired paths are described in the r-dimensional task space T (i.e. the locus of the positions and orientations that the robot tool must attain in O ⊆ Rm—the operational space, T ⊆ O), which is isomorphic to the special Euclidian group SE3.
T = x(t) x ∈ Rr , t ∈ R+ , T ⊆ SE3 = R3 × SO3
The vectors x = xn0 = [ p φ ]T, n = no. of d.o.f. express the location of the nth coordinate frame (xn, yn, zn), attached to the end-effector, relative to the world frame (x0, y0, z0) attached to the base of the robot, p ∈ R3 speciﬁes the coordinates of the origin of the task frame (or end-effector frame), whereas the current orientation φ of the task frame is described either by the rotation matrix R—a member of the special orthogonal group SO3, or minimally by a set of 3 Euler angles (in the sequel, the yaw, pitch and roll angles will be considered). If the tool is a single rigid body moving arbitrarily in the Cartesian 3D workspace, then T = SE3 = R3 × SO3, m = 6.
Because on one hand robotic tasks are speciﬁed with respect to one or more coordinate frames, and on the other hand visual servoing of robots makes intensive

Off line

Real time

computation (non-vision robot systems)

External sensors (video)

Motion planner

Internal sensors (encoders)

Trajectory generator

Trajectory tracking

MOTION CONTROL

Manipulator

Working environment

Fig. 1 Functional architecture for the global robot motion planning and control problem

Open Architecture for Vision-Based Robot Motion Planning and Control

65

use of a number of speciﬁc, additional coordinate frames, coordinate transformations are used in motion planning and tracking as a generalisation of poses to express relative locations between such frames of interest [2, 3].
Coordinate transformations must be often composed in the stage of motion planning and tracking, off line or at run time, to obtain the desired pose of the end-effector. Assuming that we are given the coordinate transformations xv0is and xovibsj expressing respectively the location of the coordinate frame (xvis, yvis)attached to the image plane relative to the world frame (x0, y0, z0) in the base of the robot, and the location of the frame (xobj , yobj ) attached to an object relative to (xvis, yvis ), then the coordinates Mobj of a point in the object frame can be expressed in the world frame by the composition rule (:):
M0 = xv0is [xovibsj [Mobj ]] = (xv0is : xovibsj )[Mobj ] = xo0bj [Mobj ]
The associated relative rotation matrix and translation are given by Ro0bj = Rv0is Rovibsj , p0obj = Rv0is pvoibsj + p0vis . In the V+ structured robot programming environment, the simple transformations: to.cam[cam]—available from camera-robot calibration, and vis.loc—the object location computed at run time, stand respectively for xv0is and xovibsj ; the object-attached frame is related to the world frame by the composed transformation obj.loc ← to.cam[cam]:vis.loc
During motion planning stage, the desired paths are generated without timing information, i.e., without specifying the velocity and the acceleration along the path. Of primary concern is the deﬁnition of collision-free paths in the workspace. A secondary objective may be included, for example the optimization of some cost functions like: minimization of the total travel time or distance, keeping as low as possible changes in direction, continuity of velocity, etc. [4].
The trajectory planner (generator) parameterises the end-effector path directly in the task space either as a curve in SE3, or in R6 when a minimal Euler representation is used for SO3. The trajectory planner may also compute a trajectory for the individual joints of the manipulator as a curve in the conﬁguration space C = q(t) q ∈ Rn, t ∈ Z+, n = no. of d.o.f. .
The trajectory planner TP, represented as block—and connection diagram in Fig. 2, is a software module, component of the basic software system of the robot controller, being characterised as follows:
1. The inputs to the TP are the path description and constraints, and the constraints imposed by the manipulator’s dynamics.
2. The output from the TP is the joint—or end-effector trajectory data, expressed as a discrete time sequence of the values which must be attained by the position, velocity and acceleration computed respectively in the conﬁguration space q ∈ C or in the task space x = (p, φ) ∈ Rr , from the initial to the ﬁnal pose.
3. The trajectory planning task is executed by the TP in one of the two following modes:
• Assuming that a set of constraints (e.g. continuity or smoothness) on position, velocity and acceleration of the manipulator’s joint variables has been explicitly

66

T. Borangiu et al.

Path constraints

Path specification

Trajectory planner
• interpolating support points • time parameterization of path • speed, acceleration profile • (Inverse Kinematics)

Dynamic constraints of the manipulator
Fig. 2 Trajectory planner task and I/O representation

{q(t), q(t), q(t)} or {x(t), x(t), x(t)}, t ∈ Z

speciﬁed at selected joint conﬁgurations (called support—or interpolating points) along the trajectory, the TP selects then a parameterised trajectory from a class of polynomial functions in the total travelling time interval, which interpolates and satisﬁes the imposed constraints at the support points. • A path that the end-effector must traverse is explicitly speciﬁed by an analytical function (e.g. a 3D straight-line path, a 2D circular-arc path in Cartesian coordinates or any computed curve), and the TP adds a time law to compute a trajectory that approximates the desired path either in joint coordinates or in Cartesian coordinates.
In the ﬁrst mode, the constraint speciﬁcation and the planning of the manipulator trajectory are performed in joint coordinates. In the second mode, the path constraints are speciﬁed in Cartesian coordinates, and the joint actuators are servoed in joint coordinates.
To compute a joint-space trajectory, a given end-effector path must be transformed into a joint-space path via the Inverse Kinematics (IK) mapping. Due to the difﬁculty of computing on line this mapping, the usual approach is to compute a discrete set of joint vectors along the end-effector path (joint support vectors), and then to interpolate in joint space between these support points in order to complete the joint-space trajectory. Common approaches to trajectory interpolation include polynomial spline interpolation using trapezoidal velocity proﬁles and time laws of blended polynomial type, cubic polynomial trajectories, or trajectories generated by reference models [5].

2 The Trajectory Generation Problem in Robot Motion Control
A path can be deﬁned either in the joint space or in the operational space. Usually, the latter is preferred since it allows: • a natural description of the task the manipulator has to do,

Open Architecture for Vision-Based Robot Motion Planning and Control

67

• a simple description of the path constraints—these are due to regions of the workspace which are forbidden to the manipulator (e.g. due to the presence of obstacles), and
• a direct knowledge of the pose of the end-effector in the workspace [6].
A geometric path cannot be fully speciﬁed by the user due to complexity reasons. Typically, a reduced number of parameters are speciﬁed, such as: ﬁnal points, possible intermediate points, geometric primitives interpolating the points. Also, the motion time law is not typically speciﬁed at each point of the geometric path, but rather it regards: the total trajectory time, the constraints on the maximum velocities and accelerations or the eventual assignment of velocity and acceleration at some points of particular interest.
This section presents algorithms and implementing solutions for operationalspace and joint-space and motion planning. Real-time computational aspects and performances are analysed.

2.1 Joint-Space Trajectory Planning

For this type of trajectory planning, the time history of all joint variables and of their ﬁrst two derivatives is planned to describe the desired motion of the manipulator. Planning in the joint space has the following advantages:
• the trajectory is planned directly, in terms of the controlled joint variables q(t) during motion execution;
• the trajectory planning can be done nearly in real time; • the joint trajectories are planned with a reasonable computational effort.
The main disadvantage is the difﬁculty in determining the locations of the various links and of the end-effector in the operational space, a condition which is usually required to guarantee obstacle avoidance along the trajectory.
The global algorithm for generating joint-trajectory set points is given next:

loop:

t = t0 ; wait for next control interval; t = t + Δt ; Update the trajectory planner tp(t) → compute the necessary joint posture
of the manipulator: {q(t), q(t), q(t)} at time t ;
if t = tfinal exit; else go to loop.

Four constraints are imposed to the planned joint-space trajectory:
1. The trajectory set points must be non-iteratively readily calculable. 2. Intermediate points must be evaluated in a deterministic mode.

68

T. Borangiu et al.

3. The continuity of the joint position and its ﬁrst two time derivatives must be guaranteed so that the planned joint trajectory is smooth.
4. Extraneous motions must be avoided.
The constraints 1–4 for the planned trajectory will be satisﬁed if the time history of the joint variables can be speciﬁed by polynomial sequences.
Robot controllers use electronic gearing in the joint-space trajectory generator in order to synchronize the movement of one or more slave axes to the movement of a master device, which can be an encoder, A/DC, or the trajectory of another axis, e.g. the robot’s leading axis which must execute the longest displacement.

2.2 Operational-Space Trajectory Planning

The general case of Cartesian-space planning is considered, for which the global algorithm is given below:

loop:

t = t0 ; wait for next control interval; t = t + Δt ; Update the operational hand planner TP(t) → compute the necessary
position and orientation of the end-effector: {p(t), φ(t), p(t), ω(t)}
in the operational space at current control time interval t ; Compute the closed IK joint solution – CIKS, IK[TP(t)], corresponding to
TP(t) ;
if t = tfinal exit; else go to loop.

In general, task-space planning is done in two steps:

STEP 1: Generating or selecting the set of support points in operational coordinates according to some rules, along the operational path
STEP 2: Specifying a class of functions to link the support points deﬁned in STEP 1 (or to approximate the path segments) according to some criteria. The criteria which are chosen are often dictated by the control algorithm following the trajectory planning, which tracks the desired path.

There are two approaches which can be used for achieving STEP 2:
1. The operational space—oriented approach: support points are generated along the task path in operational coordinates. Then, the TP interpolates in operational space between these support points and adds the time law expressed in terms of the desired speed and acceleration proﬁles. The result will be the discrete

Open Architecture for Vision-Based Robot Motion Planning and Control

69

time sequence of values that must be attained by the end-effector’s position and velocity computed in the task space, i.e. the trajectory in the task space.
Next, the task-space trajectory is converted into the corresponding joint-space trajectory, by applying for inverse kinematics computation. Several techniques can be used to this purpose:
• The kinematics inversion using the Jacobean pseudo-inverse J+ or the Jacobean transpose JT [1, 7];
• The resolved motion rate control (RMRC) algorithm in the form:

δqc(t) = J−1(qc(t))δxc(t)
where:
δqc(t) = q(tk+1) − q(tk ), δqc(t) = IOS(xd (tk+1) − dk(q(tk ))
This corresponds to an incremental IK task space computation IOS, δxc(t) being the incremental displacement along the operational path, and dk(q) is the time function that computes the Direct Kinematics model. Hence it can be observed that the two time-consuming computing tasks:
– operational path interpolation between support points, and – conversion of the task-space trajectory to a joint-space trajectory
are performed incrementally with arguments representing relative position and speed values. This will consequently reduce the computation time and augment the bandwidth of the TP (Fig. 3).

Operational path
description
Speed and acceleration profiles

Generating support points along the opera-
tional path
Linking support points by interpolating in operational space

δx c (t), δx c (t) δq c (t),δq c (t)

Incremental IK(J −1 , J T )

Numerical integration

Absolute DK q c (t) ≡ q d (t) (Direct
Kinematics)
x(t)

Real-time computation
Fig. 3 Linking support points by interpolating in operational space

70

T. Borangiu et al.

Moreover, in order to additionally reduce the computing time, truncation of results and approximations like sin θ ≈ 0, cos θ ≈ 1 − θ 2/2 for |θ | < ε with ε a small, positive quantity, or reduced-order series development are accepted for the IK computation task. This is because any induced errors will be compensated by the DK task, placed on the feedback path and operating with the absolute values of the argument “qc—the computed joint conﬁguration on the operational path” [5, 8]. In the case of linear interpolation, the resulting output trajectory generated by the TP is a piecewise straight line in the task space.
Attention must be paid as IK transformations do not produce unique solutions; in addition, if the manipulator dynamics is included in the trajectory planning, then path constraints will be speciﬁed in operational coordinates, while physical constraints such as force, torque, velocity and acceleration limits of each joint motor will be bounded in joint coordinates.
2. The joint space—oriented approach: converts ﬁrst the support points that have been deﬁned along the operational path into their corresponding joint coordinates, and the uses low-degree polynomial functions to interpolate between these converted support points (Fig. 4). Figures 3 and 4 represent two approaches used for interpolating between support points generated along the operational path.
If the TP must generate a linear trajectory in the task space, the support points will be on this linear path, but the linear joint-space interpolation between support points will produce a ﬁnal output trajectory which is a non–piecewise straight line in the task space. According to the maximum allowed deviation in position of the planned trajectory with respect to the ideal, linear one in the task space, a certain number of support points will be deﬁned on the operational path. The smaller the admitted deviation, the larger the number of support points to be deﬁned on the operational path. This second approach is widely used, because of its reduced computational effort.
In the trajectory tracking stage, the computed reference trajectory is input to the motion controller, whose function is to determine the end-effector to track the given trajectory as close as possible. The trajectory tracking task is executed in real time

Speed and acceleration profiles

Operational path
description

x c (t)

q c (t)

Selecting support points along the operational path

Absolute IK

q d (t)
Linking support points by joint space interpolation

Off-line computation
Fig. 4 Linking support points by interpolating in joint space

Real-time computation

Open Architecture for Vision-Based Robot Motion Planning and Control

71

by the motion controller and consists in computing the time history of joint control inputs u, i.e. the vector of control voltages for the n axes’ servomotors.
Task description is in most cases expressed in the m-dimensional operational space (with a particular minimal representation for the end-effector orientation), whereas control inputs (control velocities or forces/torques for the joint actuators) are generated in the n-dimensional joint space. Consequently, two types of motion control schemes have been thought of: with joint-space trajectory tracking and with operational-space trajectory tracking.

3 The Taxonomy of Visual Robot Servoing
The AI approach to intelligent robot automation is best characterised as the attempt to provide a robot with a symbolic representation of its environment and of its own actions, to be exploited by some kind of inference procedure. In this ﬁeld, the main contributions of AI have been signiﬁcant in two directions [9–11]:
• perception, with particular regard to object recognition and locating through vision; • planning, i.e. the automatic construction of a sequence of actions capable to achieve
a predeﬁned goal.
The behavioural intelligence of a robotic system refers to the following properties:
1. Flexibility: in different situations, the robot controller is able to produce appropriately different behavioural patterns in pursuit of different goals.
2. Robustness: the robotic system can absorb and neutralise the effects of incomplete and noisy information and of limited changes in the environment’s structure and dynamics.
3. Adaptiveness: the ability of the robotic system to alter behaviour signiﬁcantly in response to radical changes in the environment.
Robot-vision systems use intelligent image processing to detect, recognize or track object features and act in consequence to plan and guide the motion of the robot. The chapter introduces the Look-and-Move approach for guidance vision (visually planning the robot’s motion—the industry solution), see Fig. 5.
This is a hierarchical motion control structure, with the vision processor providing (planning) set-points as references to the robot’s joint-level controller—thus using joint data feedback to internally stabilise the robot. This structure leads to an interlaced look-and-move control scheme, where motion tracking and image processing are pipelined as follows:
• while a motion segment is executed, no image is acquired and processed, and • while an image is taken and treated according to the speciﬁc needs of a robot task,
the motion controller does not start generating a trajectory and tracking it.

72

T. Borangiu et al.

Camera-robot Robot-object

calibration calibration

(x

obj n

)

d

Σ +

xvsis

(x0n )c = udr

Cartesian-space trajectory generator

Joint controllers

Robot manipulator

u

motors

Power

amp

−

(x

vis obj

)

est

(x0s )m (x0n )m

dk( )

Trajectory tracking

Camera
encoders qm, m

(x

obj n

)

est

Pose estimation

Image feature extraction
(f )est

Object's image

Fig. 5 Position-based look-and-move visual servoing architecture for object tracking

It can be observed that, whereas the global robotic system operates in an open
loop structure at motion control level, it is subject to a closed loop control at the
global task level.
Position-based look-and-move control is further discussed in this section. As
described in Fig. 5, features are extracted from the image and used to estimate the pose xˆovibsj = (xovibsj )est of the target (object, point) with respect to the camera. Using these values, an error between the current estimated and the desired pose of the robot, (xovibsj )d is deﬁned in the task space T . Thus, position-based control neatly separates the control actions, i.e. the computation of the feedback signal (xs0)m = dk(qm,s), n − 3 ≤ s ≤ n using the direct kinematics model dk(·) of the robot manipulator, from the estimation problem involved in computing position or pose xˆovibsj from visual data (f)est .
A visual positioning task is expressed by an error function E : T → Rm. This
function is referred to as the virtual kinematic error function VKE. A positioning task is fulﬁlled when the end-effector has been moved in pose xn = xn0 if E(xn) = 0.
Once a suitable VKE function deﬁned and its parameters instantiated from visual
data, a compensator can be designed that reduces the value of the VKE function
to zero. This compensator computes at every sampling time instant the necessary end-effector position (xn)c that is sent as dynamic reference to the joint-space (or operational-space) motion tracking controller [1]. Since the VKE functions are
deﬁned usually in the Cartesian space, it is common sense to develop the compen-
sator’s control law through geometric insight.

Open Architecture for Vision-Based Robot Motion Planning and Control

73

4 Guidance Vision for Robot Motion Planning

The problem of visual feature tracking for robot motion planning and object access control will be further presented for two types of working environments: (1) ﬁxed scene, e.g. workstation, storage, ASRS, and (2) mobile scene, e.g. conveyor belts [12, 13].

4.1 Open, Vision-Based Robot Motion Planning for Fixed Scene Foreground
An open, vision-based robot motion planning and control method and implementing solution is presented in this section. The method allows using any general purpose machine vision system (here an industrial camera with c-mount and AdeptSight software) with any type of industrial robot controller (here ABB), with a proper interfacing (Ethernet or serial communication).
In order to be used, a camera calibration is needed (which is provided by vision any image processing library based on a calibration pattern), and also a robot-camera calibration (which must be done manually by the robot technician); the models of the objects to be accessed by the robot and the robot-object (class) grasping will be off-line taught for collision free motion at execution time.
In industrial applications of position-based dynamic look-and-move control structures, the robot-vision system works in most cases with off line learned objects which can be visually recognised and located at run time [14, 15]. It becomes thus possible:
• to recover the object’s pose, xˆobj , relative to the base frame of the robot, from the direct estimate xˆovibsj of the object’s pose in the vision frame and by composing it with the camera-robot calibration estimate xˆvis;
• to deﬁne stationing points Sobj on the object’s image, relative to a suitable objectattached frame (xobj , yobj ).
Figure 6 shows a ﬁxed camera conﬁguration and related camera-robot transformations; this is an endpoint open-loop (EOL) system that only observe the target object to guide the robot’s motion for grasping it.
The physical camera is related to the base coordinate system of the robot by the time-invariant pose evaluated a single time during an interactive off line camerarobot calibration session, and to the object in the scene by. The camera image of the object is independent of the robot motion (unless the target is the end-effector itself, described for example by image feature of the gripper’s ﬁngerprints projected onto the image plane). The pose is computed at run time, and involves the search, recognition and locating of image features(s) on the object of interest [16–18].

74

T. Borangiu et al.

Stationary camera

x

0 n

xo0bj

z0

y0

x v0is x0

Visualised

object surface

Image

x

obj n

plane

x

vis obj

Projection of visualized

object surface onto (xvis , yvis )

Fig. 6 Stationary camera conﬁguration and related camera—robot relative transformations xo0bj , xn0 respectively for the feature tracking and feature tracking for object grasping tasks

For object grasping, the image features must unambiguously describe the entire object for its successful identiﬁcation and locating at run time. In addition, the pose of the gripper, relative to the frame attached to the object in its current location, is required.
For a stationary camera, the relationship between these poses is:
xn0 = xv0is : xovibsj : xnobj , for feature tracking for object grasping.
Assuming a random part presentation in the robot workstation, the object’s pose relative to a (unique) camera frame, xˆovibsj_1 will be estimated at run time in a ﬁrst stage in terms of the following image feature parameters:
• xC , yC : coordinates of the centre of mass C of the 2D projection of the object’s visualised surface onto the image plane (xvis, yvis );
• orient = ∠(MIA, xvis): orientation angle of the object.
The object-attached frame (xobj_1, yobj_1) has the origin in C and the abscissa xobj_1 ≡ MIA, where MIA stands for the object’s Minimum Inertia Axis (Fig. 7).
To move the robot to grasp objects of a certain class always in the same way, irrespective of their location in the robot scene, the desired (unique) pose of the gripper, xnob∗ j , relative to the object-attached frame must be a priori learned.
Let us denote by G the projection of the end-tip point T, the origin of the gripperattached frame (xn, yn, zn), onto the image plane: G = proj|(xvis,yvis) {T}.
For a desired grasping style, Gobj_1 is a stationing point in the object’s coordinates (xobj_1, yobj_1), irrespective of the current position and orientation of the object. Its

Open Architecture for Vision-Based Robot Motion Planning and Control

75

Visualised object surface

yn T

Gripper in desired grasping location

xn

zn

dir(C, G)

yvis

alpha

yC

Fingerprint 1

yobj yobj _ 1

G
xobj

C xobj _ 1

MIA

Fingerprint 2

xC

xvis

Fig. 7 Deﬁnition of the object-attached coordinate frame

coordinates are: xG = dCG · cos(alpha); yG = dCG · sin(alpha), where dCG = dist(C, G), and alpha = ∠(dir(C, G), MIA) measured CCW from the Minimum
Inertia Axis MIA) to dir(C, G). In a second stage, the object-attached frame will be
shifted to origin G, by a translation of distance dCG along dir(MIA) followed by a rota-
tion of angle alpha about the normal in C to the image plane, as represented in Fig. 7. Given an object pose, xovibsj , estimated visually at run time, and assuming that the
object was recognised as a member of that class for which a relative grasping pose xnob∗ j was a priori learned using a stationary camera calibrated to the robot base frame by xvis, then the positioning error can be deﬁned by the VKE function

E(xn; x˜nob∗ j , xˆovibsj , xˆvis ) = xnn∗ = xˆ0n : xˆvis : xˆovibsj : x˜nob∗ j ,

where:

x˜nob∗ j =

xnob∗ j a priori known from learning, xˆnob∗ j visually updated at run time,

particular “grasping style” general “grasping style"

.

With an EOL system, xˆ0n = inverse(xˆn0) will be dynamically updated by the trajectory generator to bring to zero the positioning error xnn∗ . This can be simply done applying for an IK-based Resolved Motion Rate Control algorithm.
The closed-loop servo control uses the visually estimated pose of the object, xˆovibsj ,
the estimated camera-robot calibration pose xˆvis, and assumes that reduced-error direct kinematics (xˆn0)—and inverse kinematics (xˆ0n) models are available. As for the imposed grasping pose, for a priori unknown object location in the scene, some
components in xˆnob∗ j must be estimated at run time whenever the “style" in which the object will be grasped is general, i.e. such that G ≡ C and G ∈/ MIA [19–21].

76

T. Borangiu et al.

For object access and handling using vision, the problem is reduced to expressing the object position in the image relative to the robot base. This is done in the robotcamera calibration session, the result of which is a relative transformation expressing the position and orientation of the vision frame relative to the robot base. Once the calibration is executed, robot points will be computed relative to the position and orientation of the vision-attached frame, and the robot motion planning follows the procedure described in Sect. 2.
The robot-camera calibration procedure requires the usage of an object that will be handled by the robot; during the execution of the procedure the robot will move the object to different locations and will acquire pictures, generating a set of pairs of descriptions of the object’s location: (a) from the camera and (b) from the joint encoders. The solution of this set of equations will describe the camera’s ﬁeld of view location relative to the robot base.
For testing purpose an AdeptSight system and ABB robot manipulator were used, the robot-vision calibration process and the training of the object grasping model have been integrated in a single procedure. The procedure consists in four human-robot interactive steps where the robot grasps the object and places it different positions in the workspace for image acquisition and processing [2]:
The calibration object is placed in the workspace and grasped by the robot and then released (position P1), after which the robot clears the vision plane and the object’s position in the vision plane is computed by the AdeptSight library. The point P1 is the point which will be used to express all the positions of the objects in the image. For example a position of an object will be computed as Po where Po is P1 shifted with a set of offsets (for translations on X and Y and rotation on the Z axis). The position of the object in point P1 is also computed in the vision plane, having the coordinates P1Xv, P1Y v (the position of the coordinate system attached to the object model) [22, 23].
In the second step the robot grasps the object and places it in the same position, but rotated with 180◦ (point P1 ), in the vision coordinates P1 Xv, P1 Y v. By comparing the position of the coordinate system of the object in these positions the system can compute the position of the mass centre of the object (the mass centre of the model relative to the grasping point). In this case the grasping point is located in the image on the middle of the segment [P1, P1 ] (see Fig. 8).

Pgvis

Pgvisx = min(P1x , P1 x ) + P1x − P1 x Pgvisy = min(P1y, P1 y) + P1y − P1 y

,

where Pgvis is the grasping point in the vision workspace. Next the object is placed in a position P2 which is trained relative to the position
P1 shifted with 100 mm on X axis of the base coordinate system of the robot. In the ﬁnal step the robot places the object in the position P3 which is trained
relative to the position P1 shifted with 100 mm on Y axis of the base coordinate system of the robot. By knowing the correspondence robot-point—image-point, the system can compute now the orientation of the vision plane relative to the robot base

Open Architecture for Vision-Based Robot Motion Planning and Control

77

dist(P1,P1’)

Fig. 8 The relationship robot point—vision point
coordinate system, and also the distance which the robot must cover to reach an object which is placed at a certain distance from the initial point P1 in the image plane.
This can be expressed as follows: for 100 mm travelling length along the X coordinate system (base coordinate system) the object moves in the image P2x − P1x along the Xvis axis, and P2y − P1y along Yvis; the same travelling length on the Y coordinate system generates P3x − P1x on Xvis axis, and P3y − P1y on Yvis , in the vision workspace. It results also that the vision system is rotated with the angle:
α = a tan 2(P2Y − P1Y , P2X − P1X )
toward the base coordinate system. Hence for an object which is recognized in the image at the location Pv, the object will be grasped at the coordinates:
Px = PG_x + (P1_x − Pv_x )2 + (P1_x − Pv_x )2 · cos(α + a tan 2(Pv_y − P1_y, Pv_x − P1_x )
Py = PG_y + (P1_x − Pv_x )2 + (P1_x − Pv_x )2 · sin(α + a tan 2(Pv_y − P1_y, Pv_x − P1_x )
Prot = PG_rot + ( Pv_rot − P1_rot )
where Px , Py, Prot are the position coordinates and the rotation of the grasping point of the object which was located in the vision workspace at the location Pv (Pv_x , Pv_y, Pv_rot); PG (PG_x , PG_y, PG_rot) is the grasping point (in the object’s centre of the mass in the base coordinates system) for the object located in the image in P1 (P1_x , P1_y, P1_rot).

78

T. Borangiu et al.

After the calibration is executed, the object model must be trained; this stage involves object edges processing in order to obtain the geometrical model of the object. The grasping position must be also trained in order to validate a collision free point for accessing the object. The grasping position (for grasping validation) is deﬁned by two or more rectangular areas placed around the object and linked to the object frame. These areas represent the projections of the gripper ﬁngerprints on the image plane and by processing the image colour inside these areas the program detects the presence of obstacles and can invalidate the grasping position.
These three pieces of information are used for robot motion planning; ﬁrst the location of the ﬁeld of view is used by extracting it from the calibration data, then the location of the object in the ﬁeld of view is computed (online) using the object model and in the last stage the action of grasping the object is validated by using the grasping model and collision free tests. Experimental results validating the proposed solution are shown from a robotized ceramic production line (Fig. 9).
The experimental application runs two communications threads: a TCP/IP server and a serial communication thread. Both threads have the same role, they are listening and if they receive an acquisition request, they initialize the execution of the AdeptSight sequence of tools (the vision program), returning three numbers specifying the position and orientation of the plate (X, Y in mm, and the angle in degrees). The position and orientation is speciﬁed relative to the calibration object.

Fig. 9 Real-time locating a ceramic plate for robot motion planning and grasping control

Open Architecture for Vision-Based Robot Motion Planning and Control

79

The requests are sent as ASCII characters, and they are of two types (i— information for debugging or r—real requests); when the vision server receive a request the vision sequence is executed, the object is recognized based on its boundary contours, and the values (X, Y and rotation) relative to the initial grasping point (from the calibration procedure) are computed and sent to the ABB robot.
When the robot receives the three values, it shifts the initial grasping position (from the calibration) and grasps the plate. The following pseudo-code describes how the communication is integrated with the vision server [24]:
Open the communication channel (Serial line) Clear the serial line buffer Request object coordinates from vision Read the data streams (X,Y coordinates and rotation) Transform the coordinates from string to real Request object coordinates from vision Read the data streams (X,Y coordinates and rotation) Transform the coordinates from string to real /*In order to avoid problems caused by communication errors the coordinates are sent twice and only if they are the same at the destination then the position can be computed*/ Verify if the coordinates are the same IF YES
Compute the grasping position //The position is computed relative to a predefined //position p1 Close the communication ELSE
Repeat the request
The presented image processing system, AdeptSight, is robust, offers generic robot-vision functions, and can be easily integrated with controllers of other industrial equipment (robots, measuring machines, ASRS, part feeders). AdeptSight allows a rapid development of visually planned applications, based on visual tools which can be combined and conﬁgured leading to sequences which can be executed from external C# applications.

4.2 Multitasking Robot Motion Planning for Object Tracking on Mobile Scenes
The problem of robot tracking objects of interest moving on conveyor belts and randomly entering the robot’s dexterous space can be solved by integrating the following devices in a multitasking control structure, implemented on multiprocessor robot controllers:
• the robot manipulator, tracking a conveyor belt; • the conveyor belt, driven at constant, regulated speed; • the vision module, inspecting parts on the conveyor belt.

80

T. Borangiu et al.

Conceptually, the problem is solved by deﬁning a number of user tasks which attach two types of “robots”: the n—d.o.f. manipulator grasping on-the-ﬂy objects moving on the conveyor belt, and one m ≤ 3—axis “robot” emulating the conveyor belt under vision control; m is the number of non-null projections of the conveyor belt displacement direction on the 3 axes of an orthonormal reference frame (e.g., deﬁned in the belt tracking robot environment). These user tasks run concurrently with the internal system tasks of a multitasking belt tracking robot controller, which are responsible for trajectory generation, axis servoing and resources management [20].
In this respect, the minimum number of tasks to be deﬁned for the tracking problem is equal to 3:
• Task 1: Dynamic re planning of the destination location (grasping the moving object) for the robot manipulator.
• Task 2: Continuously moving (driving) the m-axis vision belt. (e.g., m = 1) • Task 3: Reading once the belt’s location the very moment an object of interest
has been recognised, located and its grasping estimated as collision-free, and then continuously until the object is effectively picked.

4.2.1 Tasks and Priorities for the Multitasking Robot Motion Planning Problem
Consider that each control system cycle of the robot is divided into 16 time slices of one millisecond, the time slices being numbered 0 through 15. A single occurrence of all 16 time slices is referred to as a major cycle. For a robot system, each of these cycles corresponds to one output from the trajectory generator to the digital servos. A number of user tasks, e.g. from 0 to 6, can be used and conﬁgured to suit the needs of speciﬁc applications. Tasks are normally assigned default time slices and priorities according to the current system conﬁguration [5, 8].
An execution cycle is terminated when a STOP instruction is executed, a RETURN instruction is executed in the top-level program, or the last deﬁned step of the program is encountered. Tasks are scheduled to run with a speciﬁed priority in one or more time slices. Tasks may have priorities from −1 to 64, and the priorities may be different in each time slice. The priority meanings are: 1–31 (normal user tasks); 32– 62 (used by robot controller’s device drivers and system tasks); 63 (used by trajectory generator); 64 (used by the servo).

4.2.2 Scheduling Program Execution Tasks with Simultaneous Belt Tracking
An analysis of the time slice and priority allocation for the system, and of default user tasks imposes several requirements for timing and priority assignment of tasks: vision guided robot planning (“object recognition and locating”), and dynamical re planning of robot destination (“robot tracking the belt”) should always be conﬁgured on user

Open Architecture for Vision-Based Robot Motion Planning and Control

81

tasks 0 and/or 1, in “Look-and-Move” interlaced robot motion control applications, due to the continuous assignment of these two tasks, over the ﬁrst 13 time slices, with high priorities [25].
Because vision guidance and motion re planning programs complete their computation in less than the 13 time slices (0–12), in order to give the chance to conveyorassociated tasks (“drive” the vision belt, “read” the current position of the vision belt) to provide the “robot tracking” programs with the necessary position update information earlier than the slice 13, and to the high-priority trajectory generation system task to effectively use this updates, a WAIT instruction should be inserted in the loop-type vision guidance and motion re planning programs of tasks 0 and/or 1.
All time slices are checked, wrapping around from slice 15 to slice 0 until the original slice is reached. If no runnable tasks are encountered, a null task executes. Whenever a 1 ms interval expires, the multitasking OS performs a similar search of the next time slice. If the next time slice does not contain a runnable task, execution of the current task continues. If more than one task in the same time slice has the same priority, they become part of a round-robin scheduling group. Programs that execute in continuous loops, like vision guidance and motion re planning for belt tracking, should generally execute a WAIT instruction occasionally (for example, once through each loop execution). This should not be done, however, if timing considerations for the tracking application preclude such execution delays in some stages of vision and motion processing [6, 26].
As previously stated, the problem of conveyor tracking with vision guiding for moving part identiﬁcation and locating requires the deﬁnition of three user tasks, to which the following programs were associated:
1. Task 1: program “track” executes in this task, with robot 1 (e.g., SCARA) selected. This program has two main functions, carried out in a 2–stage sequence:
STAGE 1: Continuous checking whether an object travelling on the conveyor belt (it will be called in the sequel vision belt) entered the ﬁeld of view of the camera and the reachable workspace of the SCARA robot. If such an event occurs, the vision is activated to identify whether the object is of interest and to locate it. Processing on this stage terminates with the computation of the end-effector’s location which would move the SCARA robot in the object picking location evaluated once by vision.
STAGE 2: Continuously re planning the end-effector’s location, computed when the object of interest was located by vision, by consuming the belt position data produced by encoder reads in the program “read” which executes on task 3, and by dynamically altering the robot’s target in the current motion segment.
2. Task 2: program “drive” executes in this task, with robot 2 ((m = 1)-axis robot, i.e. the conveyor belt) selected. This program moves the belt in linear displacement increments, at a sufﬁciently high rate to provide a jerk-free, continuous belt motion. This program executes in stages 1 and 2 previously deﬁned.

82

T. Borangiu et al.

3. Task 3: program “read” executes in this task, with robot 2 selected. This program executes differently in the two stages of the application:
STAGE 1: Executes a single time upon receiving an input signal (“la_reco”, e.g. for “LA” objects of interest) from vision in task 1, conﬁrming the recognition and successful locating of an “LA” part. In response, “drive” reads the instantaneous belt position, which from now on will be used as an offset for the position updates.
STAGE 2: Continuously reads the belt position, upon a request (“info” in the example of the ﬁrst case study) issued by “track” in task 1, when it starts its dynamic target re planning process.
From the three user tasks, the default priority assignment is maintained. This leads to the following priority analysis for a major cycle:
• Task 1 has the highest priority in time slices 0–12 (inclusively), with values of 19, 21, 9 and 11.
• Task 2 has the highest priority (20) in a single time slice: 13. • Task 3 never detains a position of highest priority with respect to tasks 1 and 2. • The three tasks become part of a round-robin group as follows:
– tasks 2 and 3 in slices 0–12 inclusively, – tasks 1, 2 and 3 in slices 14 and 15.
Because tasks 2 and 3 are in more than one round-robin group on different slices, then all three tasks in the corresponding pairs of different slices appear to be in a big group. This property can cause, in general, a task to be run in a slice one does not expect; however, this risk is eliminated for task 1 in STAGE 2 since it will never be runnable in slices 14 and 15 (after generating a WAIT).
As for tasks 2 and 3, they cannot generate this risk in the remaining slices from 0–12, after “track” generates the WAIT, because they will switch continuously between them at the beginning of each new time slice.
As a result of the priority scan and scheduling, the programs in the three user tasks execute as follows:
• STAGE 1—vision is processing, the SCARA robot is not moving and no WAIT is issued by task 1 (Fig. 10):
• STAGE 2—vision is not processing, the SCARA robot is moving and WAIT commands are issued in task 1 by the “track” program after each re planning of the end-effector’s target destination within a V+ major cycle of 16 ms:
– Task 1 runs in slices i − j, i ≤ j, i ≥ 0, j ≤ 12, (when it detains the highest priority), i.e., starting with the time moment when it is authorised to run by the highest-priority system tasks “trajectory generation” and “servo” (in slice i), and executing until it accesses the position update provided by task 3 from the most recent belt encoder read, alters the last computed end-effector destination and issues a WAIT (in slice j), to give the trajectory generator a chance to execute.

Open Architecture for Vision-Based Robot Motion Planning and Control

83

Program priority

20 task 1 running "track", task priority >=9

10

RR RR

before request for

belt offset read

after request for

20 task 2 running "drive", task priority =20

belt offset read

10

RR RR

before request

20 task 3 running "read", task priority =15

after request

10

RR RR

before request

after request
0 1 2 1 millisecond time slices 12 13 14 15

One major system cycle
= task waiting = task running RR = round-robin member selection
Fig. 10 Priority assignment and tasks running in STAGE 1 of vision guidance for motion planning in the belt tracking problem

– Task 2 runs: in slices ( j + 1) − 12 switching alternatively with task 3 whenever it is selected as the member of the round-robin group following task 3 that run most recently, in slice 13 (it detains the highest priority), and in slice 15 (it is member of the round-robin group following task 3 that run more recently—in slice 14). Task 2 runs always exactly for 1 ms whenever selected, so that the round-robin group scanning authorises task 3 to run always at the beginning of the next time slice.
– Task 3 runs in slices ( j + 1) − 12 switching alternatively with task 2 when-ever it is selected as the member of the round-robin group following task 2 that run most recently, and in slice 14 (it is member of the round-robin group following task 2 that run more recently—in slice 13). The task 3 runs, whenever selected, for less than 1 ms and issues a RELEASE “to anyone” command.
4.2.3 Dynamically Altering Belt Locations as Robot Motion References
The three previously discussed user tasks, when runnable and selected by the system’s task scheduler, attach respectively the robots:
• Task 1: robot 1—a SCARA-type robot (e.g. Adept Cobra 600) is considered in this case
• Task 2, 3: robot 2—the “vision conveyor belt” of a ﬂexible feeding system is considered.

84

T. Borangiu et al.

Program “track” executing in task 1 has two distinct timing aspects: during STAGE 1, “track” waits ﬁrst the occurrence of the on-off transition of a signal from the photocell, indicating that an object passed over the sensor and will enter the ﬁeld of view of the camera. Then, after waiting for a period of time set up function of the belt’s speed, “track” commands the vision system to acquire an image, identify an object of interest and locate it [27, 28].
During STAGE 2, “track” alters continuously, once per each major 16 ms system cycle, the target location of the end-effector, part.loc, that was computed (when one “LA”-part was located by vision and returned in the vis.loc transformation) by composing the following relative transformations (the “:” character stands for composition)
part.loc=to.cam[1]:vis.loc:grip.la
Here grip.la is the off line learned grasping transformation for the class of “LA” objects. The updating of the end-effector target location for picking-on-the-ﬂy “LA” objects according to a predeﬁned grasping style uses the V+ operation:
ALTER () Dx,Dy,Dz,Rx,Ry,Rz
which speciﬁes the magnitude of the real-time path modiﬁcation that is to be applied to the robot path during the next trajectory computation (Dx,Dy,Dz/Rx,Ry,Rz are the translations/ rotations respectively along the X, Y, Z axes).
This operation is executed by “track” in task 1 that is controlling the robot 1 (SCARA) in alter mode, enabled by the ALTON command. When alter mode is enabled, this instruction should be executed once during each trajectory cycle. The stopping decision is taken in “track” by using the STATE (select) function, which returns information about the state of robot 1 (“Motion stopped at planned location”) selected by task 1 executing the ALTER loop. The ALTOFF operation was used to terminate real-time path-modiﬁcation mode (alter mode) [3, 10, 14].
Program “drive” executing in task 2 has a unique timing aspect in both STAGES 1 and 2: when activated by the main program, it issues continuously motion commands for the individual joint number 1 of robot 2—the vision belt.
Program “read” executing in task 3 evaluates the current motion of robot 2—the vision belt along its single axis, in two different timing modes. During STAGE 1, upon receiving from task 1 the request la_reco (an instance of “LA” was recognised) to compute the belt’s offset, reads the current robot 2 location and extracts the component along Y .
This invariant offset component, read when the “LA” was successfully located by vision and the grasping authorised as collision-free, will be further used in STAGE 2 to estimate the updates of the y_off motion, to alter the SCARA robot’s target location along the Y axis.
The program below shows how the STATE function is used to stop the continuous updating of the end-effector’s target location by altering at every major cycle the position along the Y axis. The altering loop will be exit when motion stopped at planned location, i.e. when the robot’s gripper, moving to track the part

Open Architecture for Vision-Based Robot Motion Planning and Control

85

travelling on the conveyor belt, arrives in the imposed picking position relative to the moving part.

ALTON () 2 ;Enable altering mode
;The robot is commanded to move towards the grasping position ;computed when the object was VLOCATEd by vision.

MOVES part.loc WHILE STATE(2)<>2 DO

;While the robot is far from the moving target (motion not ;completed at planned location...

ALTER(),-pulse.to.mm*y_off

;Continuously alter the target grasping location

WAIT

;Wait for the next major time cycle to give the trajectory ;generator a chance to execute

END ALTOFF CLOSEI DEPARTS MOVES place

;Disable altering mode ;Robot picks the tracked object ;Robot exits the belt tracking mode

;Robot moves towards the fixed object-placing location place

In the example presented, the ALTOFF operation has been used to terminate real-time path-modiﬁcation mode (alter mode). The instruction suspends program execution until any previous robot motion has been completed (similarly to a BREAK instruction), and then terminates real-time path-modiﬁcation mode.
After alter mode terminates, the robot is left at a ﬁnal location that reﬂects both the destination of the last robot motion and the total ALTER correction that has been applied [13, 17, 29].
The cooperation between the tasks on which run “track”, “drive” and “read” is shown in Fig. 11.

86

T. Borangiu et al.

Task Scheduler

Enable belt drive

Disable by

1 millisecond

end_application

timing

check

enable

trajectory

run

generator

Setup

Major sys-

WAIT belt

tem cycle/ 16 msec

check

STATE(2)=2

sensor

inactive Task 2

Task 1

run

inactive

alter mode

Select new task

Round-robin switched selection

y_off

Image

acquisition

la_reco

VLOCATE success,

run

inactive

collision-free
Vision Processing

offset,

read encoder

pos

info

Task 3
Disable by ALTOFF

Fig. 11 Cooperation between tasks in the robot-vision belt tracking problem

5 Experimental Results and Conclusions
Visual robot motion planning allows relaxation of the numerous constraints which arise when setting up a manufacturing environment, as well as the need for highprecision material transportation and presentation devices, such as conveyors, vibrating bowls, a.o. The look-and-move motion planning methodology offers a robust solution to create workstations with components from different manufacturers: image sensors and cameras, vision software, robot manipulators, shop ﬂoor conveyors and other mechanical devices.
The open architecture system for vision-based robot motion planning application was developed in C# and managed the robot-vision communication and sequence execution. Also the camera-robot calibration procedure and the learning of the grasping model learning were developed in the same open system concept based on standard communication means [30, 31].
Figure 12 shows a screen capture of the open architecture robot-vision user application interface. The application consists in precision locating with AdeptSight of

Open Architecture for Vision-Based Robot Motion Planning and Control

87

Fig. 12 Screen of the application interface for high-precision plate locating and vision-based robot motion planning for stationary plate grasping
ceramic plates travelling on a conveyor belt and guiding the motion of an ABB robot with help of the location data sent via standard communication channels and interfaces.
The motion control method presented above for robots picking on-the-ﬂy objects on moving scenes was implemented in the V+ robot programming environment with AdeptSight vision extension, and tested on a robot vision platform containing one Adept Cobra 600 SCARA-type manipulator, a 3-belt ﬂexible feeding conveyor Adept Flex Feeder 250 and a stationary, down looking matrix camera Panasonic GP MF 650 inspecting the vision belt with backlighting [10]. The vision belt on which parts are travelling and are viewed by a ﬁxed, down looking camera was positioned parallel to the Y0 axis of the manipulator, for a convenient robot access within a window of 460 mm. Experiments have been carried out at several speed values of the conveyor belt, in the range from 5 to 180 mm/s.
Table 1 shows the correspondence between the belt speeds and the maximum time intervals from the visual detection of a part up to its effective grasping.
It can be observed that at the maximal speed of 180 mm/s, the robot-vision multitasking controller is still able to direct the SCARA-type manipulator to access visually detected, recognised and located objects.

88
Table 1 Correspondence between belt speed and part access time

T. Borangiu et al.

Belt speed (mm/sec)

5 10 30 50 100 180

Grasping time (max) (sec) 1.4 1.6 1.9 2.0 2.3 2.5

In the experiment reported in Chap. 4.1, the vision library was successfully interfaced to an ABB 1570 vertical articulated robot.
The novelty of the research consist in developing an open architecture system for vision-based robot motion planning, allowing to use closed vision systems (here AdeptSight), that can be integrated with proprietary systems (for example AdeptSight has native functions which can be integrated only with Adept robots), with any other devices (robots, machines, feeders, a.o.) using standard communication mechanisms (serial line or Ethernet). Another novel contribution is the multitasking solution for picking objects in motion from any type of conveyor modelled as a m ≤ 3 degree of freedom Cartesian robot.

References
1. Siciliano B, Sciavicco L, Villani L, Oriolo G (2010) Robotics, modelling, planning and control. Springer, Berlin
2. Borangiu Th, Ecaterina O, Manu M (2000) Multi-processor design of nonlinear robust motion control for rigid robots. Lecture notes in computer science, vol 1798. Springer, Berlin, pp 224–238
3. Borangiu Th (2002) Advanced robot motion control. Romanian Academy Press, Bucharest 4. Braun BM, Starr GP, Wood JE, Lumia R (2004) A framework for implementing cooperative
motion on industrial controllers. IEEE Trans Robot Autom 20:583–589 5. Gueaieb W, Karray F, Al-Sharhan S (2003) A robust adaptive fuzzy position/force control
scheme for cooperative manipulators. IEEE Trans Control Syst Technol 11:516–528 6. Battilotti S, Lanari L (1996) Tracking with disturbance attenuation for rigid robots. In: Pro-
ceedings of IEEE international conference on robot automation, Minneapolis, April 1996, pp 1570–1583 7. Borangiu Th, Anton F, Dumitrache A (2010) Robot programming. AGIR Publishing House, Bucharest 8. Kawasaki H, Ueki S, Ito S (2006) Decentralized adaptive coordinated control of multiple robot arms without using a force sensor. Automatica 42:481–488 9. Borangiu Th, Ionescu F, Manu M (2003) Visual servoing in robot motion control. In: Proceedings of 7th multi-conference on systemics, cybernetics and informatics SCI’03. Orlando, 27–30 July 2003, pp 987–992 10. Hutchinson S, Hager G, Corke P (1996) A tutorial on visual servo control. IEEE Trans Robot Autom 12:6561–6670 11. Xie WF, Li Z, Tu XW, Perron C (2009) Switching control of image based visual servoing with laser pointer in robotic assembly systems. IEEE Trans Ind Electron 520–529 12. Mendes JM, Restivo F, Leitao P, Colombo A (2010) Injecting service-orientation into multiagent systems in industrial automation. Lecture notes in computer science, vol 6114, pp 313– 320 13. Allotta B, Fioravanti D (2005) 3D motion planning for image-based visual servoing tasks. In: Proceedings of the IEEE international conference on robotics and automation, Barcelona, pp 2173–2178

Open Architecture for Vision-Based Robot Motion Planning and Control

89

14. Nelson BJ, Papanikoloupoulos P, Khosla PK (1996) Robotic visual servoing and robotic assembly tasks. IEEE Robot Autom Mag 23:97–102
15. Lowe DG (2004) Distinctive image features from scale-invariant keypoints. J Comput Vis 60(2):91–110
16. Hossu A, Borangiu Th, Croicu A (1995) Robot Visionpro machine vision software for industrial training and applications. Version 2.2, Cat. #100062, Amsterdam, Tel Aviv, New Jersey, Eshed Robotec
17. Wilson W, Hulls C, Bell G (2006) Relative end-effector control using Cartesian position-based visual servoing. IEEE Trans Robot Autom 12:684–696
18. Miyabe T, Konno A, Uchiyama M, Yamano M (2004) An approach toward an automated object retrieval operation with a two-arm ﬂexible manipulator. Int J Robot Res 23:275–291
19. ABB, Technical Reference Manual, RAPID Instructions, Functions, and Data types, 2004 20. Adept Reference Guide, V+ Programming, Adept Technology Inc. 2011 21. Bilen H, Hocaoglu M, Unel U, Sabanovic A (2012) Developing robust vision modules for
microsystems applications. Mach Vis Appl 23(1):25–42 22. Borangiu Th, Ivanescu N, Brotac S (2002) An analytical method for visual robot -object
calibration. In: Proceedings of the 7th international workshop robotics in Alpe-Adria-Danube region RAAD’98. Balatonfüred, pp 149–154 23. Chaumette F, Hutchinson S (2006) Visual servo control. Part I: basic approaches. IEEE Robot Autom Mag 13(4):82–90 24. Martinez-Rosas JC, Arteaga MA, Castillo-Sanchez A (2006) Decentralized control of cooperative robots without velocity-force measurements. Automatica 42:329–336 25. Gudiño-Lau J, Arteaga MA (2006) Dynamic model, control and simulation of cooperative robots: a case study, mobile robots, moving intelligence. ARS/pIV 26. Chaumette F, Hutchinson S (2005) A general and useful set of features for visual servoing. IEEE Trans Robot Autom 21:1116–1127 27. Lippiello V, Siciliano B, Villani L (2007) Position-based visual servoing in industrial multirobot cells using a hybrid camera conﬁguration. IEEE Trans Robot 23:73–86 28. Borangiu Th (2004) Intelligent image processing in robotics and manufacturing. Romanian Academy Press, Bucharest 29. Corke P, Hutchinson S (2001) A new partitioned approach to image-based visual servo control. IEEE Trans Robot Autom 17:507–515 30. Lazar C, Burlacu A (2009) Visual servoing of robot manipulators using model-based predictive control. In: Proceedings of the 7th IEEE international conference on industrial informatics, Cardiff, pp 690–695 31. Lazar C, Burlacu A, Copot C (2011) Predictive control architecture for visual servoing of robot manipulators. In: Proceedings of the 18th IFAC world congress, Milano, pp 9464–9469

Grasping and Manipulation of Unknown Objects Based on Visual and Tactile Feedback
Robert Haschke

Abstract The sense of touch allows humans and higher animals to perform coordinated and efﬁcient interactions within their environment. Recently, tactile sensor arrays providing high force, spatial, and temporal resolution became available for robotics, which allows us to consider new control strategies to exploit this important and valuable sensory channel for grasping and manipulation tasks. Successful dexterous manipulation strongly depends on tight feedback loops integrating proprioceptive, visual, and tactile feedback. We introduce a framework for tactile servoing that can realize speciﬁc tactile interaction patterns, for example to establish and maintain contact (grasping) or to explore and manipulate objects. We demonstrate and evaluate the capabilities of the proposed control framework in a series of preliminary experiments employing a 16 × 16 tactile sensor array attached to a Kuka LWR arm as a large ﬁngertip.
Keywords Grasping · Tactile servoing · Online motion planning

1 Introduction

The sense of touch allows humans to perform coordinated and efﬁcient interactions within their environment. Without the sense of touch, subjects have severe difﬁculties maintaining a stable grasp or performing a complex action such as lightning matches [1, 2]. Also in robot applications, lacking tactile feedback results in loosing an initially grasped object or failing to robustly carry out manipulation tasks [3]. In recent years, the resolution and sensitivity of tactile sensors only sufﬁced for basic force feedback during blind grasping [4]. However, tactile sensor arrays providing high spatial and temporal resolution as well as high sensitivity [5, 6] emerged recently, allowing for more advanced control methods involving tactile feedback too.

R. Haschke (B)
Cognitive Interaction Technology Excellence Cluster (CITEC),
Bielefeld University, Inspiration 1, 33619 Bielefeld, Germany
e-mail: rhaschke@techfak.uni-bielefeld.de

© Springer International Publishing Switzerland 2015

91

G. Carbone and F. Gomez-Bravo (eds.), Motion and Operation Planning

of Robotic Systems, Mechanisms and Machine Science 29,

DOI 10.1007/978-3-319-14705-5_4

92

R. Haschke

Such control approaches—which we denote as tactile servoing in accordance to corresponding control approaches involving direct visual feedback—require advanced tactile perception methods and their integration into control programs for direct robot control. Tactile servoing includes important tasks like sliding a ﬁnger tip along an object’s surface, tracking speciﬁc surface structures like ridges, searching for distinctive tactile patterns, or exploring the object shape by groping. Most of these tasks are essential for both in-hand object manipulation [7], and haptic object identiﬁcation [8].
Drawing on ideas for visual servoing and applying image processing algorithms to the tactile force image provided by modern tactile sensor arrays, it is possible to extract basic tactile features in real time and employ them for robot control. The challenging mission is to ﬁnd generic features, which not only work in speciﬁc hardcoded control scenarios on a speciﬁc type of tactile sensor, but that generalize to a rich set of control tasks and sensor types.
We argue for a uniﬁed and open control framework that can cover many grasping and manipulation tasks including tactile exploration. The proposed control approach facilitates the exploitation of task symmetries to unleash redundancies which can be efﬁciently utilized by subordinated tasks. Different, challenging tasks can be easily composed from a set of basic control primitives without the need for a detailed situation modeling (object and hand shape, friction properties, etc.), thus providing the foundation to yield robust manipulation skills also in unknown and unstructured environments.
The remaining chapter is organized as follows: In the next section we introduce the general concept of the control basis framework and discuss how efﬁcient local motion generation methods can reduce the need for explicit planning in grasping of unknown objects. The subsequent Sect. 3 will introduce some recent tactile sensor developments and vision-based feature extraction methods to yield tactile features, which are at the basis of four tactile servoing control primitives. Finally, in Sect. 4 we describe and evaluate some tactile exploration tasks that impressively demonstrate the power of the proposed control framework.

2 Planning-Less Grasping in the Control Basis Framework

Grupen et al. ﬁrst developed the idea of the control basis framework (CBF), which allows to realize complex tasks by composition of several basic controllers [9, 10]. Each of those controllers realizes resolved motion rate control, mapping updates of task control variables Δx to joint angle updates Δq of the robot. An important key idea was to stack controllers by priority allowing a subordinate controller to operate in the null-space of a higher-priority controller only, which can be easily achieved using appropriate null-space projections. Given any nonlinear relationship x(q) between joint and task-space variables, the relation of their velocities at any point t in time is linear and given as

x˙(t) = J (q(t)) · q˙ (t),

(1)

Grasping and Manipulation of Unknown Objects …

93

where Jij(q) = ∂ xi /∂q j is the task Jacobian at time t. Then, the solution to realize three priority-ordered task space motions x˙1, x˙2, x˙3 looks like this:

q˙ = q˙ 1 + N1 (q˙ 2 + N2q˙ 3)

(2)

= J1+(q)x˙1 + N1 J2+(q)x˙2 + N2 J3+(q)x˙3 ,

(3)

where Ji+ denotes the Moore-Penrose pseudoinverse of Ji and Ni = 1− J + J denotes the corresponding null-space projector of task i = 1, 2, 3.
To work in practice, it’s important, that every controller’s null-space is rich enough to accommodate lower-priority motions, i.e. that there is enough redundancy. However, classical motion planning approaches attempt to control the end-effector motion in all six degrees of freedom (dof) and thus do not leave the necessary redundancy. But, exploiting the inherent symmetry of many everyday tasks, we can restrict ourselves to a few task-relevant dofs and thus gain the required redundancy.
As a prominent example, consider the grasping of a spherical object. Nowadays grasp planning approaches attempt to generate and evaluate grasps that approach the sphere from all possible directions [11]. However, in this particular task, it’s only important to drive the hand towards the sphere—no matter from which direction. This reduced task description only consumes a single dof, namely the hand-objectdistance, and frees up all other dofs. The resulting task-space motion x˙ is a straightline towards the goal, much like in classical Cartesian control. However, the redundant space at a given goal distance is the complete sphere around the target and any null space motion is automatically projected onto this sphere. In this manner, we can easily approach spherical objects for grasping from any direction, without the need to precompute a multitude of feasible grasps in advance. The corresponding task Jacobian J · can be easily computed from the Jacobian J of the standard forward transform:

J · = (x − xgoal)t · J

(4)

Similarly, grasping a cylindrical object, like a bottle, only requires to align the hand axis with the object axis—the orientation angle around this axis can freely be chosen [12]. To allow even more ﬂexibility, one may specify a task-space interval instead of a unique target value [13]. Within the original control basis framework, Platt et al. also propose more abstract controllers, e.g. to maintain force closure, to optimize grasp quality, manipulability, or visibility [14].

2.1 Collision Avoidance

In the context of motion planning, an important subordinate control task is collision and joint-limit avoidance. Joint limits can be easily avoided minimizing a quadratic or higher-order polynomial function [12, 15]:

Hq = wi (qi − qiref) p wi = (qimax − qimin)−1,

(5)

94

R. Haschke

where qref deﬁnes a reference pose, e.g. in the middle of the joint range, and the wi ’s weight the contribution of individual joints according to their overall motion range.
Local collision avoidance is achieved by a repelling force ﬁeld originating from each object. To this end, Sugiura [16] proposed to minimize a quadratic cost function deﬁned on the distance dp = p1 − p2 between the two closest points p1 and p2 on the robot and the obstacle:

Hca(p1, p2) =

η (dp − dB )2 0

dp < dB otherwise

(6)

Here, dB acts as a distance threshold below which the force ﬁeld becomes active and η is a gain parameter. The gradient of this cost function directly serves as a joint-level
control target and can be easily computed in terms of the body point Jacobians Jpi by applying the chain rule:

q˙ ca = −∇qt Hca = −2η (1 − dB /dp)( Jp1 − Jp2 )t (p1 − p2).

(7)

Thus we yield straight-line task-space motions (e.g. of the end-effector in Cartesian space), while the redundancy is exploited to circumvent obstacles as schematically shown in Fig. 1, left. To allow more ﬂexible obstacle avoidance, Behnisch [17] proposed a relaxed motion control scheme, which allows deviations from straight-line motions, if the robot gets too close to obstacles:

q˙ = J +(x˙ − β x˙ca) − N (∇ Hca + ∇ Hq).

(8)

Here, additionally to the null-space motion, which minimizes a superposition of both

cost functions Hq and Hca, an obstacle avoidance motion x˙ca is directly allowed in

task-space as well. This contribution is determined by projecting the cost gradient

(7) to the task space:

x˙ ca = J ∇qt Hca.

(9)

3

2.5

2.5

2.5

2

2

2

1.5

1.5

1.5

β = 1

β = 1

1

1

1

β = 0.5

0.5

0.5

0.5

β = 0.5

β = 0

0

0

0

−0.5

β = 0

−1

−0.5

−0.5

−1

0

1

2

3

4

−1

0

1

2

3

−1

0

1

2

3

Fig. 1 Goal-directed task-space motion with collision avoidance. Left restricting avoidance motions
to redundant space yields a straight line motion of the end-effector. Middle using relaxed motion control (8), the trajectory more strongly avoids the obstacle for larger weights β, but does not converge to the target anymore. Right dynamic adaption of β achieves both goals, target reaching and obstacle avoidance

