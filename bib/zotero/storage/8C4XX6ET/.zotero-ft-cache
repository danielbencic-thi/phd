Open Access
Fast Visibility Restoration Using a Single Degradation Image in Scattering Media
Volume 12, Number 3, JUNE 2020
Yingbo Wang Jie Cao Chengqiang Xu Saad Rizvi Kun Li Qun Hao
DOI: 10.1109/JPHOT.2020.2988279

IEEE Photonics Journal

Fast Visibility Restoration

Fast Visibility Restoration Using a Single Degradation Image in Scattering Media
Yingbo Wang , Jie Cao , Chengqiang Xu, Saad Rizvi , Kun Li, and Qun Hao
School of Optics and Photonics, Beijing Institute of Technology, Key Laboratory of Biomimetic Robots and Systems, Ministry of Education, Beijing 100081, China
DOI:10.1109/JPHOT.2020.2988279 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see
https://creativecommons.org/licenses/by/4.0/
Manuscript received March 29, 2020; revised April 6, 2020; accepted April 13, 2020. Date of publication April 20, 2020; date of current version May 26, 2020. This work was supported in part by the National Natural Science Foundation of China under Grants 61875012 and 61871031, in part by the Natural Science Foundation of Beijing Municipality under Grant 4182058, and in part by Graduate Technological Innovation Project of Beijing Institute of Technology 2019CX20027. Corresponding authors: Jie Cao; Qun Hao (e-mail: ajieanyyn@163.com; qhao@bit.edu.cn).

Abstract: Visibility restoration of an image degraded by scattering media (such as haze, fog, smog) is a challenging task which requires careful design of computational methods. The fundamental problem which limits clear image reconstruction is the random diffusion of light in the scattering medium. Recently, the dark channel prior method has emerged as a powerful approach for haze removal under adverse weather conditions. However, this method requires high computational time, and fails to achieve haze-free image in the sky region. To overcome these problems, we propose a novel imaging method based on quadtree theory combined with transmission optimization (QTCTO) to restore the visibility of images degraded by scattering medium. The proposed method uses the quadtree theory (for region segmentation) to estimate the global atmospheric light, while the transmission in the media is estimated by coefﬁcient modiﬁcation for the dark channel. The experimental results show that the proposed method is robust against scattering (under smoke and turbid water conditions) and has the advantage of low computational time. The proposed method can be used for security surveillance, remote sensing, and various military applications.
Index Terms: Visibility restoration, propagation and scattering, turbid media, atmospheric optics.
1. Introduction
Image restoration under scattering (turbid) media has been a topic of constant research recently. The reconstruction of image through turbid media ﬁnds numerous applications in remote sensing, intelligent vehicles, and military surveillance. Studies on image visibility restoration have been conducted in the past from two aspects. One of these methods is the contrast enhancement method based on image processing [1]–[5], and the other is the image restoration method based on physical model [6]–[9]. The contrast enhancement method simply applies image processing algorithm to rectify the degraded image without taking into account the physical phenomena and reasons behind degradation. Therefore, this method loses more information and fails to recover images efﬁciently. Compared to this method, the image restoration method based on physical model proves to be more efﬁcient by considering light propagation in the medium and recovering more details about the target image. It is observed that these restoration methods lose less information during restoration process to efﬁciently recover the original image. Therefore, the

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

proposed method is a type of image restoration method which considers physical model for fast and efﬁcient image restoration.
The visibility restoration method based on physical model can further be categorized as polarization-based methods [10]–[12], depth-based methods [8, 13]–[15], and prior-based methods [16]–[25]. Amongst these methods, the prior based methods are extensively used. Tan [16] observes that a haze-free image must have higher contrast compared to an input hazy image, and the haze is removed by maximizing the local contrast of the restored image. The results are visually compelling but the model may not be physically valid [18]. Similarly, Fattal et al. [17] assumes the albedo of an image local patch to be a constant vector, and uses independent component analysis to estimate the albedo. This method further uses atmospheric physical model to restore the colors of image. This approach is physical model-based and produces a natural haze-free image together with a good depth map. However, this method strictly adheres to model assumptions and fails when these assumptions become invalid. The method also fails when the haze is heavy [18, 22]. He et al. [18] proposed a dark channel prior method to estimate the atmospheric light and transmission. The method employs a soft matting algorithm to reﬁne transmission maps. The haze-free images can be recovered by dark channel prior with haze imaging model. However, this method has a high computational cost and complexity associated with soft matting algorithm, which lowers its haze removal efﬁciency. He et al. [19] also proposed a fast guided ﬁlter algorithm with edge-preserving capability. The guided ﬁlter can be used to reﬁne the transmission and achieve dehazing. However, due to inaccurate estimation of atmospheric light, it is difﬁcult to use the model for dehazing in the sky region. Tarel et al. [21] proposed a fast image dehazing algorithm which estimates atmospheric veil by using a median ﬁlter. The main advantages of this algorithm are fast computation and remarkable dehazing capability. However, the edge-preserving ability of this algorithm is poor due to median ﬁltering, and the algorithm produces Halo effect when the ﬁlter size settings are inappropriate.
To summarize, in order to obtain more useful information from the degraded image, the visibility restoration of an image (degraded by scattering medium) can be achieved by different methods, amongst which the prior-based method is most commonly used. The dark channel prior method is a prime example of prior-based method. However, the dark channel prior method suffers from high computational (time) cost, and poor recovery performance for the sky region of degraded image.
In this paper, we report a fast visibility restoration method based on quadtree theory combined with transmission optimization (QTCTO) to solve aforementioned problems. The core ideas of our approach are to estimate global atmospheric light and transmission, and to reﬁne the transmission rapidly. Our method offers three advantages: (1) the global atmospheric light can efﬁciently be estimated by the quadtree method of region segmentation, (2) the transmission of the degraded image is optimized by coefﬁcient modiﬁcation for the dark channel and the reﬁned transmission can be quickly obtained by the guided ﬁltering, (3) the proposed method is effective for the sky region, and the visibility can be quickly recovered under different scattering conditions. The recovered image acquired from the proposed algorithm retains all ﬁne details in the original image.

2. Quadtree Theory Combined With Transmission Optimization
QTCTO involves three processes. First, the global atmospheric light is estimated by the quadtree method of region segmentation. Second, atmospheric transmission is optimized by coefﬁcient modiﬁcation for the dark channel, and the reﬁned transmission is calculated by guided ﬁltering. Finally, the color correction algorithm is used to restore colors and obtain recovered image.

2.1 Estimation of Global Atmospheric Light
The classical atmospheric scattering model based on Mie scattering theorem is shown in Fig. 1. The degraded image received by the camera through scattering media can be written as:

I(x ) = J (x )e−βd (x) + A(1 − e−βd (x) ),

(1)

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 1. Atmospheric scattering model

Fig. 2. Schematic of the quadtree method of region segmentation. (a) The processes of regional
segmentation: (a0) degraded image, (a1) gradient map, (a2) gradient enhancement map, (a3) edge detection, (a4) morphological dilation, and (a5) sky region is segmented. (b) The estimation of atmospheric light using rectangular windows with red box as the selected region by quadtree method. (c)–(e)
The atmospheric light estimation from the red rectangular window with size of 10 × 10 pixels.

where I(x) is the observed intensity, J(x) is the scene radiance, t(x) = e−βd(x) is the transmission describing the portion of the light that is not scattered and reaches the camera, β is the scattering coefﬁcient of the atmosphere, d(x) is the depth of ﬁeld of the scene, and A denotes the global atmospheric light. Once the A and t(x) are estimated, the scene radiance J(x) can be restored.
The atmospheric light can be estimated by the quadtree method of region segmentation. The sky region is found by the proposed regional segmentation method shown as blue outline in Fig. 2(a5). First, the gradient of the degraded image is calculated, and the gradient map D(x) is obtained as shown in Fig. 2(a1). Then the maximum gradient value Dmax(x) in the gradient map is found out and the parameter α(0 < α ≤ 1) is used to control the gradient enhancement, expressed as:

D(x ) D(x )

= =

D(x ), (D(x ) < α · Dmax(x )) α · D(x ), (D(x ) > α · Dmax(x ))

,

(2)

D(x )

D (x ) = 255 ·

,

(3)

α · Dmax(x )

when the value of α is large: the degree of edge enhancement reduces and the accuracy of edge detection is affected. In case the α is small, the noise in the sky region is ampliﬁed and this leads to

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

edge detection errors. The optimal value of α is calculated to be between 0.05–0.2. The enhanced
gradient map computed through Gaussian ﬁlter is shown in Fig. 2(a2). The Canny algorithm is used for edge detection (results in Fig. 2(a3)), and morphological dilation operation is used to increase the stability of edge connections (results in Fig. 2(a4)). Finally, the sky region can be extracted by ﬁnding the maximal connected domain as shown in Fig. 2(a5).
After ﬁnding the sky region by regional segmentation method shown as blue line in Fig. 2(a5), the information is subsequently utilized by quadtree decomposition to estimate the atmospheric light
as shown in Fig. 2(b). The intensity of sky region can be expressed as:

Iup(x ) = Om(I(x )),

(4)

where Iup is the sky region intensity used to calculate the atmospheric light, Om(I) represents the regional segmentation operation of degraded image I. The atmospheric light can be calculated by

quadtree theory in the range of Iup, written as:

⎧

⎪⎪⎨

I1 I3

=Iu =Iu

p p

(1 :

(

h 2·2i

h 2·2i

;

1

: h; 1

: :

w 2·2i w 2·2i

), I2=Iup(1 :

),

I4

=Iu

p

(

h 2·2i

⎪⎪⎩

A = max(I¯1, Iup = I up(A)

I¯2,

I¯3

,

I¯4

)

h 2·2i

;

w 2·2i

:

h;

w 2·2i

: w) : w)

,

(5)

where h, w denotes the number of rows and the number of columns of the segmented region Iup, respectively; h/2i > L, w/2i > L, i = 0, 1, 2, …, n. L denotes the window size of the quadtree method. I’up(A) represents the region in which atmospheric light A is calculated after the i-th segmentation. The process of estimating the atmospheric light is shown in Fig. 2. The atmospheric
light is calculated by averaging the intensity values inside the red boxed area shown in Fig. 2(b).
For Fig. 2(c)–2(e), the red box is located in the sky region where the gray intensity values are high.

2.2 Estimation of Reﬁned Transmission For an arbitrary image I, the dark channel Idark can be written as follows [18]:

Idark (x ) = min ( min (Ic (y ))),

(6)

c∈(r,g,b) y∈ (x )

where Ic is the color channel of image I, and (x) denotes a local patch centered at x. A dark channel is the outcome of two minimum operators, and the minimum operators are commutative. If I is an outdoor haze-free image, except for the sky region, the intensity of I’s dark channel is low and tends to be zero, i.e., Idark→0. To overcome the problem of the reduced visibility in the sky regions, the transmission is estimated by coefﬁcient modiﬁcation for the dark channel. The difference between the extreme values of dark channel serves as the correction coefﬁcient for media transmission to compensate the transmission of the sky region. The optimized transmission can be written as:

Imdaarxk (x ) = max (Idark (x )), Imdainrk (x ) = min(Idark (x )) t (x ) = (Imdaarxk (x )−Imdainrk (x ))·(A◦U )−Idark (x )
A·(Imdaarxk (x )−Imdainrk (x ))◦U −(Idark (x )−Imdainrk (x ))◦Idark (x )

,

(7)

where max(·) denotes the maximum extraction operation, U represents the identity matrix, and ‘◦’

denotes the Hadamard product. The transmission of degraded image can be estimated by Eq. (7),

shown in Fig. 3(c). Since the estimated transmission contains noise, it causes halo artifacts and

block effects in the restored image. Therefore, the transmission is reﬁned by guided ﬁltering, which

can be expressed as follows:

⎧

⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎩

a¯i b¯i
ti

=

1 |w|

k ∈wi

=

1 |w|

k ∈wi

= a¯i Ii + b¯i

ak , ak bk , bk

= =

1 |w|
p¯k

i∈wk Ii pi −μk pk σk2 +ε
− ak μk , p¯k =

1 |w|

pi

i ∈wk

,

(8)

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 3. Visibility restoration results for the degraded images under scattering conditions. (a) degraded images. (b) dark channel. (c) estimated transmission maps. (d) reﬁned transmission maps after guided ﬁltering. (e) depth maps. (f) recovered images.

where i and k are pixel indexes, wk is a window centered at the pixel k, ε is a regularization parameter penalizing large ak, μk and σk2 are the mean and variance of I in wk, (a¯i ,b¯i ) are the average coefﬁcients of all windows overlapping k in wk, I denotes the guided image, and pi (that is the t(x)) represents the rough transmission estimated by the Eq. (7). The reﬁned transmission map
after guided ﬁltering is shown in Fig. 3(d).

2.3 Restoring the Scene Radiance According to Eq. (1), the scene radiance of degraded image is restored by:

I(x ) − A

J(x ) =

+ A,

(9)

max(t , t0)

where t0 is the adjustment factor used to improve the visual effect of restored image. The value of t0 is set as 0.1. Finally, the correction algorithm [21] is used to obtain the restored image without any color distortion.

3. Experimental Comparisons and Analyses
3.1 Image Visibility Restoration Analysis
3.1.1 Image Visibility Restoration: To validate the mathematical model presented above, the proposed method is tested through numerical simulations. The visibility restoration results for different degraded scenes (in Fig. 3(a)) are presented in Fig. 3(f). It can be seen from Fig. 3(f) that the proposed method efﬁciently restores the visibility of images (scenes) degraded by the scattering medium. The scene depth is estimated by setting β = 0.1, shown in Fig. 3(e). The recovered images and corresponding depth maps, before and after transmission, reﬁned by guided ﬁltering are shown in Fig. 4. For qualitative comparison, the portions of Fig. 4 marked with red boxes are shown as image insets (inside red dotted box, and magniﬁed 2.5 times). Compared to Fig. 4(b), the depth map of Fig. 4(d) is more reﬁned (smooth). Fig. 4(e) validates the efﬁcient performance of the proposed method which recovers degraded image by applying guided ﬁlter to remove halo effect and retain scene colors.

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 4. The visibility restoration comparison before and after guided ﬁltering. (a) degraded image and zoomed image insets. (b) depth map before reﬁned transmission. (c) image restored before reﬁned transmission along with zoomed insets. (d) depth map after transmission reﬁned by guided ﬁltering. (e) image restored after transmission reﬁned by guided ﬁltering and zoomed image insets.

Fig. 5. The visibility restoration results in different atmospheric light conditions and window sizes. (a) degraded images. (b) image restoration using 10 × 10 pixel window size. (c) using 15 × 15 pixel window size. (d) using 30 × 30 pixel window size. Image insets shown with red dotted boxes in between for the zoomed parts in the images.

The atmospheric light can be estimated from the degraded image by dividing the image into smaller regions and selecting the area with high average intensity values (dense zone). The proposed method uses three window sizes (10 × 10, 15 × 15, and 30 × 30) for quadtree sub division which can be predeﬁned in the algorithm. The degraded images and their recovered counterparts are shown in Fig. 5, along with image insets (red dotted lines), zoomed in for visualizing reconstruction quality for far regions in the image. From Fig. 5(b)–(d), it can be seen that the results of recovered images using different window sizes are the same. This result demonstrates the consistency of our algorithm on different window sizes. Therefore, when the window size changes within a small range, it has no effect on the visibility restoration of degraded image, which is beneﬁcial for fast estimation of atmospheric light and makes the proposed method robust against variations.
3.1.2 Qualitative and Quantitative Analysis of Image Restoration Methods: The visibility restoration of the proposed method is analyzed both qualitatively and quantitatively. For the qualitative analysis, the proposed method is compared with three classical haze removal algorithms, shown in Fig. 6. The images used for testing are diverse scenes degraded by haze (fog). Fig. 6(b) shows that the He’s algorithm produces some block effects because of invariable transmission through a patch. The results of Fig. 6(c) and Fig. 6(d) show that there is color distortion under heavy fog (haze), resulting in dark restored images. Furthermore, the Tarel’s method (Fig. 6(d)) produces halo effect in the restored images. The results for the proposed method are shown in Fig. 6(e). The proposed

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 6. Qualitative comparison for different haze removal methods. (a) input degraded images. (b) He’s results. (c) Fattal’s results. (d) Tarel’s results. (e) our results.

Fig. 7. Quantitative comparison of four visibility restoration methods (on four images from Fig. 6) using the metrics of (a) recovery time, (b) information entropy, (c) mean gradient, and (d) the rate of new visible edges.

method employs quadtree decomposition method based on sky region segmentation to estimate atmospheric light (details of calculation shown in Fig. 2). The atmospheric light can be accurately estimated from the sky region through high intensity values, and helps in effectively restoring degraded images. The proposed method also takes the advantage of optimized transmission (given by Eq.(7)) and color correction algorithm to give clear reconstructions with no color distortions and halo effects. The superior performance of the proposed algorithm can be observed from the qualitative comparison in Fig. 6(e).
To quantitatively compare the restoration results of proposed method with existing methods, four evaluation metrics are used i.e., recovery time (T), information entropy (E), mean gradient (Ag), and rate of new visible edges (e). The recovery time (T) is calculated on a computer with: Windows 10 64bit, CPU(i7-7700HQ @2.8 GHz), RAM(8G, DDR4 2667 MHz), MATLAB2017b. Furthermore, the information entropy (E) [26] is introduced to quantify the amount of information in the image, and the mean gradient (Ag) is used to evaluate image deﬁnition. Unlike image quality assessment, it is difﬁcult to compare our results with a standard image, so we choose the rate of new visible edges (e) of blind assessment method [27] for quantitative evaluation of our method. The quantitative results for different methods are shown in Fig. 7. Compared to He’s and Tarel’s methods, the processing time of our method is very small. From Fig. 7, it can be clearly seen that the proposed method has better restoration capability showing high information entropy and mean gradient values compared to other methods. Although the value of index e for the proposed method

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 8. Color analysis of the degraded image “C” before and after restoration. (a) quantitative comparison of color histograms before and after restoration by the proposed method; (b) comparison of color similarity histograms between different algorithms.

Fig. 9. Experiments are carried out under different conditions. (a) experimental setup of testing under smoke scattering conditions; (b) experimental setup of testing under turbid water.

is not the highest, the proposed method still outperforms other methods in terms of restoration quality.
To evaluate color retention capability of the proposed method, the color histogram similarity method [28] is used to calculate color similarity before and after image restoration. The color histograms (for the degraded and recovered images) before and after image restoration are shown in Fig. 8. Fig. 8(a) shows that the histogram trend for the three channels remains consistent before and after restoration. Similarly, through quantitative comparison between different algorithms based on color similarity histograms (calculated on before and after recovery images) (in Fig. 8(b)), it can be seen that the proposed method efﬁciently retains colors with the highest percentile value of 63.5%. Overall, the visibility of degraded image can quickly be restored by the proposed method.

3.2 Experimental Results
Experiments are carried out to verify the visibility restoration capability of QTCTO on the degraded images. Experiments are performed under different scattering mediums, as shown in Fig. 9. The targets used in the experiments are: 3D print model, wire stripper, and cup. The degraded images are captured using a camera. The experiments are carried out during the daytime to avoid the color distortion due to uneven lighting at night.
3.2.1 Restoration Comparisons for Targets Under Smoke Scattering Conditions: The visibility restoration results for the degraded images under smoke scattering using the proposed method are shown in Fig. 10. The scattering medium is created by generating smoke from a smoke machine. The concentration of scattering medium cannot be quantiﬁed due to smoke’s non-uniformity. For comparison, we divide the density of smoke into three grades by visual inspection shown in Fig. 10. Fig. 10 shows that the visibility of degraded image is efﬁciently restored by the proposed method, and the colors in the recovered image are not distorted. The colors are corrected by the color

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 10. Visibility restoration results for the degraded images under smoke conditions (left-degraded image, right-recovered image). (a) low scattering conditions, (b) medium scattering conditions, and (c) dense scattering conditions.
TABLE 1 Quantitative comparison for visibility restoration under smoke scattering conditions

correction algorithm [21]. More importantly, the visibility of the degraded image is well restored even under dense scattering conditions shown in Fig. 10(c).
Quantitative results before and after visibility restoration for the degraded images under smoke scattering using the proposed method are presented in Table 1. The recovery time (T) for all the images is same due to similar image resolution. By accurately estimating the atmospheric light and transmission, the proposed method efﬁciently recovers ﬁne details from the degraded image. The metrics of E and Ag indicate that the values of information entropy and mean gradient for the restored images are greatly improved. The rate of new visible edges (e) is also greatly improved considering the superior performance of the proposed method as well as the simplicity of the target scene.
To verify the superiority of our method, we compare its performance with three well-known existing methods. We capture degraded images under different smoke scattering conditions (each with a different target). We compare the restoration results of our method with the results of three existing algorithms (namely He’s, Fattal’s and Tarel’s), shown in Fig. 11. From Fig. 11(b) and Fig. 11(c), it can be seen that both He and Fattal algorithms produce color distortion. Similarly, the results in Fig. 11(c) presents halo effects at the edges. Fig. 11(e) shows that the visibility restoration results of the proposed method are better compared to other methods. We further present quantitative results using different metrics for the four methods under smoke scattering

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 11. Qualitative comparison of visibility restoration methods under smoke scattering conditions. (a) input degraded images, (b) He’s results, (c) Fattal’s results, (d) Tarel’s results, and (e) our results.
Fig. 12. Quantitative comparison of different visibility restoration methods under smoke scattering conditions using the metrics of (a) similarity of color histograms, (b) information entropy, (c) mean gradient, and (d) the rate of new visible edges.

Fig. 13. Visibility restoration results for targets under turbid water. (a) low scattering condition, (b) medium scattering condition, and (c) dense scattering condition.

conditions, shown in Fig. 12. From quantitative comparison in Fig. 12, it can be seen that the proposed method clearly outperforms existing methods over different metrics.
3.2.2 Restoration Comparisons for Targets Under Turbid Water: The proposed method is based on the atmospheric scattering model and it is necessary to test it under different mediums. Therefore, we extend the testing of QTCTO under turbid water to evaluate its robustness. The visibility restoration results for the images degraded under turbid water are shown in Fig. 13. In Fig. 13(a)–(c), the left and right side for each taget represents degraded and restored images, respectively.The scattering medium is generated by adding milk in water. From Fig. 13, it can be seen that the proposed method efﬁciently restores the degraded image captured under turbid water.

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

TABLE 2 Quantitative comparison for visibility restoration under turbid water

Fig. 14. Qualitative comparison of visibility restoration methods under turbid water. (a) input degraded images. (b) He’s results. (c) Fattal’s results. (d) Tarel’s results. (e) our results.
Furthermore, it can be observed that the colors of restored images in Fig. 13 are brighter than those in Fig. 10. This is due to the fact that the water turbidity is unifom compared to smoke. Quantitative results for the degraded images before and after visibility restoration under turbid water are shown in Table 2. Table 2 shows that the values of metrics E, Ag and e for the restored image have been improved, particularly the values for the rate of new visible edges are greatly improved. Overall, the proposed method is robust and effective for turbid water.
To further verify the robustness of the proposed method, its performance is compared with three other methods under turbid water with different scattering conditions. The visibility restoration results for different dehaze algorithms are shown in Fig. 14. The results in Fig. 14(c) show severe color distortion using the Fattal’s algorithm. In case where the restoration is clear, the colors are very dim, shown in Fig. 14(b) and Fig. 14(d). Similarly, the visibility restoration of Fig. 14(d) is insufﬁcient. The visibility restoration results of the proposed method, shown in Fig. 14(e), indicate that the proposed method outpeforms other methods under turbid water. The performance of the proposed method can quantitatively be analyzed using different mertrics shown in Fig. 15. The color histogram similarity results indicate that the proposed method performs better compared to existing methods in preserving colors (Fig. 15(a)). Overall, the proposed method retains more details in the recovered images compared to other methods, shown in Fig. 15(b)–(d).

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

Fig. 15. Quantitative comparison of different visibility restoration methods under turbid water using (a) similarity of color histograms, (b) information entropy, (c) mean gradient, and (d) the rate of new visible edges.

3.3 Discussion
According to the above experimental results, to further improve the restoration quality of degraded images under different conditions for practical applications, we discuss some potential limitations that affect restoration performance. We also provide solutions as future direction which would improve the performance of the proposed algorithm.
First, the real-time performance of QTCTO method needs to be improved for the visibility restoration of degraded video. Although the image recovery time for the proposed method is very small, it is still difﬁcult to achieve higher frame rates required by video processing. Therefore, to cater real-time needs, as future work, an advanced model can be developed, or the support of special hardware such as GPU can be used for acceleration. Similarly, executing the algorithm on fast platforms (such as C using SSE instructions) can also achieve real-time performance.
Second, the proposed method has poor restoration capability under non-uniform scattering medium. The experimental results reveal that the restoration performance under turbid water is better compared to a smoky medium. This can be attributed to the uniformity of turbid water and non-uniformity of the smoke distribution in our experiments. However, in practice, images are captured from diverse inhomogeneous medium (i.e., under dense fog) which may degrade the performance of QTCTO. Therefore, the performance of the proposed method can be improved in the future by computing atmospheric light and transmission from different regions within the degraded image to achieve good restoration.
Third, although the proposed method is based on physical atmospheric model, it achieves better results under turbid water compared to a smoky medium. By improving the color correction algorithm used in our work, the proposed method can easily be extended to restore degraded images under marine environment. In general, the restoration capability of the proposed method can be improved by capturing the target within the camera’s depth of ﬁeld, and without defocus blur.
4. Conclusion
The paper presents QTCTO algorithm for the visibility restoration of degraded images under scattering medium. The proposed method is based on computing atmospheric light and transmission for efﬁcient restoration capability. The method is tested for different scattering conditions such as sky, turbid water, and smoke. The experimental results show that the proposed method outperforms other existing methods over different metrics achieving good restoration results. The proposed method restores degraded image with high contrast and sharpness without any color distortion. Similarly, the halo artifacts that appear in other methods are also removed by the proposed method. Although the proposed method is based on the atmospheric scattering model, it can handle complex scattering mediums as shown by its robustness under turbid water. To achieve real-time performance for video processing, the algorithm can be written in C language (using SSE

Vol. 12, No. 3, JUNE 2020

6100813

IEEE Photonics Journal

Fast Visibility Restoration

instructions) to cater degraded video. The proposed method can effectively be used for different applications such as security monitoring, remote sensing, and various military applications.

References
[1] T. K. Kim, J. K. Paik, and B. S. Kang, “Contrast enhancement system using spatially adaptive histogram equalization with temporal ﬁltering,” IEEE Trans. Consum. Electron., vol. 44, no. 1, pp. 82–87, 1998.
[2] J. A. Stark, “Adaptive image contrast enhancement using generalizations of histogram equalization,” IEEE Trans. Image Process., vol. 9, no. 5, pp. 889–896, 2000.
[3] F. Russo, “An image enhancement technique combining sharpening and noise reduction,” IEEE Trans. Instrum. Meas., vol. 51, no. 4, pp. 824–828, 2002.
[4] M.-J. Seow and V. K. Asari, “Ratio rule and homomorphic ﬁlter for enhancement of digital colour image,” Neurocomputing, vol. 69, no. 7, pp. 954–958, 2006.
[5] E. H. Land and J. J. McCann, “Lightness and retinex theory,” J. Opt. Soc. Am., vol. 61, no. 1, pp. 1–11, 1971. [6] J. P. Oakley and B. L. Satherley, “Improving image quality in poor visibility conditions using a physical model for contrast
degradation,” IEEE Trans. Image Process., vol. 7, no. 2, pp. 167–179, 1998. [7] S. K. Nayar and S. G. Narasimhan, “Vision in bad weather,” in Proceedings of the Seventh IEEE International
Conference on Computer Vision, 1999, pp. 820–827. [8] S. G. Narasimhan and S. K. Nayar, “Chromatic framework for vision in bad weather,” in Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2000, pp. 598–605. [9] S. G. Narasimhan and S. K. Nayar, “Contrast restoration of weather degraded images,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 25, no. 6, pp. 713–724, 2003. [10] Y. Y. Schechner, S. G. Narasimhan, and S. K. Nayar, “Instant dehazing of images using polarization,” in Proceedings
of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2001, pp. 325–332. [11] Y. Y. Schechner, S. G. Narasimhan, and S. K. Nayar, “Polarization-based vision through haze,” Appl. Optics, vol. 42,
no. 3, pp. 511–525, 2003. [12] S. Shwartz, E. Namer and Y. Y. Schechner, “Blind haze separation,” in Proceedings of the 2006 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition, 2006, pp. 1984–1991. [13] S. G. Narasimhan and S. K. Nayar, “Vision and the atmosphere,” Int. J. Comput. Vis., vol. 48, no. 3, pp. 233–254, 2002. [14] J. Kopf et al., “Deep photo: Model-based photograph enhancement and viewing,” ACM Trans. Graph., vol. 27, no. 5,
pp. 111–119, 2008. [15] S. G. Narasimhan and S. K. Nayar, “Interactive (de) weathering of an image using physical models,” in Proceedings of
the 2003 IEEE Conference on Workshop Color and Photometric Methods in computer Vision, 2003, pp. 1–8. [16] R. T. Tan, “Visibility in bad weather from a single image,” in Proceedings of the 2008 IEEE Conference on Computer
Vision and Pattern Recognition, 2008, pp. 1–8. [17] R. Fattal, “Single image dehazing,” ACM Trans. Graph., vol. 27, no. 3, pp. 721–729, 2008. [18] K. He, J. Sun, and X. Tang, “Single image haze removal using dark channel prior,” IEEE Trans. Pattern Anal. Mach.
Intell., vol. 33, no. 12, pp. 2341–2353, 2010. [19] K. He, J. Sun, and X. Tang, “Guided image ﬁltering,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 6,
pp. 1397–1409, 2012. [20] L. Kratz and K. Nishino, “Factorizing scene albedo and depth from a single foggy image,” in Proceedings of the 2009
IEEE 12th International Conference on Computer Vision, 2009, pp. 1701–1708. [21] J.-P. Tarel and N. Hautiere, “Fast visibility restoration from a single color or gray level image,” in Proceedings of the
2009 IEEE 12th International Conference on Computer Vision, 2009, pp. 2201–2208. [22] R. Fattal, “Dehazing using color-lines,” ACM Trans. Graph., vol. 34, no. 1, pp. 131–1314, 2014. [23] L. Bao, Y. Song, Q. Yang, and N. Ahuja, “An edge-preserving ﬁltering framework for visibility restoration,” in Proceed-
ings of the 21th IEEE International Conference on Pattern Recognition, 2012, pp. 384–387. [24] Q. Yan, L. Xu, and J. Jia, “Dense scattering layer removal,” in Proceedings of the Siggraph Asia 2013 Technial Briefs,
2013, pp. 1–10. [25] L. Caraffa and J.-P. Tarel, “Markov random ﬁeld model for single image defogging,” in Proceedings of the 2013 IEEE
Conference on Intelligent Vehicles Symposium, 2013, pp. 994–999. [26] S. R. Gadre, “Information entropy and Thomas-Fermi theory,” Phys. Rev. A, vol. 30, no. 1, pp. 620–621, 1984. [27] N. Hautiere, J.-P. Tarel, D. Aubert, and E. Dumont, “Blind contrast enhancement assessment by gradient ratioing at
visible edges,” Image Anal. Stereol., vol. 27, no. 2, pp. 87–95, 2008. [28] M. Chambah, A. Rizzi, C. Gatta, B. Besserer, and D. Marini, “Perceptual approach for unsupervised digital color
restoration of cinematographic archives,” in Proceedings of the Proc. SPIE 5008, Color Imaging VIII: Processing, Hardcopy, and Applications, 2003, pp. 138–149.

Vol. 12, No. 3, JUNE 2020

6100813

