Advanced Textbooks in Control and Signal Processing

Series Editors
Professor Michael J. Grimble, Professor of Industrial Systems and Director Professor Michael A. Johnson, Professor Emeritus of Control Systems and Deputy Director Industrial Control Centre, Department of Electronic and Electrical Engineering, University of Strathclyde, Graham Hills Building, 50 George Street, Glasgow G1 1QE, UK

Other titles published in this series:
Genetic Algorithms K.F. Man, K.S. Tang and S. Kwong
Introduction to Optimal Estimation E.W. Kamen and J.K. Su
Discrete-time Signal Processing D. Williamson
Neural Networks for Modelling and Control of Dynamic Systems M. Nørgaard, O. Ravn, N.K. Poulsen and L.K. Hansen
Fault Detection and Diagnosis in Industrial Systems L.H. Chiang, E.L. Russell and R.D. Braatz
Soft Computing L. Fortuna, G. Rizzotto, M. Lavorgna, G. Nunnari, M.G. Xibilia and R. Caponetto
Statistical Signal Processing T. Chonavel
Discrete-time Stochastic Processes (2nd Edition) T. Söderström
Parallel Computing for Real-time Signal Processing and Control M.O. Tokhi, M.A. Hossain and M.H. Shaheed
Multivariable Control Systems P. Albertos and A. Sala

Control Systems with Input and Output Constraints A.H. Glattfelder and W. Schaufelberger
Analysis and Control of Non-linear Process Systems K.M. Hangos, J. Bokor and G. Szederkényi
Model Predictive Control (2nd Edition) E.F. Camacho and C. Bordons
Principles of Adaptive Filters and Selflearning Systems A. Zaknich
Digital Self-tuning Controllers V. Bobál, J. Böhm, J. Fessl and J. Macháček
Control of Robot Manipulators in Joint Space R. Kelly, V. Santibáñez and A. Loría
Receding Horizon Control W.H. Kwon and S. Han
Robust Control Design with MATLAB® D.-W. Gu, P.H. Petkov and M.M. Konstantinov
Control of Dead-time Processes J.E. Normey-Rico and E.F. Camacho
Modeling and Control of Discrete-event Dynamic Systems B. Hrúz and M.C. Zhou

Bruno Siciliano • Lorenzo Sciavicco Luigi Villani • Giuseppe Oriolo
Robotics
Modelling, Planning and Control
123

Bruno Siciliano, PhD Dipartimento di Informatica e Sistemistica Università di Napoli Federico II Via Claudio 21 80125 Napoli Italy
siciliano@unina.it

Lorenzo Sciavicco, DrEng Dipartimento di Informatica e Automazione Università di Roma Tre Via della Vasca Navale 79 00146 Roma Italy sciavicco@uniroma3.it

Luigi Villani, PhD Dipartimento di Informatica e Sistemistica Università di Napoli Federico II Via Claudio 21 80125 Napoli Italy lvillani@unina.it

Giuseppe Oriolo, PhD Dipartimento di Informatica e Sistemistica Università di Roma “La Sapienza” Via Ariosto 25 00185 Roma Italy
oriolo@dis.uniroma1.it

ISSN 1439-2232 ISBN 978-1-84628-641-4 DOI 10.1007/978-1-84628-642-1

e-ISBN 978-1-84628-642-1

British Library Cataloguing in Publication Data A catalogue record for this book is available from the British Library

Library of Congress Control Number: 2008939574

© Springer-Verlag London Limited 2010
MATLAB® is a registered trademark of The MathWorks, Inc., 3 Apple Hill Drive, Natick, MA 017602098, USA. http://www.mathworks.com

Apart from any fair dealing for the purposes of research or private study, or criticism or review, as permitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced, stored or transmitted, in any form or by any means, with the prior permission in writing of the publishers, or in the case of reprographic reproduction in accordance with the terms of licences issued by the Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to the publishers. The use of registered names, trademarks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant laws and regulations and therefore free for general use. The publisher makes no representation, express or implied, with regard to the accuracy of the information contained in this book and cannot accept any legal responsibility or liability for any errors or omissions that may be made.

Cover design: eStudioCalamar, Figueres/Berlin

Printed on acid-free paper

Springer is part of Springer Science+Business Media (www.springer.com)

to our families

Series Editors’ Foreword
The topics of control engineering and signal processing continue to ﬂourish and develop. In common with general scientiﬁc investigation, new ideas, concepts and interpretations emerge quite spontaneously and these are then discussed, used, discarded or subsumed into the prevailing subject paradigm. Sometimes these innovative concepts coalesce into a new sub-discipline within the broad subject tapestry of control and signal processing. This preliminary battle between old and new usually takes place at conferences, through the Internet and in the journals of the discipline. After a little more maturity has been acquired by the new concepts then archival publication as a scientiﬁc or engineering monograph may occur.
A new concept in control and signal processing is known to have arrived when suﬃcient material has evolved for the topic to be taught as a specialised tutorial workshop or as a course to undergraduate, graduate or industrial engineers. Advanced Textbooks in Control and Signal Processing are designed as a vehicle for the systematic presentation of course material for both popular and innovative topics in the discipline. It is hoped that prospective authors will welcome the opportunity to publish a structured and systematic presentation of some of the newer emerging control and signal processing technologies in the textbook series.
Robots have appeared extensively in the artistic ﬁeld of science ﬁction writing. The actual name robot arose from its use by the playwright Karel Cˇ apek in the play Rossum’s Universal Robots (1920). Not surprisingly, the artistic focus has been on mechanical bipeds with anthropomorphic personalities often termed androids. This focus has been the theme of such cinematic productions as, I, Robot (based on Isaac Asimov’s stories) and Stanley Kubrick’s ﬁlm, A.I.; however, this book demonstrates that robot technology is already widely used in industry and that there is some robot technology which is at prototype stage rapidly approaching introduction to commercial use. Currently, robots may be classiﬁed according to their mobility attributes as shown in the ﬁgure.

viii Series Editors’ Foreword
The largest class of robots extant today is that of the ﬁxed robot which does repetitive but often precise mechanical and physical tasks. These robots pervade many areas of modern industrial automation and are mainly concerned with tasks performed in a structured environment. It seems highly likely that as the technology develops the number of mobile robots will significantly increase and become far more visible as more applications and tasks in an unstructured environment are serviced by robotic technology.
What then is robotics? A succinct deﬁnition is given in The Chamber’s Dictionary (2003): the branch of technology dealing with the design, construction and use of robots. This deﬁnition certainly captures the spirit of this volume in the Advanced Textbooks in Control and Signal Processing series entitled Robotics and written by Bruno Siciliano, Lorenzo Sciavicco, Luigi Villani and Giuseppe Oriolo. This book is a greatly extended and revised version of an earlier book in the series, Modelling and Control of Robot Manipulators (2000, ISBN: 978-1-85233-221-1). As can be seen from the ﬁgure above, robots cover a wide variety of types and the new book seeks to present a uniﬁed approach to robotics whilst focusing on the two leading classes of robots, the ﬁxed and the wheeled types. The textbook series publishes volumes in support of new disciplines that are emerging with their own novel identity, and robotics as a subject certainly falls into this category. The full scope of robotics lies at the intersection of mechanics, electronics, signal processing, control engineering, computing and mathematical modelling. However, within this very broad framework the authors have pursued the themes of modelling, planning and control . These are, and will remain, fundamental aspects of robot design and operation for years to come. Some interesting innovations in this text include material on wheeled robots and on vision as used in the control of robots. Thus, the book provides a thorough theoretical grounding in an area where the technologies are evolving and developing in new applications.
The series is one of textbooks for advanced courses, and volumes in the series have useful pedagogical features. This volume has twelve chapters covering both fundamental and specialist topics, and there is a Problems section at the end of each chapter. Five appendices have been included to give more depth to some of the advanced methods used in the text. There are over twelve pages of references and nine pages of index. The details of the citations and index should also facilitate the use of the volume as a source of reference as

Series Editors’ Foreword

ix

well as a course study text. We expect that the student, the researcher, the lecturer and the engineer will ﬁnd this volume of great value for the study of robotics.

Glasgow August 2008

Michael J. Grimble Michael A. Johnson

Preface
In the last 25 years, the ﬁeld of robotics has stimulated an increasing interest in a wide number of scholars, and thus literature has been conspicuous, both in terms of textbooks and monographs, and in terms of specialized journals dedicated to robotics. This strong interest is also to be attributed to the interdisciplinary character of robotics, which is a science having roots in diﬀerent areas. Cybernetics, mechanics, controls, computers, bioengineering, electronics — to mention the most important ones — are all cultural domains which undoubtedly have boosted the development of this science.
Despite robotics representing as yet a relatively young discipline, its foundations are to be considered well-assessed in the classical textbook literature. Among these, modelling, planning and control play a basic role, not only in the traditional context of industrial robotics, but also for the advanced scenarios of ﬁeld and service robots, which have attracted an increasing interest from the research community in the last 15 years.
This book is the natural evolution of the previous text Modelling and Control of Robot Manipulators by the ﬁrst two co-authors, published in 1995, and in 2000 with its second edition. The cut of the original textbook has been conﬁrmed with the educational goal of blending the fundamental and technological aspects with those advanced aspects, on a uniform track as regards a rigorous formalism.
The fundamental and technological aspects are mainly concentrated in the ﬁrst six chapters of the book and concern the theory of manipulator structures, including kinematics, statics and trajectory planning, and the technology of robot actuators, sensors and control units.
The advanced aspects are dealt with in the subsequent six chapters and concern dynamics and motion control of robot manipulators, interaction with the environment using exteroceptive sensory data (force and vision), mobile robots and motion planning.
The book contents are organized in 12 chapters and 5 appendices. In Chap. 1, the diﬀerences between industrial and advanced applications are enlightened in the general robotics context. The most common mechanical

xii Preface
structures of robot manipulators and wheeled mobile robots are presented. Topics are also introduced which are developed in the subsequent chapters.
In Chap. 2 kinematics is presented with a systematic and general approach which refers to the Denavit-Hartenberg convention. The direct kinematics equation is formulated which relates joint space variables to operational space variables. This equation is utilized to ﬁnd manipulator workspace as well as to derive a kinematic calibration technique. The inverse kinematics problem is also analyzed and closed-form solutions are found for typical manipulation structures.
Diﬀerential kinematics is presented in Chap. 3. The relationship between joint velocities and end-eﬀector linear and angular velocities is described by the geometric Jacobian. The diﬀerence between the geometric Jacobian and the analytical Jacobian is pointed out. The Jacobian constitutes a fundamental tool to characterize a manipulator, since it allows the determination of singular conﬁgurations, an analysis of redundancy and the expression of the relationship between forces and moments applied to the end-eﬀector and the resulting joint torques at equilibrium conﬁgurations (statics). Moreover, the Jacobian allows the formulation of inverse kinematics algorithms that solve the inverse kinematics problem even for manipulators not having a closed-form solution.
In Chap. 4, trajectory planning techniques are illustrated which deal with the computation of interpolating polynomials through a sequence of desired points. Both the case of point-to-point motion and that of motion through a sequence of points are treated. Techniques are developed for generating trajectories both in the joint space and in the operational space, with a special concern to orientation for the latter.
Chapter 5 is devoted to the presentation of actuators and sensors. After an illustration of the general features of an actuating system, methods to control electric and hydraulic drives are presented. The most common proprioceptive and exteroceptive sensors in robotics are described.
In Chap. 6, the functional architecture of a robot control system is illustrated. The characteristics of programming environments are presented with an emphasis on teaching-by-showing and robot-oriented programming. A general model for the hardware architecture of an industrial robot control system is ﬁnally discussed.
Chapter 7 deals with the derivation of manipulator dynamics, which plays a fundamental role in motion simulation, manipulation structure analysis and control algorithm synthesis. The dynamic model is obtained by explicitly taking into account the presence of actuators. Two approaches are considered, namely, one based on Lagrange formulation, and the other based on Newton– Euler formulation. The former is conceptually simpler and systematic, whereas the latter allows computation of a dynamic model in a recursive form. Notable properties of the dynamic model are presented, including linearity in the parameters which is utilized to develop a model identiﬁcation technique. Finally,

Preface xiii
the transformations needed to express the dynamic model in the operational space are illustrated.
In Chap. 8 the problem of motion control in free space is treated. The distinction between joint space decentralized and centralized control strategies is pointed out. With reference to the former, the independent joint control technique is presented which is typically used for industrial robot control. As a premise to centralized control, the computed torque feedforward control technique is introduced. Advanced schemes are then introduced including PD control with gravity compensation, inverse dynamics control, robust control, and adaptive control. Centralized techniques are extended to operational space control.
Force control of a manipulator in contact with the working environment is tackled in Chap. 9. The concepts of mechanical compliance and impedance are deﬁned as a natural extension of operational space control schemes to the constrained motion case. Force control schemes are then presented which are obtained by the addition of an outer force feedback loop to a motion control scheme. The hybrid force/motion control strategy is ﬁnally presented with reference to the formulation of natural and artiﬁcial constraints describing an interaction task.
In Chap. 10, visual control is introduced which allows the use of information on the environment surrounding the robotic system. The problems of camera position and orientation estimate with respect to the objects in the scene are solved by resorting to both analytical and numerical techniques. After presenting the advantages to be gained with stereo vision and a suitable camera calibration, the two main visual control strategies are illustrated, namely in the operational space and in the image space, whose advantages can be eﬀectively combined in the hybrid visual control scheme.
Wheeled mobile robots are dealt with in Chap. 11, which extends some modelling, planning and control aspects of the previous chapters. As far as modelling is concerned, it is worth distinguishing between the kinematic model, strongly characterized by the type of constraint imposed by wheel rolling, and the dynamic model which accounts for the forces acting on the robot. The peculiar structure of the kinematic model is keenly exploited to develop both path and trajectory planning techniques. The control problem is tackled with reference to two main motion tasks: trajectory tracking and conﬁguration regulation. Further, it is evidenced how the implementation of the control schemes utilizes odometric localization methods.
Chapter 12 reprises the planning problems treated in Chaps. 4 and 11 for robot manipulators and mobile robots respectively, in the case when obstacles are present in the workspace. In this framework, motion planning is referred to, which is eﬀectively formulated in the conﬁguration space. Several planning techniques for mobile robots are then presented: retraction, cell decomposition, probabilistic, artiﬁcial potential. The extension to the case of robot manipulators is ﬁnally discussed.

xiv Preface
This chapter concludes the presentation of the topical contents of the textbook; ﬁve appendices follow which have been included to recall background methodologies.
Appendix A is devoted to linear algebra and presents the fundamental notions on matrices, vectors and related operations.
Appendix B presents those basic concepts of rigid body mechanics which are preliminary to the study of manipulator kinematics, statics and dynamics.
Appendix C illustrates the principles of feedback control of linear systems and presents a general method based on Lyapunov theory for control of nonlinear systems.
Appendix D deals with some concepts of diﬀerential geometry needed for control of mechanical systems subject to nonholonomic constraints.
Appendix E is focused on graph search algorithms and their complexity in view of application to motion planning methods.
The organization of the contents according to the above illustrated scheme allows the adoption of the book as a reference text for a senior undergraduate or graduate course in automation, computer, electrical, electronics, or mechanical engineering with strong robotics content.
From a pedagogical viewpoint, the various topics are presented in an instrumental manner and are developed with a gradually increasing level of diﬃculty. Problems are raised and proper tools are established to ﬁnd engineeringoriented solutions. Each chapter is introduced by a brief preamble providing the rationale and the objectives of the subject matter. The topics needed for a proﬁcient study of the text are presented in the ﬁve appendices, whose purpose is to provide students of diﬀerent extraction with a homogeneous background.
The book contains more than 310 illustrations and more than 60 workedout examples and case studies spread throughout the text with frequent resort to simulation. The results of computer implementations of inverse kinematics algorithms, trajectory planning techniques, inverse dynamics computation, motion, force and visual control algorithms for robot manipulators, and motion control for mobile robots are presented in considerable detail in order to facilitate the comprehension of the theoretical development, as well as to increase sensitivity of application in practical problems. In addition, nearly 150 end-of-chapter problems are proposed, some of which contain further study matter of the contents, and the book is accompanied by an electronic solutions manual (downloadable from www.springer.com/978-1-84628-641-4) containing the MATLAB R code for computer problems; this is available free of charge to those adopting this volume as a text for courses. Special care has been devoted to the selection of bibliographical references (more than 250) which are cited at the end of each chapter in relation to the historical development of the ﬁeld.
Finally, the authors wish to acknowledge all those who have been helpful in the preparation of this book.
With reference to the original work, as the basis of the present textbook, devoted thanks go to Pasquale Chiacchio and Stefano Chiaverini for their

Preface xv
contributions to the writing of the chapters on trajectory planning and force control, respectively. Fabrizio Caccavale and Ciro Natale have been of great help in the revision of the contents for the second edition.
A special note of thanks goes to Alessandro De Luca for his punctual and critical reading of large portions of the text, as well as to Vincenzo Lippiello, Agostino De Santis, Marilena Vendittelli and Luigi Freda for their contributions and comments on some sections.

Naples and Rome July 2008

Bruno Siciliano Lorenzo Sciavicco
Luigi Villani Giuseppe Oriolo

Contents
1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1 Robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Robot Mechanical Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2.1 Robot Manipulators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2.2 Mobile Robots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.3 Industrial Robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 1.4 Advanced Robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 1.4.1 Field Robots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 1.4.2 Service Robots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 1.5 Robot Modelling, Planning and Control . . . . . . . . . . . . . . . . . . . 29 1.5.1 Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 1.5.2 Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 1.5.3 Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2 Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.1 Pose of a Rigid Body . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.2 Rotation Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 2.2.1 Elementary Rotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 2.2.2 Representation of a Vector . . . . . . . . . . . . . . . . . . . . . . . . 42 2.2.3 Rotation of a Vector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 2.3 Composition of Rotation Matrices . . . . . . . . . . . . . . . . . . . . . . . . 45 2.4 Euler Angles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2.4.1 ZYZ Angles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 2.4.2 RPY Angles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 2.5 Angle and Axis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 2.6 Unit Quaternion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 2.7 Homogeneous Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 2.8 Direct Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 2.8.1 Open Chain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 2.8.2 Denavit–Hartenberg Convention . . . . . . . . . . . . . . . . . . . 61

xviii Contents
2.8.3 Closed Chain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 2.9 Kinematics of Typical Manipulator Structures . . . . . . . . . . . . . 68
2.9.1 Three-link Planar Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 2.9.2 Parallelogram Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 2.9.3 Spherical Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 2.9.4 Anthropomorphic Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 2.9.5 Spherical Wrist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 2.9.6 Stanford Manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 2.9.7 Anthropomorphic Arm with Spherical Wrist . . . . . . . . . 77 2.9.8 DLR Manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 2.9.9 Humanoid Manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 2.10 Joint Space and Operational Space . . . . . . . . . . . . . . . . . . . . . . . 83 2.10.1 Workspace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 2.10.2 Kinematic Redundancy . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 2.11 Kinematic Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 2.12 Inverse Kinematics Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 2.12.1 Solution of Three-link Planar Arm . . . . . . . . . . . . . . . . . 91 2.12.2 Solution of Manipulators with Spherical Wrist . . . . . . . 94 2.12.3 Solution of Spherical Arm . . . . . . . . . . . . . . . . . . . . . . . . . 95 2.12.4 Solution of Anthropomorphic Arm . . . . . . . . . . . . . . . . . 96 2.12.5 Solution of Spherical Wrist . . . . . . . . . . . . . . . . . . . . . . . . 99 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
3 Diﬀerential Kinematics and Statics . . . . . . . . . . . . . . . . . . . . . . . . 105 3.1 Geometric Jacobian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 3.1.1 Derivative of a Rotation Matrix . . . . . . . . . . . . . . . . . . . . 106 3.1.2 Link Velocities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 3.1.3 Jacobian Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 3.2 Jacobian of Typical Manipulator Structures . . . . . . . . . . . . . . . 113 3.2.1 Three-link Planar Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 3.2.2 Anthropomorphic Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 3.2.3 Stanford Manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 3.3 Kinematic Singularities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 3.3.1 Singularity Decoupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 3.3.2 Wrist Singularities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 3.3.3 Arm Singularities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 3.4 Analysis of Redundancy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 3.5 Inverse Diﬀerential Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 3.5.1 Redundant Manipulators . . . . . . . . . . . . . . . . . . . . . . . . . . 124 3.5.2 Kinematic Singularities . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 3.6 Analytical Jacobian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 3.7 Inverse Kinematics Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 3.7.1 Jacobian (Pseudo-)inverse . . . . . . . . . . . . . . . . . . . . . . . . . 133 3.7.2 Jacobian Transpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134

Contents xix
3.7.3 Orientation Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 3.7.4 Second-order Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 141 3.7.5 Comparison Among Inverse Kinematics Algorithms . . . 143 3.8 Statics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 3.8.1 Kineto-Statics Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 3.8.2 Velocity and Force Transformation . . . . . . . . . . . . . . . . . 149 3.8.3 Closed Chain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151 3.9 Manipulability Ellipsoids . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
4 Trajectory Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 4.1 Path and Trajectory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 4.2 Joint Space Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 4.2.1 Point-to-Point Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 4.2.2 Motion Through a Sequence of Points . . . . . . . . . . . . . . 168 4.3 Operational Space Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 4.3.1 Path Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 4.3.2 Position . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184 4.3.3 Orientation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
5 Actuators and Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 5.1 Joint Actuating System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 5.1.1 Transmissions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 5.1.2 Servomotors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193 5.1.3 Power Ampliﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 5.1.4 Power Supply . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 5.2 Drives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 5.2.1 Electric Drives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 5.2.2 Hydraulic Drives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202 5.2.3 Transmission Eﬀects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204 5.2.4 Position Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 5.3 Proprioceptive Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209 5.3.1 Position Transducers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210 5.3.2 Velocity Transducers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 5.4 Exteroceptive Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215 5.4.1 Force Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215 5.4.2 Range Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219 5.4.3 Vision Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231

xx Contents
6 Control Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 6.1 Functional Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 6.2 Programming Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 6.2.1 Teaching-by-Showing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240 6.2.2 Robot-oriented Programming . . . . . . . . . . . . . . . . . . . . . . 241 6.3 Hardware Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
7 Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247 7.1 Lagrange Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247 7.1.1 Computation of Kinetic Energy . . . . . . . . . . . . . . . . . . . . 249 7.1.2 Computation of Potential Energy . . . . . . . . . . . . . . . . . . 255 7.1.3 Equations of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255 7.2 Notable Properties of Dynamic Model . . . . . . . . . . . . . . . . . . . . 257 7.2.1 Skew-symmetry of Matrix B˙ − 2C . . . . . . . . . . . . . . . . . 257 7.2.2 Linearity in the Dynamic Parameters . . . . . . . . . . . . . . . 259 7.3 Dynamic Model of Simple Manipulator Structures . . . . . . . . . . 264 7.3.1 Two-link Cartesian Arm . . . . . . . . . . . . . . . . . . . . . . . . . . 264 7.3.2 Two-link Planar Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265 7.3.3 Parallelogram Arm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277 7.4 Dynamic Parameter Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . 280 7.5 Newton–Euler Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282 7.5.1 Link Accelerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285 7.5.2 Recursive Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286 7.5.3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289 7.6 Direct Dynamics and Inverse Dynamics . . . . . . . . . . . . . . . . . . . 292 7.7 Dynamic Scaling of Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . 294 7.8 Operational Space Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . 296 7.9 Dynamic Manipulability Ellipsoid . . . . . . . . . . . . . . . . . . . . . . . . 299 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
8 Motion Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303 8.1 The Control Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303 8.2 Joint Space Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305 8.3 Decentralized Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309 8.3.1 Independent Joint Control . . . . . . . . . . . . . . . . . . . . . . . . 311 8.3.2 Decentralized Feedforward Compensation . . . . . . . . . . . 319 8.4 Computed Torque Feedforward Control . . . . . . . . . . . . . . . . . . . 324 8.5 Centralized Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327 8.5.1 PD Control with Gravity Compensation . . . . . . . . . . . . 328 8.5.2 Inverse Dynamics Control . . . . . . . . . . . . . . . . . . . . . . . . . 330 8.5.3 Robust Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333 8.5.4 Adaptive Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338

Contents xxi
8.6 Operational Space Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343 8.6.1 General Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344 8.6.2 PD Control with Gravity Compensation . . . . . . . . . . . . 345 8.6.3 Inverse Dynamics Control . . . . . . . . . . . . . . . . . . . . . . . . . 347
8.7 Comparison Among Various Control Schemes . . . . . . . . . . . . . . 349 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360
9 Force Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363 9.1 Manipulator Interaction with Environment . . . . . . . . . . . . . . . . 363 9.2 Compliance Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364 9.2.1 Passive Compliance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366 9.2.2 Active Compliance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367 9.3 Impedance Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372 9.4 Force Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378 9.4.1 Force Control with Inner Position Loop . . . . . . . . . . . . . 379 9.4.2 Force Control with Inner Velocity Loop . . . . . . . . . . . . . 380 9.4.3 Parallel Force/Position Control . . . . . . . . . . . . . . . . . . . . 381 9.5 Constrained Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384 9.5.1 Rigid Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385 9.5.2 Compliant Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . 389 9.6 Natural and Artiﬁcial Constraints . . . . . . . . . . . . . . . . . . . . . . . . 391 9.6.1 Analysis of Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392 9.7 Hybrid Force/Motion Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396 9.7.1 Compliant Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . 397 9.7.2 Rigid Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404
10 Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407 10.1 Vision for Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407 10.1.1 Conﬁguration of the Visual System . . . . . . . . . . . . . . . . . 409 10.2 Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410 10.2.1 Image Segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411 10.2.2 Image Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 416 10.3 Pose Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418 10.3.1 Analytical Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419 10.3.2 Interaction Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424 10.3.3 Algorithmic Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 427 10.4 Stereo Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433 10.4.1 Epipolar Geometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433 10.4.2 Triangulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435 10.4.3 Absolute Orientation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436 10.4.4 3D Reconstruction from Planar Homography . . . . . . . . 438 10.5 Camera Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440

xxii Contents
10.6 The Visual Servoing Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443 10.7 Position-based Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
10.7.1 PD Control with Gravity Compensation . . . . . . . . . . . . 446 10.7.2 Resolved-velocity Control . . . . . . . . . . . . . . . . . . . . . . . . . 447 10.8 Image-based Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449 10.8.1 PD Control with Gravity Compensation . . . . . . . . . . . . 449 10.8.2 Resolved-velocity Control . . . . . . . . . . . . . . . . . . . . . . . . . 451 10.9 Comparison Among Various Control Schemes . . . . . . . . . . . . . . 453 10.10 Hybrid Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466
11 Mobile Robots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469 11.1 Nonholonomic Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469 11.1.1 Integrability Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 473 11.2 Kinematic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 476 11.2.1 Unicycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 478 11.2.2 Bicycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479 11.3 Chained Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482 11.4 Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485 11.5 Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489 11.5.1 Path and Timing Law . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489 11.5.2 Flat Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 491 11.5.3 Path Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492 11.5.4 Trajectory Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498 11.5.5 Optimal Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499 11.6 Motion Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 502 11.6.1 Trajectory Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503 11.6.2 Regulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 510 11.7 Odometric Localization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 518 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 518
12 Motion Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523 12.1 The Canonical Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523 12.2 Conﬁguration Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525 12.2.1 Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527 12.2.2 Obstacles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527 12.2.3 Examples of Obstacles . . . . . . . . . . . . . . . . . . . . . . . . . . . . 528 12.3 Planning via Retraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532 12.4 Planning via Cell Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . 536 12.4.1 Exact Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536 12.4.2 Approximate Decomposition . . . . . . . . . . . . . . . . . . . . . . . 539 12.5 Probabilistic Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541 12.5.1 PRM Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541

Contents xxiii
12.5.2 Bidirectional RRT Method . . . . . . . . . . . . . . . . . . . . . . . . 543 12.6 Planning via Artiﬁcial Potentials . . . . . . . . . . . . . . . . . . . . . . . . . 546
12.6.1 Attractive Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 546 12.6.2 Repulsive Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547 12.6.3 Total Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549 12.6.4 Planning Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 550 12.6.5 The Local Minima Problem . . . . . . . . . . . . . . . . . . . . . . . 551 12.7 The Robot Manipulator Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557
Appendices
A Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563 A.1 Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563 A.2 Matrix Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565 A.3 Vector Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 569 A.4 Linear Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 572 A.5 Eigenvalues and Eigenvectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 573 A.6 Bilinear Forms and Quadratic Forms . . . . . . . . . . . . . . . . . . . . . . 574 A.7 Pseudo-inverse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575 A.8 Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . 577 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 578
B Rigid-body Mechanics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579 B.1 Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579 B.2 Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581 B.3 Work and Energy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584 B.4 Constrained Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 585 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 588
C Feedback Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589 C.1 Control of Single-input/Single-output Linear Systems . . . . . . . 589 C.2 Control of Nonlinear Mechanical Systems . . . . . . . . . . . . . . . . . . 594 C.3 Lyapunov Direct Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 598
D Diﬀerential Geometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 599 D.1 Vector Fields and Lie Brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . 599 D.2 Nonlinear Controllability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 604

xxiv Contents
E Graph Search Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605 E.1 Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605 E.2 Breadth-ﬁrst and Depth-ﬁrst Search . . . . . . . . . . . . . . . . . . . . . . 606 E.3 A Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 607 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 608
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 623

1
Introduction
Robotics is concerned with the study of those machines that can replace human beings in the execution of a task, as regards both physical activity and decision making. The goal of the introductory chapter is to point out the problems related to the use of robots in industrial applications, as well as the perspectives oﬀered by advanced robotics. A classiﬁcation of the most common mechanical structures of robot manipulators and mobile robots is presented. Topics of modelling, planning and control are introduced which will be examined in the following chapters. The chapter ends with a list of references dealing with subjects both of speciﬁc interest and of related interest to those covered by this textbook.
1.1 Robotics
Robotics has profound cultural roots. Over the course of centuries, human beings have constantly attempted to seek substitutes that would be able to mimic their behaviour in the various instances of interaction with the surrounding environment. Several motivations have inspired this continuous search referring to philosophical, economic, social and scientiﬁc principles.
One of human beings’ greatest ambitions has been to give life to their artifacts. The legend of the Titan Prometheus, who molded humankind from clay, as well as that of the giant Talus, the bronze slave forged by Hephaestus, testify how Greek mythology was inﬂuenced by that ambition, which has been revisited in the tale of Frankenstein in modern times.
Just as the giant Talus was entrusted with the task of protecting the island of Crete from invaders, in the Industrial Age a mechanical creature (automaton) has been entrusted with the task of substituting a human being in subordinate labor duties. This concept was introduced by the Czech playwright Karel Cˇ apek who wrote the play Rossum’s Universal Robots (R.U.R.) in 1920. On that occasion he coined the term robot — derived from the term

2

1 Introduction

robota that means executive labour in Slav languages — to denote the automaton built by Rossum who ends up by rising up against humankind in the science ﬁction tale.
In the subsequent years, in view of the development of science ﬁction, the behaviour conceived for the robot has often been conditioned by feelings. This has contributed to rendering the robot more and more similar to its creator.
It is worth noticing how Rossum’s robots were represented as creatures made with organic material. The image of the robot as a mechanical artifact starts in the 1940s when the Russian Isaac Asimov, the well-known science ﬁction writer, conceived the robot as an automaton of human appearance but devoid of feelings. Its behaviour was dictated by a “positronic” brain programmed by a human being in such a way as to satisfy certain rules of ethical conduct. The term robotics was then introduced by Asimov as the science devoted to the study of robots which was based on the three fundamental laws :

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey the orders given by human beings, except when such orders would conﬂict with the ﬁrst law.
3. A robot must protect its own existence, as long as such protection does not conﬂict with the ﬁrst or second law.

These laws established rules of behaviour to consider as speciﬁcations for the design of a robot, which since then has attained the connotation of an industrial product designed by engineers or specialized technicians.
Science ﬁction has inﬂuenced the man and the woman in the street that continue to imagine the robot as a humanoid who can speak, walk, see, and hear, with an appearance very much like that presented by the robots of the movie Metropolis, a precursor of modern cinematography on robots, with Star Wars and more recently with I, Robot inspired by Asimov’s novels.
According to a scientiﬁc interpretation of the science-ﬁction scenario, the robot is seen as a machine that, independently of its exterior, is able to modify the environment in which it operates. This is accomplished by carrying out actions that are conditioned by certain rules of behaviour intrinsic in the machine as well as by some data the robot acquires on its status and on the environment. In fact, robotics is commonly deﬁned as the science studying the intelligent connection between perception and action.
With reference to this deﬁnition, a robotic system is in reality a complex system, functionally represented by multiple subsystems (Fig. 1.1).
The essential component of a robot is the mechanical system endowed, in general, with a locomotion apparatus (wheels, crawlers, mechanical legs) and a manipulation apparatus (mechanical arms, end-eﬀectors, artiﬁcial hands). As an example, the mechanical system in Fig. 1.1 consists of two mechanical arms (manipulation apparatus), each of which is carried by a mobile vehicle

1.2 Robot Mechanical Structure

3

Fig. 1.1. Components of a robotic system
(locomotion apparatus). The realization of such a system refers to the context of design of articulated mechanical systems and choice of materials.
The capability to exert an action, both locomotion and manipulation, is provided by an actuation system which animates the mechanical components of the robot. The concept of such a system refers to the context of motion control , dealing with servomotors, drives and transmissions.
The capability for perception is entrusted to a sensory system which can acquire data on the internal status of the mechanical system (proprioceptive sensors, such as position transducers) as well as on the external status of the environment (exteroceptive sensors, such as force sensors and cameras). The realization of such a system refers to the context of materials properties, signal conditioning, data processing, and information retrieval.
The capability for connecting action to perception in an intelligent fashion is provided by a control system which can command the execution of the action in respect to the goals set by a task planning technique, as well as of the constraints imposed by the robot and the environment. The realization of such a system follows the same feedback principle devoted to control of human body functions, possibly exploiting the description of the robotic system’s components (modelling). The context is that of cybernetics, dealing with control and supervision of robot motions, artiﬁcial intelligence and expert systems, the computational architecture and programming environment.
Therefore, it can be recognized that robotics is an interdisciplinary subject concerning the cultural areas of mechanics, control , computers, and electronics .
1.2 Robot Mechanical Structure
The key feature of a robot is its mechanical structure. Robots can be classiﬁed as those with a ﬁxed base, robot manipulators, and those with a mobile base,

4

1 Introduction

mobile robots. In the following, the geometrical features of the two classes are presented.

1.2.1 Robot Manipulators
The mechanical structure of a robot manipulator consists of a sequence of rigid bodies (links) interconnected by means of articulations (joints); a manipulator is characterized by an arm that ensures mobility, a wrist that confers dexterity, and an end-eﬀector that performs the task required of the robot.
The fundamental structure of a manipulator is the serial or open kinematic chain. From a topological viewpoint, a kinematic chain is termed open when there is only one sequence of links connecting the two ends of the chain. Alternatively, a manipulator contains a closed kinematic chain when a sequence of links forms a loop.
A manipulator’s mobility is ensured by the presence of joints. The articulation between two consecutive links can be realized by means of either a prismatic or a revolute joint. In an open kinematic chain, each prismatic or revolute joint provides the structure with a single degree of freedom (DOF). A prismatic joint creates a relative translational motion between the two links, whereas a revolute joint creates a relative rotational motion between the two links. Revolute joints are usually preferred to prismatic joints in view of their compactness and reliability. On the other hand, in a closed kinematic chain, the number of DOFs is less than the number of joints in view of the constraints imposed by the loop.
The degrees of freedom should be properly distributed along the mechanical structure in order to have a suﬃcient number to execute a given task. In the most general case of a task consisting of arbitrarily positioning and orienting an object in three-dimensional (3D) space, six DOFs are required, three for positioning a point on the object and three for orienting the object with respect to a reference coordinate frame. If more DOFs than task variables are available, the manipulator is said to be redundant from a kinematic viewpoint.
The workspace represents that portion of the environment the manipulator’s end-eﬀector can access. Its shape and volume depend on the manipulator structure as well as on the presence of mechanical joint limits.
The task required of the arm is to position the wrist which then is required to orient the end-eﬀector. The type and sequence of the arm’s DOFs, starting from the base joint, allows a classiﬁcation of manipulators as Cartesian, cylindrical , spherical , SCARA, and anthropomorphic.
Cartesian geometry is realized by three prismatic joints whose axes typically are mutually orthogonal (Fig. 1.2). In view of the simple geometry, each DOF corresponds to a Cartesian space variable and thus it is natural to perform straight motions in space. The Cartesian structure oﬀers very good mechanical stiﬀness. Wrist positioning accuracy is constant everywhere in the workspace. This is the volume enclosed by a rectangular parallel-piped

1.2 Robot Mechanical Structure

5

Fig. 1.2. Cartesian manipulator and its workspace

Fig. 1.3. Gantry manipulator
(Fig. 1.2). As opposed to high accuracy, the structure has low dexterity since all the joints are prismatic. The direction of approach in order to manipulate an object is from the side. On the other hand, if it is desired to approach an object from the top, the Cartesian manipulator can be realized by a gantry structure as illustrated in Fig. 1.3. Such a structure makes available a workspace with a large volume and enables the manipulation of objects of large dimensions and heavy weight. Cartesian manipulators are employed for material handling and assembly. The motors actuating the joints of a Cartesian manipulator are typically electric and occasionally pneumatic.
Cylindrical geometry diﬀers from Cartesian in that the ﬁrst prismatic joint is replaced with a revolute joint (Fig. 1.4). If the task is described in cylindri-

6

1 Introduction

Fig. 1.4. Cylindrical manipulator and its workspace

Fig. 1.5. Spherical manipulator and its workspace
cal coordinates, in this case each DOF also corresponds to a Cartesian space variable. The cylindrical structure oﬀers good mechanical stiﬀness. Wrist positioning accuracy decreases as the horizontal stroke increases. The workspace is a portion of a hollow cylinder (Fig. 1.4). The horizontal prismatic joint makes the wrist of a cylindrical manipulator suitable to access horizontal cavities. Cylindrical manipulators are mainly employed for carrying objects even of large dimensions; in such a case the use of hydraulic motors is to be preferred to that of electric motors.
Spherical geometry diﬀers from cylindrical in that the second prismatic joint is replaced with a revolute joint (Fig. 1.5). Each DOF corresponds to a Cartesian space variable provided that the task is described in spherical coordinates. Mechanical stiﬀness is lower than the above two geometries and mechanical construction is more complex. Wrist positioning accuracy decreases as the radial stroke increases. The workspace is a portion of a hollow sphere (Fig. 1.5); it can also include the supporting base of the manipulator and thus

1.2 Robot Mechanical Structure

7

Fig. 1.6. SCARA manipulator and its workspace

Fig. 1.7. Anthropomorphic manipulator and its workspace
it can allow manipulation of objects on the ﬂoor. Spherical manipulators are mainly employed for machining. Electric motors are typically used to actuate the joints.
A special geometry is SCARA geometry that can be realized by disposing two revolute joints and one prismatic joint in such a way that all the axes of motion are parallel (Fig. 1.6). The acronym SCARA stands for Selective Compliance Assembly Robot Arm and characterizes the mechanical features of a structure oﬀering high stiﬀness to vertical loads and compliance to horizontal loads. As such, the SCARA structure is well-suited to vertical assembly tasks. The correspondence between the DOFs and Cartesian space variables is maintained only for the vertical component of a task described in Cartesian coordinates. Wrist positioning accuracy decreases as the distance of the wrist from the ﬁrst joint axis increases. The typical workspace is illustrated

8

1 Introduction

Fig. 1.8. Manipulator with parallelogram
Fig. 1.9. Parallel manipulator
in Fig. 1.6. The SCARA manipulator is suitable for manipulation of small objects; joints are actuated by electric motors.
Anthropomorphic geometry is realized by three revolute joints; the revolute axis of the ﬁrst joint is orthogonal to the axes of the other two which are parallel (Fig. 1.7). By virtue of its similarity with the human arm, the second joint is called the shoulder joint and the third joint the elbow joint since it connects the “arm” with the “forearm.” The anthropomorphic structure is the most dexterous one, since all the joints are revolute. On the other hand, the correspondence between the DOFs and the Cartesian space variables is lost, and wrist positioning accuracy varies inside the workspace. This is approximately a portion of a sphere (Fig. 1.7) and its volume is large compared to manipulator encumbrance. Joints are typically actuated by electric motors. The range of industrial applications of anthropomorphic manipulators is wide.

1.2 Robot Mechanical Structure

9

Fig. 1.10. Hybrid parallel-serial manipulator
According to the latest report by the International Federation of Robotics (IFR), up to 2005, 59% of installed robot manipulators worldwide has anthropomorphic geometry, 20% has Cartesian geometry, 12% has cylindrical geometry, and 8% has SCARA geometry.
All the previous manipulators have an open kinematic chain. Whenever larger payloads are required, the mechanical structure will have higher stiﬀness to guarantee comparable positioning accuracy. In such a case, resorting to a closed kinematic chain is advised. For instance, for an anthropomorphic structure, parallelogram geometry between the shoulder and elbow joints can be adopted, so as to create a closed kinematic chain (Fig. 1.8).
An interesting closed-chain geometry is parallel geometry (Fig. 1.9) which has multiple kinematic chains connecting the base to the end-eﬀector. The fundamental advantage is seen in the high structural stiﬀness, with respect to open-chain manipulators, and thus the possibility to achieve high operational speeds; the drawback is that of having a reduced workspace.
The geometry illustrated in Fig. 1.10 is of hybrid type, since it consists of a parallel arm and a serial kinematic chain. This structure is suitable for the execution of manipulation tasks requiring large values of force along the vertical direction.
The manipulator structures presented above are required to position the wrist which is then required to orient the manipulator’s end-eﬀector. If arbitrary orientation in 3D space is desired, the wrist must possess at least three DOFs provided by revolute joints. Since the wrist constitutes the terminal part of the manipulator, it has to be compact; this often complicates its mechanical design. Without entering into construction details, the realization endowing the wrist with the highest dexterity is one where the three revolute

10 1 Introduction
Fig. 1.11. Spherical wrist
axes intersect at a single point. In such a case, the wrist is called a spherical wrist, as represented in Fig. 1.11. The key feature of a spherical wrist is the decoupling between position and orientation of the end-eﬀector; the arm is entrusted with the task of positioning the above point of intersection, whereas the wrist determines the end-eﬀector orientation. Those realizations where the wrist is not spherical are simpler from a mechanical viewpoint, but position and orientation are coupled, and this complicates the coordination between the motion of the arm and that of the wrist to perform a given task.
The end-eﬀector is speciﬁed according to the task the robot should execute. For material handling tasks, the end-eﬀector consists of a gripper of proper shape and dimensions determined by the object to be grasped (Fig. 1.11). For machining and assembly tasks, the end-eﬀector is a tool or a specialized device, e.g., a welding torch, a spray gun, a mill, a drill, or a screwdriver.
The versatility and ﬂexibility of a robot manipulator should not induce the conviction that all mechanical structures are equivalent for the execution of a given task. The choice of a robot is indeed conditioned by the application which sets constraints on the workspace dimensions and shape, the maximum payload, positioning accuracy, and dynamic performance of the manipulator.
1.2.2 Mobile Robots
The main feature of mobile robots is the presence of a mobile base which allows the robot to move freely in the environment. Unlike manipulators, such robots are mostly used in service applications, where extensive, autonomous motion capabilities are required. From a mechanical viewpoint, a mobile robot consists of one or more rigid bodies equipped with a locomotion system. This description includes the following two main classes of mobile robots:1 • Wheeled mobile robots typically consist of a rigid body (base or chassis)
and a system of wheels which provide motion with respect to the ground. 1 Other types of mechanical locomotion systems are not considered here. Among
these, it is worth mentioning tracked locomotion, very eﬀective on uneven terrain, and undulatory locomotion, inspired by snake gaits, which can be achieved without speciﬁc devices. There also exist types of locomotion that are not constrained to the ground, such as ﬂying and navigation.

1.2 Robot Mechanical Structure 11
Fig. 1.12. The three types of conventional wheels with their respective icons
Other rigid bodies (trailers), also equipped with wheels, may be connected to the base by means of revolute joints. • Legged mobile robots are made of multiple rigid bodies, interconnected by prismatic joints or, more often, by revolute joints. Some of these bodies form lower limbs, whose extremities (feet) periodically come in contact with the ground to realize locomotion. There is a large variety of mechanical structures in this class, whose design is often inspired by the study of living organisms (biomimetic robotics): they range from biped humanoids to hexapod robots aimed at replicating the biomechanical eﬃciency of insects.
Only wheeled vehicles are considered in the following, as they represent the vast majority of mobile robots actually used in applications. The basic mechanical element of such robots is indeed the wheel. Three types of conventional wheels exist, which are shown in Fig. 1.12 together with the icons that will be used to represent them:
• The ﬁxed wheel can rotate about an axis that goes through the center of the wheel and is orthogonal to the wheel plane. The wheel is rigidly attached to the chassis, whose orientation with respect to the wheel is therefore constant.
• The steerable wheel has two axes of rotation. The ﬁrst is the same as a ﬁxed wheel, while the second is vertical and goes through the center of the wheel. This allows the wheel to change its orientation with respect to the chassis.
• The caster wheel has two axes of rotation, but the vertical axis does not pass through the center of the wheel, from which it is displaced by a constant oﬀset. Such an arrangement causes the wheel to swivel automatically, rapidly aligning with the direction of motion of the chassis. This type of wheel is therefore introduced to provide a supporting point for static balance without aﬀecting the mobility of the base; for instance, caster wheels are commonly used in shopping carts as well as in chairs with wheels.

12 1 Introduction
Fig. 1.13. A diﬀerential-drive mobile robot
Fig. 1.14. A synchro-drive mobile robot
The variety of kinematic structures that can be obtained by combining the three conventional wheels is wide. In the following, the most relevant arrangements are brieﬂy examined.
In a diﬀerential-drive vehicle there are two ﬁxed wheels with a common axis of rotation, and one or more caster wheels, typically smaller, whose function is to keep the robot statically balanced (Fig. 1.13). The two ﬁxed wheels are separately controlled, in that diﬀerent values of angular velocity may be arbitrarily imposed, while the caster wheel is passive. Such a robot can rotate on the spot (i.e., without moving the midpoint between the wheels), provided that the angular velocities of the two wheels are equal and opposite.
A vehicle with similar mobility is obtained using a synchro-drive kinematic arrangement (Fig. 1.14). This robot has three aligned steerable wheels which are synchronously driven by only two motors through a mechanical coupling, e.g., a chain or a transmission belt. The ﬁrst motor controls the rotation of the wheels around the horizontal axis, thus providing the driving force (traction) to the vehicle. The second motor controls the rotation of the wheels around the vertical axis, hence aﬀecting their orientation. Note that the heading of the chassis does not change during the motion. Often, a third motor is used in this type of robot to rotate independently the upper part of the chassis (a turret) with respect to the lower part. This may be useful to orient arbitrarily a directional sensor (e.g., a camera) or in any case to recover an orientation error.
In a tricycle vehicle (Fig. 1.15) there are two ﬁxed wheels mounted on a rear axle and a steerable wheel in front. The ﬁxed wheels are driven by a single

1.2 Robot Mechanical Structure 13
Fig. 1.15. A tricycle mobile robot
Fig. 1.16. A car-like mobile robot
motor which controls their traction,2 while the steerable wheel is driven by another motor which changes its orientation, acting then as a steering device. Alternatively, the two rear wheels may be passive and the front wheel may provide traction as well as steering.
A car-like vehicle has two ﬁxed wheels mounted on a rear axle and two steerable wheels mounted on a front axle, as shown in Fig. 1.16. As in the previous case, one motor provides (front or rear) traction while the other changes the orientation of the front wheels with respect to the vehicle. It is worth pointing out that, to avoid slippage, the two front wheels must have a diﬀerent orientation when the vehicle moves along a curve; in particular, the internal wheel is slightly more steered with respect to the external one. This is guaranteed by the use of a speciﬁc device called Ackermann steering.
Finally, consider the robot in Fig. 1.17, which has three caster wheels usually arranged in a symmetric pattern. The traction velocities of the three wheels are independently driven. Unlike the previous cases, this vehicle is omnidirectional : in fact, it can move instantaneously in any Cartesian direction, as well as re-orient itself on the spot.
In addition to the above conventional wheels, there exist other special types of wheels, among which is notably the Mecanum (or Swedish) wheel , shown in Fig. 1.18. This is a ﬁxed wheel with passive rollers placed along the external rim; the axis of rotation of each roller is typically inclined by 45◦ with respect to the plane of the wheel. A vehicle equipped with four such wheels mounted in pairs on two parallel axles is also omnidirectional. 2 The distribution of the traction torque on the two wheels must take into account
the fact that in general they move with diﬀerent speeds. The mechanism which equally distributes traction is the diﬀerential .

14 1 Introduction
Fig. 1.17. An omnidirectional mobile robot with three independently driven caster wheels
Fig. 1.18. A Mecanum (or Swedish) wheel
In the design of a wheeled robot, the mechanical balance of the structure does not represent a problem in general. In particular, a three-wheel robot is statically balanced as long as its center of mass falls inside the support triangle, which is deﬁned by the contact points between the wheels and ground. Robots with more than three wheels have a support polygon, and thus it is typically easier to guarantee the above balance condition. It should be noted, however, that when the robot moves on uneven terrain a suspension system is needed to maintain the contact between each wheel and the ground.
Unlike the case of manipulators, the workspace of a mobile robot (deﬁned as the portion of the surrounding environment that the robot can access) is potentially unlimited. Nevertheless, the local mobility of a non-omnidirectional mobile robot is always reduced; for instance, the tricycle robot in Fig. 1.15 cannot move instantaneously in a direction parallel to the rear wheel axle. Despite this fact, the tricycle can be manoeuvered so as to obtain, at the end of the motion, a net displacement in that direction. In other words, many mobile robots are subject to constraints on the admissible instantaneous motions, without actually preventing the possibility of attaining any position and orientation in the workspace. This also implies that the number of DOFs of the robot (meant as the number of admissible instantaneous motions) is lower than the number of its conﬁguration variables.
It is obviously possible to merge the mechanical structure of a manipulator with that of a mobile vehicle by mounting the former on the latter. Such a robot is called a mobile manipulator and combines the dexterity of the articulated arm with the unlimited mobility of the base. An example of such a mechanical structure is shown in Fig. 1.19. However, the design of a mobile manipulator involves additional diﬃculties related, for instance, to the static

1.3 Industrial Robotics 15
Fig. 1.19. A mobile manipulator obtained by mounting an anthropomorphic arm on a diﬀerential-drive vehicle
and dynamic mechanical balance of the robot, as well as to the actuation of the two systems.
1.3 Industrial Robotics
Industrial robotics is the discipline concerning robot design, control and applications in industry, and its products have by now reached the level of a mature technology. The connotation of a robot for industrial applications is that of operating in a structured environment whose geometrical or physical characteristics are mostly known a priori. Hence, limited autonomy is required.
The early industrial robots were developed in the 1960s, at the conﬂuence of two technologies: numerical control machines for precise manufacturing, and teleoperators for remote radioactive material handling. Compared to its precursors, the ﬁrst robot manipulators were characterized by: • versatility, in view of the employment of diﬀerent end-eﬀectors at the tip
of the manipulator, • adaptability to a priori unknown situations, in view of the use of sensors, • positioning accuracy, in view of the adoption of feedback control tech-
niques, • execution repeatability, in view of the programmability of various opera-
tions. During the subsequent decades, industrial robots have gained a wide popularity as essential components for the realization of automated manufacturing

16 1 Introduction

140,000 120,000

127 112

100,000

99

97

80,000

77 82

79

69

69

78

81

69

60,000 53 55

Units

40,000

20,000

0 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006

Fig. 1.20. Yearly installations of industrial robots worldwide

systems. The main factors having determined the spread of robotics technology in an increasingly wider range of applications in the manufacturing industry are reduction of manufacturing costs, increase of productivity, improvement of product quality standards and, last but not least, the possibility of eliminating harmful or oﬀ-putting tasks for the human operator in a manufacturing system.
By its usual meaning, the term automation denotes a technology aimed at replacing human beings with machines in a manufacturing process, as regards not only the execution of physical operations but also the intelligent processing of information on the status of the process. Automation is then the synthesis of industrial technologies typical of the manufacturing process and computer technology allowing information management. The three levels of automation one may refer to are rigid automation, programmable automation, and ﬂexible automation.
Rigid automation deals with a factory context oriented to the mass manufacture of products of the same type. The need to manufacture large numbers of parts with high productivity and quality standards demands the use of ﬁxed operational sequences to be executed on the workpiece by special purpose machines.
Programmable automation deals with a factory context oriented to the manufacture of low-to-medium batches of products of diﬀerent types. A programmable automated system permits changing easy the sequence of operations to be executed on the workpieces in order to vary the range of products. The machines employed are more versatile and are capable of manufacturing diﬀerent objects belonging to the same group technology. The majority of the products available on the market today are manufactured by programmable automated systems.

1.3 Industrial Robotics 17

Automotive parts

Motor vehicles

Chemical, rubber and plastics

Electrical/electronics

Metal products
Machinery (industrial and consumer)
Food

2005 2006

Communication

Precision and optical products

0

5,000

10,000 15,000 20,000 25,000 30,000

Units

Fig. 1.21. Yearly supply of industrial robots by main industries

Flexible automation represents the evolution of programmable automation. Its goal is to allow manufacturing of variable batches of diﬀerent products by minimizing the time lost for reprogramming the sequence of operations and the machines employed to pass from one batch to the next. The realization of a ﬂexible manufacturing system (FMS) demands strong integration of computer technology with industrial technology.
The industrial robot is a machine with signiﬁcant characteristics of versatility and ﬂexibility. According to the widely accepted deﬁnition of the Robot Institute of America, a robot is a reprogrammable multifunctional manipulator designed to move materials, parts, tools or specialized devices through variable programmed motions for the performance of a variety of tasks. Such a deﬁnition, dating back to 1980, reﬂects the current status of robotics technology.
By virtue of its programmability, the industrial robot is a typical component of programmable automated systems. Nonetheless, robots can be entrusted with tasks in both rigid and ﬂexible automated systems.
According to the above-mentioned IFR report, up to 2006 nearly one million industrial robots are in use worldwide, half of which are in Asia, one third in Europe, and 16% in North America. The four countries with the largest number of robots are Japan, Germany, United States and Italy. The ﬁgures for robot installations in the last 15 years are summarized in the graph in Fig. 1.20; by the end of 2007, an increase of 10% in sales with respect to the previous year is foreseen, with milder increase rates in the following years, reaching a worldwide ﬁgure of 1,200,000 units at work by the end of 2010.
In the same report it is shown how the average service life of an industrial robot is about 12 years, which may increase to 15 in a few years from now. An interesting statistic is robot density based on the total number of persons employed: this ranges from 349 robots in operation per 10,000 workers to

18 1 Introduction
Fig. 1.22. Examples of AGVs for material handling (courtesy of E&K Automation GmbH)
187 in Korea, 186 in Germany, and 13 in Italy. The United States has just 99 robots per 10,000 workers. The average cost of a 6-axis industrial robot, including the control unit and development software, ranges from 20,000 to 60,000 euros, depending on the size and applications.
The automotive industry is still the predominant user of industrial robots. The graph in Fig. 1.21 referring to 2005 and 2006, however, reveals how both the chemical industry and the electrical/electronics industry are gaining in importance, and new industrial applications, such as metal products, constitute an area with a high potential investment.
Industrial robots present three fundamental capacities that make them useful for a manufacturing process: material handling, manipulation, and measurement .
In a manufacturing process, each object has to be transferred from one location in the factory to another in order to be stored, manufactured, assembled, and packed. During transfer, the physical characteristics of the object do not undergo any alteration. The robot’s capability to pick up an object, move it in space on predeﬁned paths and release it makes the robot itself an ideal candidate for material handling operations. Typical applications include: • palletizing (placing objects on a pallet in an ordered way), • warehouse loading and unloading, • mill and machine tool tending, • part sorting, • packaging.
In these applications, besides robots, Automated Guided Vehicles (AGV) are utilized which ensure handling of parts and tools around the shop ﬂoor

1.3 Industrial Robotics 19

Handling

Welding

Assembly Dispensing

2005 2006

Processing

Others

0

2,000 4,000 6,000 8,000 10,000 12,000 14,000 16,000 18,000

Units

Fig. 1.23. Yearly supply of industrial robots in Europe for manufacturing operations

from one manufacturing cell to the next (Fig. 1.22). As compared to the traditional ﬁxed guide paths for vehicles (inductive guide wire, magnetic tape, or optical visible line), modern AGVs utilize high-tech systems with onboard microprocessors and sensors (laser, odometry, GPS) which allow their localization within the plant layout, and manage their work ﬂow and functions, allowing their complete integration in the FMS. The mobile robots employed in advanced applications can be considered as the natural evolution of the AGV systems, as far as enhanced autonomy is concerned.
Manufacturing consists of transforming objects from raw material into ﬁnished products; during this process, the part either changes its own physical characteristics as a result of machining, or loses its identity as a result of an assembly of more parts. The robot’s capability to manipulate both objects and tools make it suitable to be employed in manufacturing. Typical applications include:
• arc and spot welding, • painting and coating, • gluing and sealing, • laser and water jet cutting, • milling and drilling, • casting and die spraying, • deburring and grinding, • screwing, wiring and fastening, • assembly of mechanical and electrical groups, • assembly of electronic boards.

20 1 Introduction
Fig. 1.24. The AdeptOne XL robot (courtesy of Adept Technology Inc)
Besides material handling and manipulation, in a manufacturing process it is necessary to perform measurements to test product quality. The robot’s capability to explore 3D space together with the availability of measurements on the manipulator’s status allow a robot to be used as a measuring device. Typical applications include: • object inspection, • contour ﬁnding, • detection of manufacturing imperfections.
The graph in Fig. 1.23 reports the number of robots employed in Europe in 2005 and 2006 for various operations, which reveals how material handling requires twice as many robots employed for welding, whereas a limited number of robots is still employed for assembly.
In the following some industrial robots are illustrated in terms of their features and application ﬁelds.
The AdeptOne XL robot in Fig. 1.24 has a four-joint SCARA structure. Direct drive motors are employed. The maximum reach is 800 mm, with a repeatability of 0.025 mm horizontally and 0.038 mm vertically. Maximum speeds are 1200 mm/s for the prismatic joint, while they range from to 650 to 3300 deg/s for the three revolute joints. The maximum payload3 is 12 kg. Typical industrial applications include small-parts material handling, assembly and packaging.
3 Repeatability and payload are classical parameters found in industrial robot data sheets. The former gives a measure of the manipulator’s ability to return to a previously reached position, while the latter indicates the average load to be carried at the robot’s end-eﬀector.

1.3 Industrial Robotics 21
Fig. 1.25. The COMAU Smart NS robot (courtesy of COMAU SpA Robotica)
Fig. 1.26. The ABB IRB 4400 robot (courtesy of ABB Robotics) The Comau SMART NS robot in Fig. 1.25 has a six-joint anthropomorphic structure with spherical wrist. In its four versions, the outreach ranges from 1650 and 1850 mm horizontally, with a repeatability of 0.05 mm. Maximum speeds range from 155 to 170 deg/s for the inner three joints, and from 350 to 550 deg/s for the outer three joints. The maximum payload is 16 kg. Both ﬂoor and ceiling mounting positions are allowed. Typical industrial applications include arc welding, light handling, assembly and technological processes. The ABB IRB 4400 robot in Fig. 1.26 also has a six-joint anthropomorphic structure, but unlike the previous open-chain structure, it possesses a closed chain of parallelogram type between the shoulder and elbow joints. The outreach ranges from 1960 to 2550 mm for the various versions, with a

22 1 Introduction
Fig. 1.27. The KUKA KR 60 Jet robot (courtesy of KUKA Roboter GmbH)
repeatability from 0.07 to 0.1 mm. The maximum speed at the end-eﬀector is 2200 mm/s. The maximum payload is 60 kg. Floor or shelf-mounting is available. Typical industrial applications include material handling, machine tending, grinding, gluing, casting, die spraying and assembly.
The KUKA KR 60 Jet robot in Fig. 1.27 is composed of a ﬁve-axis structure, mounted on a sliding track with a gantry-type installation; the upright installation is also available. The linear unit has a stroke from a minimum of 400 mm to a maximum of 20 m (depending on customer’s request), and a maximum speed of 3200 mm/s. On the other hand, the robot has a payload of 60 kg, an outreach of 820 mm and a repeatability of 0.15 mm. Maximum speeds are 120 deg/s and 166 deg/s for the ﬁrst two joints, while they range from 260 to 322 deg/s for the outer three joints. Typical industrial applications include machine tending, arc welding, deburring, coating, sealing, plasma and waterjet cutting.
The ABB IRB340 FlexPicker robot in Fig. 1.28 adopts a parallel geometry with four axes; in view of its reduced weight and ﬂoor mounting, the robot can transport 150 objects a minute (cycle time of just 0.4 s), reaching record speeds of 10 m/s and accelerations of 100 m/s2, for a payload of 1 kg, with a repeatability of 0.1 mm. In its ‘clean’ aluminum version, it is particularly suitable for packaging in the food and pharmaceutical industries.
The Fanuc M-16iB robot in Fig. 1.29 has a six-joint anthropomorphic structure with a spherical wrist. In its two versions, the outreach varies from 1667 to 1885 mm horizontally, with a repeatability of 0.1 mm. Maximum speeds range from 165 to 175 deg/s for the inner three joints, and from 340 to 520 deg/s for the outer three joints. Payload varies from 10 to 20 kg. The peculiarity of this robot consists of the integrated sensors in the control unit, including a servoing system based on 3D vision and a six-axis force sensor.

1.3 Industrial Robotics 23
Fig. 1.28. The ABB IRB 340 FlexPicker robot (courtesy of ABB Robotics)
Fig. 1.29. The Fanuc M-16iB robot (courtesy of Fanuc Ltd) The robot is utilized for handling arbitrarily located objects, deburring, sealing and waterjet cutting.
The Light Weight Robot (LWR) in Fig. 1.30 with a seven-axis structure was introduced in 2006 as the outcome of technology transfer from DLR (the German Aerospace Agency) to KUKA. In view of the adoption of lightweight materials, as well as the adoption of torque sensors at the joints, the robot can manipulate a payload of 7 to 14 kg, in the face of a weight of the structure of just 15 kg. The horizontal outreach is 868 mm, with joint speeds ranging from 110 to 210 deg/s. On the other hand, the presence of the seventh axis of motion confers kinematic redundancy to the robot, which can then be reconﬁgured into more dexterous postures for the execution of given tasks. Such

24 1 Introduction
Fig. 1.30. The KUKA LWR robot (courtesy of KUKA Roboter GmbH)
a manipulator represents one of the most advanced industrial products and, in view of its lightweight feature, it oﬀers interesting performance for interaction with the environment, ensuring an inherent safety in case of contact with human beings.
In most industrial applications requiring object manipulation, typical grippers are utilized as end-eﬀectors. Nevertheless, whenever enhanced manipulability and dexterity is desired, multiﬁngered robot hands are available.
The BarrettHand (Fig. 1.31), endowed with a ﬁxed ﬁnger and two mobile ﬁngers around the base of the palm, allows the manipulation of objects of diﬀerent dimension, shape and orientation.
The SCHUNK Antropomorphic Hand (SAH) in Fig. 1.32 is the outcome of technology transfer from DLR and Harbin Institute of Technology (China) to SCHUNK. Characterized by three independent aligned ﬁngers and an opposing ﬁnger which is analogous to the human thumb. The ﬁnger joints are endowed with magnetic angular sensors and torque sensors. This hand oﬀers good dexterity and approaches the characteristics of the human hand.
LWR technology has been employed for the realization of the two arms of Justin, a humanoid manipulator made by DLR, composed of a three-joint torso with an anthropomorphic structure, two seven-axis arms and a sensorized head. The robot is illustrated in Fig. 1.33 in the execution of a bimanual manipulation task; the hands employed are previous versions of the SAH anthropomorphic hand.
The applications listed describe the current employment of robots as components of industrial automation systems. They all refer to strongly structured working environments and thus do not exhaust all the possible utilizations of robots for industrial applications. Whenever it is desired to tackle problems requiring the adaptation of the robot to a changeable working environment, the fall-out of advanced robotics products are of concern. In this regard, the

1.4 Advanced Robotics 25
Fig. 1.31. The BarrettHand (courtesy of Barrett Technology Inc)
Fig. 1.32. The SCHUNK Anthropomorphic Hand (courtesy of SCHUNK Intec Ltd)
lightweight robot, the hands and the humanoid manipulator presented above are to be considered at the transition from traditional industrial robotics systems toward those innovative systems of advanced robotics.
1.4 Advanced Robotics
The expression advanced robotics usually refers to the science studying robots with marked characteristics of autonomy, operating in scarcely structured or unstructured environments, whose geometrical or physical characteristics would not be known a priori.
Nowadays, advanced robotics is still in its youth. It has indeed featured the realization of prototypes only, because the associated technology is not yet mature. There are many motivations which strongly encourage advances in knowledge within this ﬁeld. They range from the need for automata whenever human operators are not available or are not safe (ﬁeld robots), to the opportunity of developing products for potentially wide markets which are aimed at improving quality of life (service robots).
The graph in Fig. 1.34 reports the number of robots in stock for nonindustrial applications at the end of 2006 and the forecast to 2010. Such applications are characterized by the complexity level, the uncertainty and variability of the environment with which the robot interacts, as shown in the following examples.

26 1 Introduction
Fig. 1.33. The Justin humanoid robot manipulator (courtesy of DLR)
1.4.1 Field Robots The context is that of deploying robots in areas where human beings could not survive or be exposed to unsustainable risks. Such robots should carry out exploration tasks and report useful data on the environment to a remote operator, using suitable onboard sensors. Typical scenarios are the exploration of a volcano, the intervention in areas contaminated by poisonous gas or radiation, or the exploration of the deep ocean or space. As is well known, NASA succeeded in delivering some mobile robots (rovers) to Mars (Fig. 1.35) which navigated on the Martian soil, across rocks, hills and crevasses. Such rovers were partially teleoperated from earth and have successfully explored the environment with suﬃcient autonomy. Some mini-robots were deployed on September 11, 2001 at Ground Zero after the collapse of the Twin Towers in New York, to penetrate the debris in the search for survivors.
A similar scenario is that of disasters caused by ﬁres in tunnels or earthquakes; in such occurrences, there is a danger of further explosions, escape of harmful gases or collapse, and thus human rescue teams may cooperate with robot rescue teams. Also in the military ﬁeld, unmanned autonomous aircrafts and missiles are utilized, as well as teleoperated robots with onboard cameras to explore buildings. The ‘Grand Challenge’ of October 2005 (Fig. 1.36) was ﬁnancially supported by the US Department of Defense (DARPA) with the goal of developing autonomous vehicles to carry weapons and sensors, thus reducing soldier employment.

Units

1.4 Advanced Robotics 27

14,000

12,000 10,000

Stock at the end of 2006 New installations 2007í2010

8,000

6,000

4,000

2,000

0

Underwater Defense, rescue, security
Cleaning

Hostile fields

Medical

Others

Mobile platforms

Logistics

Construction and demolition

Fig. 1.34. Robots on stock for non-industrial applications

Fig. 1.35. The Sojourner rover was deployed by the Pathﬁnder lander and explored 250 m2 of Martian soil in 1997 (courtesy of NASA)
1.4.2 Service Robots
Autonomous vehicles are also employed for civil applications, i.e., for mass transit systems (Fig. 1.37), thus contributing to the reduction of pollution levels. Such vehicles are part of the so-called Intelligent Transportation Systems (ITS) devoted to traﬃc management in urban areas. Another feasible application where the adoption of mobile robots oﬀers potential advantages is museum guided tours (Fig. 1.38).
Many countries are investing in establishing the new market of service robots which will co-habitat with human beings in everyday life. According to the above-mentioned IFR report, up to 2005 1.9 million service robots for domestic applications (Fig. 1.39) and 1 million toy robots have been sold.
Technology is ready to transform into commercial products the prototypes of robotic aids to enhance elderly and impaired people’s autonomy in everyday life; autonomous wheelchairs, mobility aid lifters, feeding aids and rehabilitation robots allowing tetraplegics to perform manual labor tasks are examples of such service devices. In perspective, other than an all-purpose robot waiter,

28 1 Introduction
Fig. 1.36. The unmanned car Stanley autonomously completed a path of 132 miles in the record time of 6 h and 53 min (courtesy of DARPA)
Fig. 1.37. The Cycab is an electrically-driven vehicle for autonomous transportation in urban environments (courtesy of INRIA) assistance, and healthcare systems integrating robotic and telematic modules will be developed for home service management (domotics).
Several robotic systems are employed for medical applications. Surgery assistance systems exploit a robot’s high accuracy to position a tool, i.e., for hip prosthesis implant. Yet, in minimally-invasive surgery, i.e., cardiac surgery, the surgeon operates while seated comfortably at a console viewing a 3D image of the surgical ﬁeld, and operating the surgical instruments remotely by means of a haptic interface (Fig. 1.40).
Further, in diagnostic and endoscopic surgery systems, small teleoperated robots travels through the cavities of human body, i.e., in the gastrointestinal system, bringing live images or intervening in situ for biopsy, dispensing drugs or removing neoplasms.

1.5 Robot Modelling, Planning and Control 29
Fig. 1.38. Rhino, employing the synchro-drive mobile base B21 by Real World Interface, was one of the ﬁrst robots for museum guided tours (courtesy of Deutsches Museum Bonn)
Fig. 1.39. The vacuum robot Roomba, employing a diﬀerential-drive kinematics, autonomously sweeps and cleans ﬂoors (courtesy of I-Robot Corp)
Finally, in motor rehabilitation systems, a hemiplegic patient wears an exoskeleton, which actively interacts, sustains and corrects the movements according to the physiotherapist’s programmed plan.
Another wide market segment comes from entertainment, where robots are used as toy companions for children, and life companions for the elderly, such as humanoid robots (Fig. 1.41) and the pet robots (Fig. 1.42) being developed in Japan. It is reasonable to predict that service robots will be naturally integrated into our society. Tomorrow, robots will be as pervasive and personal as today’s personal computers, or just as TV sets in the homes of 20 years ago. Robotics will then become ubiquitous, a challenge under discussion within the scientiﬁc community.
1.5 Robot Modelling, Planning and Control
In all robot applications, completion of a generic task requires the execution of a speciﬁc motion prescribed to the robot. The correct execution of such

30 1 Introduction
Fig. 1.40. The da Vinci robotic system for laparoscopic surgery (courtesy of Intuitive Surgical Inc)
motion is entrusted to the control system which should provide the robot’s actuators with the commands consistent with the desired motion. Motion control demands an accurate analysis of the characteristics of the mechanical structure, actuators, and sensors. The goal of such analysis is the derivation of the mathematical models describing the input/output relationship characterizing the robot components. Modelling a robot manipulator is therefore a necessary premise to ﬁnding motion control strategies.
Signiﬁcant topics in the study of modelling, planning and control of robots which constitute the subject of subsequent chapters are illustrated below.
1.5.1 Modelling Kinematic analysis of the mechanical structure of a robot concerns the description of the motion with respect to a ﬁxed reference Cartesian frame by ignoring the forces and moments that cause motion of the structure. It is meaningful to distinguish between kinematics and diﬀerential kinematics. With reference to a robot manipulator, kinematics describes the analytical relationship between the joint positions and the end-eﬀector position and orientation. Diﬀerential kinematics describes the analytical relationship between the joint motion and the end-eﬀector motion in terms of velocities, through the manipulator Jacobiann.
The formulation of the kinematics relationship allows the study of two key problems of robotics, namely, the direct kinematics problem and the inverse kinematics problem. The former concerns the determination of a systematic, general method to describe the end-eﬀector motion as a function of the joint motion by means of linear algebra tools. The latter concerns the

1.5 Robot Modelling, Planning and Control 31
Fig. 1.41. The Asimo humanoid robot, launched in 1996, has been endowed with even more natural locomotion and human-robot interaction skills (courtesy of Honda Motor Company Ltd)
Fig. 1.42. The AIBO dog had been the most widely diﬀused entertainment robot in the recent years (courtesy of Sony Corp)
inverse problem; its solution is of fundamental importance to transform the desired motion, naturally prescribed to the end-eﬀector in the workspace, into the corresponding joint motion.
The availability of a manipulator’s kinematic model is also useful to determine the relationship between the forces and torques applied to the joints and the forces and moments applied to the end-eﬀector in static equilibrium conﬁgurations.
Chapter 2 is dedicated to the study of kinematics. Chapter 3 is dedicated to the study of diﬀerential kinematics and statics, whereas Appendix A provides a useful brush-up on linear algebra.
Kinematics of a manipulator represents the basis of a systematic, general derivation of its dynamics, i.e., the equations of motion of the manipulator as a function of the forces and moments acting on it. The availability of the dynamic model is very useful for mechanical design of the structure, choice of actuators, determination of control strategies, and computer simulation of

32 1 Introduction
manipulator motion. Chapter 7 is dedicated to the study of dynamics, whereas Appendix B recalls some fundamentals on rigid body mechanics.
Modelling of mobile robots requires a preliminary analysis of the kinematic constraints imposed by the presence of wheels. Depending on the mechanical structure, such constraints can be integrable or not; this has direct consequence on a robot’s mobility. The kinematic model of a mobile robot is essentially the description of the admissible instantaneous motions in respect of the constraints. On the other hand, the dynamic model accounts for the reaction forces and describes the relationship between the above motions and the generalized forces acting on the robot. These models can be expressed in a canonical form which is convenient for design of planning and control techniques. Kinematic and dynamic analysis of mobile robots is developed in Chap. 11, while Appendix D contains some useful concepts of diﬀerential geometry .
1.5.2 Planning
With reference to the tasks assigned to a manipulator, the issue is whether to specify the motion at the joints or directly at the end-eﬀector. In material handling tasks, it is suﬃcient to assign only the pick-up and release locations of an object (point-to-point motion), whereas, in machining tasks, the endeﬀector has to follow a desired trajectory (path motion). The goal of trajectory planning is to generate the timing laws for the relevant variables (joint or endeﬀector) starting from a concise description of the desired motion. Chapter 4 is dedicated to trajectory planning for robot manipulators.
The motion planning problem for a mobile robot concerns the generation of trajectories to take the vehicle from a given initial conﬁguration to a desired ﬁnal conﬁguration. Such a problem is more complex than that of robot manipulators, since trajectories have to be generated in respect of the kinematic constraints imposed by the wheels. Some solution techniques are presented in Chap. 11, which exploit the speciﬁc diﬀerential structure of the mobile robots’ kinematic models.
Whenever obstacles are present in a mobile robot’s workspace, the planned motions must be safe, so as to avoid collisions. Such a problem, known as motion planning, can be formulated in an eﬀective fashion for both robot manipulators and mobile robots utilizing the conﬁguration space concept. The solution techniques are essentially of algorithmic nature and include exact, probabilistic and heuristic methods. Chapter 12 is dedicated to motion planning problem, while Appendix E provides some basic concepts on graph search algorithms .
1.5.3 Control
Realization of the motion speciﬁed by the control law requires the employment of actuators and sensors. The functional characteristics of the most commonly used actuators and sensors for robots are described in Chap. 5.

Bibliography 33
Chapter 6 is concerned with the hardware/software architecture of a robot’s control system which is in charge of implementation of control laws as well as of interface with the operator.
The trajectories generated constitute the reference inputs to the motion control system of the mechanical structure. The problem of robot manipulator control is to ﬁnd the time behaviour of the forces and torques to be delivered by the joint actuators so as to ensure the execution of the reference trajectories. This problem is quite complex, since a manipulator is an articulated system and, as such, the motion of one link inﬂuences the motion of the others. Manipulator equations of motion indeed reveal the presence of coupling dynamic eﬀects among the joints, except in the case of a Cartesian structure with mutually orthogonal axes. The synthesis of the joint forces and torques cannot be made on the basis of the sole knowledge of the dynamic model, since this does not completely describe the real structure. Therefore, manipulator control is entrusted to the closure of feedback loops; by computing the deviation between the reference inputs and the data provided by the proprioceptive sensors, a feedback control system is capable of satisfying accuracy requirements on the execution of the prescribed trajectories.
Chapter 8 is dedicated to the presentation of motion control techniques, whereas Appendix C illustrates the basic principles of feedback control .
Control of a mobile robot substantially diﬀers from the analogous problem for robot manipulators. This is due, in turn, to the availability of fewer control inputs than the robot has conﬁguration variables. An important consequence is that the structure of a controller allowing a robot to follow a trajectory (tracking problem) is unavoidably diﬀerent from that of a controller aimed at taking the robot to a given conﬁguration (regulation problem). Further, since a mobile robot’s proprioceptive sensors do not yield any data on the vehicle’s conﬁguration, it is necessary to develop localization methods for the robot in the environment. The control design problem for wheeled mobile robots is treated in Chap. 11.
If a manipulation task requires interaction between the robot and the environment, the control problem should account for the data provided by the exteroceptive sensors; the forces exchanged at the contact with the environment, and the objects’ position as detected by suitable cameras. Chapter 9 is dedicated to force control techniques for robot manipulators, while Chap. 10 presents visual control techniques.
Bibliography
In the last 30 years, the robotics ﬁeld has stimulated the interest of an increasing number of scholars. A truly respectable international research community has been established. Literature production has been conspicuous, both in terms of textbooks and scientiﬁc monographs and in terms of journals dedicated to robotics. Therefore, it seems appropriate to close this introduction

34 1 Introduction
by oﬀering a selection of bibliographical reference sources to those readers who wish to make a thorough study of robotics.
Besides indicating those basic textbooks sharing an aﬃnity of contents with this one, the following lists include specialized books on related subjects, collections of contributions on the state of the art of research, scientiﬁc journals, and series of international conferences.
Basic textbooks
• J. Angeles, Fundamentals of Robotic Mechanical Systems: Theory, Methods, and Algorithms, Springer-Verlag, New York, 1997.
• H. Asada, J.-J.E. Slotine, Robot Analysis and Control , Wiley, New York, 1986.
• G.A. Bekey, Autonomous Robots, MIT Press, Cambridge, MA, 2005. • C. Canudas de Wit, B. Siciliano, G. Bastin, (Eds.), Theory of Robot Con-
trol , Springer-Verlag, London, 1996. • J.J. Craig, Introduction to Robotics: Mechanics and Control , 3rd ed., Pear-
son Prentice Hall, Upper Saddle River, NJ, 2004. • A.J. Critchlow, Introduction to Robotics, Macmillan, New York, 1985. • J.F. Engelberger, Robotics in Practice, Amacom, New York, 1980. • J.F. Engelberger, Robotics in Service, MIT Press, Cambridge, MA, 1989. • K.S. Fu, R.C. Gonzalez, C.S.G. Lee, Robotics: Control, Sensing, Vision,
and Intelligence, McGraw-Hill, New York, 1987. • W. Khalil, E. Dombre, Modeling, Identiﬁcation and Control of Robots,
Hermes Penton Ltd, London, 2002. • A.J. Koivo, Fundamentals for Control of Robotic Manipulators, Wiley,
New York, 1989. • Y. Koren, Robotics for Engineers, McGraw-Hill, New York, 1985. • F.L. Lewis, C.T. Abdallah, D.M. Dawson, Control of Robot Manipulators,
Macmillan, New York, 1993. • P.J. McKerrow, Introduction to Robotics, Addison-Wesley, Sydney, Aus-
tralia, 1991. • R.M. Murray, Z. Li, S.S. Sastry, A Mathematical Introduction to Robotic
Manipulation, CRC Press, Boca Raton, FL, 1994. • S.B. Niku, Introduction to Robotics: Analysis, Systems, Applications,
Prentice-Hall, Upper Saddle River, NJ, 2001. • R.P. Paul, Robot Manipulators: Mathematics, Programming, and Control
MIT Press, Cambridge, MA, 1981. • R.J. Schilling, Fundamentals of Robotics: Analysis and Control , Prentice-
Hall, Englewood Cliﬀs, NJ, 1990. • L. Sciavicco, B. Siciliano, Modelling and Control of Robot Manipulators,
2nd ed., Springer, London, UK, 2000. • W.E. Snyder, Industrial Robots: Computer Interfacing and Control , Pren-
tice-Hall, Englewood Cliﬀs, NJ, 1985.

Bibliography 35
• M.W. Spong, S. Hutchinson, M. Vidyasagar, Robot Modeling and Control , Wiley, New York, 2006.
• M. Vukobratovi´c, Introduction to Robotics, Springer-Verlag, Berlin, Germany, 1989.
• T. Yoshikawa, Foundations of Robotics, MIT Press, Boston, MA, 1990.
Specialized books
Topics of related interest to robot modelling, planning and control are:
• manipulator mechanical design, • manipulation tools, • manipulators with elastic members, • parallel robots, • locomotion apparatus, • mobile robots, • underwater and space robots, • control architectures • motion and force control, • robot vision, • multisensory data fusion, • telerobotics, • human-robot interaction.
The following books are dedicated to these topics:
• G. Antonelli, Underwater Robots: Motion and Force Control of VehicleManipulator Systems, 2nd ed., Springer, Heidelberg, Germany, 2006.
• R.C. Arkin, Behavior-Based Robotics, MIT Press, Cambridge, MA, 1998. • J. Baeten, J. De Schutter, Integrated Visual Servoing and Force Control:
The Task Frame Approach, Springer, Heidelberg, Germany, 2003. • M. Buehler, K. Iagnemma, S. Singh, (Eds.), The 2005 DARPA Grand
Challenge: The Great Robot Race, Springer, Heidelberg, Germany, 2007. • J.F. Canny, The Complexity of Robot Motion Planning, MIT Press, Cam-
bridge, MA, 1988. • H. Choset, K.M. Lynch, S. Hutchinson, G. Kantor, W. Burgard, L.E.
Kavraki, S. Thrun, Principles of Robot Motion: Theory, Algorithms, and Implementations, MIT Press, Cambridge, MA, 2005. • P.I. Corke, Visual Control of Robots: High-Performance Visual Servoing, Research Studies Press, Taunton, UK, 1996. • M.R. Cutkosky, Robotic Grasping and Fine Manipulation, Kluwer, Boston, MA, 1985. • H.F. Durrant-Whyte, Integration, Coordination and Control of MultiSensor Robot Systems, Kluwer, Boston, MA, 1988. • A. Ellery, An Introduction to Space Robotics, Springer-Verlag, London, UK, 2000.

36 1 Introduction
• A.R. Fraser, R.W. Daniel, Perturbation Techniques for Flexible Manipulators, Kluwer, Boston, MA, 1991.
• B.K. Ghosh, N. Xi, T.-J. Tarn, (Eds.), Control in Robotics and Automation: Sensor-Based Integration, Academic Press, San Diego, CA, 1999.
• K. Goldberg, (Ed.), The Robot in the Garden: Telerobotics and Telepistemology in the Age of the Internet, MIT Press, Cambridge, MA, 2000.
• S. Hirose, Biologically Inspired Robots, Oxford University Press, Oxford, UK, 1993.
• B.K.P. Horn, Robot Vision, McGraw-Hill, New York, 1986. • K. Iagnemma, S. Dubowsky, Mobile Robots in Rough Terrain Estimation:
Motion Planning, and Control with Application to Planetary Rovers Series, Springer, Heidelberg, Germany, 2004. • R. Kelly, V. Santiban˜ez, A. Lor´ıa, Control of Robot Manipulators in Joint Space, Springer-Verlag, London, UK, 2005. • J.-C. Latombe, Robot Motion Planning, Kluwer, Boston, MA, 1991. • M.T. Mason, Mechanics of Robotic Manipulation, MIT Press, Cambridge, MA, 2001. • M.T. Mason, J.K. Salisbury, Robot Hands and the Mechanics of Manipulation, MIT Press, Cambridge, MA, 1985. • J.-P. Merlet, Parallel Robots, 2nd ed., Springer, Dordrecht, The Netherlands, 2006. • R.R. Murphy, Introduction to AI Robotics, MIT Press, Cambridge, MA, 2000. • C. Natale, Interaction Control of Robot Manipulators: Six-degrees-offreedom Tasks, Springer, Heidelberg, Germany, 2003. • M. Raibert, Legged Robots that Balance, MIT Press, Cambridge, MA, 1985. • E.I. Rivin, Mechanical Design of Robots, McGraw-Hill, New York, 1987. • B. Siciliano, L. Villani, Robot Force Control , Kluwer, Boston, MA, 2000. • R. Siegwart, Introduction to Autonomous Mobile Robots, MIT Press, Cambridge, MA, 2004. • S. Thrun, W. Burgard, D. Fox, Probabilistic Robotics, MIT Press, Cambridge, MA, 2005. • D.J. Todd, Walking Machines, an Introduction to Legged Robots, Chapman Hall, London, UK, 1985. • L.-W. Tsai, Robot Analysis: The Mechanics of Serial and Parallel Manipulators, Wiley, New York, 1999.
Edited collections on the state of the art of research
• M. Brady, (Ed.), Robotics Science, MIT Press, Cambridge, MA, 1989. • M. Brady, J.M. Hollerbach, T.L. Johnson, T. Lozano-P´erez, M.T. Mason,
(Eds.), Robot Motion: Planning and Control , MIT Press, Cambridge, MA, 1982. • R.C. Dorf, International Encyclopedia of Robotics, Wiley, New York, 1988.

Bibliography 37
• V.D. Hunt, Industrial Robotics Handbook , Industrial Press, New York, 1983.
• O. Khatib, J.J. Craig, T. Lozano-P´erez, (Eds.), The Robotics Review 1 , MIT Press, Cambridge, MA, 1989.
• O. Khatib, J.J. Craig, T. Lozano-P´erez, (Eds.), The Robotics Review 2 , MIT Press, Cambridge, MA., 1992.
• T.R. Kurfess, (Ed.), Robotics and Automation Handbook , CRC Press, Boca Raton, FL, 2005.
• B. Siciliano, O. Khatib, (Eds.), Springer Handbook of Robotics, Springer, Heidelberg, Germany, 2008.
• C.S.G. Lee, R.C. Gonzalez, K.S. Fu, (Eds.), Tutorial on Robotics, 2nd ed., IEEE Computer Society Press, Silver Spring, MD, 1986.
• M.W. Spong, F.L. Lewis, C.T. Abdallah, (Eds.), Robot Control: Dynamics, Motion Planning, and Analysis, IEEE Press, New York, 1993.
Scientiﬁc journals
• Advanced Robotics • Autonomous Robots • IEEE Robotics and Automation Magazine • IEEE Transactions on Robotics • International Journal of Robotics Research • Journal of Field Robotics • Journal of Intelligent and Robotic Systems • Robotica • Robotics and Autonomous Systems
Series of international scientiﬁc conferences
• IEEE International Conference on Robotics and Automation • IEEE/RSJ International Conference on Intelligent Robots and Systems • International Conference on Advanced Robotics • International Symposium of Robotics Research • International Symposium on Experimental Robotics • Robotics: Science and Systems
The above journals and conferences represent the reference sources for the international scientiﬁc community. Many other robotics journals and conferences exist which are devoted to speciﬁc topics, such as kinematics, control, vision, algorithms, haptics, industrial applications, space and underwater exploration, humanoid robotics, and human-robot interaction. On the other hand, several journals and prestigious conferences in other ﬁelds, such as mechanics, control, sensors, and artiﬁcial intelligence, oﬀer generous space to robotics topics.

2
Kinematics
A manipulator can be schematically represented from a mechanical viewpoint as a kinematic chain of rigid bodies (links) connected by means of revolute or prismatic joints. One end of the chain is constrained to a base, while an end-eﬀector is mounted to the other end. The resulting motion of the structure is obtained by composition of the elementary motions of each link with respect to the previous one. Therefore, in order to manipulate an object in space, it is necessary to describe the end-eﬀector position and orientation. This chapter is dedicated to the derivation of the direct kinematics equation through a systematic, general approach based on linear algebra. This allows the end-eﬀector position and orientation (pose) to be expressed as a function of the joint variables of the mechanical structure with respect to a reference frame. Both open-chain and closed-chain kinematic structures are considered. With reference to a minimal representation of orientation, the concept of operational space is introduced and its relationship with the joint space is established. Furthermore, a calibration technique of the manipulator kinematic parameters is presented. The chapter ends with the derivation of solutions to the inverse kinematics problem, which consists of the determination of the joint variables corresponding to a given end-eﬀector pose.
2.1 Pose of a Rigid Body
A rigid body is completely described in space by its position and orientation (in brief pose) with respect to a reference frame. As shown in Fig. 2.1, let O–xyz be the orthonormal reference frame and x, y, z be the unit vectors of the frame axes.
The position of a point O on the rigid body with respect to the coordinate frame O–xyz is expressed by the relation
o = oxx + oyy + ozz,

40 2 Kinematics

Fig. 2.1. Position and orientation of a rigid body

where ox, oy, oz denote the components of the vector o ∈ IR3 along the frame axes; the position of O can be compactly written as the (3 × 1) vector

⎡ ox ⎤ o = ⎣ oy ⎦ .

(2.1)

oz

Vector o is a bound vector since its line of application and point of application are both prescribed, in addition to its direction and norm.
In order to describe the rigid body orientation, it is convenient to consider an orthonormal frame attached to the body and express its unit vectors with respect to the reference frame. Let then O –x y z be such a frame with origin in O and x , y , z be the unit vectors of the frame axes. These vectors are expressed with respect to the reference frame O–xyz by the equations:

x = xxx + xyy + xzz y = yxx + yyy + yzz z = zxx + zyy + zzz.

(2.2)

The components of each unit vector are the direction cosines of the axes of frame O –x y z with respect to the reference frame O–xyz.

2.2 Rotation Matrix

By adopting a compact notation, the three unit vectors in (2.2) describing the

body orientation with respect to the reference frame can be combined in the

(3 × 3) matrix

⎡

⎤ ⎡ xx yx zx ⎤ ⎡ x T x y T x z T x ⎤

R = ⎣ x y z ⎦ = ⎣ xy yy zy ⎦ = ⎣ x T y y T y z T y ⎦ ,

xz yz zz

xTz y Tz z Tz

(2.3)

2.2 Rotation Matrix 41

which is termed rotation matrix . It is worth noting that the column vectors of matrix R are mutually or-
thogonal since they represent the unit vectors of an orthonormal frame, i.e.,
x T y = 0 y T z = 0 z T x = 0.

Also, they have unit norm xTx = 1

y Ty = 1

z T z = 1.

As a consequence, R is an orthogonal matrix meaning that

RT R = I3

(2.4)

where I3 denotes the (3 × 3) identity matrix. If both sides of (2.4) are postmultiplied by the inverse matrix R−1, the

useful result is obtained:

RT = R−1,

(2.5)

that is, the transpose of the rotation matrix is equal to its inverse. Further, observe that det(R) = 1 if the frame is right-handed, while det(R) = −1 if the frame is left-handed.
The above-deﬁned rotation matrix belongs to the special orthonormal group SO(m) of the real (m × m) matrices with othonormal columns and determinant equal to 1; in the case of spatial rotations it is m = 3, whereas in the case of planar rotations it is m = 2.

2.2.1 Elementary Rotations

Consider the frames that can be obtained via elementary rotations of the

reference frame about one of the coordinate axes. These rotations are positive

if they are made counter-clockwise about the relative axis.

Suppose that the reference frame O–xyz is rotated by an angle α about

axis z (Fig. 2.2), and let O–x y z be the rotated frame. The unit vectors of

the new frame can be described in terms of their components with respect

to the reference frame. Consider the frames that can be obtained via elemen-

tary rotations of the reference frame about one of the coordinate axes. These

rotations are positive if they are made counter-clockwise about the relative

axis.

Suppose that the reference frame O–xyz is rotated by an angle α about

axis z (Fig. 2.2), and let O–x y z be the rotated frame. The unit vectors of

the new frame can be described in terms of their components with respect to

the reference frame, i.e.,

⎡⎤ cos α
x = ⎣ sin α ⎦

⎡

⎤

−sin α

y = ⎣ cos α ⎦

⎡⎤ 0
z = ⎣0⎦.

0

0

1

42 2 Kinematics

Fig. 2.2. Rotation of frame O–xyz by an angle α about axis z

Hence, the rotation matrix of frame O–x y z with respect to frame O–xyz is

⎡

⎤

cos α −sin α 0

Rz(α) = ⎣ sin α cos α 0 ⎦ .

(2.6)

0

01

In a similar manner, it can be shown that the rotations by an angle β

about axis y and by an angle γ about axis x are respectively given by

⎡

⎤

cos β 0 sin β

Ry(β) = ⎣ 0 1 0 ⎦

−sin β 0 cos β

⎡

⎤

10

0

Rx(γ) = ⎣ 0 cos γ −sin γ ⎦ .

0 sin γ cos γ

(2.7) (2.8)

These matrices will be useful to describe rotations about an arbitrary axis in space.
It is easy to verify that for the elementary rotation matrices in (2.6)–(2.8) the following property holds:

Rk(−ϑ) = RTk (ϑ)

k = x, y, z.

(2.9)

In view of (2.6)–(2.8), the rotation matrix can be attributed a geometrical meaning; namely, the matrix R describes the rotation about an axis in space needed to align the axes of the reference frame with the corresponding axes of the body frame.

2.2.2 Representation of a Vector
In order to understand a further geometrical meaning of a rotation matrix, consider the case when the origin of the body frame coincides with the origin

2.2 Rotation Matrix 43

Fig. 2.3. Representation of a point P in two diﬀerent coordinate frames

of the reference frame (Fig. 2.3); it follows that o = 0, where 0 denotes the (3 × 1) null vector. A point P in space can be represented either as
⎡⎤ px
p = ⎣ py ⎦ pz

with respect to frame O–xyz, or as
⎡ px ⎤ p = ⎣ py ⎦
pz

with respect to frame O–x y z .

Since p and p are representations of the same point P , it is

⎡

⎤

p = pxx + pyy + pzz = ⎣ x y z ⎦ p

and, accounting for (2.3), it is

p = Rp .

(2.10)

The rotation matrix R represents the transformation matrix of the vector

coordinates in frame O–x y z into the coordinates of the same vector in frame

O–xyz. In view of the orthogonality property (2.4), the inverse transformation

is simply given by

p = RT p.

(2.11)

44 2 Kinematics
Fig. 2.4. Representation of a point P in rotated frames
Example 2.1 Consider two frames with common origin mutually rotated by an angle α about the axis z. Let p and p be the vectors of the coordinates of a point P , expressed in the frames O–xyz and O–x y z , respectively (Fig. 2.4). On the basis of simple geometry, the relationship between the coordinates of P in the two frames is
px = px cos α − py sin α py = px sin α + py cos α pz = pz. Therefore, the matrix (2.6) represents not only the orientation of a frame with respect to another frame, but it also describes the transformation of a vector from a frame to another frame with the same origin.
2.2.3 Rotation of a Vector A rotation matrix can be also interpreted as the matrix operator allowing rotation of a vector by a given angle about an arbitrary axis in space. In fact, let p be a vector in the reference frame O–xyz; in view of orthogonality of the matrix R, the product Rp yields a vector p with the same norm as that of p but rotated with respect to p according to the matrix R. The norm equality can be proved by observing that pT p = p T RT Rp and applying (2.4). This interpretation of the rotation matrix will be revisited later.

2.3 Composition of Rotation Matrices 45
Fig. 2.5. Rotation of a vector
Example 2.2 Consider the vector p which is obtained by rotating a vector p in the plane xy by an angle α about axis z of the reference frame (Fig. 2.5). Let (px, py, pz) be the coordinates of the vector p . The vector p has components
px = px cos α − py sin α py = px sin α + py cos α pz = pz. It is easy to recognize that p can be expressed as
p = Rz(α)p , where Rz(α) is the same rotation matrix as in (2.6).
In sum, a rotation matrix attains three equivalent geometrical meanings: • It describes the mutual orientation between two coordinate frames; its
column vectors are the direction cosines of the axes of the rotated frame with respect to the original frame. • It represents the coordinate transformation between the coordinates of a point expressed in two diﬀerent frames (with common origin). • It is the operator that allows the rotation of a vector in the same coordinate frame.
2.3 Composition of Rotation Matrices
In order to derive composition rules of rotation matrices, it is useful to consider the expression of a vector in two diﬀerent reference frames. Let then O–x0y0z0,

46 2 Kinematics

O–x1y1z1, O–x2y2z2 be three frames with common origin O. The vector p
describing the position of a generic point in space can be expressed in each of the above frames; let p0, p1, p2 denote the expressions of p in the three frames.1
At ﬁrst, consider the relationship between the expression p2 of the vector p in Frame 2 and the expression p1 of the same vector in Frame 1. If Rji denotes the rotation matrix of Frame i with respect to Frame j, it is

p1 = R12p2.

(2.12)

Similarly, it turns out that

p0 = R01p1 p0 = R02p2.

(2.13) (2.14)

On the other hand, substituting (2.12) in (2.13) and using (2.14) gives

R02 = R01R12.

(2.15)

The relationship in (2.15) can be interpreted as the composition of successive rotations. Consider a frame initially aligned with the frame O–x0y0z0. The rotation expressed by matrix R02 can be regarded as obtained in two steps:
• First rotate the given frame according to R01, so as to align it with frame O–x1y1z1.
• Then rotate the frame, now aligned with frame O–x1y1z1, according to R12, so as to align it with frame O–x2y2z2.

Notice that the overall rotation can be expressed as a sequence of partial rotations; each rotation is deﬁned with respect to the preceding one. The frame with respect to which the rotation occurs is termed current frame. Composition of successive rotations is then obtained by postmultiplication of the rotation matrices following the given order of rotations, as in (2.15). With the adopted notation, in view of (2.5), it is

Rji = (Rij )−1 = (Rij )T .

(2.16)

Successive rotations can be also speciﬁed by constantly referring them
to the initial frame; in this case, the rotations are made with respect to a ﬁxed frame. Let R01 be the rotation matrix of frame O–x1y1z1 with respect to the ﬁxed frame O–x0y0z0. Let then R¯ 02 denote the matrix characterizing frame O–x2y2z2 with respect to Frame 0, which is obtained as a rotation of Frame 1 according to the matrix R¯ 12. Since (2.15) gives a composition rule of successive rotations about the axes of the current frame, the overall rotation
can be regarded as obtained in the following steps:

1 Hereafter, the superscript of a vector or a matrix denotes the frame in which its components are expressed.

2.3 Composition of Rotation Matrices 47

• First realign Frame 1 with Frame 0 by means of rotation R10. • Then make the rotation expressed by R¯ 12 with respect to the current frame. • Finally compensate for the rotation made for the realignment by means of
the inverse rotation R01.
Since the above rotations are described with respect to the current frame, the application of the composition rule (2.15) yields

R¯ 02 = R01R10R¯ 12R01.

In view of (2.16), it is

R¯ 02 = R¯ 12R01

(2.17)

where the resulting R¯ 02 is diﬀerent from the matrix R02 in (2.15). Hence, it can be stated that composition of successive rotations with respect to a ﬁxed

frame is obtained by premultiplication of the single rotation matrices in the

order of the given sequence of rotations.

By recalling the meaning of a rotation matrix in terms of the orientation

of a current frame with respect to a ﬁxed frame, it can be recognized that its

columns are the direction cosines of the axes of the current frame with respect

to the ﬁxed frame, while its rows (columns of its transpose and inverse) are

the direction cosines of the axes of the ﬁxed frame with respect to the current

frame.

An important issue of composition of rotations is that the matrix product

is not commutative. In view of this, it can be concluded that two rotations

in general do not commute and its composition depends on the order of the

single rotations.

Example 2.3
Consider an object and a frame attached to it. Figure 2.6 shows the eﬀects of two successive rotations of the object with respect to the current frame by changing the order of rotations. It is evident that the ﬁnal object orientation is diﬀerent in the two cases. Also in the case of rotations made with respect to the current frame, the ﬁnal orientations diﬀer (Fig. 2.7). It is interesting to note that the eﬀects of the sequence of rotations with respect to the ﬁxed frame are interchanged with the eﬀects of the sequence of rotations with respect to the current frame. This can be explained by observing that the order of rotations in the ﬁxed frame commutes with respect to the order of rotations in the current frame.

48 2 Kinematics
Fig. 2.6. Successive rotations of an object about axes of current frame
Fig. 2.7. Successive rotations of an object about axes of ﬁxed frame
2.4 Euler Angles
Rotation matrices give a redundant description of frame orientation; in fact, they are characterized by nine elements which are not independent but related by six constraints due to the orthogonality conditions given in (2.4). This implies that three parameters are suﬃcient to describe orientation of a rigid body

2.4 Euler Angles 49
Fig. 2.8. Representation of Euler angles ZYZ
in space. A representation of orientation in terms of three independent parameters constitutes a minimal representation. In fact, a minimal representation of the special orthonormal group SO(m) requires m(m − 1)/2 parameters; thus, three parameters are needed to parameterize SO(3), whereas only one parameter is needed for a planar rotation SO(2).
A minimal representation of orientation can be obtained by using a set of three angles φ = [ ϕ ϑ ψ ]T . Consider the rotation matrix expressing the elementary rotation about one of the coordinate axes as a function of a single angle. Then, a generic rotation matrix can be obtained by composing a suitable sequence of three elementary rotations while guaranteeing that two successive rotations are not made about parallel axes. This implies that 12 distinct sets of angles are allowed out of all 27 possible combinations; each set represents a triplet of Euler angles. In the following, two sets of Euler angles are analyzed; namely, the ZYZ angles and the ZYX (or Roll–Pitch– Yaw) angles.
2.4.1 ZYZ Angles The rotation described by ZYZ angles is obtained as composition of the following elementary rotations (Fig. 2.8): • Rotate the reference frame by the angle ϕ about axis z; this rotation is
described by the matrix Rz(ϕ) which is formally deﬁned in (2.6). • Rotate the current frame by the angle ϑ about axis y ; this rotation is
described by the matrix Ry (ϑ) which is formally deﬁned in (2.7). • Rotate the current frame by the angle ψ about axis z ; this rotation is
described by the matrix Rz (ψ) which is again formally deﬁned in (2.6).

50 2 Kinematics

The resulting frame orientation is obtained by composition of rotations
with respect to current frames, and then it can be computed via postmultiplication of the matrices of elementary rotation, i.e.,2

R(φ) = R⎡ z(ϕ)Ry (ϑ)Rz (ψ) cϕcϑcψ − sϕsψ −cϕcϑsψ − sϕcψ
= ⎣ sϕcϑcψ + cϕsψ −sϕcϑsψ + cϕcψ

−sϑcψ

sϑsψ

⎤ cϕsϑ sϕsϑ ⎦ .
cϑ

(2.18)

It is useful to solve the inverse problem, that is to determine the set of

Euler angles corresponding to a given rotation matrix

⎡

⎤

r11 r12 r13

R = ⎣ r21 r22 r23 ⎦ .

r31 r32 r33

Compare this expression with that of R(φ) in (2.18). By considering the elements [1, 3] and [2, 3], under the assumption that r13 = 0 and r23 = 0, it follows that
ϕ = Atan2(r23, r13)
where Atan2(y, x) is the arctangent function of two arguments3. Then, squaring and summing the elements [1, 3] and [2, 3] and using the element [3, 3] yields
ϑ = Atan2 r123 + r223, r33 .

The choice of the positive sign for the term r123 + r223 limits the range of feasible values of ϑ to (0, π). On this assumption, considering the elements [3, 1] and [3, 2] gives
ψ = Atan2(r32, −r31).
In sum, the requested solution is

ϕ = Atan2(r23, r13)

ϑ = Atan2 r123 + r223, r33

(2.19)

ψ = Atan2(r32, −r31).

It is possible to derive another solution which produces the same eﬀects as solution (2.19). Choosing ϑ in the range (−π, 0) leads to

ϕ = Atan2(−r23, −r13)
2 The notations cφ and sφ are the abbreviations for cos φ and sin φ, respectively; short-hand notations of this kind will be adopted often throughout the text.
3 The function Atan2(y, x) computes the arctangent of the ratio y/x but utilizes the sign of each argument to determine which quadrant the resulting angle belongs to; this allows the correct determination of an angle in a range of 2π.

2.4 Euler Angles 51

Fig. 2.9. Representation of Roll–Pitch–Yaw angles

ϑ = Atan2 − r123 + r223, r33 ψ = Atan2(−r32, r31).

(2.20)

Solutions (2.19), (2.20) degenerate when sϑ = 0; in this case, it is possible to determine only the sum or diﬀerence of ϕ and ψ. In fact, if ϑ = 0, π,
the successive rotations of ϕ and ψ are made about axes of current frames
which are parallel, thus giving equivalent contributions to the rotation; see Problem 2.2.4

2.4.2 RPY Angles
Another set of Euler angles originates from a representation of orientation in the (aero)nautical ﬁeld. These are the ZYX angles, also called Roll–Pitch– Yaw angles, to denote the typical changes of attitude of an (air)craft. In this case, the angles φ = [ ϕ ϑ ψ ]T represent rotations deﬁned with respect to a ﬁxed frame attached to the centre of mass of the craft (Fig. 2.9).
The rotation resulting from Roll–Pitch–Yaw angles can be obtained as follows:
• Rotate the reference frame by the angle ψ about axis x (yaw); this rotation is described by the matrix Rx(ψ) which is formally deﬁned in (2.8).
• Rotate the reference frame by the angle ϑ about axis y (pitch); this rotation is described by the matrix Ry(ϑ) which is formally deﬁned in (2.7).
• Rotate the reference frame by the angle ϕ about axis z (roll); this rotation is described by the matrix Rz(ϕ) which is formally deﬁned in (2.6).

4 In the following chapter, it will be seen that these conﬁgurations characterize the so-called representation singularities of the Euler angles.

52 2 Kinematics

The resulting frame orientation is obtained by composition of rotations with
respect to the ﬁxed frame, and then it can be computed via premultiplication of the matrices of elementary rotation, i.e.,5

R(φ) = R⎡ z(ϕ)Ry(ϑ)Rx(ψ) cϕcϑ cϕsϑsψ − sϕcψ
= ⎣ sϕcϑ sϕsϑsψ + cϕcψ

−sϑ

cϑsψ

⎤ cϕsϑcψ + sϕsψ sϕsϑcψ − cϕsψ ⎦ .
cϑcψ

(2.21)

As for the Euler angles ZYZ, the inverse solution to a given rotation matrix

⎡

⎤

r11 r12 r13

R = ⎣ r21 r22 r23 ⎦ ,

r31 r32 r33

can be obtained by comparing it with the expression of R(φ) in (2.21). The solution for ϑ in the range (−π/2, π/2) is

ϕ = Atan2(r21, r11) ϑ = Atan2 −r31, r322 + r323 ψ = Atan2(r32, r33). The other equivalent solution for ϑ in the range (π/2, 3π/2) is

(2.22)

ϕ = Atan2(−r21, −r11) ϑ = Atan2 −r31, − r322 + r323 ψ = Atan2(−r32, −r33).

(2.23)

Solutions (2.22), (2.23) degenerate when cϑ = 0; in this case, it is possible to determine only the sum or diﬀerence of ϕ and ψ.

2.5 Angle and Axis
A nonminimal representation of orientation can be obtained by resorting to four parameters expressing a rotation of a given angle about an axis in space. This can be advantageous in the problem of trajectory planning for a manipulator’s end-eﬀector orientation.
Let r = [ rx ry rz ]T be the unit vector of a rotation axis with respect to the reference frame O–xyz. In order to derive the rotation matrix R(ϑ, r) expressing the rotation of an angle ϑ about axis r, it is convenient to compose
5 The ordered sequence of rotations XYZ about axes of the ﬁxed frame is equivalent to the sequence ZYX about axes of the current frame.

2.5 Angle and Axis 53

Fig. 2.10. Rotation of an angle about an axis

elementary rotations about the coordinate axes of the reference frame. The angle is taken to be positive if the rotation is made counter-clockwise about axis r.
As shown in Fig. 2.10, a possible solution is to rotate ﬁrst r by the angles necessary to align it with axis z, then to rotate by ϑ about z and ﬁnally to rotate by the angles necessary to align the unit vector with the initial direction. In detail, the sequence of rotations, to be made always with respect to axes of ﬁxed frame, is the following:

• Align r with z, which is obtained as the sequence of a rotation by −α about z and a rotation by −β about y.
• Rotate by ϑ about z. • Realign with the initial direction of r, which is obtained as the sequence
of a rotation by β about y and a rotation by α about z.

In sum, the resulting rotation matrix is

R(ϑ, r) = Rz(α)Ry(β)Rz(ϑ)Ry(−β)Rz(−α).

(2.24)

From the components of the unit vector r it is possible to extract the transcendental functions needed to compute the rotation matrix in (2.24), so as to eliminate the dependence from α and β; in fact, it is

sin α =

ry rx2 + ry2

cos α =

rx rx2 + ry2

sin β = rx2 + ry2 cos β = rz.

54 2 Kinematics

Then, it can be found that the rotation matrix corresponding to a given angle

and axis is — see Problem 2.4 —

⎡

R(ϑ,

r)

=

⎢⎣

rx2 (1 rx ry (1

− −

cϑ) cϑ)

+ +

cϑ rz sϑ

rxry(1 − cϑ) − rzsϑ ry2(1 − cϑ) + cϑ

⎤ rxrz(1 − cϑ) + rysϑ ryrz(1 − cϑ) − rxsϑ ⎥⎦.

rxrz(1 − cϑ) − rysϑ ryrz(1 − cϑ) + rxsϑ

rz2(1 − cϑ) + cϑ (2.25)

For this matrix, the following property holds:

R(−ϑ, −r) = R(ϑ, r),

(2.26)

i.e., a rotation by −ϑ about −r cannot be distinguished from a rotation by ϑ

about r; hence, such representation is not unique.

If it is desired to solve the inverse problem to compute the axis and angle

corresponding to a given rotation matrix

⎡

⎤

r11 r12 r13

R = ⎣ r21 r22 r23 ⎦ ,

r31 r32 r33

the following result is useful:

ϑ = cos −1 r11 + r22 + r33 − 1

⎡

2⎤

r

=

1 2 sin ϑ

r32 ⎣ r13
r21

− r23 − r31 ⎦ , − r12

(2.27) (2.28)

for sin ϑ = 0. Notice that the expressions (2.27), (2.28) describe the rotation in terms of four parameters; namely, the angle and the three components of the axis unit vector. However, it can be observed that the three components of r are not independent but are constrained by the condition

rx2 + ry2 + rz2 = 1.

(2.29)

If sin ϑ = 0, the expressions (2.27), (2.28) become meaningless. To solve the inverse problem, it is necessary to directly refer to the particular expressions attained by the rotation matrix R and ﬁnd the solving formulae in the two cases ϑ = 0 and ϑ = π. Notice that, when ϑ = 0 (null rotation), the unit vector r is arbitrary (singularity). See also Problem 2.5.

2.6 Unit Quaternion

The drawbacks of the angle/axis representation can be overcome by a different four-parameter representation; namely, the unit quaternion, viz. Euler parameters, deﬁned as Q = {η, } where:

ϑ η = cos
2

(2.30)

2.6 Unit Quaternion 55

= sin ϑ r; 2

(2.31)

η is called the scalar part of the quaternion while = [ x y z ]T is called the vector part of the quaternion. They are constrained by the condition

η2 +

2 x

+

2 y

+

2 z

=

1,

(2.32)

hence, the name unit quaternion. It is worth remarking that, unlike the an-

gle/axis representation, a rotation by −ϑ about −r gives the same quater-

nion as that associated with a rotation by ϑ about r; this solves the above

nonuniqueness problem. In view of (2.25), (2.30), (2.31), (2.32), the rotation

matrix corresponding to a given quaternion takes on the form — see Prob-

lem 2.6 —

⎡ 2(η2 +

2 x

)

−

1

R(η, ) = ⎢⎣ 2( x y + η z)

2( x y − η z)

2(η2 +

2 y

)

−

1

⎤ 2( x z + η y) 2( y z − η x) ⎥⎦ .

(2.33)

2( x z − η y)

2( y z + η x)

2(η2 +

2 z

)

−

1

If it is desired to solve the inverse problem to compute the quaternion

corresponding to a given rotation matrix ⎡ r11 r12
R = ⎣ r21 r22 r31 r32

⎤ r13 r23 ⎦ , r33

the following result is useful:

1√

η

=

2

r11 ⎡

+

r22

+

r33 + √

1

⎤

=

1 2

sgn (r32 ⎢⎣ sgn (r13

− −

r23)√r11 r31)√r22

− −

r22 r33

− −

r33 r11

+ +

1 1 ⎥⎦ ,

sgn (r21 − r12) r33 − r11 − r22 + 1

(2.34) (2.35)

where conventionally sgn (x) = 1 for x ≥ 0 and sgn (x) = −1 for x < 0. Notice

that in (2.34) it has been implicitly assumed η ≥ 0; this corresponds to an

angle ϑ ∈ [−π, π], and thus any rotation can be described. Also, compared to

the inverse solution in (2.27), (2.28) for the angle and axis representation, no

singularity occurs for (2.34), (2.35). See also Problem 2.8. The quaternion extracted from R−1 = RT is denoted as Q−1, and can be

computed as

Q−1 = {η, − }.

(2.36)

Let Q1 = {η1, 1} and Q2 = {η2, 2} denote the quaternions corresponding to the rotation matrices R1 and R2, respectively. The quaternion corresponding to the product R1R2 is given by

Q1 ∗ Q2 = {η1η2 −

T 1

2, η1 2 + η2 1 +

1×

2}

(2.37)

where the quaternion product operator “∗” has been formally introduced. It is easy to see that if Q2 = Q−1 1 then the quaternion {1, 0} is obtained from (2.37)
which is the identity element for the product. See also Problem 2.9.

56 2 Kinematics

Fig. 2.11. Representation of a point P in diﬀerent coordinate frames

2.7 Homogeneous Transformations

As illustrated at the beginning of the chapter, the position of a rigid body in

space is expressed in terms of the position of a suitable point on the body with

respect to a reference frame (translation), while its orientation is expressed in

terms of the components of the unit vectors of a frame attached to the body

— with origin in the above point — with respect to the same reference frame

(rotation).

As shown in Fig. 2.11, consider an arbitrary point P in space. Let p0

be the vector of coordinates of P with respect to the reference frame O0– x0y0z0. Consider then another frame in space O1–x1y1z1. Let o01 be the vector describing the origin of Frame 1 with respect to Frame 0, and R01 be the rotation matrix of Frame 1 with respect to Frame 0. Let also p1 be the vector

of coordinates of P with respect to Frame 1. On the basis of simple geometry,

the position of point P with respect to the reference frame can be expressed

as

p0 = o01 + R01p1.

(2.38)

Hence, (2.38) represents the coordinate transformation (translation + rota-
tion) of a bound vector between two frames.
The inverse transformation can be obtained by premultiplying both sides of (2.38) by R01T ; in view of(2.4), it follows that

p1 = −R01T o01 + R01T p0

(2.39)

which, via (2.16), can be written as

p1 = −R10o01 + R10p0.

(2.40)

In order to achieve a compact representation of the relationship between the coordinates of the same point in two diﬀerent frames, the homogeneous representation of a generic vector p can be introduced as the vector p˜ formed by adding a fourth unit component, i.e.,

2.7 Homogeneous Transformations 57

⎡⎤

p = ⎢⎣ p ⎥⎦ .

(2.41)

1

By adopting this representation for the vectors p0 and p1 in (2.38), the coordinate transformation can be written in terms of the (4 × 4) matrix

⎡

⎤

A01 = ⎢⎣ R01

o01 ⎥⎦

(2.42)

0T

1

which, according to (2.41), is termed homogeneous transformation matrix . Since o01 ∈ IR3 e R01 ∈ SO(3), this matrix belongs to the special Euclidean group SE(3) = IR3 × SO(3).
As can be easily seen from (2.42), the transformation of a vector from
Frame 1 to Frame 0 is expressed by a single matrix containing the rotation
matrix of Frame 1 with respect to Frame 0 and the translation vector from the origin of Frame 0 to the origin of Frame 1.6 Therefore, the coordinate
transformation (2.38) can be compactly rewritten as

p0 = A01p1.

(2.43)

The coordinate transformation between Frame 0 and Frame 1 is described by the homogeneous transformation matrix A10 which satisﬁes the equation

p1 = A10p0 = A01 −1 p0.

(2.44)

This matrix is expressed in a block-partitioned form as

⎡

⎤⎡

⎤

A10 = ⎢⎣ R01T

−R01T o01 ⎥⎦ = ⎢⎣ R10

−R10o01 ⎥⎦ ,

0T

1

0T

1

(2.45)

which gives the homogeneous representation form of the result already established by (2.39), (2.40) — see Problem 2.10.
Notice that for the homogeneous transformation matrix the orthogonality property does not hold; hence, in general,

A−1 = AT .

(2.46)

In sum, a homogeneous transformation matrix expresses the coordinate transformation between two frames in a compact form. If the frames have the
6 It can be shown that in (2.42) non-null values of the ﬁrst three elements of the fourth row of A produce a perspective eﬀect, while values other than unity for the fourth element give a scaling eﬀect.

58 2 Kinematics

Fig. 2.12. Conventional representations of joints

same origin, it reduces to the rotation matrix previously deﬁned. Instead, if

the frames have distinct origins, it allows the notation with superscripts and

subscripts to be kept which directly characterize the current frame and the

ﬁxed frame.

Analogously to what presented for the rotation matrices, it is easy to

verify that a sequence of coordinate transformations can be composed by the

product

p0 = A01A12 . . . Ann−1pn

(2.47)

where Aii−1 denotes the homogeneous transformation relating the description of a point in Frame i to the description of the same point in Frame i − 1.

2.8 Direct Kinematics
A manipulator consists of a series of rigid bodies (links) connected by means of kinematic pairs or joints. Joints can be essentially of two types: revolute and prismatic; conventional representations of the two types of joints are sketched in Fig. 2.12. The whole structure forms a kinematic chain. One end of the chain is constrained to a base. An end-eﬀector (gripper, tool) is connected to the other end allowing manipulation of objects in space.
From a topological viewpoint, the kinematic chain is termed open when there is only one sequence of links connecting the two ends of the chain. Alternatively, a manipulator contains a closed kinematic chain when a sequence of links forms a loop.
The mechanical structure of a manipulator is characterized by a number of degrees of freedom (DOFs) which uniquely determine its posture.7 Each DOF is typically associated with a joint articulation and constitutes a joint variable. The aim of direct kinematics is to compute the pose of the end-eﬀector as a function of the joint variables.
7 The term posture of a kinematic chain denotes the pose of all the rigid bodies composing the chain. Whenever the kinematic chain reduces to a single rigid body, then the posture coincides with the pose of the body.

2.8 Direct Kinematics 59

Fig. 2.13. Description of the position and orientation of the end-eﬀector frame

It was previously illustrated that the pose of a body with respect to a reference frame is described by the position vector of the origin and the unit vectors of a frame attached to the body. Hence, with respect to a reference frame Ob–xbybzb, the direct kinematics function is expressed by the homogeneous transformation matrix

⎡

⎤

T

b e

(q

)

=

⎢⎣

nbe(q)

sbe(q)

abe(q)

pbe(q) ⎥⎦ ,

(2.48)

0

0

0

1

where q is the (n × 1) vector of joint variables, ne, se, ae are the unit vectors of a frame attached to the end-eﬀector, and pe is the position vector of the origin of such a frame with respect to the origin of the base frame Ob–xbybzb (Fig. 2.13). Note that ne, se, ae and pe are a function of q.
The frame Ob–xbybzb is termed base frame. The frame attached to the endeﬀector is termed end-eﬀector frame and is conveniently chosen according to
the particular task geometry. If the end-eﬀector is a gripper, the origin of the
end-eﬀector frame is located at the centre of the gripper, the unit vector ae is chosen in the approach direction to the object, the unit vector se is chosen normal to ae in the sliding plane of the jaws, and the unit vector ne is chosen normal to the other two so that the frame (ne, se, ae) is right-handed.
A ﬁrst way to compute direct kinematics is oﬀered by a geometric analysis
of the structure of the given manipulator.

60 2 Kinematics

Fig. 2.14. Two-link planar arm

Example 2.4

Consider the two-link planar arm in Fig. 2.14. On the basis of simple trigonometry,

the choice of the joint variables, the base frame, and the end-eﬀector frame leads

to8

⎡

⎤⎡

⎤

0 s12 c12 a1c1 + a2c12

T

b e

(q)

=

⎢⎣

nbe

sbe

abe

pbe

⎥⎦

=

⎢⎣

0 1

−c12 0

s12 0

a1s1

+ 0

a2s12

⎥⎦

.

(2.49)

0001

00 0

1

It is not diﬃcult to infer that the eﬀectiveness of a geometric approach to the direct kinematics problem is based ﬁrst on a convenient choice of the relevant quantities and then on the ability and geometric intuition of the problem solver. Whenever the manipulator structure is complex and the number of joints increases, it is preferable to adopt a less direct solution, which, though, is based on a systematic, general procedure. The problem becomes even more complex when the manipulator contains one or more closed kinematic chains. In such a case, as it will be discussed later, there is no guarantee to obtain an analytical expression for the direct kinematics function in (2.48).
2.8.1 Open Chain
Consider an open-chain manipulator constituted by n + 1 links connected by n joints, where Link 0 is conventionally ﬁxed to the ground. It is assumed that each joint provides the mechanical structure with a single DOF, corresponding to the joint variable.
The construction of an operating procedure for the computation of direct kinematics is naturally derived from the typical open kinematic chain of the manipulator structure. In fact, since each joint connects two consecutive
8 The notations si...j, ci...j denote respectively sin (qi + . . . + qj ), cos (qi + . . . + qj ).

2.8 Direct Kinematics 61

Fig. 2.15. Coordinate transformations in an open kinematic chain

links, it is reasonable to consider ﬁrst the description of kinematic relationship between consecutive links and then to obtain the overall description of manipulator kinematics in a recursive fashion. To this purpose, it is worth deﬁning a coordinate frame attached to each link, from Link 0 to Link n. Then, the coordinate transformation describing the position and orientation of Frame n with respect to Frame 0 (Fig. 2.15) is given by

T 0n(q) = A01(q1)A12(q2) . . . Ann−1(qn).

(2.50)

As requested, the computation of the direct kinematics function is recursive
and is obtained in a systematic manner by simple products of the homogeneous transformation matrices Aii−1(qi) (for i = 1, . . . , n), each of which is a function of a single joint variable.
With reference to the direct kinematics equation in (2.49), the actual co-
ordinate transformation describing the position and orientation of the end-
eﬀector frame with respect to the base frame can be obtained as

T

b e

(q

)

=

T

b0T

0 n

(q)T

n e

(2.51)

where

T

b 0

and

T

n e

are

two

(typically)

constant

homogeneous

transformations

describing the position and orientation of Frame 0 with respect to the base

frame, and of the end-eﬀector frame with respect to Frame n, respectively.

2.8.2 Denavit–Hartenberg Convention
In order to compute the direct kinematics equation for an open-chain manipulator according to the recursive expression in (2.50), a systematic, general

62 2 Kinematics
Fig. 2.16. Denavit–Hartenberg kinematic parameters
method is to be derived to deﬁne the relative position and orientation of two consecutive links; the problem is that of determining two frames attached to the two links and computing the coordinate transformations between them. In general, the frames can be arbitrarily chosen as long as they are attached to the link they are referred to. Nevertheless, it is convenient to set some rules also for the deﬁnition of the link frames.
With reference to Fig. 2.16, let Axis i denote the axis of the joint connecting Link i − 1 to Link i; the so-called Denavit–Hartenberg convention (DH) is adopted to deﬁne link Frame i: • Choose axis zi along the axis of Joint i + 1. • Locate the origin Oi at the intersection of axis zi with the common normal9
to axes zi−1 and zi. Also, locate Oi at the intersection of the common normal with axis zi−1. • Choose axis xi along the common normal to axes zi−1 and zi with positive direction from Joint i to Joint i + 1. • Choose axis yi so as to complete a right-handed frame. The Denavit–Hartenberg convention gives a nonunique deﬁnition of the link frame in the following cases: • For Frame 0, only the direction of axis z0 is speciﬁed; then O0 and x0 can be arbitrarily chosen. • For Frame n, since there is no Joint n + 1, zn is not uniquely deﬁned while xn has to be normal to axis zn−1. Typically, Joint n is revolute, and thus zn can be aligned with the direction of zn−1. 9 The common normal between two lines is the line containing the minimum distance segment between the two lines.

2.8 Direct Kinematics 63

• When two consecutive axes are parallel, the common normal between them is not uniquely deﬁned.
• When two consecutive axes intersect, the positive direction of xi is arbitrary.
• When Joint i is prismatic, only the direction of zi−1 is speciﬁed.
In all such cases, the indeterminacy can be exploited to simplify the procedure; for instance, the axes of consecutive frames can be made parallel.
Once the link frames have been established, the position and orientation of Frame i with respect to Frame i − 1 are completely speciﬁed by the following parameters :

ai distance between Oi and Oi , di coordinate of Oi along zi−1, αi angle between axes zi−1 and zi about axis xi to be taken positive when
rotation is made counter-clockwise,
ϑi angle between axes xi−1 and xi about axis zi−1 to be taken positive when rotation is made counter-clockwise.

Two of the four parameters (ai and αi) are always constant and depend only on the geometry of connection between consecutive joints established by Link i. Of the remaining two parameters, only one is variable depending on the type of joint that connects Link i − 1 to Link i. In particular:

• if Joint i is revolute the variable is ϑi, • if Joint i is prismatic the variable is di.

At this point, it is possible to express the coordinate transformation between Frame i and Frame i − 1 according to the following steps:

• Choose a frame aligned with Frame i − 1. • Translate the chosen frame by di along axis zi−1 and rotate it by ϑi about
axis zi−1; this sequence aligns the current frame with Frame i and is described by the homogeneous transformation matrix

⎡ cϑi −sϑi 0 0 ⎤

Aii−1

=

⎢⎣

sϑi 0

cϑi 0

0 1

0 di

⎥⎦

.

0 0 01

• Translate the frame aligned with Frame i by ai along axis xi and rotate it by αi about axis xi ; this sequence aligns the current frame with Frame i and is described by the homogeneous transformation matrix

⎡1 0

0 ai ⎤

Aii

=

⎢⎣

0 0

cαi sαi

−sαi cαi

0 0

⎥⎦

.

00 0 1

64 2 Kinematics

• The resulting coordinate transformation is obtained by postmultiplication of the single transformations as

⎡ cϑi

Aii−1(qi) = Aii−1Aii

=

⎢⎣

sϑi 0

0

−sϑi cαi cϑi cαi
sαi 0

sϑi sαi −cϑi sαi
cαi 0

aicϑi ⎤

aisϑi di

⎥⎦

.

1

(2.52)

Notice that the transformation matrix from Frame i to Frame i−1 is a function only of the joint variable qi, that is, ϑi for a revolute joint or di for a prismatic joint.
To summarize, the Denavit–Hartenberg convention allows the construction of the direct kinematics function by composition of the individual coordinate transformations expressed by (2.52) into one homogeneous transformation matrix as in (2.50). The procedure can be applied to any open kinematic chain and can be easily rewritten in an operating form as follows.

1. Find and number consecutively the joint axes; set the directions of axes z0, . . . , zn−1.
2. Choose Frame 0 by locating the origin on axis z0; axes x0 and y0 are chosen so as to obtain a right-handed frame. If feasible, it is worth choosing Frame 0 to coincide with the base frame.
Execute steps from 3 to 5 for i = 1, . . . , n − 1:

3. Locate the origin Oi at the intersection of zi with the common normal to axes zi−1 and zi. If axes zi−1 and zi are parallel and Joint i is revolute, then locate Oi so that di = 0; if Joint i is prismatic, locate Oi at a reference position for the joint range, e.g., a mechanical limit.
4. Choose axis xi along the common normal to axes zi−1 and zi with direction from Joint i to Joint i + 1.
5. Choose axis yi so as to obtain a right-handed frame.
To complete:

6. Choose Frame n; if Joint n is revolute, then align zn with zn−1, otherwise,

if Joint n is prismatic, then choose zn arbitrarily. Axis xn is set according

to step 4.

7. For i = 1, . . . , n, form the table of parameters ai, di, αi, ϑi.

8. On the basis of the parameters in 7, compute the homogeneous transfor-

mation matrices Aii−1(qi) for i = 1, . . . , n.

9.

Compute

the

homogeneous

transformation

T

0 n

(q)

=

A01 . . . Ann−1

that

yields the position and orientation of Frame n with respect to Frame 0.

10.Given

T

b 0

and

T

n e

,

compute

the

direct

kinematics

function

as

T

b e

(q)

=

T

b 0

T

0nT

n e

that

yields

the

position

and

orientation

of

the

end-eﬀector

frame

with respect to the base frame.

2.8 Direct Kinematics 65
Fig. 2.17. Connection of a single link in the chain with two links
For what concerns the computational aspects of direct kinematics, it can be recognized that the heaviest load derives from the evaluation of transcendental functions. On the other hand, by suitably factorizing the transformation equations and introducing local variables, the number of ﬂops (additions + multiplications) can be reduced. Finally, for computation of orientation it is convenient to evaluate the two unit vectors of the end-eﬀector frame of simplest expression and derive the third one by vector product of the ﬁrst two.
2.8.3 Closed Chain
The above direct kinematics method based on the DH convention exploits the inherently recursive feature of an open-chain manipulator. Nevertheless, the method can be extended to the case of manipulators containing closed kinematic chains according to the technique illustrated below.
Consider a closed-chain manipulator constituted by n + 1 links. Because of the presence of a loop, the number of joints l must be greater than n; in particular, it can be understood that the number of closed loops is equal to l − n.
With reference to Fig. 2.17, Links 0 through i are connected successively through the ﬁrst i joints as in an open kinematic chain. Then, Joint i + 1 connects Link i with Link i + 1 while Joint i + 1 connects Link i with Link i + 1 ; the axes of Joints i + 1 and i + 1 are assumed to be aligned. Although not represented in the ﬁgure, Links i + 1 and i + 1 are members of the closed kinematic chain. In particular, Link i + 1 is further connected to Link i + 2 via Joint i + 2 and so forth, until Link j via Joint j. Likewise, Link i + 1 is further connected to Link i + 2 via Joint i + 2 and so forth, until Link k via Joint k. Finally, Links j and k are connected together at Joint j + 1 to form a closed chain. In general, j = k.
In order to attach frames to the various links and apply DH convention, one closed kinematic chain is taken into account. The closed chain can be virtually cut open at Joint j + 1, i.e., the joint between Link j and Link k. An equivalent tree-structured open kinematic chain is obtained, and thus link

66 2 Kinematics

Fig. 2.18. Coordinate transformations in a closed kinematic chain

frames can be deﬁned as in Fig. 2.18. Since Links 0 through i occur before the two branches of the tree, they are left out of the analysis. For the same reason, Links j + 1 through n are left out as well. Notice that Frame i is to be chosen with axis zi aligned with the axes of Joints i + 1 and i + 1 .
It follows that the position and orientation of Frame j with respect to Frame i can be expressed by composing the homogeneous transformations as

Aij (q ) = Aii+1 (qi+1 ) . . . Ajj−1(qj )

(2.53)

where q = [ qi+1 . . . qj ]T . Likewise, the position and orientation of Frame k with respect to Frame i is given by

Aik(q ) = Aii+1 (qi+1 ) . . . Akk−1(qk)

(2.54)

where q = [ qi+1 . . . qk ]T . Since Links j and k are connected to each other through Joint j + 1,
it is worth analyzing the mutual position and orientation between Frames j and k, as illustrated in Fig. 2.19. Notice that, since Links j and k are connected to form a closed chain, axes zj and zk are aligned. Therefore, the following orientation constraint has to be imposed between Frames j and k:

zij(q ) = zik(q ),

(2.55)

where the unit vectors of the two axes have been conveniently referred to Frame i.
Moreover, if Joint j + 1 is prismatic, the angle ϑjk between axes xj and xk is ﬁxed; hence, in addition to (2.55), the following constraint is obtained:

xijT (q )xik(q ) = cos ϑjk.

(2.56)

Obviously, there is no need to impose a similar constraint on axes yj and yk since that would be redundant.

2.8 Direct Kinematics 67

Fig. 2.19. Coordinate transformation at the cut joint

Regarding the position constraint between Frames j and k, let pij and pik respectively denote the positions of the origins of Frames j and k, when referred to Frame i. By projecting on Frame j the distance vector of the origin
of Frame k from Frame j, the following constraint has to be imposed:

Rji (q ) pij (q ) − pik(q ) = [ 0 0 djk ]T

(2.57)

where Rji = RijT denotes the orientation of Frame i with respect to Frame j. At this point, if Joint j + 1 is revolute, then djk is a ﬁxed oﬀset along axis zj; hence, the three equalities of (2.57) fully describe the position constraint. If,
however, Joint j + 1 is prismatic, then djk varies. Consequently, only the ﬁrst two equalities of (2.57) describe the position constraint, i.e.,

xijT (q )

y

iT j

(q

)

pij(q ) − pik(q ) =

0 0

where Rij = [ xij yij zij ]. In summary, if Joint j + 1 is revolute the constraints are

(2.58)

Rji (q ) pij (q ) − pik(q ) = [ 0 0 djk ]T zij(q ) = zik(q ),

(2.59)

whereas if Joint j + 1 is prismatic the constraints are

⎧ ⎪⎪⎪⎨

xijT (q ) yijT (q )

pij(q ) − pik(q ) =

0 0

⎪⎪⎪⎩

zij (q ) xijT (q

= zik(q )xik(q )

) =

cos

ϑj k .

(2.60)

68 2 Kinematics

In either case, there are six equalities that must be satisﬁed. Those should be solved for a reduced number of independent joint variables to be keenly chosen among the components of q and q which characterize the DOFs of the closed chain. These are the natural candidates to be the actuated joints, while the other joints in the chain (including the cut joint) are typically not actuated. Such independent variables, together with the remaining joint variables not involved in the above analysis, constitute the joint vector q that allows the direct kinematics equation to be computed as

T

0 n

(q)

=

A0i Aij Ajn,

(2.61)

where the sequence of successive transformations after the closure of the chain has been conventionally resumed from Frame j.
In general, there is no guarantee to solve the constraints in closed form unless the manipulator has a simple kinematic structure. In other words, for a given manipulator with a speciﬁc geometry, e.g., a planar structure, some of the above equalities may become dependent. Hence, the number of independent equalities is less than six and it should likely be easier to solve them.
To conclude, it is worth sketching the operating form of the procedure to compute the direct kinematics function for a closed-chain manipulator using the Denavit–Hartenberg convention.

1. In the closed chain, select one joint that is not actuated. Assume that the joint is cut open so as to obtain an open chain in a tree structure.
2. Compute the homogeneous transformations according to DH convention. 3. Find the equality constraints for the two frames connected by the cut joint. 4. Solve the constraints for a reduced number of joint variables. 5. Express the homogeneous transformations in terms of the above joint vari-
ables and compute the direct kinematics function by composing the various transformations from the base frame to the end-eﬀector frame.

2.9 Kinematics of Typical Manipulator Structures
This section contains several examples of computation of the direct kinematics function for typical manipulator structures that are often encountered in industrial robots.
With reference to the schematic representation of the kinematic chain, manipulators are usually illustrated in postures where the joint variables, deﬁned according to the DH convention, are diﬀerent from zero; such values might diﬀer from the null references utilized for robot manipulator programming. Hence, it will be necessary to sum constant contributions (oﬀsets) to the values of the joint variables measured by the robot sensory system, so as to match the references.

2.9 Kinematics of Typical Manipulator Structures 69

Fig. 2.20. Three-link planar arm

2.9.1 Three-link Planar Arm
Consider the three-link planar arm in Fig. 2.20, where the link frames have been illustrated. Since the revolute axes are all parallel, the simplest choice was made for all axes xi along the direction of the relative links (the direction of x0 is arbitrary) and all lying in the plane (x0, y0). In this way, all the parameters di are null and the angles between the axes xi directly provide the joint variables. The DH parameters are speciﬁed in Table 2.1.

Table 2.1. DH parameters for the three-link planar arm

Link

ai

αi

di

ϑi

1

a1

0

0

ϑ1

2

a2

0

0

ϑ2

3

a3

0

0

ϑ3

Since all joints are revolute, the homogeneous transformation matrix deﬁned in (2.52) has the same structure for each joint, i.e.,

⎡ ci −si 0 aici ⎤

Aii−1(ϑi)

=

⎢⎣

si 0

ci 0

0 1

aisi 0

⎥⎦

0 001

i = 1, 2, 3.

(2.62)

70 2 Kinematics

Fig. 2.21. Parallelogram arm

Computation of the direct kinematics function as in (2.50) yields

⎡ c123 −s123 0 a1c1 + a2c12 + a3c123 ⎤

T

03(q)

=

A01A12A23

=

⎢⎣

s123 0

c123 0

0 1

a1s1

+

a2s12 0

+

a3s123

⎥⎦

0 00

1

(2.63)

where q = [ ϑ1 ϑ2 ϑ3 ]T . Notice that the unit vector z03 of Frame 3 is aligned with z0 = [ 0 0 1 ]T , in view of the fact that all revolute joints are parallel to axis z0. Obviously, pz = 0 and all three joints concur to determine the end-eﬀector position in the plane of the structure. It is worth pointing out

that Frame 3 does not coincide with the end-eﬀector frame (Fig. 2.13), since

the resulting approach unit vector is aligned with x03 and not with z03. Thus, assuming that the two frames have the same origin, the constant transforma-

tion

⎡ 0 0 1 0⎤

T

3 e

=

⎢⎣

0 −1

1 0

0 0

0 0

⎥⎦

.

0 001

is needed, having taken n aligned with z0.

2.9.2 Parallelogram Arm
Consider the parallelogram arm in Fig. 2.21. A closed chain occurs where the ﬁrst two joints connect Link 1 and Link 1 to Link 0, respectively. Joint 4 was selected as the cut joint, and the link frames have been established accordingly. The DH parameters are speciﬁed in Table 2.2, where a1 = a3 and a2 = a1 in view of the parallelogram structure.
Notice that the parameters for Link 4 are all constant. Since the joints are revolute, the homogeneous transformation matrix deﬁned in (2.52) has

Link 1 2 3 1 4

2.9 Kinematics of Typical Manipulator Structures 71

Table 2.2. DH parameters for the parallelogram arm

ai

αi

di

ϑi

a1

0

0

ϑ1

a2

0

0

ϑ2

a3

0

0

ϑ3

a1

0

0

ϑ1

a4

0

0

0

the same structure for each joint, i.e., as in (2.62) for Joints 1 , 2 , 3 and 1 .

Therefore, the coordinate transformations for the two branches of the tree are

respectively:

⎡ c1 2 3

A03 (q ) = A01 A12 A23

=

⎢⎣

s1

2
0

3

−s1 2 3 c1 2 3
0

0 a1 c1 + a2 c1 2 + a3 c1 2 3 ⎤

0 1

a1 s1

+ a2 s1 2 0

+ a3 s1 2 3

⎥⎦

0

00

1

where q = [ ϑ1 ϑ2 ϑ3 ]T , and

⎡ c1 −s1 0 a1 c1 ⎤

A01

(q

)

=

⎢⎣

s1 0

c1 0

0 1

a1 s1 0

⎥⎦

0 00 1

where q = ϑ1 . To complete, the constant homogeneous transformation for

the last link is

⎡ 1 0 0 a4 ⎤

A34

=

⎢⎣

0 0

1 0

0 1

0 0

⎥⎦ .

000 1

With reference to (2.59), the position constraints are (d3 1
⎡⎤ 0
R30 (q ) p03 (q ) − p01 (q ) = ⎣ 0 ⎦ 0

= 0)

while the orientation constraints are satisﬁed independently of q and q . Since a1 = a3 and a2 = a1 , two independent constraints can be extracted, i.e.,

a1 (c1 + c1 2 3 ) + a1 (c1 2 − c1 ) = 0 a1 (s1 + s1 2 3 ) + a1 (s1 2 − s1 ) = 0.
In order to satisfy them for any choice of a1 and a1 , it must be
ϑ2 = ϑ1 − ϑ1 ϑ3 = π − ϑ2 = π − ϑ1 + ϑ1

72 2 Kinematics

Therefore, the vector of joint variables is q = [ ϑ1 ϑ1 ]T . These joints are natural candidates to be the actuated joints.10 Substituting the expressions of ϑ2 and ϑ3 into the homogeneous transformation A03 and computing the
direct kinematics function as in (2.61) yields

⎡ −c1 s1 0 a1 c1 − a4c1 ⎤

T 04(q) = A03 (q)A34

=

⎢⎣

−s1 0

−c1 0

0 1

a1

s1

− a4s1 0

⎥⎦ .

0 00

1

(2.64)

A comparison between (2.64) and (2.49) reveals that the parallelogram arm is kinematically equivalent to a two-link planar arm. The noticeable diﬀerence, though, is that the two actuated joints — providing the DOFs of the structure — are located at the base. This will greatly simplify the dynamic model of the structure, as will be seen in Sect. 7.3.3.

2.9.3 Spherical Arm
Consider the spherical arm in Fig. 2.22, where the link frames have been illustrated. Notice that the origin of Frame 0 was located at the intersection of z0 with z1 so that d1 = 0; analogously, the origin of Frame 2 was located at the intersection between z1 and z2. The DH parameters are speciﬁed in Table 2.3.

Table 2.3. DH parameters for the spherical arm

Link

ai

αi

di

ϑi

1

0

−π/2

0

ϑ1

2

0

π/2

d2

ϑ2

3

0

0

d3

0

The homogeneous transformation matrices deﬁned in (2.52) are for the single joints:

⎡ c1 0 −s1 0 ⎤

A01(ϑ1)

=

⎢⎣

s1 0

0 −1

c1 0

0 0

⎥⎦

00 01

⎡ c2 0 s2 0 ⎤

A12(ϑ2)

=

⎢⎣

s2 0

0 1

−c2 0

0 d2

⎥⎦

00 0 1

⎡1 0 0 0 ⎤

A23(d3)

=

⎢⎣

0 0

1 0

0 1

0 d3

⎥⎦

.

000 1

10 Notice that it is not possible to solve (2.64) for ϑ2 and ϑ3 since they are constrained by the condition ϑ2 + ϑ3 = π.

2.9 Kinematics of Typical Manipulator Structures 73

Fig. 2.22. Spherical arm

Computation of the direct kinematics function as in (2.50) yields

⎡ c1c2 −s1 c1s2 c1s2d3 − s1d2 ⎤

T

0 3

(q

)

=

A01A12A23

=

⎢⎣

s1c2 −s2

c1 0

s1s2 c2

s1

s2d3 + c2d3

c1

d2

⎥⎦

000

1

(2.65)

where q = [ ϑ1 ϑ2 d3 ]T . Notice that the third joint does not obviously inﬂuence the rotation matrix. Further, the orientation of the unit vector y03
is uniquely determined by the ﬁrst joint, since the revolute axis of the second

joint z1 is parallel to axis y3. Diﬀerent from the previous structures, in this

case Frame 3 can represent an end-eﬀector frame of unit vectors (ne, se, ae),

i.e.,

T

3 e

=

I4.

2.9.4 Anthropomorphic Arm
Consider the anthropomorphic arm in Fig. 2.23. Notice how this arm corresponds to a two-link planar arm with an additional rotation about an axis of the plane. In this respect, the parallelogram arm could be used in lieu of the two-link planar arm, as found in some industrial robots with an anthropomorphic structure.
The link frames have been illustrated in the ﬁgure. As for the previous structure, the origin of Frame 0 was chosen at the intersection of z0 with z1 (d1 = 0); further, z1 and z2 are parallel and the choice of axes x1 and x2 was made as for the two-link planar arm. The DH parameters are speciﬁed in Table 2.4.

74 2 Kinematics

Fig. 2.23. Anthropomorphic arm

Table 2.4. DH parameters for the anthropomorphic arm

Link

ai

αi

di

ϑi

1

0

π/2

0

ϑ1

2

a2

0

0

ϑ2

3

a3

0

0

ϑ3

The homogeneous transformation matrices deﬁned in (2.52) are for the

single joints:

⎡ c1 0 s1 0 ⎤

A01(ϑ1)

=

⎢⎣

s1 0

0 1

−c1 0

0 0

⎥⎦

00 0 1

⎡ ci −si 0 aici ⎤

Aii−1(ϑi)

=

⎢⎣

si 0

ci 0

0 1

aisi 0

⎥⎦

i = 2, 3.

0 001

Computation of the direct kinematics function as in (2.50) yields

⎡ c1c23 −c1s23 s1 c1(a2c2 + a3c23) ⎤

T

03(q)

=

A01A12A23

=

⎢⎣

s1c23 s23

−s1s23 c23

−c1 0

s1(a2c2 + a3c23 a2s2 + a3s23

)

⎥⎦

0

0

0

1

(2.66)

where q = [ ϑ1 ϑ2 ϑ3 ]T . Since z3 is aligned with z2, Frame 3 does not coincide with a possible end-eﬀector frame as in Fig. 2.13, and a proper constant transformation would be needed.

2.9 Kinematics of Typical Manipulator Structures 75

Fig. 2.24. Spherical wrist

2.9.5 Spherical Wrist
Consider a particular type of structure consisting just of the wrist of Fig. 2.24. Joint variables were numbered progressively starting from 4, since such a wrist is typically thought of as mounted on a three-DOF arm of a six-DOF manipulator. It is worth noticing that the wrist is spherical since all revolute axes intersect at a single point. Once z3, z4, z5 have been established, and x3 has been chosen, there is an indeterminacy on the directions of x4 and x5. With reference to the frames indicated in Fig. 2.24, the DH parameters are speciﬁed in Table 2.5.

Table 2.5. DH parameters for the spherical wrist

Link

ai

αi

di

ϑi

4

0

−π/2

0

ϑ4

5

0

π/2

0

ϑ5

6

0

0

d6

ϑ6

The homogeneous transformation matrices deﬁned in (2.52) are for the single joints:

⎡ c4 0 −s4 0 ⎤

A34(ϑ4)

=

⎢⎣

s4 0

0 −1

c4 0

0 0

⎥⎦

00 01

⎡ c5 0 s5 0 ⎤

A45(ϑ5)

=

⎢⎣

s5 0

0 1

−c5 0

0 0

⎥⎦

00 0 1

⎡ c6 −s6 0 0 ⎤

A56(ϑ6)

=

⎢⎣

s6 0

c6 0

0 1

0 d6

⎥⎦

.

0 0 01

76 2 Kinematics

Fig. 2.25. Stanford manipulator

Computation of the direct kinematics function as in (2.50) yields

⎡ c4c5c6 − s4s6

T 36(q)

=

A34A45A56

=

⎢⎣

s4c5c6 + c4s6 −s5c6

0

−c4c5s6 − s4c6 −s4c5s6 + c4c6
s5s6 0

c4s5 s4s5 c5
0

c4s5d6 ⎤

s4s5d6 c5d6

⎥⎦

1

(2.67)

where q = [ ϑ4 ϑ5 ϑ6 ]T . Notice that, as a consequence of the choice made

for

the

coordinate

frames,

the

block

matrix

R36

that

can

be

extracted

from

T

3 6

coincides with the rotation matrix of Euler angles (2.18) previously derived,

that is, ϑ4, ϑ5, ϑ6 constitute the set of ZYZ angles with respect to the reference frame O3–x3y3z3. Moreover, the unit vectors of Frame 6 coincide with the unit vectors of a possible end-eﬀector frame according to Fig. 2.13.

2.9.6 Stanford Manipulator

The so-called Stanford manipulator is composed of a spherical arm and a spherical wrist (Fig. 2.25). Since Frame 3 of the spherical arm coincides with Frame 3 of the spherical wrist, the direct kinematics function can be obtained via simple composition of the transformation matrices (2.65), (2.67) of the previous examples, i.e.,

⎡

⎤

T

0 6

=

T

03T

3 6

=

⎢⎣ n0

s0

a0

p0 ⎥⎦ .

0001

2.9 Kinematics of Typical Manipulator Structures 77

Carrying out the products yields

⎡

⎤

c1s2d3 − s1d2 + c1(c2c4s5 + s2c5) − s1s4s5 d6

p06 = ⎣ s1s2d3 + c1d2 + s1(c2c4s5 + s2c5) + c1s4s5 d6 ⎦

c2d3 + (−s2c4s5 + c2c5)d6

(2.68)

for the end-eﬀector position, and

⎡

⎤

c1 c2(c4c5c6 − s4s6) − s2s5c6 − s1(s4c5c6 + c4s6)

n06 = ⎣ s1 c2(c4c5c6 − s4s6) − s2s5c6 + c1(s4c5c6 + c4s6) ⎦

⎡

−s2(c4c5c6 − s4s6) − c2s5c6

⎤

c1 −c2(c4c5s6 + s4c6) + s2s5s6 − s1(−s4c5s6 + c4c6)

s06 = ⎣ s1 −c2(c4c5s6 + s4c6) + s2s5s6 + c1(−s4c5s6 + c4c6) ⎦ (2.69)

⎡

s2(c4c5s6 + s⎤4c6) + c2s5s6

c1(c2c4s5 + s2c5) − s1s4s5

a06 = ⎣ s1(c2c4s5 + s2c5) + c1s4s5 ⎦

−s2c4s5 + c2c5

for the end-eﬀector orientation. A comparison of the vector p06 in (2.68) with the vector p03 in (2.65) relative
to the sole spherical arm reveals the presence of additional contributions due
to the choice of the origin of the end-eﬀector frame at a distance d6 from the origin of Frame 3 along the direction of a06. In other words, if it were d6 = 0, the position vector would be the same. This feature is of fundamental importance for the solution of the inverse kinematics for this manipulator, as
will be seen later.

2.9.7 Anthropomorphic Arm with Spherical Wrist

A comparison between Fig. 2.23 and Fig. 2.24 reveals that the direct kinemat-

ics function cannot be obtained by multiplying the transformation matrices

T

0 3

and

T

3 6

,

since

Frame

3

of

the

anthropomorphic

arm

cannot

coincide

with

Frame 3 of the spherical wrist.

Direct kinematics of the entire structure can be obtained in two ways.

One

consists

of

interposing

a

constant

transformation

matrix

between

T

0 3

and

T

3 6

which

allows

the

alignment

of

the

two

frames.

The

other

refers

to

the

Denavit–Hartenberg operating procedure with the frame assignment for the

entire structure illustrated in Fig. 2.26. The DH parameters are speciﬁed in

Table 2.6.

Since Rows 3 and 4 diﬀer from the corresponding rows of the tables for

the two single structures, the relative homogeneous transformation matrices

A23 and A34 have to be modiﬁed into

⎡ c3 0 s3 0 ⎤

⎡ c4 0 −s4 0 ⎤

A23(ϑ3)

=

⎢⎣

s3 0

0 1

−c3 0

0 0

⎥⎦

A34(ϑ4)

=

⎢⎣

s4 0

0 −1

c4 0

0 d4

⎥⎦

00 0 1

00 0 1

78 2 Kinematics

Fig. 2.26. Anthropomorphic arm with spherical wrist

Table 2.6. DH parameters for the anthropomorphic arm with spherical wrist

Link

ai

αi

di

ϑi

1

0

π/2

0

ϑ1

2

a2

0

0

ϑ2

3

0

π/2

0

ϑ3

4

0

−π/2

d4

ϑ4

5

0

π/2

0

ϑ5

6

0

0

d6

ϑ6

while the other transformation matrices remain the same. Computation of the

direct kinematics function leads to expressing the position and orientation of

the end-eﬀector frame as:

⎡

⎤

a2c1c2 + d4c1s23 + d6 c1(c23c4s5 + s23c5) + s1s4s5

p06 = ⎣ a2s1c2 + d4s1s23 + d6 s1(c23c4s5 + s23c5) − c1s4s5 ⎦

a2s2 − d4c23 + d6(s23c4s5 − c23c5)

(2.70)

and

⎡

⎤

c1 c23(c4c5c6 − s4s6) − s23s5c6 + s1(s4c5c6 + c4s6)

n06 = ⎣ s1 c23(c4c5c6 − s4s6) − s23s5c6 − c1(s4c5c6 + c4s6) ⎦

⎡

s23(c4c5c6 − s4s6) + c23s5c6

⎤

c1 −c23(c4c5s6 + s4c6) + s23s5s6 + s1(−s4c5s6 + c4c6)

s06 = ⎣ s1 −c23(c4c5s6 + s4c6) + s23s5s6 − c1(−s4c5s6 + c4c6) ⎦ (2.71)

⎡

−s23(c4c5s6 + s⎤4c6) − c23s5s6

c1(c23c4s5 + s23c5) + s1s4s5

a06 = ⎣ s1(c23c4s5 + s23c5) − c1s4s5 ⎦ .

s23c4s5 − c23c5

2.9 Kinematics of Typical Manipulator Structures 79

Fig. 2.27. DLR manipulator

By setting d6 = 0, the position of the wrist axes intersection is obtained. In that case, the vector p0 in (2.70) corresponds to the vector p03 for the sole anthropomorphic arm in (2.66), because d4 gives the length of the forearm (a3) and axis x3 in Fig. 2.26 is rotated by π/2 with respect to axis x3 in Fig. 2.23.
2.9.8 DLR Manipulator
Consider the DLR manipulator, whose development is at the basis of the realization of the robot in Fig. 1.30; it is characterized by seven DOFs and as such it is inherently redundant. This manipulator has two possible conﬁgurations for the outer three joints (wrist). With reference to a spherical wrist similar to that introduced in Sect. 2.9.5, the resulting kinematic structure is illustrated in Fig. 2.27, where the frames attached to the links are evidenced.
As in the case of the spherical arm, notice that the origin of Frame 0 has been chosen so as to zero d1. The DH parameters are speciﬁed in Table 2.7.

Table 2.7. DH parameters for the DLR manipulator

Link

ai

αi

di

ϑi

1

0

π/2

0

ϑ1

2

0

π/2

0

ϑ2

3

0

π/2

d3

ϑ3

4

0

π/2

0

ϑ4

5

0

π/2

d5

ϑ5

6

0

π/2

0

ϑ6

7

0

0

d7

ϑ7

