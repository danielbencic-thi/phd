IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Typesetting math: 52%

Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

    Cart 
    Create Account
    Personal Sign In

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
Access provided by:
Technische Hochschule Ingolstadt
Sign Out
ADVANCED SEARCH
Conferences > 2021 International Conference...
3D Trajectory Planning for UAV-based Search Missions: An Integrated Assessment and Search Planning Approach
Publisher: IEEE
Cite This
PDF
  << Results   
Savvas Papaioannou ; Panayiotis Kolios ; Theocharis Theocharides ; Christos G. Panayiotou ; Marios M. Polycarpou
All Authors
View Document
1
Paper
Citation
157
Full
Text Views

    Alerts
    Alerts
    Manage Content Alerts
    Add to Citation Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Related Work
    III.
    System Architecture
    IV.
    System Model
    V.
    Assessment Planning

Show Full Outline
Authors
Figures
References
Citations
Keywords
Metrics
More Like This

    Download PDF
    View References
    Request Permissions
    Save to
    Alerts 

Abstract: The ability to efficiently plan and execute search missions in challenging and complex environments during natural and man-made disasters is imperative. In many emergency... View more
Metadata
Abstract:
The ability to efficiently plan and execute search missions in challenging and complex environments during natural and man-made disasters is imperative. In many emergency situations, precise navigation between obstacles and time-efficient searching around 3D structures is essential for finding survivors. In this work we propose an integrated assessment and search planning approach which allows an autonomous UAV (unmanned aerial vehicle) agent to plan and execute collision-free search trajectories in 3D environments. More specifically, the proposed search-planning framework aims to integrate and automate the first two phases (i.e., the assessment phase and the search phase) of a traditional search-and-rescue (SAR) mission. In the first stage, termed assessment-planning we aim to find a high-level assessment plan which the UAV agent can execute in order to visit a set of points of interest. The generated plan of this stage guides the UAV to fly over the objects of interest thus providing a first assessment of the situation at hand. In the second stage, termed search-planning, the UAV trajectory is further fine-tuned to allow the UAV to search in 3D (i.e., across all faces) the objects of interest for survivors. The performance of the proposed approach is demonstrated through extensive simulation analysis.
Published in: 2021 International Conference on Unmanned Aircraft Systems (ICUAS)
Date of Conference: 15-18 June 2021
Date Added to IEEE Xplore : 19 July 2021
ISBN Information:
ISSN Information:
INSPEC Accession Number: 20902148
DOI: 10.1109/ICUAS51884.2021.9476869
Publisher: IEEE
Conference Location: Athens, Greece
Contents
SECTION I.
Introduction

Over the last several years we have witnessed an unprecedented interest in unmanned aerial systems. Indeed, the miniaturization and cost reduction of electronic components and the recent technological advancements in avionics, robotic systems and artificial intelligence has led to the rapid growth of unmanned aerial vehicles (UAVs). This has enabled the utilization of UAVs in search-and-rescue (SAR) missions [1] – [2] [3] [4] i.e., during natural or man-made disasters and in emergency response situations. UAVs are currently being used by first responders mainly to provide a birds-eye view of the incident and for conducting rapid spot searches over inaccessible areas to locate missing people and for damage assessment. However, in many situations searching the affected area for survivors with a birds-eye view in not sufficient, especially in challenging and complex environments with obstacles and occlusions, as illustrated in Fig. 1 . In such emergency situations, precise navigation between obstacles and efficient searching around 3D structures is essential for finding survivors.

UAV-based SAR missions are quite challenging by nature, with complex objectives and tight constraints. Take for instance the real-world scenario of a missing person in the woods depicted in Fig. 1(b) . Specifically, the figure shows a birds-eye-view of the scene from a real-world deployment of a UAV in a SAR mission that the authors participated to assist civil protection officers in a missing person incident. The scene depicts the first responders and their vehicles after the UAV took off and the surrounding rural scenery composed of various forms of vegetation. In the depicted thermal image, lighter color represents higher temperatures. Evidently, trees and high foliage block any thermal dissipation from being detected and thus make it impossible to search for the missing person with this top-down view. Additionally, missing people tend to find cover under tall trees to safeguard themselves from the elements of bad weather which makes detection from above impractical. Although, the use of the UAV in this scenario can provide a first assessment of the situation at hand, the chances of finding the missing person using this tactic are very limited.
Fig. 1. - (a) In many emergency situations, precise navigation between obstacles and efficient searching around 3D structures is essential for finding survivors, (b) Aerial view of a rural area taken during a SAR missing person incident from a UAV equipped with a thermal camera.
Fig. 1.

(a) In many emergency situations, precise navigation between obstacles and efficient searching around 3D structures is essential for finding survivors, (b) Aerial view of a rural area taken during a SAR missing person incident from a UAV equipped with a thermal camera.

Show All

Motivated by the challenges described above, in this work we proposed a UAV-based 3D search-planning framework which can be utilized by first responders during search and rescue missions. More specifically our contributions are the following:

    We propose an integrated assessment and search planning approach which can be used to aid search-and-rescue missions with an autonomous UAV agent. In the assessment planning stage, a high-level plan is produced which guides the UAV to fly over the area of interest and gather mission critical information. Then in the second stage, i.e., the search planning stage, the generated search plan is further fine-tuned to allow the UAV agent to search the objects of interest in 3D (i.e., across all faces).

    In order to accomplish the 3D search task a number of artificial rectangular cuboids are generated and placed around the objects of interest that need to be searched. Then, a model predictive control (MPC) algorithm with linear and binary constraints is proposed, for guiding the UAV agent through the generated cuboids. The proposed formulation allows the problem to be solved exactly and efficiently using off-the-shelf solvers.

    We demonstrate the capabilities and performance of the proposed approach through extensive simulated search scenarios.

The rest of the paper is structured as follows. Section II presents an overview of the related work on UAV-based trajectory planning for SAR missions. Section III presents the proposed system architecture and Section IV develops the system model. Section V discusses the details of the assessment planning phase and Section VI presents the proposed 3D search planning phase. Finally, Section VII evaluates the proposed system and Section VIII concludes the paper.
SECTION II.
Related Work

Autonomous planning and control are perhaps the two most desired capabilities in mobile robotics. Over the last years a plethora of methods have been proposed from academic and industrial research labs especially for the problem of planning and control of ground robots operating in 2D environments. Although the proposed approaches have reached a significant level of maturity, there are still challenges to be tackled when more complex scenarios are considered i.e., planning and control in 3D with UAVs during search and rescue (SAR) missions. In such scenarios the task of planning and control is considerably more challenging mainly due to the more demanding mission objectives (e.g., searching with a UAV for survivors during natural disasters in three-dimensional environments, scanning around buildings for people in need, etc.).

UAV-based 3D trajectory planning was investigated in [5] – [6] [7] [8] , with the main objective being the search for a collision-free trajectory to the goal region. More specifically, [5] proposes a two-step trajectory planning approach using Voronoi graph search and artificial forces. In [6] , the authors investigate the problem of UAV trajectory planning in GPS-denied environments. To handle the inherited uncertainty in these situations the authors extend the Belief Roadmap [9] (BRM) planning algorithm with accurate state-estimation based on stochastic-filtering techniques. The trajectory planning problem studied in this work however, is purely kinematic and ignores the UAV dynamics. In [7] , a receding horizon trajectory planning approach is proposed for UAVs and solved using gradient-based methods whereas in [8] the authors use rapidly-exploring random trees (RTTs) to generate collision-free waypoints in a computationally efficient way. At a second stage the generated waypoints are connected with straight line segments and the resulting path is smoothed out using cubic Bezier curves to create a continuous curvature path which the UAV can execute. Because of the complex and not flat terrain, the authors in [10] develop a 3D path planning and execution method based on D*-Lite for search-and-rescue ground robots. In order to reduce the computational complexity of the task, the authors propose to decouple the problem into positioning and orientation planning.

The work in [11] proposes a multi-agent path-planner for detecting a static target with unknown location during search and rescue missions. The proposed technique is exact and is solved using mixed-integer linear programming (MILP). However, it is based on a 2D discrete representation of the world and it does not considers the system dynamics.

The authors in [12] investigate various discrete path-planning techniques for searching survivors with UAVs during disasters, including artificial potential fields (APF), fuzzy logic and genetic algorithms (GA). The works in [13] – [14] [15] [16] develop searching-and-tracking (SAT) approaches for searching an area of interest with multiple UAV agents and tracking multiple targets of interest. These works however are myopic and are based on a 2D representation of the world.

More recently the work in [17] investigated the problem of search planning during SAR missions using UAVs. The authors formulate the trajectory planning problem as a model predictive control (MPC) problem and they solve it using particle swarm optimization (PSO). This technique used a 2D coordinated kinematic model for the UAVs and the search planning was conducted in two-dimensions. Detailed surveys discussing the various trajectory/path planning methods in the literature and their applications can be found in [18] – [19] [20] [21] .

Compared to the related work the most notable differentiating factors of this work are a) the proposed two-stage search planning architecture which captures the increasing level of complexity of the various phases of a SAR mission and b) the necessity to search in 3D the objects of interest from all views in order to search for survivors.
SECTION III.
System Architecture

SAR missions typically consist of three phases [22] , [23] namely a) assessment, b) search and c) rescue. The goal of the assessment phase is the determination of the course of action. This is a critical phase in which the rescue team assesses the damages and the hazards in the vicinity of the affected area in order to prepare and organize the search and rescue mission. On the other hand the goal of the search phase is to conduct efficient, organized and thorough searches in the affected area in order to located survivors as efficiently as possible. Search operations when possible follow optimized search patterns which have been planned ahead in order to increase the efficiency of the search. In addition, the search team is often required to search around and along large structures/buildings, below bridges and under high foliage in order to locate people in need. Finally, during the last phase, people are given medical aid and are transported to safety.

The proposed approach aims to integrate and automate the first two phases (i.e., the assessment and the search phases) of a traditional SAR mission with a single UAV agent. The proposed approach is illustrated in Fig. 2 . In the first phase the human operator specifies the critical areas (as waypoints) to be visited in order for the rescue team to assess the incident at hand. In the second phase a more detailed specification is given regarding the mission which allows the UAV agent to search the objects of interest across all faces in 3D.

In this paper we assume that a controllable flying agent or a UAV, operates inside a bounded 3D environment which contains a) objects of interest which need to be searched (i.e., searched across all faces) and b) obstacles that need to be avoided.
Fig. 2. - Overview of the proposed search planning system architecture. The proposed framework aims to automate the first two phases (i.e., the assessment phase and the search phase) of a traditional SAR mission with a UAV agent.
Fig. 2.

Overview of the proposed search planning system architecture. The proposed framework aims to automate the first two phases (i.e., the assessment phase and the search phase) of a traditional SAR mission with a UAV agent.

Show All

Let the set of all objects of interest inside the surveillance region that need to be searched be denoted by J = { j 1 , j 2 , ⋯ , j | J | } , with the set cardinality | J | denoting their total count. Similarly, we denote the set of all obstacles in the environment by Ξ = { ξ 1 , ξ 2 , ⋯ , ξ | Ξ | } . We assume that the UAV agent is controllable and evolves in time according to a discrete-time dynamical model. Additionally, we assume that the agent is equipped with a camera system, with finite field-of-view (FoV), which uses for perceiving its surroundings.

In the first stage, termed Assessment planning , we aim to derive a high-level 3D search plan in order to acquire more information about the objects of interest in the set J . This plan is generated in accordance to the agent dynamics and optimizes a simplified mission objective (i.e., minimizing the proximity of the agent with a set of waypoints). In this stage, the 3D objects of interest are approximated by waypoints in 3D, produced in a pre-processing step (i.e., during the waypoint generation step). The generated trajectory of this stage will guide the UAV to fly over the objects of interest by visiting their waypoint approximation, gathering information about the mission such as the dimensions of the objects of interest and the location of the obstacles in the environment. Essentially, the generated UAV trajectory of this phase is used to build a 3D map of the environment [24] – [25] [26] [27] , which in turn is utilized to reconstruct the objects of interest J and obstacles Ξ in the environment as rectangular cuboids for the Search Planning stage.

In the second stage, termed Search Planning , all objects of interest and obstacles are represented as rectangular cuboids based on the information acquired in the first stage. In this stage, the planning takes place over a smaller area of the surveillance region and produces accurate and fine-tuned plans which take into account the agent dynamics, the environmental constraints (i.e., obstacles), and the agent sensing model (i.e., the specifications of the UAV onboard camera system) and allows the agent to search in 3D all objects of interest while avoiding collisions with the obstacles in the environment. In essence, during this stage we find the optimal UAV control inputs which allow the UAV to search an object of interest across all faces.
SECTION IV.
System Model
A. Agent Dynamical Model

In this work we assume that the UAV agent evolves in 3D space according to the following discrete-time dynamical model:
x t = Φ x t − 1 + Γ u t − 1 (1)
View Source Right-click on figure for MathML and additional features. \begin{equation*} x_{t}=\Phi x_{t-1}+\Gamma u_{t-1} \tag{1} \end{equation*} where x t = [ x , x ˙ ] ⊤ t ∈ R 6 denotes the agent's state at time t which consists of position x t = [ p x , p y , p z ] t ∈ R 3 and velocity x ˙ t = [ ν x , ν y , ν z ] t ∈ R 3 components in 3D cartesian coordinates. The agent can be controlled by applying an amount of force u ∈ R 3 in each dimension, thus u t = [ f x , f y , f z ] ⊤ t denotes the applied force vector at t . The matrices Φ and Γ are given by:
Φ = [ I 3 0 3 Δ T ⋅ I 3 ϕ ⋅ I 3 ] ,   Γ = [ 0 3 γ ⋅ I 3 ] (2)
View Source Right-click on figure for MathML and additional features. \begin{equation*} \Phi= \begin{bmatrix}\mathrm{I}_{3}& \Delta T\cdot \mathrm{I}_{3}\\ 0_{3}& \phi\cdot \mathrm{I}_{3}\end{bmatrix},\ \Gamma= \begin{bmatrix}0_{3}\\ \gamma\cdot \mathrm{I}_{3}\end{bmatrix} \tag{2} \end{equation*} where Δ T is the sampling interval, I 3 is the identity matrix of dimension 3 × 3 and 0 3 is the zero matrix of dimension 3 × 3 . The parameters ϕ and γ are further given by ϕ = ( 1 − η ) and γ = m − 1 Δ T , where η is used to model the air resistance and m is the agent mass.

B. Agent Sensing Model

The agent is equipped with an onboard camera taking snapshots of the objects of interest in order to search for survivors or people in need. Without loss of generality, we assume in this work that the camera field of view (FoV) angles in the horizontal and vertical axis are equal [28] and thus the projected FoV footprint on a planar surface is square with side length r and given by:
r ( d ) = 2 d tan ( φ 2 ) (3)
View Source Right-click on figure for MathML and additional features. \begin{equation*} r(d)=2d \tan\left(\frac{\varphi}{2}\right)\tag{3} \end{equation*} where d denotes the distance in meters between the location of agent and the surface of the object that needs to be searched and φ is the angle opening of the FoV according to the camera specifications. Thus the area of the FoV footprint at a distance d is r ( d ) 2 meters. Before taking a snapshot of the object of interest the agent first aligns its camera with respect to the surface in such a way so that the optical axis of the camera (i.e., the viewing direction) is parallel to the normal vector ( α ) of the surface, as illustrated in Fig. 3 .

In order to search an object of interest the agent needs to take multiple snapshots (according to the size of the FoV as given by Eqn. (3) ) such that the surface area of each face of the object is completely included in the acquired images.
Fig. 3. - The figure illustrates the agent sensing model i.e., a square region with dimensions $r\times r$. The angle $\varphi$ determines the FoV opening and $\alpha$ is the normal vector to the face of the object.
Fig. 3.

The figure illustrates the agent sensing model i.e., a square region with dimensions r × r . The angle φ determines the FoV opening and α is the normal vector to the face of the object.

Show All

C. Object Representation

The objects of interest that need to be searched in 3D and the obstacles inside the surveillance area that need to be avoided are represented in this work as rectangular cuboids of various sizes (referred to as cuboids hereafter). A rectangular cuboid is a convex hexahedron in three dimensional space which exhibits six rectangular faces (i.e., where each pair of adjacent faces meets in a right angle). A point x = [ x , y , z ] ⊤ ∈ R 3 that belongs to the cuboid C or resides inside the cuboid satisfies the following system of linear inequalities:
a 11 x + a 12 y + a 13 z ≤ b 1 a 21 x + a 22 y + a 23 z ≤ b 2     ⋮ a n 1 x + a n 2 y + a n 3 z ≤ b n
View Source Right-click on figure for MathML and additional features. \begin{align*} &a_{11}x+ a_{12}y+ a_{13}z\leq b_{1}\\ &a_{21}x+ a_{22}y+ a_{23}z\leq b_{2}\\ &\qquad\ \ \qquad\vdots\\ &a_{n1}x+ a_{n2}y+ a_{n3}z\leq b_{n} \end{align*} where n = 6 is the total number of faces which compose the cuboid C ,   α i = [ a i 1 , a i 2 , a i 3 ] is the outward normal vector to the i th face of the cuboid and b i is a constant. In more compact form the expression above can be written as A x ≤ B where A is a n × 3 matrix, x is a 3 × 1 column vector and B is a n × 1 column vector. For the rest of the paper, we will denote a rectangular cuboid C by the matrices A and B . That said, in this work we assume that the surveillance region has been 3D mapped [24] , [25] during the assessment phase and subsequently the objects of interest and obstacles in the environment have been represented as cuboids, as discussed above. Moreover, we should note here that the proposed technique can be applied to any type of object as long as it can be represented as a convex polyhedron.

SECTION V.
Assessment Planning

In the assessment planning phase the objective is to compute the UAV control inputs which guide the agent to fly over the objects of interest with the ultimate purpose of collecting critical information regarding the mission. We assume that this information includes the dimensions of the objects of interest and obstacles and the faces of the objects of interest that need to be searched. This information is passed to the second stage which is responsible for guiding the UAV agent to search the objects of interest in 3D while avoiding collisions with obstacles in the environment.

In this stage, the objects of interest are approximated by single 3D waypoints and by taking into account the agent dynamics a high-level plan is generated which minimizes the proximity of the agent with the waypoints. Thus the waypoint generation pre-processing step is applied first in which each object of interest j ∈ J is approximated by a single location in 3D space (i.e., the waypoint w j ) and a mixed integer linear program ( P 1 ) is derived below to compute the plan which guides the UAV as close as possible to the waypoints.

Problem Assessment Planning :
( P 1 )     min u 0 : T − 1 ∑ t = 1 T ∑ j = 1 | J | ζ t , j s u b j e c t   t o   t ∈ { 1 , … , T } : x t = Φ t x 0 + ∑ τ = 0 t − 1 Φ τ Γ u t − τ − 1 x w + t , j − x w − t , j = d ( H x t , w j ) ∑ t = 1 T b t , j = 1 ζ t , j ≤ M b t , j ζ t , j ≤ x w + t , j + x w − t , j ζ t , j ≥ x w + t , j + x w − t , j − M ( 1 − b t , j ) { x w + t , j , x w − t , j , ζ t , j } ≥ 0 b t , j ∈ { 0 , 1 } ∀ t , j ∀ j ∀ t , j ∀ t , j ∀ t , j ∀ t , j ∀ t , j (4a) (4b) (4c) (4d) (4e) (4f) (4g) (4h) (4i)
View Source Right-click on figure for MathML and additional features. \begin{align*} &(\mathrm{P}1)\ \ \min\limits_{u_{0:T-1}}\sum\limits_{t=1}^{T} \sum\limits_{j=1}^{\vert J\vert} \zeta_{t, j}\tag{4a}\\ &\mathbf{subject\ to}\ t\in\{1, \ldots, T\}:\\ &x_{t}= \Phi^{t} x_{0}+ \sum\limits_{\tau=0}^{t-1}\Phi^{\tau}\Gamma u_{t-\tau-1}\tag{4b}\\ &xw_{t, j}^{+}- xw_{t, j}^{-}=d(Hx_{t}, w_{j})&&\forall t, j\tag{4c}\\ &\sum\limits_{t=1}^{T} b_{t, j}=1&&\quad\forall j\tag{4d}\\ & \zeta_{t, j}\leq Mb_{t, j}&&\forall t, j\tag{4e}\\ & \zeta_{t, j}\leq xw_{t, j}^{+}+ xw_{t, j}^{-}&&\forall t, j\tag{4f}\\ & \zeta_{t, j}\geq xw_{t, j}^{+}+ xw_{t, j}^{-}-M(1- b_{t, j})&&\forall t, j\tag{4g}\\ &\{xw_{t, j}^{+}, xw_{t, j}^{-}, \zeta_{t, j}\}\geq 0&&\forall t, j\tag{4h}\\ &b_{t, j}\in\{0,1\}&&\forall t, j\tag{4i} \end{align*}

The program in ( P 1 ) finds the optimal control inputs u 0 : T − 1 over the planning horizon T which minimizes the L 1 -norm between the computed UAV 3D trajectory and the waypoints according to the agent dynamics defined in Eqn. (4b) . First, we linearize the L 1 -norm between the position of the agent H x t at a specific time instance and the position of waypoint w j of object j i.e., | H x t − w j | , where H is a matrix which extracts the position coordinates from the agent state x t .

To do that we define d ( H x t , w j ) = H x t − w j , which according to the constraint in Eqn. (4c) , is assigned to the variable x w + t , j if it is positive and to the variable x w − t , j if it is negative. Because, x w + t , j and x w − t , j are tied to the decision variable ζ t , j which is minimized and since x w + t , j ,   x w − t j and ζ t , j are all defined to take positive values (i.e., Eqn. (4h)), the optimizer assigns the value of | H x t − w j | to ζ t , j via the constraints in Eqn. (4e)–Eqn. (4g) when the binary variable b t , j is activated.

More specifically, the binary variable b t , j indicates the time instance that waypoint w j is visited by the agent. Thus the decision variable ζ t , j is assigned with distance values at the time-steps which specific waypoints are visited. The constraint in Eqn. (4c) computes the L 1 -norm between the UAV trajectory and the waypoints for all possible UAV positions in the planning horizon. The constraint in Eqn. (4d) ensures that the number of binary variables that are activated are equal to the total number of waypoints i.e., each waypoint is visited exactly once during the planning horizon. Finally, the set of constraints (4e)-(4g) assign the distance between waypoint j and the UAV position H x t at time t to ζ t , j , if b t , j = 1 . Observe, that when b t , j = 0 the value of ζ t , j is driven to zero. Thus, the minimization of Eqn. (4a) forces the UAV agent to approach as close as possible to the waypoints, one waypoint at a time, while enforcing the constraint of its dynamical model.
Fig. 4. - The figure illustrates the cuboid-generation pre-processing step which allows the agent to search all faces of an object of interest by passing through the generated cuboids.
Fig. 4.

The figure illustrates the cuboid-generation pre-processing step which allows the agent to search all faces of an object of interest by passing through the generated cuboids.

Show All

The produced 3D trajectory guides the agent to pass from all waypoints thus acquiring information regarding the objects of interest i.e., their dimensions and other critical information about the mission such as the location of obstacles which are used in stage two below.
SECTION VI.
Search Planning

In the second phase, termed Search Planning , the framework can be used to compute fine-tuned and collision-free search plans inside a smaller area of the surveillance region. In particular in this stage the generated search plans allow the agent to search the objects of interest in 3D (i.e., for each object of interest all their faces are searched for survivors according to the camera specifications). We assume that the information collected during the first stage allows us to represent each object of interest j that needs to be searched and the obstacles in the environment as rectangular cuboids i.e., Sec IV-C . Thus for this phase we assume that the UAV has obtained a map of the environment which contains the locations of the objects of interest as well as the locations of the obstacles in the environment. In this map all objects of interest and obstacles have been represented as rectangular cuboids of appropriate dimensions.

Before discussing the details of the proposed search planning technique we first describe the pre-processing step (i.e., the cuboid generation step) which takes place before the main trajectory planning process.
A. Cuboid Generation

The main idea here is to generate artificial cuboids all around the object of interest and then guide the UAV agent through these cuboids in order to search the object in 3D from all faces, i.e., scan the total surface area of the object with the UAV's camera system. The generated cuboids are placed at specific distances from the object of interest according to the specifications of the UAV camera system Eqn. (3) . More specifically, we assume that we know apriori the distance d that the UAV must maintain with a particular object of interest during searching. Given d and the camera FoV angle φ , the size of the UAV FoV footprint can be determined by Eqn. (3) as a square with length r . Subsequently, the area of each face of the object of interest that needs to be searched is decomposed into several r × r cells and for each of those cells a cuboid is generated at distance d , so that when the agent passes from within a cuboid the corresponding area of the face is searched. That said, in the cuboid generation preprocessing step, for each face f i , i ∈ [ 1 , … , 6 ] of the object of interest j we generate artificial cuboids C j i , n , n ∈ [ 1 , … , N j i ] at distance d where N j i is the total number of cuboids that are necessary to cover the whole area of face f i of object of interest j .

This is illustrated in Fig. 4 , where 4 faces of the object of interest need to be searched and thus each of the 4 faces has been decomposed into several cells marked with light blue color. For each cell a cuboid shown in black color is generated to allow the agent to pass through it and search the corresponding part (area) of the face. More specifically, in Fig. 4 , the object of interest (with brown color) is represented by a rectangular cuboid with dimensions width = 60 m ,   length = 60 m and height = 60 m . We assume that this information was acquired during the Assessment planning phase. The UAV agent must maintain a distance of d = 27 m from each of the object's faces, and the FoV angle is φ = 60 deg . The camera FoV area in this case is approximately 30 × 30   m 2 according to Eqn. (3) . That said, each of the objects's faces is decomposed into cells of size 30 × 30   m 2 creating a grid of 4 cells. This is depicted in Fig. 4 with the light blue 3D boxes in front of each face. Then for each cell a cuboid is generated at distance d from the object, shown in black color in Fig. 4 . When the agent resides within a cuboid their FoV projection captures an area of size 30 × 30   m 2 on the face of the object. By guiding the agent through all 4 cuboids we allow the agent to cover the total surface area of a face with its camera system. Consequently, we are interested in guiding the agent via all the generated cuboids in order to search the object of interest across all faces.
B. 3D Search Planning

Once the cuboid generation pre-processing step is completed, we formulate the problem of searching the object of interest in 3D, as a rolling-horizon model predictive control (MPC) problem with linear and binary constraints and we solve it using off-the-shelf mixed-integer programming (MIP) solvers. Specifically, in the proposed approach at each sampling time t the UAV control actions u t | t , … , u t + T − 1 | t are obtained over a rolling-horizon of length T time-steps by solving a finite horizon open-loop optimal control problem using the current state of the UAV x t | t as the initial state. The first control action u t | t in the sequence is then applied to the UAV and the optimization is repeated for the next sampling time. In this problem we consider 2 different types of constraints: a) linear constraints which govern the UAV dynamical model and b) binary constraints for the search task, obstacle avoidance and duplication of effort. Let us assume, that the cuboid generation pre-processing step has created a total of N cuboids C n ,   n ∈ [ 1 , … , N ] (across all faces) around a single object of interest j . For notational clarity we assume that for every face i of the object of interest we generate the same number of cuboids and we drop the index j of the object of interest, thus C j i , n becomes C n for a single object of interest.

We associate each cuboid \mathcal{C}_{n} that needs to be visited with a binary variable y_{n} which indicates whether this cuboid has been marked to be visited at some future time step (t+\tau+ 1\vert t), \tau\in\{0,\ldots, T-1\} i.e., y_{n}=1 , iff Hx_{t+\tau+1\vert t}\in \mathcal{C}_{n} . Here H is a matrix which extracts the position coordinates from the agent's state. That said, the 3D search task objective becomes the maximization of the cuboids to be visited over the planning horizon i.e., \begin{equation*} \max\sum\limits_{n}y_{n} \tag{5} \end{equation*}
View Source Right-click on figure for MathML and additional features. \begin{equation*} \max\sum\limits_{n}y_{n} \tag{5} \end{equation*}

For infinite planning horizon problems Eqn. (5) can be used to devise a search plan that will visit all the unvisited cuboids. However, to apply Eqn. (5) in a rolling finite horizon fashion we need to keep track of the visited cuboids in order to avoid visiting the same cuboids over and over. To achieve this, the UAV agent maintains a map V which is used to keep track of all visited cuboids as shown below: \begin{equation*} V(n)=\begin{cases} 1&, \ \text{if}\ Hx_{0:t}\in \mathcal{C}_{n}\\ 0&, \ \mathrm{o}.\mathrm{w} \end{cases} \tag{6} \end{equation*}
View Source Right-click on figure for MathML and additional features. \begin{equation*} V(n)=\begin{cases} 1&, \ \text{if}\ Hx_{0:t}\in \mathcal{C}_{n}\\ 0&, \ \mathrm{o}.\mathrm{w} \end{cases} \tag{6} \end{equation*} where Hx_{0:t} denotes the agent's locations up to time t . That said, the complete mathematical formulation of the 3D search planning problem tackled in this work is shown in (P2) below:

1) Mission Objective

In (P2) we are interested in finding the optimal UAV control actions u_{t\vert t}, \ldots, u_{t+T-1\vert t} over the rolling horizon of length T that minimizes the mission objective h(\mathbf{x},\mathbf{u},\mathbf{y}) shown in Eqn. (7) . The mission objective is a function of the agent's future state \mathbf{x} , control inputs \mathbf{u} and the binary variables \mathbf{y} which indicate whether a cuboid has been planned to be visited in the future. More specifically, the mission objective is given by: \begin{equation*}\begin{split} h(\mathbf{x}, \mathbf{u}, \mathbf{y})=a\Vert Hx_{t+\tau^{\star}+1\vert t}-x^{\star} \Vert_{2}^{2} +&\\ b\sum\limits_{\tau=1}^{T-1}\Vert u_{t+\tau\vert t}- u_{t+\tau-1\vert t}\Vert_{2}^{2}-c& \sum\limits_{n=1}^{N} y_{n} \end{split}\tag{7}\end{equation*}
View Source Right-click on figure for MathML and additional features. \begin{equation*}\begin{split} h(\mathbf{x}, \mathbf{u}, \mathbf{y})=a\Vert Hx_{t+\tau^{\star}+1\vert t}-x^{\star} \Vert_{2}^{2} +&\\ b\sum\limits_{\tau=1}^{T-1}\Vert u_{t+\tau\vert t}- u_{t+\tau-1\vert t}\Vert_{2}^{2}-c& \sum\limits_{n=1}^{N} y_{n} \end{split}\tag{7}\end{equation*} where \tau^{\star}\in\{0,\ldots, T-1\},\ x^{\star} is the centroid of the nearest (with respect to the agent's current location) unvisited cuboid and ( a, b, c ) are weights associated with the different mission objectives. In particular, the first term i.e., \Vert Hx_{t+\tau^{\star}+1\vert t}-x^{\star}\Vert_{2}^{2} guides the UAV agent towards the nearest unvisited cuboid by minimizing the squared euclidian distance of the future agent location Hx_{t+\tau^{-\star}+1\vert t} with the centroid of the nearest unvisited cuboid x^{\star} . Moreover, the second term i.e., \sum_{\tau=0}^{T-1}\Vert u_{t+\tau+1\vert t}-u_{t+\tau\vert t}\Vert_{2}^{2} is used to minimize the deviations between consecutive control inputs, thus leading to smoother UAV trajectories. Finally, the last term in Eqn. (7) is used for maximizing the number of cuboids to be visited over the planning horizon, as discussed previously.

2) Mission Constraints

We can now describe the mission constraints which lead to the desired 3D search planning behavior. The constraints in Eqn. (8b)–(8c) are due to the agent dynamical model as described in Section IV , assuming a known initial state x_{1\vert 1}=x_{0} . As we have already mentioned, the cuboid generation pre-processing step has created a total of N cuboids \mathcal{C}_{i}, i\in[1,\ldots, N] for the object of interest j .

The constraints in Eqn. (8d)-(8g) are due to the 3D search task. Specifically, the constraint in (8d) uses \tau\times N\times L binary variables b_{\tau, n, l} , for \tau\in\{0,\ldots, T-1\},\ n\in\{1,\ldots, N\} and l\in\{1,\ldots, L\} to determine whether the agent position Hx_{t+\tau+1\vert t} resides inside the negative or positive half-space defined by the plane which contains the l_{\text{th}} face of the n_{\text{th}} cuboid. The matrix A_{n} of size ( L\times 3 ) and the vector B_{n} of size ( L\times 1 ) represent the linear system of inequalities A_{n}x\leq B_{n} for which a 3D point x must satisfy in order to reside inside the cuboid \mathcal{C}_{n} i.e., Sec IV-C . Thus, the inequality A_{n, l}Hx_{t+\tau+1\vert t}\leq B_{n, l} becomes true when the UAV location resides inside the negative half-space created by the plane containing the l_{\text{th}} face of the n_{\text{th}} cuboid. When this happens the corresponding binary variable b_{\tau, n, l} becomes 1 to satisfy the constraint. Otherwise b_{\tau, n, l}=0 and the constraint in Eqn. (8d) is valid with the addition of a large positive constant (i.e., big-M) M as shown.

Problem Search Planning : \begin{align*} &(\mathrm{P}2) \min\limits_{u_{t\vert t},\ldots, u_{t+T-1\vert t}}h(\mathbf{x}, \mathbf{u}, \mathbf{y})\tag{8a}\\ &\mathbf{subject\ to}\ \tau\in\{0, \ldots, T-1\}:\\ &x_{t+\tau+1\vert t}=\Phi x_{t+\tau\vert t}+\Gamma_{u_{t+\tau\vert t}}&& \ \ \ \quad\forall\tau\tag{8b}\\ &x_{t\vert t}= x_{t\vert t-1}\tag{8c}\\ &A_{n, l} Hx_{t+\tau+1\vert t}+(M- B_{n, l}) b_{\tau, n, l}\leq M&& \forall\tau, n, l\tag{8d}\\ &L \tilde{b}_{\tau, n}- \sum\limits_{l=1}^{L} b_{\tau, n, l}\leq 0&& \ \ \forall\tau, n\tag{8e}\\ &\hat{b}_{n}\leq \sum\limits_{\tau}\tilde{b}_{\tau, n}&& \ \ \quad\forall n\tag{8f}\\ &y_{n}\leq\hat{b}_{n}+V(n)&& \ \ \forall\tau, n\tag{8g}\\ &A_{\psi, l} Hx_{t+\tau+1\vert t} > B_{\psi, l}- Mz_{\tau,\psi, l}&& \forall\tau, \psi, l\tag{8h}\\ & \sum\limits_{l=1}^{L} z_{\tau,\psi, l}\leq L-1&& \ \ \ \forall\tau, \psi\tag{8i}\\ &b_{\tau, n, l},\tilde{b}_{\tau, n},\hat{b}_{n}, y_{n}, z_{\tau,\psi, l}\in\{0,1\}&& \forall\tau, n, \psi, l \tag{8j}\\ &\vert \dot{\mathrm{x}}_{t+\tau+1\vert t}\vert \leq v_{\max}&&\qquad\ \ \forall\tau\tag{8k}\\ &\vert u_{t+\tau+1\vert t}\vert \leq u_{\max}&& \qquad\ \ \forall\tau \tag{8l} \end{align*}
View Source Right-click on figure for MathML and additional features. \begin{align*} &(\mathrm{P}2) \min\limits_{u_{t\vert t},\ldots, u_{t+T-1\vert t}}h(\mathbf{x}, \mathbf{u}, \mathbf{y})\tag{8a}\\ &\mathbf{subject\ to}\ \tau\in\{0, \ldots, T-1\}:\\ &x_{t+\tau+1\vert t}=\Phi x_{t+\tau\vert t}+\Gamma_{u_{t+\tau\vert t}}&& \ \ \ \quad\forall\tau\tag{8b}\\ &x_{t\vert t}= x_{t\vert t-1}\tag{8c}\\ &A_{n, l} Hx_{t+\tau+1\vert t}+(M- B_{n, l}) b_{\tau, n, l}\leq M&& \forall\tau, n, l\tag{8d}\\ &L \tilde{b}_{\tau, n}- \sum\limits_{l=1}^{L} b_{\tau, n, l}\leq 0&& \ \ \forall\tau, n\tag{8e}\\ &\hat{b}_{n}\leq \sum\limits_{\tau}\tilde{b}_{\tau, n}&& \ \ \quad\forall n\tag{8f}\\ &y_{n}\leq\hat{b}_{n}+V(n)&& \ \ \forall\tau, n\tag{8g}\\ &A_{\psi, l} Hx_{t+\tau+1\vert t} > B_{\psi, l}- Mz_{\tau,\psi, l}&& \forall\tau, \psi, l\tag{8h}\\ & \sum\limits_{l=1}^{L} z_{\tau,\psi, l}\leq L-1&& \ \ \ \forall\tau, \psi\tag{8i}\\ &b_{\tau, n, l},\tilde{b}_{\tau, n},\hat{b}_{n}, y_{n}, z_{\tau,\psi, l}\in\{0,1\}&& \forall\tau, n, \psi, l \tag{8j}\\ &\vert \dot{\mathrm{x}}_{t+\tau+1\vert t}\vert \leq v_{\max}&&\qquad\ \ \forall\tau\tag{8k}\\ &\vert u_{t+\tau+1\vert t}\vert \leq u_{\max}&& \qquad\ \ \forall\tau \tag{8l} \end{align*}

Subsequently, the binary variable \tilde{b}_{\tau, n} in Eqn. (8e) is activated when the system of linear inequalities is satisfied i.e., A_{n, l}Hx_{t+\tau+1\vert t}\leq B_{n, l}, \forall l which indicates that the agent location Hx_{t+\tau+1\vert t} resides inside the cuboid n at time t+\tau+1 . The constraint in Eqn. (8f) makes sure that the agent is not rewarded by planning trajectories which visit the same cuboid more than once in the future.

Finally, the constraint in Eqn. (8g) makes sure that the agent is not rewarded for visiting cuboids that have been visited in the past.
Fig. 5. - An illustrative example of the assessment planning phase
Fig. 5.

An illustrative example of the assessment planning phase

Show All

Lastly, the constraints (8h)–(8i) are the collision avoidance constraints with the object of interest and with obstacles in the environment. The UAV agent avoids a collision with an object when: \begin{equation*} Hx_{t+\tau+1\vert t}\ /{\!\!\!\in} \mathcal{C}_{\psi},\ \forall\psi\in\Psi, \tau\in\{0,\ldots, T-1\} \tag{9} \end{equation*}
View Source Right-click on figure for MathML and additional features. \begin{equation*} Hx_{t+\tau+1\vert t}\ /{\!\!\!\in} \mathcal{C}_{\psi},\ \forall\psi\in\Psi, \tau\in\{0,\ldots, T-1\} \tag{9} \end{equation*} where \mathcal{C}_{\psi} denotes the obstacle \psi\in\Psi to be avoided which is represented as a convex polyhedron e.g., a rectangular cuboid. Suppose that all objects \psi to be avoided contain L faces, then a collision is avoided at time \tau with object \psi if \exists l\in\{1,\ldots, L\}: A_{\psi, l}Hx_{t+\tau+1\vert t} > B_{\psi, l} .

The constraint in Eqn. (8h) uses T\times\vert \Psi\vert \times L binary variables z_{t,\psi, l} to check if the constraint A_{\psi, l}Hx_{t+\tau+1\vert t} > B_{\psi, l} is violated where M is a big positive constant. Then, constraint (8i) counts the number of times z_{t,\psi, l} is activated and makes sure that this number is less or equal than L-1 . Equivalently, agent controls are chosen so that the linear system of inequalities A_{\psi}Hx_{t+\tau+1\vert t} < B_{\psi} is not satisfied. The constraint in Eqn. (8j) declares the binary variables of the problem and finally the constraints in Eqn. (8k) and Eqn. (8l) define the agent's maximum speed and maximum control input respectively.

Finally, we should mention that the above search planning formulation can be easily extended for multiple objects of interest. This can be achieved by expanding the binary variables by one dimension in order to distinguish the cuboids of different objects of interest. For instance for objects of interest j\in J the binary variable b_{\tau, n, l} in Eqn. (8d) becomes b_{\tau, n, l}^{j} , the binary variable \tilde{b}_{\tau, n} in Eqn. (8e) becomes \tilde{b}_{\tau, n}^{j} and so forth.
SECTION VII.
Evaluation
A. Experimental Setup

To evaluate the performance of the proposed two-stage search planning approach we have conducted several synthetic experiments and simulations with varying number of waypoints, obstacles and objects of interest. In each test we evaluate the proposed approach either qualitatively or quantitatively and we discuss its strengths and weaknesses. The experimental evaluation is divided into two parts. First, we investigate the performance of the Assessment Planning phase as discussed in Sec V and then we conduct the experimental evaluation of the Search Planning phase i.e., Sec VI .
Fig. 6. - The figure illustrates how the number of waypoints affects the performance of the proposed technique.
Fig. 6.

The figure illustrates how the number of waypoints affects the performance of the proposed technique.

Show All

The experimental setup used for the evaluation of the proposed system is as follows: The agent dynamics are expressed by Eqn. (1) with \Delta T=1\mathrm{s} , agent mass m= 3.35\text{kg} and \eta=0.2 . The maximum applied control input u_{\max} is 20N or ( \text{kg}.\mathrm{m}/\mathrm{s}^{2} ), the maximum agent velocity v_{\max} is 15m/s and the agent acceleration can reach 6m/s 2 . Moreover, we assume that the agent FoV angle \phi is 60deg.
B. Results
1) Assessment Planning

We begin our evaluation with a 3D simulated scenario for the assessment planning phase. In this scenario we deploy 7 objects of interest of various sizes throughout the surveillance area of dimension 600\mathrm{m} \times 300\mathrm{m}\times 70\mathrm{m} . The objects of interest are approximated in this step as 3D waypoints shown as green circles in Fig. 5a . The planning horizon T is set to 55 time-steps and the mixed-integer linear program in (P1) is applied to obtain the results shown in Fig. 5 . The objective here is to devise a plan that will guide the UAV agent to visit all waypoints within the specified time horizon while satisfying the agent dynamical constraints. The agent start position is marked with a green asterisk and the agent final position is marked with a red asterisk as shown in the figure. Figure 5a shows the generated UAV trajectory that visits all the specified waypoints. Figure 5b shows the L1 -distance of the planned trajectory with each of the 7 waypoints and finally Fig. 5c and Fig. 5d show in more detail the ( x, y, z ) coordinates of obtained trajectory and the applied control inputs respectively.

The next experiment aims to investigate how the number of waypoints affect the performance of the proposed assessment planning technique. For this experiment we have conducted 20 Monte Carlo trials where we uniformly generate random waypoints inside a surveillance area of dimensions 200\mathrm{m} \times 200\mathrm{m}\times 50\mathrm{m} and will let our system to run with a fixed time-horizon of 50 time-steps, measuring the runtime, the number of explored nodes during the MIP branch-and-bound optimization and the value of the objective function at the end of the optimization. Figure 6a shows the average runtime and the average number of explored nodes as a function of the number of waypoints. As we can observe the average runtime increases as the number of waypoints increases. Additionally, we can observe that the complexity of the problem increases with the number of waypoints. This is also shown by the number of nodes that have been explored until a solution is found. As the number of binary variables increases in a mixed-integer program the produced search tree that is needed to be explored during the branch-and-bound optimization procedure also increases in size and as a result more nodes are needed to be explored until a solution is found. Finally, Fig. 6b shows the value of the objective function at the end of the optimization. Essentially, we would like to drive this value close to zero, as we would like to bring the generated search plan as close as possible to the waypoints. However, this is not always possible especially as the number of waypoints increases. This is attributed to the overall complexity of the problem i.e., agent dynamics, the placement of the waypoints, the length of time horizon, etc.
Fig. 7. - Simulated scenario demonstrating the search planning phase for one object of interest as discussed in sec VI.
Fig. 7.

Simulated scenario demonstrating the search planning phase for one object of interest as discussed in sec VI .

Show All

2) Search Planning

The next set of experiments aims to demonstrate the performance of the proposed search planning technique as discussed in Sec VI . The objective here is to produce fine-tuned and accurate search plans which search the object of interest in 3D across all faces while avoiding collisions with the surrounding obstacles.

The first experiment aims to demonstrate the 3D search task for an object of interest which is represented by a cuboid with size 60\mathrm{m}\times 60\mathrm{m}\times 60\mathrm{m} . In this experiment, the agent is tasked to conduct search planning around the object (i.e., covering four of its faces) at a distance of no less than d=27\mathrm{m} from the object of interest. At this distance the camera FoV footprint has size 30\mathrm{m}\times 30\mathrm{m} and thus for each of the object's faces 4 cuboids are generated to capture the total surface area of the face. In total 16 cuboids are generated around the object of interest as illustrated in Fig. 7(a) . The agent's initial state is X_{0}=[60,230,10,0,0,0]^{\top} , indicated by the green square in Fig. 7(a) , and the weights of the objective function in Eqn. (7) are set to (a, b, c)= (0.3, 0.001, 1.5) . The planning horizon for this experiment is set to 10 time-steps.

In Fig. 7(a) , the object of interest to be searched is colored orange and the generated cuboids that need to be visited by the agent are marked in black. Finally, the executed UAV trajectory is marked with green diamonds and the future UAV trajectory over the planning horizon is marked with red circles.

As shown, in Fig. 7 the agent passes from all 16 cuboids and thus manages to search all 4 faces of this object. More specifically, Fig. 7(b) – Fig. 7(h) show the agent executed and planned trajectory at time-steps 1, 6, 13, 38, 50, 57 and 63 respectively. As we can observe in each planning horizon the agent tries to maximize the number of cuboids that are visited while at the same time minimizes its distance to the nearest unvisited cuboid according to the mission objective in Eqn. (7) . For this scenario, the search planning problem in (P2) requires 10\times 16\times 6 binary variables for b_{\tau, n, l},\ 10\times 16 binary variables for \tilde{b}_{\tau, n},\ 16 binary variables for \hat{b}_{n} and finally 16 binary variables for y_{n} . Thus, in total we need 1152 binary variables to model the functionality of this problem in an obstacle free environment.

In particular, the main factor that drives the computational complexity is the number of binary variables which are required by (P2). As the number of binary variables increases the search-space that is needed to be explored during the optimization process increases in size and as a result more nodes are needed to be explored until a feasible solution is found. For a problem with \vert J\vert objects of interest, N cuboids per object of interest, \vert \Psi\vert obstacles and planning horizon of length T , the number of binary variables needed by (P2) is equal to 2N\vert J\vert +T[N\vert J\vert (L+1)+\vert \Psi\vert L] (assuming each polyhedron in the environment has L faces) which drives the main computational complexity.

Finally, Fig. 8 shows the proposed 3D search planning approach for multiple objects of interest in the presence of obstacles. In this scenario, two objects of interest of size 60\mathrm{m} \times 60\mathrm{m}\times 60\mathrm{m} each are placed inside the surveillance area. The UAV agent is instructed to search the first object from a distance of d_{1}=53\mathrm{m} and the second object from a distance of d_{2}=27\mathrm{m} . This results in FoV sizes of 60\mathrm{m}\times 60\mathrm{m} and 30\mathrm{m}\times 30\mathrm{m} for d_{1} and d_{2} respectively. Additionally, the two objects of interest are separated by an obstacle of dimensions 30\mathrm{m}\times 380\mathrm{m}\times 63\mathrm{m} as shown in Fig. 8 . The UAV initial state is X_{0}=[460,140,10,0,0,0]^{\top} , the planning horizon T is 12 time-steps and and the weights of the objective function in Eqn. (7) are set to (a, b, c)=(0.3, 0.001, 0.001) . According to the agent FoV size for this scenario each face of the first object was decomposed into one cell (illustrated by the light blue 3d boxes) whereas each face of the second object was decomposed into 4 cells. The cuboid generation pre-processing step generates 4 cuboids (1 cuboid per face) for the first object and 16 cuboids (4 cuboids per face) for the second object. As we can observe, the proposed approach guides the UAV agent to search both objects starting from the first object of interest and moving to the second while avoiding the obstacle in its path. The final agent location is shown in Fig. 8(b) with a red diamond. Finally we should mention that, in the examples above we have shown the search planning task on the lateral faces of the objects of interest. This is done purely for presentation purposes and for visual clarity. The orientation of the face in 3D space is irrelevant in the proposed approach i.e., a face on the horizontal plane (e.g., the face on the top of the object of interest) can be handled the same way.
Fig. 8. - Search planning for multiple objects of interest in the presence of obstacles.
Fig. 8.

Search planning for multiple objects of interest in the presence of obstacles.

Show All

SECTION VIII.
Conclusion

In this work we have proposed a novel approach, for integrating and automating the first two phases of a traditional search and rescue mission, with an autonomous UAV agent. In the first stage, namely assessment planning a high-level plan is produced which allows the UAV to fly over the area of interest and gather mission critical information. Then in the second stage i.e., search planning, the generated plan is further fine-tuned to allow the UAV agent to search the objects of interest in 3D (i.e., across all faces) while avoiding collisions with the obstacles in its path. The performance of the proposed approach has been demonstrated through extensive simulation analysis. Future work, will investigate the real-world implementation of the proposed system, and its integration into our existing multi-drone tasking platform. Additional future directions include the extension of this work to multiple UAV agents, and the investigation of search planning techniques in noisy and uncertain environments.
ACKNOWLEDGMENTS

This work is supported by the European Union's Horizon 2020 research and innovation programme under grant agreement No 739551 (KIOS CoE), by the European Union Civil Protection Call for proposals UCPM-2019-PP-AG grant agreement No 873240 (AIDERS) and from the Republic of Cyprus through the Directorate General for European Programmes, Coordination and Development.

Authors
Figures
References
Citations
Keywords
Metrics
   Back to Results   
More Like This
An Improved Real-Time Path Planning Method Based on Dragonfly Algorithm for Heterogeneous Multi-Robot System

IEEE Access

Published: 2020
Path Planning Based on Ant Colony Algorithm and Distributed Local Navigation for Multi-Robot Systems

2006 International Conference on Mechatronics and Automation

Published: 2006
Show More
References
1. M. A. Goodrich, B. S. Morse, D. Gerhardt, J. L. Cooper, M. Quigley, J. A. Adams, et al., "Supporting Wilderness Search and Rescue using a Camera-equipped mini UAV", Journal of Field Robotics , vol. 25, no. 1–2, pp. 89-110, 2008.
Show in Context CrossRef Google Scholar
2. E. Bitton and K. Goldberg, "Hydra: A Framework and Algorithms for Mixed-initiative UAV-assisted Search and Rescue", 2008 IEEE International Conference on Automation Science and Engineering , pp. 61-66, 2008.
Show in Context View Article Full Text: PDF (527) Google Scholar
3. S. Hayat, E. Yanmaz, T. X. Brown and C. Bettstetter, "Multi-objective uav path planning for search and rescue", 2017 IEEE International Conference on Robotics and Automation (ICRA) , pp. 5569-5574, 2017.
Show in Context View Article Full Text: PDF (357) Google Scholar
4. M. Bernard, K. Kondak, I. Maza and A. Ollero, "Autonomous transportation and deployment with aerial robots for search and rescue missions", Journal of Field Robotics , vol. 28, no. 6, pp. 914-931, 2011.
Show in Context CrossRef Google Scholar
5. S. A. Bortoff, "Path Planning for UAVs", Proceedings of the 2000 American Control Conference (ACC) , vol. 1, no. 6, pp. 364-368, 2000.
Show in Context View Article Full Text: PDF (907) Google Scholar
6. He Ruijie, S. Prentice and N. Roy, "Planning in Information Space for a Quadrotor Helicopter in a GPS-denied environment", 2008 IEEE International Conference on Robotics and Automation , pp. 1814-1820, 2008.
Show in Context View Article Full Text: PDF (369) Google Scholar
7. J. Tisdale, Z. Kim and J. K. Hedrick, "Autonomous UAV Path Planning and Estimation", IEEE Robotics Automation Magazine , vol. 16, no. 2, pp. 35-42, 2009.
Show in Context View Article Full Text: PDF (1116) Google Scholar
8. Kwangjin Yang and S. Sukkarieh, "3D Smooth Path Planning for a UAV in Cluttered Natural Environments", 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 794-800, 2008.
Show in Context Google Scholar
9. S. Prentice and N. Roy, "The Belief Roadmap: Efficient Planning in Belief Space by Factoring the Covariance", The International Journal of Robotics Research , vol. 28, no. 11–12, pp. 1448-1465, 2009.
Show in Context CrossRef Google Scholar
10. F. Colas, S. Mahesh, F. Pomerleau, M. Liu and R. Siegwart, "3D Path Planning and Execution for Search and Rescue Ground Robots", 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 722-727, 2013.
Show in Context View Article Full Text: PDF (2035) Google Scholar
11. J. Berger and N. Lo, "An Innovative Multi-agent Search-and-rescue Path Planning Approach", Computers & Operations Research , vol. 53, pp. 24-31, 2015.
Show in Context CrossRef Google Scholar
12. V. San Juan, M. Santos and J. M. Andújar, "Intelligent UAV Map Generation and Discrete Path Planning for Search and Rescue Operations", Complexity , vol. 2018, 2018.
Show in Context CrossRef Google Scholar
13. S. Papaioannou, P. Kolios, T. Theocharides, C. G. Panayiotou and M. M. Polycarpou, "Probabilistic search and track with multiple mobile agents", 2019 International Conference on Unmanned Aircraft Systems (ICUAS) , pp. 253-262, 2019.
Show in Context View Article Full Text: PDF (316) Google Scholar
14. S. Papaioannou, "Jointly-optimized searching and tracking with random finite sets", IEEE Transactions on Mobile Computing , vol. 19, no. 10, pp. 2374-2391, 2020.
Show in Context View Article Full Text: PDF (3472) Google Scholar
15. S. Papaioannou, "Decentralized search and track with multiple autonomous agents", 2019 IEEE 58th Conference on Decision and Control (CDC) , pp. 909-915, 2019.
Show in Context View Article Full Text: PDF (941) Google Scholar
16. S. Papaioannou, "A cooperative multi-agent probabilistic framework for search and track missions", IEEE Transactions on Control of Network Systems , pp. 1-1, 2020.
Show in Context CrossRef Google Scholar
17. F. A. de Alcantara Andrade, A. Reinier Hovenburg, L. Netto de Lima, C. Dahlin Rodin, T. A. Johansen, R. Storvold, et al., "Autonomous Unmanned Aerial Vehicles in Search and Rescue Missions Using Real-Time Cooperative Model Predictive Control", Sensors , vol. 19, no. 19, 2019.
Show in Context Google Scholar
18. L. Yang, J. Qi, J. Xiao and X. Yong, "A Literature Review of UAV 3D Path Planning", Proceeding of the 11 th World Congress on Intelligent Control and Automation , pp. 2376-2381, 2014.
Show in Context Google Scholar
19. M. Radmanesh, M. Kumar, P. H. Guentert and M. Sarim, "Overview of Path-planning and Obstacle Avoidance Algorithms for UAVs: A Comparative Study", Unmanned Systems .
Show in Context CrossRef Google Scholar
20. L. Yang, J. Qi, D. Song, J. Xiao, J. Han and Y. Xia, "Survey of Robot 3D Path Planning Algorithms", Journal of Control Science and Engineering , vol. 2016, 2016.
Show in Context CrossRef Google Scholar
21. O. Souissi, R. Benatitallah, D. Duvivier, A. Artiba, N. Belanger and P. Feyzeau, "Path Planning: A 2013 Survey", Proceedings of 2013 International Conference on Industrial Engineering and Systems Management (IESM) , pp. 1-8, 2013.
Show in Context Google Scholar
22. UNHCR's Handbook for Emergencies, 2015.
Show in Context Google Scholar
23. Guidelines and Methodology, 2012.
Show in Context Google Scholar
24. A. Nuchter, K. Lingemann and J. Hertzberg, "Mapping of rescue environments with Kurt3D", IEEE International Safety Security and Rescue Rototics Workshop 2005 , pp. 158-163, 2005.
Show in Context View Article Full Text: PDF (664) Google Scholar
25. K. Pathak, A. Birk, N. Vaskevicius, M. Pfingsthorn, S. Schwertfeger and J. Poppinga, "Online three-dimensional slam by registration of large planar surface segments and closed-form pose-graph relaxation", Journal of Field Robotics , vol. 27, no. 1, pp. 52-84, 2010.
Show in Context CrossRef Google Scholar
26. R. Dubé, A. Gawel, C. Cadena, R. Siegwart, L. Freda and M. Gianni, "3d localization mapping and path planning for search and rescue operations", 2016 IEEE International Symposium on Safety Security and Rescue Robotics (SSRR) , pp. 272-273, 2016.
Show in Context View Article Full Text: PDF (535) Google Scholar
27. A. Gawel, R. Dubé, H. Surmann, J. Nieto, R. Siegwart and C. Cadena, "3d registration of aerial and ground robots for disaster response: An evaluation of features descriptors and transformation estimation", 2017 IEEE international symposium on safety security and rescue robotics (SSRR) , pp. 27-34, 2017.
Show in Context View Article Full Text: PDF (2835) Google Scholar
28. P. Petrides, C. Kyrkou, P. Kolios, T. Theocharides and C. Panayiotou, "Towards a holistic performance evaluation framework for drone-based object detection", 2017 International Conference on Unmanned Aircraft Systems (ICUAS) , pp. 1785-1793, 2017.
Show in Context View Article Full Text: PDF (2214) Google Scholar
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
IEEE Account

    Change Username/Password
    Update Address

Purchase Details

    Payment Options
    Order History
    View Purchased Documents

Profile Information

    Communications Preferences
    Profession and Education
    Technical Interests

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support

    About IEEE Xplore
    Contact Us
    Help
    Accessibility
    Terms of Use
    Nondiscrimination Policy
    Sitemap
    Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.
© Copyright 2022 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.
