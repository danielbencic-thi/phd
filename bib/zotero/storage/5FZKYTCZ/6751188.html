<!DOCTYPE html> <html class="js postmessage history draganddrop borderimage borderradius boxshadow textshadow cssgradients csstransforms csstransforms3d csstransitions generatedcontent localstorage sessionstorage" style lang=en-US><!--
 Page saved with SingleFile 
 url: https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188?arnumber=6751188 
 saved date: Mon May 02 2022 11:16:18 GMT+0200 (CEST)
--><meta charset=utf-8>
<meta name=Description id=meta-description content="Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside ">
<link rel=canonical href="https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/?arnumber=6751188">
<meta name=viewport content="width=device-width, initial-scale=1.0">
<meta name=customerIndustry content=NA>
<title>Restoring an Image Taken through a Window Covered with Dirt or Rain | IEEE Conference Publication | IEEE Xplore</title>
<meta property=twitter:title content="Restoring an Image Taken through a Window Covered with Dirt or Rain">
<meta property=og:title content="Restoring an Image Taken through a Window Covered with Dirt or Rain">
<meta property=twitter:description content="Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.">
<meta property=og:description content="Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.">
<meta name=twitter:card content=summary>
<meta property=twitter:image content=https://ieeexplore-ieee-org.thi.idm.oclc.org/assets/img/ieee_logo_smedia_200X200.png>
<meta property=og:image content=https://ieeexplore-ieee-org.thi.idm.oclc.org/assets/img/ieee_logo_smedia_200X200.png>
<style>.cc-window{opacity:1;transition:opacity 1s ease}.cc-link{text-decoration:underline}.cc-window{position:fixed;overflow:hidden;box-sizing:border-box;font-family:Helvetica,Calibri,Arial,sans-serif;font-size:16px;line-height:1.5em;display:-ms-flexbox;display:flex;-ms-flex-wrap:nowrap;flex-wrap:nowrap;z-index:9999}.cc-window.cc-banner{padding:1em 1.8em;width:100%;-ms-flex-direction:row;flex-direction:row}.cc-btn,.cc-link{cursor:pointer}.cc-link{opacity:.8;display:inline-block;padding:.2em}.cc-link:hover{opacity:1}.cc-link:active,.cc-link:visited{color:initial}.cc-btn{display:block;padding:.4em .8em;font-size:.9em;font-weight:700;border-width:2px;border-style:solid;text-align:center;white-space:nowrap}.cc-banner .cc-btn:last-child{min-width:140px}.cc-window.cc-banner{-ms-flex-align:center;align-items:center}.cc-banner.cc-bottom{left:0;right:0;bottom:0}.cc-banner .cc-message{-ms-flex:1;flex:1}.cc-compliance{display:-ms-flexbox;display:flex;-ms-flex-align:center;align-items:center;-ms-flex-line-pack:justify;align-content:space-between}.cc-compliance>.cc-btn{-ms-flex:1;flex:1}@media screen and (max-width:900px){.cc-btn{white-space:normal}}@media screen and (max-width:414px) and (orientation:portrait),screen and (max-width:736px) and (orientation:landscape){.cc-window.cc-bottom{bottom:0}.cc-window.cc-banner{left:0;right:0}.cc-window.cc-banner{-ms-flex-direction:column;flex-direction:column}.cc-window.cc-banner .cc-compliance{-ms-flex:1;flex:1}.cc-window .cc-message{margin-bottom:1em}.cc-window.cc-banner{-ms-flex-align:unset;align-items:unset}}</style>
<meta http-equiv=X-UA-Compatible content="IE=Edge">
<meta http-equiv=origin-trial content="AxujKG9INjsZ8/gUq8+dTruNvk7RjZQ1oFhhgQbcTJKDnZfbzSTE81wvC2Hzaf3TW4avA76LTZEMdiedF1vIbA4AAABueyJvcmlnaW4iOiJodHRwczovL2ltYXNkay5nb29nbGVhcGlzLmNvbTo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2NTI3NzQ0MDAsImlzVGhpcmRQYXJ0eSI6dHJ1ZX0="><meta http-equiv=origin-trial content=Azuce85ORtSnWe1MZDTv68qpaW3iHyfL9YbLRy0cwcCZwVnePnOmkUJlG8HGikmOwhZU22dElCcfrfX2HhrBPAkAAAB7eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2NTI3NzQ0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9><meta http-equiv=origin-trial content=A16nvcdeoOAqrJcmjLRpl1I6f3McDD8EfofAYTt/P/H4/AWwB99nxiPp6kA0fXoiZav908Z8etuL16laFPUdfQsAAACBeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXRhZ3NlcnZpY2VzLmNvbTo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2NTI3NzQ0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9><meta http-equiv=origin-trial content=AxBHdr0J44vFBQtZUqX9sjiqf5yWZ/OcHRcRMN3H9TH+t90V/j3ENW6C8+igBZFXMJ7G3Pr8Dd13632aLng42wgAAACBeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2NTI3NzQ0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9><meta http-equiv=origin-trial content="A88BWHFjcawUfKU3lIejLoryXoyjooBXLgWmGh+hNcqMK44cugvsI5YZbNarYvi3roc1fYbHA1AVbhAtuHZflgEAAAB2eyJvcmlnaW4iOiJodHRwczovL2dvb2dsZS5jb206NDQzIiwiZmVhdHVyZSI6IlRydXN0VG9rZW5zIiwiZXhwaXJ5IjoxNjUyNzc0NDAwLCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><meta http-equiv=origin-trial content="AzoawhTRDevLR66Y6MROu167EDncFPBvcKOaQispTo9ouEt5LvcBjnRFqiAByRT+2cDHG1Yj4dXwpLeIhc98/gIAAACFeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjYxMjk5MTk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><meta http-equiv=origin-trial content="A6+nc62kbJgC46ypOwRsNW6RkDn2x7tgRh0wp7jb3DtFF7oEhu1hhm4rdZHZ6zXvnKZLlYcBlQUImC4d3kKihAcAAACLeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjYxMjk5MTk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><meta http-equiv=origin-trial content="A/9La288e7MDEU2ifusFnMg1C2Ij6uoa/Z/ylwJIXSsWfK37oESIPbxbt4IU86OGqDEPnNVruUiMjfKo65H/CQwAAACLeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXRhZ3NlcnZpY2VzLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjYxMjk5MTk5LCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><style>.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}.color-xplore-blue{color:#069}.color-gray-dark{color:#B7B7B7}@media only screen and (min-width:768px){.body-resp:not(.ea-only) .icon-size-md{font-size:25px}}@media only screen and (max-width:767px){.icon-size-md{font-size:20px}}@media only screen and (max-width:767px){.icon-size-md{font-size:20px}}@media only screen and (min-width:768px){.body-resp:not(.ea-only) .text-sm-md-lh{font-size:15px!important;line-height:20px!important}.body-resp:not(.ea-only) .text-base-md-lh{font-size:18px!important;line-height:30px!important}.body-resp:not(.ea-only) .text-2xl-md-lh{font-size:32px!important;line-height:38px!important}}span~a,span~i,span~span{padding-left:0.25rem}a~a{padding-left:0.25rem}.global-content-width-w-rr{width:calc(100% - 330px);flex:0 0 calc(100% - 330px);max-width:100%}.global-right-rail{box-sizing:border-box;max-width:330px!important;flex:0 0 330px}.global-ng-wrapper[_ngcontent-xhp-c451]{max-width:1680px;margin:0 auto;min-height:80vh;box-sizing:border-box}@media only screen and (min-width:768px){.global-ng-wrapper[_ngcontent-xhp-c451]{padding-right:15px;padding-left:15px}}.ng2-xplore-meta-nav #global-header-cart-count{padding-right:.5rem;border-right:none}@media only screen and (max-width:767px){.ng2-xplore-meta-nav #global-header-cart-count{padding-right:0}}.ng2-xplore-meta-nav .xplore-meta-nav{display:flex;width:100%;background-color:#17445a;box-sizing:border-box;padding:.35rem 15px;max-width:1680px}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-ieee-links{width:auto;max-width:none}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-ieee-links .meta-nav-menu{-webkit-padding-start:0;padding-inline-start:0}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-ieee-links .meta-nav-item:last-child{padding-right:0}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links{width:auto;max-width:none;margin-left:auto}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .nav-right{width:100%}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .cart-container{margin-left:auto;display:flex}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .icons-panel{padding-right:0;padding-left:0}}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links{flex:none;max-width:none;margin-left:0;width:100%;box-sizing:border-box}}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .meta-nav-item{list-style:none}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .meta-nav-item{padding-right:0}}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-user-links .meta-nav-item:last-child{padding-right:0}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item{list-style:none;font-size:14px;padding-right:.75rem}@media only screen and (max-width:991px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item{padding-right:.5rem}}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item{padding-right:0}}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item:not(:last-child){border-right:1px solid #fff}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item:not(:last-child){border-right:none}}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item:not(:first-child){padding-left:.75rem}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item:not(:first-child){padding-left:0}}.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item>a{text-decoration:none}@media only screen and (max-width:767px){.ng2-xplore-meta-nav .xplore-meta-nav .meta-nav-item>a{padding-left:.75rem}}.ng2-xplore-meta-nav .xplore-meta-nav a{color:#fff}.ng2-xplore-meta-nav .xplore-meta-nav .ieee-xplore{color:#e4a42c}.ng2-xplore-meta-nav .xplore-meta-nav .personal-signin-container{position:relative;z-index:1049}.main-header[_ngcontent-xhp-c445]{position:relative;display:flex;flex-direction:column;background-color:#14303e}.search-bar-container[_ngcontent-xhp-c445]{z-index:20}.fill-background[_ngcontent-xhp-c445]{display:flex;justify-content:center;align-items:center;position:relative;background-color:#14303e;top:auto;left:auto;transform:translate(0);width:100%;min-height:115px}.menu-link[_ngcontent-xhp-c455]{padding:.25rem .5rem;white-space:nowrap}.primary-menu[_ngcontent-xhp-c455]{flex-grow:1;min-width:301px;max-width:400px;margin-top:5px}.primary-menu[_ngcontent-xhp-c455] ul[_ngcontent-xhp-c455]{display:flex;list-style-type:none;flex-grow:1;justify-content:space-around;margin:0;padding:0 1.5rem 0 .75rem}.primary-menu[_ngcontent-xhp-c455] a[_ngcontent-xhp-c455]{color:#fff}.hamburger-menu[_ngcontent-xhp-c455]{width:33%}.hamburger-menu[_ngcontent-xhp-c455] a[_ngcontent-xhp-c455]{font-size:2rem;display:flex;color:#fff}.institution-container[_ngcontent-xhp-c455]{flex-shrink:0}.institution-container.inst-logged-in[_ngcontent-xhp-c455]{margin-top:0}.right-side-container[_ngcontent-xhp-c455]{flex-basis:50%;flex-shrink:1;display:flex;flex-direction:row-reverse}.right-side-container.inst-logged-in[_ngcontent-xhp-c455]{width:auto;padding-left:1rem;margin-left:auto}@media only screen and (max-width:767px){.right-side-container[_ngcontent-xhp-c455]{width:33%}}.inst-logged-in[_ngcontent-xhp-c455] .left-side-container[_ngcontent-xhp-c455]{min-width:465px}.left-side-container[_ngcontent-xhp-c455]{flex-basis:50%;flex-shrink:1}@media only screen and (max-width:767px){.left-side-container[_ngcontent-xhp-c455]{width:33%}}.left-side-content[_ngcontent-xhp-c455]{display:flex;justify-content:flex-start}@media only screen and (max-width:767px){.left-side-content[_ngcontent-xhp-c455]{justify-content:center}}.left-side-content[_ngcontent-xhp-c455] .xplore-logo-wrapper[_ngcontent-xhp-c455]{margin-top:-5px}.navbar-container[_ngcontent-xhp-c455]{box-sizing:border-box;display:flex;flex-direction:column;flex-grow:1;z-index:1004;width:100%;max-width:1680px;padding:18px 15px}@media only screen and (max-width:767px){.navbar-container[_ngcontent-xhp-c455]{padding-top:0}}.inst-details-container[_ngcontent-xhp-c455]{flex-grow:1}.top-navbar[_ngcontent-xhp-c455]{display:flex}@media only screen and (max-width:767px){.top-navbar[_ngcontent-xhp-c455]{padding:1rem 1rem .5rem}}.bottom-navbar[_ngcontent-xhp-c455]{display:flex;justify-content:center;padding-top:calc(18px - 5px)}.navbar-container.not-homepage[_ngcontent-xhp-c455]{position:relative;margin:0 auto;padding-bottom:1.5rem}@media screen and (-ms-high-contrast:none){.navbar-container[_ngcontent-xhp-c455]{max-width:none;width:1460px}}[_nghost-xhp-c458]{width:100%}.not-homepage [_nghost-xhp-c458] .search-bar-wrapper[_ngcontent-xhp-c458]{margin-bottom:0}.not-homepage [_nghost-xhp-c458] .search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]{justify-content:unset;margin-left:auto;margin-right:0}.not-homepage [_nghost-xhp-c458] .search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458] .advanced-search-div[_ngcontent-xhp-c458]{background-color:transparent;padding:0;margin:0;min-width:0}@media only screen and (max-width:767px){.not-homepage [_nghost-xhp-c458] .search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458] .advanced-search-div[_ngcontent-xhp-c458]{padding-right:.5rem}}.not-homepage [_nghost-xhp-c458] .search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458] .advanced-search-div[_ngcontent-xhp-c458] a[_ngcontent-xhp-c458]{font-size:12px}@media only screen and (max-width:767px){.not-homepage [_nghost-xhp-c458] .search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458]{padding-left:.5rem}}.search-bar[_ngcontent-xhp-c458]{max-width:960px;margin:0 auto}.search-bar[_ngcontent-xhp-c458] .below-search-bar[_ngcontent-xhp-c458]{display:flex;justify-content:center;max-width:780px;flex-grow:1;margin:0 auto}.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]{display:flex;margin:0 32%}@media only screen and (max-width:767px){.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]{flex-direction:column;margin:.5rem auto 0;max-width:230px}}.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]{text-align:center;max-width:200px;border-radius:.2rem}@media only screen and (max-width:767px){.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]{margin:1rem 4% 1%}}.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]>a[_ngcontent-xhp-c458]{color:#fff;font-family:Lato-Bold,Arial,sans-serif;font-weight:700}.search-bar[_ngcontent-xhp-c458] .advanced-search-wrapper[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]>a[_ngcontent-xhp-c458]:hover{text-decoration:none}.search-bar-wrapper[_ngcontent-xhp-c458]{display:flex;max-width:780px;background-color:rgba(0,0,0,.1);padding:.5em;margin:0 auto 1%;justify-content:space-between}.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]{flex-grow:0.08}@media only screen and (max-width:767px){.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]{flex-grow:1;max-width:4rem}}.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]>label[_ngcontent-xhp-c458]{position:relative}.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]>label[_ngcontent-xhp-c458]:after{content:"\f0d7";font-family:Font Awesome\ 5 Pro;font-size:22px;font-weight:900;color:#e4a42c;right:4px;top:-6px;padding:0 2%;position:absolute;pointer-events:none;height:19px;width:15px}@media only screen and (max-width:767px){.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]>label[_ngcontent-xhp-c458]:after{font-size:20px;right:5px;top:-4px;text-align:center}}.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]>label[_ngcontent-xhp-c458]:before{content:"";right:4px;top:0;background:#fff;position:absolute;pointer-events:none;display:block}.search-bar-wrapper[_ngcontent-xhp-c458]>.drop-down[_ngcontent-xhp-c458]>label[_ngcontent-xhp-c458]>select[_ngcontent-xhp-c458]{padding:.35em .35em .35em .5rem;width:100%;height:100%;margin:0;color:#000;border:none;font-weight:700;background-color:#ddd;border-radius:0;-webkit-appearance:none;-moz-appearance:none}.search-bar-wrapper[_ngcontent-xhp-c458] .search-field[_ngcontent-xhp-c458]{display:flex;justify-content:space-evenly;flex-grow:1}.search-bar-wrapper[_ngcontent-xhp-c458] .search-field[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]{flex-grow:1;padding-right:5%}.search-bar-wrapper[_ngcontent-xhp-c458] .search-field[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]:last-child{padding-right:0}@media only screen and (max-width:767px){.search-bar-wrapper[_ngcontent-xhp-c458] .search-field[_ngcontent-xhp-c458]>div[_ngcontent-xhp-c458]{padding-right:0}}.search-bar-wrapper[_ngcontent-xhp-c458] .search-field[_ngcontent-xhp-c458] .global-search-bar[_ngcontent-xhp-c458]{flex-grow:1}.search-bar-wrapper[_ngcontent-xhp-c458] .search-field-icon-container[_ngcontent-xhp-c458]{display:flex}.search-bar-wrapper[_ngcontent-xhp-c458] .search-icon[_ngcontent-xhp-c458]{background-color:#e4a42c;width:3.5625rem;display:flex;align-items:center;justify-content:center;cursor:pointer}@media only screen and (max-width:767px){.search-bar-wrapper[_ngcontent-xhp-c458] .search-icon[_ngcontent-xhp-c458]{order:1}}.search-bar-wrapper[_ngcontent-xhp-c458] .search-icon[_ngcontent-xhp-c458]>.fa-search[_ngcontent-xhp-c458]{width:29px;height:25px;color:#000;text-align:center}.global-search-bar[_ngcontent-xhp-c458]{position:relative}.xplore-logo-container[_ngcontent-xhp-c441]{display:flex;flex-direction:column}.xplore-logo-container[_ngcontent-xhp-c441] a[_ngcontent-xhp-c441]{align-self:center}.xplore-logo-container[_ngcontent-xhp-c441] img.xplore-logo[_ngcontent-xhp-c441]{width:160px;height:40px}.ieee-logo-container[_ngcontent-xhp-c440]{display:flex;flex-direction:column}.ieee-logo-container[_ngcontent-xhp-c440] .ieee-logo[_ngcontent-xhp-c440]{width:100px;align-self:flex-end}.footer-new[_ngcontent-xhp-c450]{display:flex;background-color:#17445a;padding-top:3rem;color:#fff}@media only screen and (max-width:767px){.footer-new[_ngcontent-xhp-c450]{padding-top:.1rem}}.footer-new[_ngcontent-xhp-c450]>div[_ngcontent-xhp-c450]{padding-bottom:2rem}.footer-new[_ngcontent-xhp-c450] h3[_ngcontent-xhp-c450]{font-weight:800;font-family:"IBM Plex Serif",Arial,sans-serif}.footer-new[_ngcontent-xhp-c450] ul[_ngcontent-xhp-c450]{list-style-type:none;padding-left:0}.footer-new[_ngcontent-xhp-c450] li[_ngcontent-xhp-c450]{padding:.35rem 0;text-transform:uppercase}.footer-new[_ngcontent-xhp-c450] a[_ngcontent-xhp-c450]{width:100%;text-decoration:none;color:#fff}.footer-new[_ngcontent-xhp-c450] a[_ngcontent-xhp-c450]:hover{color:#e4a42c}.footer-new[_ngcontent-xhp-c450] .follow[_ngcontent-xhp-c450] ul[_ngcontent-xhp-c450]{display:flex}.footer-new[_ngcontent-xhp-c450] .follow[_ngcontent-xhp-c450] ul[_ngcontent-xhp-c450] li[_ngcontent-xhp-c450]{padding:0 .5rem}.footer-new[_ngcontent-xhp-c450] .follow[_ngcontent-xhp-c450] ul[_ngcontent-xhp-c450] li[_ngcontent-xhp-c450]:first-child{padding-left:0}.footer-new[_ngcontent-xhp-c450] .footer-wrapper[_ngcontent-xhp-c450]{flex-grow:1;max-width:1680px;margin:0 auto}.footer-new[_ngcontent-xhp-c450] .flexible-row-col[_ngcontent-xhp-c450]{display:flex;padding-bottom:3rem}@media only screen and (max-width:767px){.footer-new[_ngcontent-xhp-c450] .flexible-row-col[_ngcontent-xhp-c450]{padding-bottom:.1rem;flex-direction:column}}.footer-new[_ngcontent-xhp-c450] .footer-col[_ngcontent-xhp-c450]{flex-grow:1;padding-left:2rem}@media only screen and (max-width:767px){.footer-new[_ngcontent-xhp-c450] .footer-col[_ngcontent-xhp-c450]{padding-top:1rem}.footer-new[_ngcontent-xhp-c450] .footer-col[_ngcontent-xhp-c450]:first-child{padding-top:2rem}.footer-new[_ngcontent-xhp-c450] .footer-col[_ngcontent-xhp-c450]:last-child{padding-bottom:.25rem}}.footer-new[_ngcontent-xhp-c450] .footer-bottom-section[_ngcontent-xhp-c450] p[_ngcontent-xhp-c450]{margin:0;padding-left:2rem;padding-right:2rem}.footer-new[_ngcontent-xhp-c450] .footer-bottom-section[_ngcontent-xhp-c450] p[_ngcontent-xhp-c450]:last-child{padding-top:1rem}.footer-new[_ngcontent-xhp-c450] .footer-bottom-section[_ngcontent-xhp-c450] p[_ngcontent-xhp-c450] span[_ngcontent-xhp-c450]{padding-left:0}.footer-new[_ngcontent-xhp-c450] .footer-bottom-section[_ngcontent-xhp-c450] p[_ngcontent-xhp-c450] .ethics-reporting-link[_ngcontent-xhp-c450] i[_ngcontent-xhp-c450]{padding-left:.25rem}.footer-new[_ngcontent-xhp-c450] .nowrap[_ngcontent-xhp-c450]{white-space:nowrap}.signout[_ngcontent-xhp-c442]{font-size:.75rem;padding-left:1rem;padding-right:1.25rem;padding-top:.5rem}.signout[_ngcontent-xhp-c442] a[_ngcontent-xhp-c442]{display:block}.inst-detail[_ngcontent-xhp-c442]{display:flex;background:#fff;margin-top:-18px;border-radius:0 0 .4rem .4rem;height:calc(18px*2 + 35px)}@media only screen and (max-width:767px){.inst-detail[_ngcontent-xhp-c442]{height:auto;border-radius:0;justify-content:center;flex-wrap:wrap}}.inst-text-container[_ngcontent-xhp-c442]{padding-left:.5rem;padding-right:.5rem;margin-top:.25rem;display:flex;margin-bottom:1rem;border-right:1px solid #ddd}.inst-text-container.no-inst-logo[_ngcontent-xhp-c442]{max-width:160px}.access-text[_ngcontent-xhp-c442]{white-space:nowrap}.access-text[_ngcontent-xhp-c442],.inst-name[_ngcontent-xhp-c442]{font-size:12px}.Typeahead-input[_ngcontent-xhp-c54]{border-radius:0}@media only screen and (max-width:767px){.document-sidebar[_ngcontent-xhp-c191]{position:absolute;height:calc(100% - 129px);z-index:11000;right:0;padding:0;max-width:40vw;transform:translateX(40vw);transition:transform .25s ease-in-out 0s}}@media only screen and (max-width:575px){.document-sidebar[_ngcontent-xhp-c191]{max-width:80vw;transform:translateX(80vw)}}@media only screen and (max-width:767px){.document-sidebar-content[_ngcontent-xhp-c191]{max-height:calc(100% - 129px);width:100%;overflow:scroll;position:absolute}}.document-sidebar.top-spacing[_ngcontent-xhp-c191]{margin-top:35px}@media only screen and (max-width:767px){.document-sidebar.top-spacing[_ngcontent-xhp-c191]{margin-top:8.5rem}}@media only screen and (min-width:768px){.document-sidebar-rel-art[_ngcontent-xhp-c191]{padding:0 15px 35px}}.header-rel-art-toggle-mobile[_ngcontent-xhp-c191]{top:-2px}.document-title[_ngcontent-xhp-c144]{letter-spacing:normal}.document-title[_ngcontent-xhp-c144]{margin:0}.document-title-fix[_ngcontent-xhp-c144]{flex-grow:1;width:100%}.pdf-btn-container[_ngcontent-xhp-c144]{margin-left:28px}.document-header-inner-container[_ngcontent-xhp-c144]{max-width:100%;width:100%}.document-header-breadcrumbs-container[_ngcontent-xhp-c144]{padding:.4rem 1rem .8rem;margin:0;font-size:.8em}.document-header-breadcrumbs-container[_ngcontent-xhp-c144] #help[_ngcontent-xhp-c144]{font-size:14px}.document-header-metrics-banner[_ngcontent-xhp-c144]{padding:.4rem 1rem .8rem;width:100%}.document-header-title-container[_ngcontent-xhp-c144]{padding:.4rem 1rem .8rem;display:flex}@media only screen and (max-width:767px){.document-header-title-container[_ngcontent-xhp-c144]{flex-direction:column}}.document-header-title-container[_ngcontent-xhp-c144] .right-container[_ngcontent-xhp-c144]{margin-left:auto;display:flex;flex-direction:column}@media only screen and (max-width:767px){.document-header-title-container[_ngcontent-xhp-c144] .right-container[_ngcontent-xhp-c144]{margin-left:0;margin-right:auto}}.document-banner-access[_ngcontent-xhp-c144]{width:100%;display:flex}.mobile-serp-nav[_ngcontent-xhp-c144]{padding:.4rem 1rem .8rem}.breadcrumbs-separator[_ngcontent-xhp-c144]{padding:.4rem}.btn-container[_ngcontent-xhp-c144]{display:flex}.btn-container[_ngcontent-xhp-c144] .cite-this-related-btn-wrapper[_ngcontent-xhp-c144] .cite-this-btn[_ngcontent-xhp-c144]{padding:.5rem;border:2px solid #069;font-weight:700}.publisher-title-tooltip[_ngcontent-xhp-c144]{margin-top:.3em;padding-right:30px}@media only screen and (max-width:767px){.document-header-title-container[_ngcontent-xhp-c144]{position:relative}}.copyright-icon[_ngcontent-xhp-c146]{font-size:1.25rem}.doc-share-tool[_ngcontent-xhp-c140] i[_ngcontent-xhp-c140]{font-size:1.2rem}.doc-share-tool[_ngcontent-xhp-c140] i.fa-share-alt[_ngcontent-xhp-c140]{color:#069}[_nghost-xhp-c158]{width:100%}.ft-toc[_ngcontent-xhp-c158]{height:52px;border-top:1px solid #e5e5e5;border-bottom:1px solid #e5e5e5}.ft-toc[_ngcontent-xhp-c158]>div[_ngcontent-xhp-c158]{margin-top:13px}.ft-toc[_ngcontent-xhp-c158] a.toc-link[_ngcontent-xhp-c158]{font-size:1.2em;font-weight:700}.ft-toc[_ngcontent-xhp-c158] a.toc-link[_ngcontent-xhp-c158]:hover{text-decoration:none}.ft-toc[_ngcontent-xhp-c158] a.toc-link[_ngcontent-xhp-c158] img[_ngcontent-xhp-c158]{position:relative;top:-2px;margin-right:.3em}.full-text-toc-wrapper[_ngcontent-xhp-c158] .previous-next-nav-ctrl[_ngcontent-xhp-c158]{overflow:visible}.stats-document-container-fullTextSection[_ngcontent-xhp-c158]{padding:0 15px}.stats-document-container-rh[_ngcontent-xhp-c158]{padding-right:1em;padding-left:1em}.toc-container[_ngcontent-xhp-c158]{margin-bottom:.7em;font-weight:700}.toc-container[_ngcontent-xhp-c158] a[_ngcontent-xhp-c158]:hover{text-decoration:none}.hide-full-text[_ngcontent-xhp-c158]{max-height:0;overflow:hidden}.accordion-header[_ngcontent-xhp-c163]{color:#069;display:flex;align-items:center}.accordion-header[_ngcontent-xhp-c163] .accordion-chevron[_ngcontent-xhp-c163] .fa[_ngcontent-xhp-c163]{font-size:1.5rem}.accordion-header[_ngcontent-xhp-c163]:hover{color:#0081c1}.document-all-references[_ngcontent-xhp-c190]{position:fixed;top:0;right:0;width:30vw;min-width:450px;padding:1rem 1rem 3rem;box-shadow:3px 10px 10px #000;overflow:auto;height:100vh;box-sizing:border-box;z-index:99999;transform:translateX(100%);background-color:#fff;transition:transform .25s ease-in-out 0s}.header[_ngcontent-xhp-c190]{display:flex;align-items:center;padding:.5rem 0}.header[_ngcontent-xhp-c190] h1[_ngcontent-xhp-c190]{margin:0;font-weight:400;color:#333}.header[_ngcontent-xhp-c190] a[_ngcontent-xhp-c190]{margin-left:auto;font-size:1.25rem;color:#333}i.help-link[_ngcontent-xhp-c59]{color:#069}i.help-link[_ngcontent-xhp-c59]:hover{color:#0081c1}.breadcrumb-help-link-icon[_ngcontent-xhp-c59]{font-size:1rem}a[_ngcontent-xhp-c59]:hover{text-decoration:none}.pdf-btn-link[_ngcontent-xhp-c113]{height:36px;background-color:#ff3500;padding:0 25px;display:flex;align-items:center;justify-content:center;border-radius:2px;color:#fff}.pdf-btn-link[_ngcontent-xhp-c113] .icon[_ngcontent-xhp-c113]{font-size:1.15rem;color:#fff;margin-right:.45rem}.pdf-btn-link[_ngcontent-xhp-c113]>span[_ngcontent-xhp-c113]{font-weight:700}.red-pdf[_ngcontent-xhp-c113]{font-size:1.3rem;margin-right:.15rem;font-style:normal}.red-pdf[_ngcontent-xhp-c113],.red-pdf[_ngcontent-xhp-c113]:after{color:#fc0d1b}.copyright-icon[_ngcontent-xhp-c143]{font-size:1.25rem}.document-authors-banner[_ngcontent-xhp-c137] .authors-container[_ngcontent-xhp-c137]{padding:0 0 0 1rem}.stats-document-authors-banner[_ngcontent-xhp-c137]{padding:.25rem 1rem .25rem 0}.authors-minimized[_ngcontent-xhp-c137]{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.toc-container[_ngcontent-xhp-c145]{padding:.6em .5em;border-bottom:1px solid #ddd}.toc-heading[_ngcontent-xhp-c145]{font-size:1em;padding-bottom:.5em}.toc-list[_ngcontent-xhp-c145]{list-style:none;padding:0}.toc-list-item[_ngcontent-xhp-c145]{padding:.5em 0}.toc-list-link[_ngcontent-xhp-c145]{display:flex;font-size:.9em}.toc-list-icon[_ngcontent-xhp-c145]{margin-right:5px}.toc-show-more-btn[_ngcontent-xhp-c145]{font-size:.85em;font-weight:700}.isbn-value[_ngcontent-xhp-c186]{white-space:nowrap}.header-rel-art-pub[_ngcontent-xhp-c189]{margin:.25rem 0}.header-rel-art-pub[_ngcontent-xhp-c189]:last-child{margin:0 0 .5rem}.header-rel-art[_ngcontent-xhp-c189]{font-size:.9375rem;color:#333;border:1px solid #e5e5e5;border-top:5px solid #0081c1;background-color:#f8f8f8}@media only screen and (max-width:767px){.header-rel-art[_ngcontent-xhp-c189]{border-bottom:none}}.header-rel-art-action[_ngcontent-xhp-c189] a[_ngcontent-xhp-c189],.header-rel-art-title[_ngcontent-xhp-c189]{font-family:Helvetica-Nue-Bold,Arial,sans-serif}.header-rel-art-list[_ngcontent-xhp-c189]{font-family:Helvetica Regular,Arial,sans-serif}.cc-color-override-170793312.cc-window{color:rgb(255,255,255);background-color:rgb(0,0,0)}.cc-color-override-170793312 .cc-link,.cc-color-override-170793312 .cc-link:active,.cc-color-override-170793312 .cc-link:visited{color:rgb(255,255,255)}.cc-color-override-170793312 .cc-btn{color:rgb(0,0,0);border-color:transparent;background-color:rgb(255,255,255)}.cc-color-override-170793312 .cc-btn:hover,.cc-color-override-170793312 .cc-btn:focus{background-color:rgb(255,255,255)}</style><meta name=cToken content=eyJhbGciOiJIUzUxMiIsInppcCI6IkRFRiJ9.eNqqVkosKFCyUoooyMkvSlXSUcosLgZyK2Dc1AqgrKGZqaGJhamZuRFQPrEEJmBkaW5UCwAAAP__.mjp1Knf-6VP_BhqoDbREsZAeGuXft5HIcJYaOr0AZVaryOVk-kgkr1hRISWDlP1tMViUOFDEpLzTc4a0UIfFPA class=sf-hidden><link type=image/x-icon rel="shortcut icon" href="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><style>.sf-hidden{display:none!important}</style><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:;"><body class="body-resp cmpl_embed_complete"><div style="visibility:hidden;overflow:hidden;position:absolute;top:0px;height:1px;width:auto;padding:0px;border:0px none;margin:0px;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal" class=sf-hidden></div><div role=dialog aria-live=polite aria-label=cookieconsent aria-describedby=cookieconsent:desc class="cc-window cc-banner cc-type-info cc-theme-block cc-bottom cc-color-override-170793312"><span id=cookieconsent:desc class=cc-message>IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our <a aria-label="learn more about cookies" role=button tabindex=0 class=cc-link href=https://www.ieee.org/about/help/security_privacy.html target=_blank>Privacy Policy.</a></span><div class=cc-compliance><a aria-label="dismiss cookie message" role=button tabindex=0 class="cc-btn cc-dismiss">Accept &amp; Close</a></div></div><div style=display:none id=lightningjs-usabilla_live></div><div id=MathJax_Message>Loading [MathJax]/jax/output/HTML-CSS/autoload/mtable.js</div><g:compress>
 <style>--></style>
 <style media="screen, print">--></style>
 <style>--></style>
 <style media="screen, print">--></style>
</g:compress>
 
 
 
 
 
 
 <p class=JumpLink id=PageTop><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/# title="Click here to Skip to main content" accesskey=s>Skip to Main Content</a></p>
 <div id=global-notification class="row stats-global-notification">
 <div class="hide u-hide-important col Notification Notification--global Notification--fixed">
 <a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class="Notification-close js-close" aria-label="close message button"><i class="fa fa-close"></i></a>
 <div class=Notification-header></div>
 <div class=Notification-text></div>
 </div>
 </div>
 <div id=LayoutWrapper>
 <div class=container-fluid>
 <div class=row>
 <div class=col>
 
 
 
 
 
<div class=Header id=xplore-header data-service=true data-inst=true data-web=false style=display:none></div>
 <div id=global-alert-message></div>
 

<div class=ng2-app>
 
 
 
 
 <div class=global-content-wrapper>
 <xpl-root _nghost-xhp-c451 ng-version=11.2.14><xpl-meta-nav _ngcontent-xhp-c451><div class=ng2-xplore-meta-nav><div class="metanav-container u-flex-display-flex u-flex-justify-center"><div class="stats-metanav xplore-meta-nav"><div class="meta-nav-ieee-links hide-mobile text-sm-md-lh"><ul class="meta-nav-menu u-flex-display-flex u-m-0"><li class="meta-nav-item stats-extLink stats-Unav_exit_aaa"><a href=http://www.ieee.org/ id=u-home class=ieeeorg>IEEE.org</a><li class="meta-nav-item stats-extLink ieee-xplore">IEEE <em>Xplore</em><li class="meta-nav-item stats-extLink"><a href=http://standards.ieee.org.thi.idm.oclc.org/ id=u-standards class=exitstandardsorg>IEEE SA</a><li class="meta-nav-item stats-extLink"><a href=http://spectrum.ieee.org.thi.idm.oclc.org/ id=u-spectrum class=exitspectrum>IEEE Spectrum</a><li class="meta-nav-item stats-extLink"><a href=http://www.ieee.org/sitemap.html id=u-more class=exitmoreieeesites>More Sites</a></ul></div><div class="meta-nav-user-links u-flex-display-flex text-sm-md-lh"><ul class="u-flex-display-flex u-relative u-m-0 nav-right icons-panel"><div class="col-4 hide-desktop"></div><div class=cart-container><li id=global-header-cart-count class="meta-nav-item stats-mnEvLinks"><a title="View Cart" tabindex=0 class="cart stats-Unav_exit_Cart" style=white-space:nowrap href="https://www.ieee.org/cart/public/myCart/page.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore"><span id=cartCount>Cart&nbsp;</span></a><div id=mc_ieee-mini-cart-include_wrapper class="content-r cart-summary product-cart" style=display:none></div><li class="meta-nav-item stats-mnEvLinks hide-desktop"><a title="Create Account" class="create-account-new stats-Unav_CreateAcct hide-desktop" href="https://www.ieee.org/profile/public/createwebaccount/showCreateAccount.html?ShowMGAMarkeatbilityOptIn=true&amp;sourceCode=xplore&amp;car=IEEE-Xplore&amp;autoSignin=Y&amp;signinurl=https%3A%2F%2Fieeexplore-ieee-org.thi.idm.oclc.org%2FXplore%2Flogin.jsp%3Furl%3D%2FXplore%2Fhome.jsp%26reason%3Dauthenticate&amp;url=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188?arnumber=6751188"><i class="fas fa-user-plus"></i></a><li class="meta-nav-item stats-mnEvLinks u-flex-display-flex u-ml-auto personal-signin-container hide-desktop"><a title="Sign In" class="stats-Unav_P_SignIn hide-desktop"><i aria-hidden=true class="fas fa-sign-in-alt"></i></a></li></div><div class="u-flex-display-flex text-sm-md-lh"><li class="meta-nav-item stats-mnEvLinks"><a title="Create Account" class="create-account-new stats-Unav_CreateAcct hide-mobile" href="https://www.ieee.org/profile/public/createwebaccount/showCreateAccount.html?ShowMGAMarkeatbilityOptIn=true&amp;sourceCode=xplore&amp;car=IEEE-Xplore&amp;autoSignin=Y&amp;signinurl=https%3A%2F%2Fieeexplore-ieee-org.thi.idm.oclc.org%2FXplore%2Flogin.jsp%3Furl%3D%2FXplore%2Fhome.jsp%26reason%3Dauthenticate&amp;url=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188?arnumber=6751188">Create Account</a><li class="meta-nav-item stats-mnEvLinks u-flex-display-flex u-ml-auto personal-signin-container"><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ title="Sign In" class="stats-Unav_P_SignIn hide-mobile u-pr-05">Personal Sign In</a></li></div></ul></div></div></div></div></xpl-meta-nav><xpl-global-notification _ngcontent-xhp-c451 _nghost-xhp-c68></xpl-global-notification><xpl-header _ngcontent-xhp-c451 _nghost-xhp-c445><div _ngcontent-xhp-c445 class=main-header><xpl-navbar _ngcontent-xhp-c445 _nghost-xhp-c455><div _ngcontent-xhp-c455 class="navbar-container not-homepage inst-logged-in"><div _ngcontent-xhp-c455 class=top-navbar><div _ngcontent-xhp-c455 class="hamburger-menu hide-desktop"><a _ngcontent-xhp-c455><i _ngcontent-xhp-c455 aria-hidden=true class="fa fa-bars"></i></a></div><div _ngcontent-xhp-c455 class=left-side-container><div _ngcontent-xhp-c455 class=left-side-content><div _ngcontent-xhp-c455 class=xplore-logo-wrapper><xpl-xplore-logo _ngcontent-xhp-c455 _nghost-xhp-c441><div _ngcontent-xhp-c441 class=xplore-logo-container><a _ngcontent-xhp-c441 accesskey=1 title="Delivering full text access to the world's highest quality technical literature in engineering and technology" alt="IEEE Advancing Technology for Humanity" href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplore/home.jsp><img _ngcontent-xhp-c441 alt="IEEE Xplore logo - Link to home" class=xplore-logo src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></div></xpl-xplore-logo></div><div _ngcontent-xhp-c455 class="primary-menu hide-mobile text-base-md-lh"><ul _ngcontent-xhp-c455><li _ngcontent-xhp-c455><div _ngcontent-xhp-c455><a _ngcontent-xhp-c455 tabindex=0 class="menu-link stats-browse-book"> Browse <i _ngcontent-xhp-c455 aria-hidden=true class="fas fa-chevron-down"></i></a></div><li _ngcontent-xhp-c455><div _ngcontent-xhp-c455><a _ngcontent-xhp-c455 tabindex=0 class="menu-link stats-my-settings"> My Settings <i _ngcontent-xhp-c455 aria-hidden=true class="fas fa-chevron-down"></i></a></div><li _ngcontent-xhp-c455><div _ngcontent-xhp-c455><a _ngcontent-xhp-c455 tabindex=0 class="menu-link stats-get-help"> Help <i _ngcontent-xhp-c455 aria-hidden=true class="fas fa-chevron-down"></i></a></div></ul></div></div></div><div _ngcontent-xhp-c455 class="institution-container hide-mobile inst-logged-in"><div _ngcontent-xhp-c455><xpl-institution-details _ngcontent-xhp-c455 _nghost-xhp-c442><div _ngcontent-xhp-c442><div _ngcontent-xhp-c442 class=inst-detail><div _ngcontent-xhp-c442 class=u-flex-display-flex><div _ngcontent-xhp-c442 class="inst-text-container no-inst-logo"><span _ngcontent-xhp-c442 class=right-line><span _ngcontent-xhp-c442 class=access-text>Access provided by:</span><h4 _ngcontent-xhp-c442 class=inst-name>Technische Hochschule Ingolstadt</h4></span></div><div _ngcontent-xhp-c442 class=signout><a _ngcontent-xhp-c442 title="Sign Out" target=_self href="https://ieeexplore-ieee-org.thi.idm.oclc.org/servlet/Login?logout=/document/6751188/?arnumber=6751188">Sign Out</a></div></div></div></div></xpl-institution-details></div></div><div _ngcontent-xhp-c455 class="right-side-container inst-logged-in"><div _ngcontent-xhp-c455 class=row><xpl-ieee-logo _ngcontent-xhp-c455 _nghost-xhp-c440><div _ngcontent-xhp-c440 class="ieee-logo-container hide-mobile"><img _ngcontent-xhp-c440 alt="IEEE logo - Link to IEEE main site homepage" class=ieee-logo src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></div></xpl-ieee-logo></div></div></div><div _ngcontent-xhp-c455 class="bottom-navbar hide-desktop"><div _ngcontent-xhp-c455 class=inst-details-container><xpl-institution-details _ngcontent-xhp-c455 _nghost-xhp-c442><div _ngcontent-xhp-c442><div _ngcontent-xhp-c442 class=inst-detail><div _ngcontent-xhp-c442 class=u-flex-display-flex><div _ngcontent-xhp-c442 class="inst-text-container no-inst-logo"><span _ngcontent-xhp-c442 class=right-line><span _ngcontent-xhp-c442 class=access-text>Access provided by:</span><h4 _ngcontent-xhp-c442 class=inst-name>Technische Hochschule Ingolstadt</h4></span></div><div _ngcontent-xhp-c442 class=signout><a _ngcontent-xhp-c442 title="Sign Out" target=_self href="https://ieeexplore-ieee-org.thi.idm.oclc.org/servlet/Login?logout=/Xplore/guesthome.jsp">Sign Out</a></div></div></div></div></xpl-institution-details></div></div></div></xpl-navbar><div _ngcontent-xhp-c445><div _ngcontent-xhp-c445 class="search-bar-container fill-background not-homepage"><xpl-search-bar-migr _ngcontent-xhp-c445 _nghost-xhp-c458><div _ngcontent-xhp-c458 class=search-bar><form _ngcontent-xhp-c458 novalidate class="search-bar-wrapper ng-untouched ng-pristine ng-valid"><div _ngcontent-xhp-c458 class=drop-down><label _ngcontent-xhp-c458><select _ngcontent-xhp-c458 aria-label="content type dropdown"><option _ngcontent-xhp-c458 selected>All<option _ngcontent-xhp-c458>Books<option _ngcontent-xhp-c458>Conferences<option _ngcontent-xhp-c458>Courses<option _ngcontent-xhp-c458>Journals &amp; Magazines<option _ngcontent-xhp-c458>Standards<option _ngcontent-xhp-c458>Authors<option _ngcontent-xhp-c458>Citations</select></label></div><div _ngcontent-xhp-c458 class="search-field all"><div _ngcontent-xhp-c458 class=search-field-icon-container><div _ngcontent-xhp-c458 class=global-search-bar><xpl-typeahead-migr _ngcontent-xhp-c458 placeholder name=search-term ulclass="search-within-results ui-autocomplete ui-front ui-menu ui-widget ui-widget-content ui-corner-all" minchars=3 _nghost-xhp-c54><div _ngcontent-xhp-c54 class="Typeahead text-sm-md-lh"><input _ngcontent-xhp-c54 autocomplete=off aria-label="Enter search text" class="Typeahead-input ng-untouched ng-pristine ng-valid" placeholder value type=text></div></xpl-typeahead-migr></div><div _ngcontent-xhp-c458 class=search-icon><button _ngcontent-xhp-c458 type=submit aria-label=Search class="fa fa-search"></button></div></div></div></form><div _ngcontent-xhp-c458 class=below-search-bar><div _ngcontent-xhp-c458 class="advanced-search-wrapper text-sm-md-lh"><div _ngcontent-xhp-c458 class=advanced-search-div><a _ngcontent-xhp-c458 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/search/advanced target=_self><span _ngcontent-xhp-c458>ADVANCED SEARCH </span><i _ngcontent-xhp-c458 aria-hidden=true class="fas fa-caret-right adv-search-arrow sf-hidden"></i></a></div></div></div></div></xpl-search-bar-migr></div></div></div></xpl-header><div _ngcontent-xhp-c451 class=global-ng-wrapper><router-outlet _ngcontent-xhp-c451></router-outlet><xpl-document-details _nghost-xhp-c191><div _ngcontent-xhp-c191 class="row document ng-document stats-document"><div _ngcontent-xhp-c191 class="document-main global-content-width-w-rr"><section _ngcontent-xhp-c191 class="document-main-leaderboard-ad col-12"><xpl-leaderboard-ad _ngcontent-xhp-c191 class=hide-desktop _nghost-xhp-c124><div _ngcontent-xhp-c124 class="Ads-leaderboard ad-panel" style=display:none><div _ngcontent-xhp-c124 class="ad-leaderboard-ad-container sf-hidden"><div _ngcontent-xhp-c124 xplgoogleadmigr class="Ads-leaderBoardTablet sf-hidden"></div><div _ngcontent-xhp-c124 xplgoogleadmigr class="Ads-leaderBoardMobile sf-hidden"></div></div></div></xpl-leaderboard-ad></section><section _ngcontent-xhp-c191 class="document-main-header row"><div _ngcontent-xhp-c191 class=col-12><xpl-document-header _ngcontent-xhp-c191 _nghost-xhp-c144><section _ngcontent-xhp-c144 class="document-header row"><div _ngcontent-xhp-c144 class="document-header-breadcrumbs-container col-12"><div _ngcontent-xhp-c144 class="breadcrumbs col text-sm-md-lh"><span _ngcontent-xhp-c144><a _ngcontent-xhp-c144 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/browse/conferences/title/>Conferences</a><span _ngcontent-xhp-c144 class=breadcrumbs-separator> &gt;</span></span><span _ngcontent-xhp-c144><a _ngcontent-xhp-c144 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/conhome/6750807/proceeding>2013 IEEE International Confe...</a><span _ngcontent-xhp-c144 class=breadcrumbs-separator></span></span><xpl-help-link _ngcontent-xhp-c144 id=help tooltiptype=breadcrumb _nghost-xhp-c59><a _ngcontent-xhp-c59 target=_blank tooltipclass=helplink-tooltip triggers=hover class="icon-size-md u-flex-display-inline" href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/ieee-xplore-training/working-with-documents#interactive-html><i _ngcontent-xhp-c59 class="fa fa-question-circle help-link breadcrumb-help-link-icon"></i></a></xpl-help-link></div></div><div _ngcontent-xhp-c144 class="document-header-inner-container row"><div _ngcontent-xhp-c144 class=col-12><div _ngcontent-xhp-c144 class="row stats-document-header"><div _ngcontent-xhp-c144 class="row document-title-fix"><div _ngcontent-xhp-c144 class="document-header-title-container col"><div _ngcontent-xhp-c144 class=left-container><h1 _ngcontent-xhp-c144 class="document-title text-2xl-md-lh"><span _ngcontent-xhp-c144>Restoring an Image Taken through a Window Covered with Dirt or Rain</span></h1><div _ngcontent-xhp-c144 class="u-mb-1 u-mt-05 btn-container"><div _ngcontent-xhp-c144 class=publisher-title-tooltip><xpl-publisher _ngcontent-xhp-c144 tooltipplacement=right _nghost-xhp-c105><span _ngcontent-xhp-c105 class="text-base-md-lh publisher-info-container black-tooltip"><span _ngcontent-xhp-c105 xplhighlight><span _ngcontent-xhp-c105><span _ngcontent-xhp-c105 class=title>Publisher: </span><span _ngcontent-xhp-c105>IEEE</span></span></span></span></xpl-publisher></div><div _ngcontent-xhp-c144 class=cite-this-related-btn-wrapper><xpl-cite-this-modal _ngcontent-xhp-c144 _nghost-xhp-c125><div _ngcontent-xhp-c144><button _ngcontent-xhp-c144 placement=bottom class="layout-btn-white cite-this-btn">Cite This</button></div></xpl-cite-this-modal></div><div _ngcontent-xhp-c144 class="black-tooltip tool-tip-pdf-button"><div _ngcontent-xhp-c144 placement=bottom class="pdf-btn-container hide-mobile"><xpl-view-pdf _ngcontent-xhp-c144 placement=document-page-desktop _nghost-xhp-c113><div _ngcontent-xhp-c113><div _ngcontent-xhp-c113><a _ngcontent-xhp-c113 class="pdf-btn-link stats-document-lh-action-downloadPdf_2 pdf" href="https://ieeexplore-ieee-org.thi.idm.oclc.org/stamp/stamp.jsp?tp=&amp;arnumber=6751188"><i _ngcontent-xhp-c113 class="icon-size-md icon red-pdf fas fa-file-pdf"></i><span _ngcontent-xhp-c113>PDF</span></a></div></div></xpl-view-pdf><xpl-login-modal-trigger _ngcontent-xhp-c144 _nghost-xhp-c135></xpl-login-modal-trigger></div></div></div></div><div _ngcontent-xhp-c144 class=right-container></div></div></div><div _ngcontent-xhp-c144 class="mobile-serp-nav col-18-24 hide-desktop"><span _ngcontent-xhp-c144 class=mobile-serp-nav-item> &nbsp;<a _ngcontent-xhp-c144 target=_self href="https://ieeexplore-ieee-org.thi.idm.oclc.org/search/searchresult.jsp?contentType=all&amp;queryText=6751188">&lt;&lt;&nbsp;Results&nbsp;</a>&nbsp; </span></div><div _ngcontent-xhp-c144 class=document-main-subheader><div _ngcontent-xhp-c144 class=document-main-author-banner><div _ngcontent-xhp-c144 class="document-authors-banner stats-document-authors-banner"><div _ngcontent-xhp-c144 class="row authors-banner-row u-flex-align-items-center u-flex-wrap-nowrap"><xpl-author-banner _ngcontent-xhp-c144 class=authors-banner-row-middle _nghost-xhp-c137><div _ngcontent-xhp-c137 class="document-authors-banner stats-document-authors-banner"><div _ngcontent-xhp-c137 class="row authors-banner-row u-flex-wrap-nowrap"><div _ngcontent-xhp-c137 class=authors-banner-row-middle><div _ngcontent-xhp-c137 class="authors-container stats-document-authors-banner-authorsContainer"><div _ngcontent-xhp-c137 class="authors-info-container overflow-ellipsis text-base-md-lh authors-minimized" id=indexTerms-container-1651482975112-0><span _ngcontent-xhp-c137 class=authors-info><span _ngcontent-xhp-c137 class=blue-tooltip><a _ngcontent-xhp-c137 placement=bottom triggers=hover href=https://ieeexplore-ieee-org.thi.idm.oclc.org/author/38467214900><span _ngcontent-xhp-c137>David Eigen</span></a></span><span _ngcontent-xhp-c137>; </span></span><span _ngcontent-xhp-c137 class=authors-info><span _ngcontent-xhp-c137 class=blue-tooltip><a _ngcontent-xhp-c137 placement=bottom triggers=hover href=https://ieeexplore-ieee-org.thi.idm.oclc.org/author/37355137900><span _ngcontent-xhp-c137>Dilip Krishnan</span></a></span><span _ngcontent-xhp-c137>; </span></span><span _ngcontent-xhp-c137 class=authors-info><span _ngcontent-xhp-c137 class=blue-tooltip><a _ngcontent-xhp-c137 placement=bottom triggers=hover href=https://ieeexplore-ieee-org.thi.idm.oclc.org/author/37419045500><span _ngcontent-xhp-c137>Rob Fergus</span></a></span><span _ngcontent-xhp-c137></span></span></div></div></div></div></div></xpl-author-banner><div _ngcontent-xhp-c144 class="u-flex-display-flex u-flex-align-items-center nowrap text-base-md-lh"><div _ngcontent-xhp-c144 class="authors-view-all-link-container hide-mobile"><a _ngcontent-xhp-c144 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=text-base-md-lh>All Authors</a></div><div _ngcontent-xhp-c144 class="authors-mobile-view-all-container blue-tooltip hide-desktop"><a _ngcontent-xhp-c144 placement=bottom-right triggers=click:click class=authors-viewall-link><i _ngcontent-xhp-c144 class=authors-viewall-icon></i></a></div></div></div></div></div><div _ngcontent-xhp-c144 class="document-header-metrics-banner row"><div _ngcontent-xhp-c144 class="document-banner col stats-document-banner"><xpl-login-modal-trigger _ngcontent-xhp-c144 _nghost-xhp-c135></xpl-login-modal-trigger><button _ngcontent-xhp-c144 class="sip-modal-button stats-document-banner-viewDocument"><div _ngcontent-xhp-c144 class=main-txt> View Document </div></button><div _ngcontent-xhp-c144 class="document-banner-metric-container row"><button _ngcontent-xhp-c144 class="document-banner-metric text-base-md-lh col"><div _ngcontent-xhp-c144 class=document-banner-metric-count>228</div><div _ngcontent-xhp-c144>Paper</div><div _ngcontent-xhp-c144>Citations</div></button><button _ngcontent-xhp-c144 class="document-banner-metric text-base-md-lh col"><div _ngcontent-xhp-c144 class=document-banner-metric-count>4</div><div _ngcontent-xhp-c144>Patent</div><div _ngcontent-xhp-c144>Citations</div></button><button _ngcontent-xhp-c144 class="document-banner-metric text-base-md-lh col"><div _ngcontent-xhp-c144 class=document-banner-metric-count>1794</div><div _ngcontent-xhp-c144><div _ngcontent-xhp-c144>Full</div><div _ngcontent-xhp-c144>Text Views</div></div></button></div><div _ngcontent-xhp-c144 class=document-banner-access></div></div><div _ngcontent-xhp-c144 class="col-7-24 black-tooltip hide-mobile"><xpl-document-toolbar _ngcontent-xhp-c144 _nghost-xhp-c143><div _ngcontent-xhp-c143 class="col-actions stats-document-container-lh u-printing-invisible-ie u-printing-invisible-ff"><div _ngcontent-xhp-c143 class=action-item-container><ul _ngcontent-xhp-c143 class="icon-size-md doc-actions doc-toolbar stats-document-lh-actions black-tooltip"><li _ngcontent-xhp-c143 placement=bottom class=doc-actions-item><a _ngcontent-xhp-c143 target=blank class="doc-actions-link stats_ReferencesView_Doc_Details_6751188" href="https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/dwnldReferences?arnumber=6751188"><i _ngcontent-xhp-c143 class="icon-size-md color-xplore-blue fas fa-registered"></i></a><li _ngcontent-xhp-c143 placement=bottom class="doc-actions-item white-blue-border-tooltip"><xpl-document-social-media _ngcontent-xhp-c143 _nghost-xhp-c140><button _ngcontent-xhp-c140 triggers=click class=doc-share-tool><i _ngcontent-xhp-c140 aria-hidden=true class="fa fa-share-alt"></i></button></xpl-document-social-media><li _ngcontent-xhp-c143 placement=bottom class="stats-permission doc-actions-item"><a _ngcontent-xhp-c143 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class="doc-actions-link stats_Doc_Details_Copyright_6751188"><i _ngcontent-xhp-c143 class="color-xplore-blue copyright-icon far fa-copyright"></i></a><li _ngcontent-xhp-c143 placement=bottom class="doc-actions-item white-blue-border-tooltip save-to disabled-look enable-hover"><a _ngcontent-xhp-c143 placement=bottom-right triggers=click href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=doc-save-tool><i _ngcontent-xhp-c143 class="icon-size-md color-xplore-blue fas fa-folder-open"></i></a><li _ngcontent-xhp-c143 placement=bottom class=doc-actions-item><xpl-manage-alerts _ngcontent-xhp-c143 class="white-blue-border-tooltip alerts-popover" _nghost-xhp-c141><a _ngcontent-xhp-c141 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ triggers=click:click class="doc-actions-link stats-document-lh-action-alerts hide-mobile"><i _ngcontent-xhp-c141 class="icon-size-md color-xplore-blue fas fa-bell"></i><span _ngcontent-xhp-c141 class=doc-actions-text>Alerts</span></a><div _ngcontent-xhp-c141 class="manage-alerts-popover-content hide-desktop"><h1 _ngcontent-xhp-c141 class=header>Alerts</h1><div _ngcontent-xhp-c141 class=manage-alerts-link><a _ngcontent-xhp-c141 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/alerts/citation> Manage Content Alerts <i _ngcontent-xhp-c141 class="icon icon-courses-chevron-blue"></i></a></div><div _ngcontent-xhp-c141 class=manage-alerts-link><a _ngcontent-xhp-c141 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/> Add to Citation Alerts <i _ngcontent-xhp-c141 class="icon icon-courses-chevron-blue"></i></a></div></div></xpl-manage-alerts></ul></div></div></xpl-document-toolbar></div></div></div></div></div></div><hr _ngcontent-xhp-c144></section></xpl-document-header></div></section><div _ngcontent-xhp-c191 class="row document-main-body"><div _ngcontent-xhp-c191 class="document-main-left-trail col-5-24"><div _ngcontent-xhp-c191 class=col-24-24><div _ngcontent-xhp-c191 class=row><nav _ngcontent-xhp-c191 class="col-24-24 bg-ltgry tab-nav text-base-md-lh"><div _ngcontent-xhp-c191 id=document-tabs class="doc-tabs-list stats-document-tabs"><div _ngcontent-xhp-c191 routerlinkactive=active class="browse-pub-tab active"><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188>Abstract</a></div><xpl-full-text-toc _ngcontent-xhp-c191 class=hide-mobile _nghost-xhp-c145><div _ngcontent-xhp-c145 class=toc-container><div _ngcontent-xhp-c145 class=toc-heading>Document Sections</div><ul _ngcontent-xhp-c145 class=toc-list><li _ngcontent-xhp-c145 class=toc-list-item><a _ngcontent-xhp-c145 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=toc-list-link tabindex=0><div _ngcontent-xhp-c145 class=toc-list-icon>1.</div><div _ngcontent-xhp-c145 class=toc-list-icon></div><div _ngcontent-xhp-c145>Introduction</div></a><li _ngcontent-xhp-c145 class=toc-list-item><a _ngcontent-xhp-c145 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=toc-list-link tabindex=0><div _ngcontent-xhp-c145 class=toc-list-icon>2.</div><div _ngcontent-xhp-c145 class=toc-list-icon></div><div _ngcontent-xhp-c145>Approach</div></a><li _ngcontent-xhp-c145 class=toc-list-item><a _ngcontent-xhp-c145 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=toc-list-link tabindex=0><div _ngcontent-xhp-c145 class=toc-list-icon>3.</div><div _ngcontent-xhp-c145 class=toc-list-icon></div><div _ngcontent-xhp-c145>Training Data Collection</div></a><li _ngcontent-xhp-c145 class=toc-list-item><a _ngcontent-xhp-c145 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=toc-list-link tabindex=0><div _ngcontent-xhp-c145 class=toc-list-icon>4.</div><div _ngcontent-xhp-c145 class=toc-list-icon></div><div _ngcontent-xhp-c145>Baseline Methods</div></a><li _ngcontent-xhp-c145 class=toc-list-item><a _ngcontent-xhp-c145 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ class=toc-list-link tabindex=0><div _ngcontent-xhp-c145 class=toc-list-icon>5.</div><div _ngcontent-xhp-c145 class=toc-list-icon></div><div _ngcontent-xhp-c145>Experiments</div></a></ul><button _ngcontent-xhp-c145 class=toc-show-more-btn><span _ngcontent-xhp-c145>Show Full Outline</span><i _ngcontent-xhp-c145 class="fa fa-caret-down"></i></button></div></xpl-full-text-toc><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/authors>Authors</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/figures>Figures</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/references>References</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/citations>Citations</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/keywords>Keywords</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/metrics>Metrics</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/media>Media</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class="browse-pub-tab similar"><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/similar>More Like This</a></div><div _ngcontent-xhp-c191 routerlinkactive=active class=browse-pub-tab><a _ngcontent-xhp-c191 class=document-tab-link href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/footnotes>Footnotes</a></div></div></nav></div></div></div><div _ngcontent-xhp-c191 class=document-main-content-container><xpl-left-side-bar _ngcontent-xhp-c191 _nghost-xhp-c146><div _ngcontent-xhp-c146 xplscrollsnapmigr scrollreset=true offsetfrom=100 fromelementid=mobile-tab-pane tillelementid=full-text-footer offsetto=-800 cssclasstostick=document-mobile-leftrail-stick class="col-2 col-actions ng-col-actions hide-desktop stats-document-container-lh u-printing-invisible-ie u-printing-invisible-ff col-actions-mobile-closed ng-col-actions-mobile-closed"><div _ngcontent-xhp-c146 id=left-rail-container><div _ngcontent-xhp-c146 class=doc-actions-mobile-expand-button></div><ul _ngcontent-xhp-c146 class="doc-actions stats-document-lh-actions"><li _ngcontent-xhp-c146 class=doc-actions-item><xpl-view-pdf _ngcontent-xhp-c146 placement=document-page-mobile _nghost-xhp-c113><div _ngcontent-xhp-c113><div _ngcontent-xhp-c113><a _ngcontent-xhp-c113 target=_blank class="doc-actions-link stats-document-lh-action-downloadPdf_2 pdf" href="https://ieeexplore-ieee-org.thi.idm.oclc.org/stamp/stamp.jsp?tp=&amp;arnumber=6751188"><i _ngcontent-xhp-c113 class="icon-size-md icon red-pdf fas fa-file-pdf"></i> Download PDF </a></div></div></xpl-view-pdf><xpl-login-modal-trigger _ngcontent-xhp-c146 _nghost-xhp-c135></xpl-login-modal-trigger><li _ngcontent-xhp-c146 class=doc-actions-item><a _ngcontent-xhp-c146 target=blank class="doc-actions-link stats_ReferencesView_Doc_Details_6751188" href="https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/dwnldReferences?arnumber=6751188"><i _ngcontent-xhp-c146 class="icon-size-md color-xplore-blue fas fa-registered"></i> View References </a><li _ngcontent-xhp-c146 class="doc-actions-item white-blue-border-tooltip"><a _ngcontent-xhp-c146 class=doc-actions-link><xpl-document-social-media _ngcontent-xhp-c146 tooltipplacement=right placement=document-page-mobile _nghost-xhp-c140><button _ngcontent-xhp-c140 triggers=click class=doc-share-tool><i _ngcontent-xhp-c140 aria-hidden=true class="fa fa-share-alt"></i></button></xpl-document-social-media></a><li _ngcontent-xhp-c146 class="stats-permission doc-actions-item"><a _ngcontent-xhp-c146 title="Request permission for reuse." class="doc-actions-link stats_Doc_Details_Copyright_6751188"><i _ngcontent-xhp-c146 class="copyright-icon far fa-copyright"></i> Request Permissions </a><li _ngcontent-xhp-c146 class="doc-actions-item disabled-look black-tooltip"><a _ngcontent-xhp-c146 placement=right triggers=click autoclose=outside class="doc-actions-link stats-document-lh-action-downloadPdf_3"><i _ngcontent-xhp-c146 class="icon-size-md color-xplore-blue fas fa-folder-open"></i> Save to </a><li _ngcontent-xhp-c146 class=doc-actions-item><a _ngcontent-xhp-c146 class="doc-actions-link stats-document-lh-action-alerts"><i _ngcontent-xhp-c146 class="icon-size-md color-xplore-blue fas fa-bell"></i> Alerts </a></ul></div></div></xpl-left-side-bar><section _ngcontent-xhp-c191 class="tab-pane col-24-24 u-printing-display-inline-ie u-printing-display-inline-ff"><div _ngcontent-xhp-c191 id=mobile-tab-pane></div><div _ngcontent-xhp-c191 class=document-main-left-trail-content><div _ngcontent-xhp-c191><router-outlet _ngcontent-xhp-c191></router-outlet><xpl-document-abstract _nghost-xhp-c186><section _ngcontent-xhp-c186 class="document-abstract document-tab"><div _ngcontent-xhp-c186 class="col-12 hide-desktop mobile-graphical-abstract"></div><div _ngcontent-xhp-c186 class="abstract-mobile-div hide-desktop"><div _ngcontent-xhp-c186 class=row><div _ngcontent-xhp-c186 class=mobile-col-12><div _ngcontent-xhp-c186 class=u-pb-1><strong _ngcontent-xhp-c186> Abstract:</strong><span _ngcontent-xhp-c186 xplmathjax>Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle,...</span><span _ngcontent-xhp-c186><a _ngcontent-xhp-c186 class=mobile-toggle-btn>View more</a></span></div></div></div><div _ngcontent-xhp-c186 class="metadata-toggle-btn mobile-content"><strong _ngcontent-xhp-c186><i _ngcontent-xhp-c186 class=icon-caret-abstract></i><span _ngcontent-xhp-c186>Metadata</span></strong></div></div><div _ngcontent-xhp-c186 class="abstract-desktop-div hide-mobile text-base-md-lh"><div _ngcontent-xhp-c186 class="abstract-text row"><div _ngcontent-xhp-c186 class=col-12><div _ngcontent-xhp-c186 class=u-mb-1><strong _ngcontent-xhp-c186> Abstract:</strong><div _ngcontent-xhp-c186 xplmathjax>Photographs taken through a window are often compromised by dirt or rain present on the window surface. Common cases of this include pictures taken from inside a vehicle, or outdoor security cameras mounted inside a protective enclosure. At capture time, defocus can be used to remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the window. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We collect a dataset of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions.</div></div></div></div><div _ngcontent-xhp-c186 data-tealium_data='{"docType": "Conference"}' class="u-pb-1 stats-document-abstract-publishedIn"><strong _ngcontent-xhp-c186>Published in: </strong><a _ngcontent-xhp-c186 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/conhome/6750807/proceeding>2013 IEEE International Conference on Computer Vision</a></div><div _ngcontent-xhp-c186 class="row u-pt-1"><div _ngcontent-xhp-c186 class=col-6><div _ngcontent-xhp-c186 class="u-pb-1 doc-abstract-confdate"><strong _ngcontent-xhp-c186>Date of Conference: </strong> 1-8 Dec. 2013 </div><div _ngcontent-xhp-c186 class="u-pb-1 doc-abstract-dateadded"><strong _ngcontent-xhp-c186>Date Added to IEEE <i _ngcontent-xhp-c186>Xplore</i>: </strong> 03 March 2014 </div><div _ngcontent-xhp-c186 class=u-pb-1><div _ngcontent-xhp-c186><div _ngcontent-xhp-c186><strong _ngcontent-xhp-c186>Electronic ISBN:</strong><span _ngcontent-xhp-c186 class=isbn-value>978-1-4799-2840-8</span></div></div></div><div _ngcontent-xhp-c186 class=u-pb-1><div _ngcontent-xhp-c186 role=button><strong _ngcontent-xhp-c186><i _ngcontent-xhp-c186 class=icon-caret-abstract></i><span _ngcontent-xhp-c186>ISSN Information:</span></strong></div></div></div><div _ngcontent-xhp-c186 class=col-6><div _ngcontent-xhp-c186 class=u-pb-1><strong _ngcontent-xhp-c186>INSPEC Accession Number: </strong> 14145033 </div><div _ngcontent-xhp-c186 class="u-pb-1 stats-document-abstract-doi"><strong _ngcontent-xhp-c186>DOI: </strong><a _ngcontent-xhp-c186 append-to-href="?src=document" target=_blank href=https://doi-org.thi.idm.oclc.org/10.1109/ICCV.2013.84>10.1109/ICCV.2013.84</a></div><div _ngcontent-xhp-c186 class="u-pb-1 doc-abstract-publisher"><xpl-publisher _ngcontent-xhp-c186 _nghost-xhp-c105><span _ngcontent-xhp-c105 class="text-base-md-lh publisher-info-container black-tooltip"><span _ngcontent-xhp-c105 xplhighlight><span _ngcontent-xhp-c105><span _ngcontent-xhp-c105 class=title>Publisher: </span><span _ngcontent-xhp-c105>IEEE</span></span></span></span></xpl-publisher></div><div _ngcontent-xhp-c186 class="u-pb-1 doc-abstract-conferenceLoc"><strong _ngcontent-xhp-c186>Conference Location: </strong> Sydney, NSW, Australia </div></div></div></div></section></xpl-document-abstract></div><xpl-leaderboard-middle-ad _ngcontent-xhp-c191 class=hide-desktop _nghost-xhp-c187><div _ngcontent-xhp-c187 class="Ads-leaderboard ad-panel"><div _ngcontent-xhp-c187 class="row u-flex-wrap-nowrap"><div _ngcontent-xhp-c187 class=ads-close-container><i _ngcontent-xhp-c187 aria-hidden=true class=ads-close-button></i></div></div><div _ngcontent-xhp-c187 class=ad-leaderboard-ad-container><div _ngcontent-xhp-c187 xplgoogleadmigr class=Ads-leaderBoardMiddleTablet><div id=div-gpt-ad-1606861708257-0 style="width:576px;height:71px;display:none;margin:0px auto;padding-bottom:0.5em"></div></div><div _ngcontent-xhp-c187 xplgoogleadmigr class=Ads-leaderBoardMiddleMobile><div id=div-gpt-ad-1606861708357-0 style="width:320px;height:50px;margin:0px auto;padding-bottom:0.5em" data-google-query-id=CIOqgsG9wPcCFUyW_QcdvQ8NKg><div id=google_ads_iframe_/3890430/IEEEXplore/DocDetailsMiddle_1__container__ style="border:0pt none"></div></div></div></div></div></xpl-leaderboard-middle-ad><xpl-document-full-text _ngcontent-xhp-c191 _nghost-xhp-c158><section _ngcontent-xhp-c158><div _ngcontent-xhp-c158 id=toc-wrapper class="row full-text-toc-wrapper"><div _ngcontent-xhp-c158 xplscrollsnapmigr cssclasstostick=document-toc-stick fromelementid=toc-wrapper tillelementid=full-text-footer offsetfrom=150 offsetto=-800 scrollreset=true class="col-12 u-align-center ft-toc previous-next-nav-ctrl hide-desktop"><div _ngcontent-xhp-c158 class="toc-container hide-desktop"><a _ngcontent-xhp-c158 ngclass="{'disabled': !toc}" class="toc-link {'disabled': !toc}"><img _ngcontent-xhp-c158 src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="> Contents </a></div></div></div><hr _ngcontent-xhp-c158><div _ngcontent-xhp-c158 class="row document-full-text-content"><div _ngcontent-xhp-c158 id=full-text-section class="col col-text stats-document-container-fullTextSection u-printing-display-inline-ie u-printing-display-inline-ff" style=font-size:15px><span _ngcontent-xhp-c158 id=full-text-header></span><div _ngcontent-xhp-c158><div _ngcontent-xhp-c158 xplmathjax xplfulltextdomhandler xpllazyloadfigures class="document-text hide-full-text ng-non-bindable stats-document-dynamicFullTextOrSnippet-container">
<div id=BodyWrapper class=ArticlePage xmlns:ieee=http://www.ieeexplore.ieee.org.thi.idm.oclc.org><div id=article>
<div class=section id=sec1><div class="header article-hdr"><div class=kicker>
 SECTION 1.</div><h2>Introduction</h2></div><p>There are many situations in which images or video might be captured through a window. A person may be inside a car, train or building and wish to photograph the scene outside. Indoor situations include exhibits in museums displayed behind protective glass. Such scenarios have become increasingly common with the widespread use of smartphone cameras. Beyond consumer photography, many cameras are mounted outside, e.g. on buildings for surveillance or on vehicles to prevent collisions. These cameras are protected from the elements by an enclosure with a transparent window.<p>Such images are affected by many factors including reflections and attenuation. However, in this paper we address the particular situation where the window is covered with dirt or water drops, resulting from rain. As shown in <a ref-type=fig anchor=fig1 class=fulltext-link>Fig. 1</a>, these artifacts significantly degrade the quality of the captured image.<p>The classic approach to removing occluders from an image is to defocus them to the point of invisibility at the time of capture. This requires placing the camera right up against the glass and using a large aperture to produce small depth-of-field. However, in practice it can be hard to move the camera sufficiently close, and aperture control may not be available on smartphone cameras or webcams. Correspondingly, many shots with smartphone cameras through dirty or rainy glass still have significant artifacts, as shown in <a ref-type=fig anchor=fig9 class=fulltext-link>Fig. 9</a>.
<div class="figure figure-full" id=fig1><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-1-source-large.gif data-fig-id=fig1><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-1-source-small.gif data-alt="Figure 1. - A photograph taken through a glass pane covered in rain, along with the output of our neural network model, trained to remove this type of corruption. The irregular size and appearance of the rain makes it difficult to remove with existing methods. This figure is best viewed in electronic form."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 1. </b><fig>A photograph taken through a glass pane covered in rain, along with the output of our neural network model, trained to remove this type of corruption. The irregular size and appearance of the rain makes it difficult to remove with existing methods. This figure is best viewed in electronic form.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p><p>In this paper we instead restore the image after capture, treating the dirt or rain as a structured form of image noise. Our method only relies on the artifacts being spatially com-pact, thus is aided by the rain/dirt being in focus  hence the shots need not be taken close to the window.<p>Image denoising is a very well studied problem, with current approaches such as BM3D <a ref-type=bibr anchor=ref3 id=context_ref_3_1>[3]</a> approaching theoretical performance limits <a ref-type=bibr anchor=ref13 id=context_ref_13_1>[13]</a>. However, the vast majority of this literature is concerned with additive white Gaussian noise, quite different to the image artifacts resulting from dirt or water drops. Our problem is closer to shot-noise removal, but differs in that the artifacts are not constrained to single pixels and have characteristic structure. Classic approaches such as median or bilateral filtering have no way of leveraging this structure, thus cannot effectively remove the artifacts (see <a ref-type=sec anchor=sec5 class=fulltext-link>Section 5</a>).<p>Our approach is to use a specialized convolutional neural network to predict clean patches, given dirty <i>or clean</i> ones as input. By asking the network to produce a clean output, regardless of the corruption level of the input, it implicitly must both detect the corruption and, if present, in-paint over it. Integrating both tasks simplifies and speeds test-time operation, since separate detection and in-painting stages are avoided.<p>Training the models requires a large set of patch pairs to adequately cover the space inputs and corruption, the gathering of which was non-trivial and required the development of new techniques. However, although training is somewhat complex, test-time operation is simple: a new image is presented to the neural network and it directly outputs a restored image.<div class=section_2 id=sec1a><h3>1.1. Related Work</h3><p>Learning-based methods have found widespread use in image denoising, e.g. <a ref-type=bibr anchor=ref23 id=context_ref_23_1a>[23]</a>, <a ref-type=bibr anchor=ref14 id=context_ref_14_1a>[14]</a>, <a ref-type=bibr anchor=ref16 id=context_ref_16_1a>[16]</a>, <a ref-type=bibr anchor=ref24 id=context_ref_24_1a>[24]</a>. These approaches remove additive white Gaussian noise (AWGN) by building a generative model of clean image patches. In this paper, however, we focus on more complex structured corruption, and address it using a neural network that directly maps corrupt images to clean ones; this obviates the slow inference procedures used by most generative models.<p>Neural networks have previously been explored for denoising natural images, mostly in the context of AWGN, e.g. Jain and Seung <a ref-type=bibr anchor=ref10 id=context_ref_10_1a>[10]</a>, and Zhang and Salari <a ref-type=bibr anchor=ref21 id=context_ref_21_1a>[21]</a>. Algorithmically, the closest work to ours is that of Burger <i>et al</i>. <a ref-type=bibr anchor=ref2 id=context_ref_2_1a>[2]</a>, which applies a large neural network to a range of non-AWGN denoising tasks, such as salt-and-pepper noise and JPEG quantization artifacts. Although more challenging than AWGN, the corruption is still significantly easier than the highly variable dirt and rain drops that we address. Furthermore, our network has important architectural differences that are crucial for obtaining good performance on these tasks.<p>Removing localized corruption can be considered a form of blind inpainting, where the position of the corrupted regions is not given (unlike traditional inpainting <a ref-type=bibr anchor=ref5 id=context_ref_5_1a>[5]</a>). Dong <i>et al</i>. <a ref-type=bibr anchor=ref4 id=context_ref_4_1a>[4]</a> show how salt-and-pepper noise can be removed, but the approach does not extend to multi-pixel corruption. Recently, Xie <i>et al</i>. <a ref-type=bibr anchor=ref20 id=context_ref_20_1a>[20]</a> showed how a neural network can perform blind inpainting, demonstrating the removal of text synthetically placed in an image. This work is close to ours, but the solid-color text has quite different statistics to natural images, thus is easier to remove than rain or dirt which vary greatly in appearance and can resemble legitimate image structures. Jancsary <i>et al</i>. <a ref-type=bibr anchor=ref11 id=context_ref_11_1a>[11]</a> denoise images with a Gaussian conditional random field, constructed using decision trees on local regions of the input; however, they too consider only synthetic corruptions.<p>Several papers explore the removal of rain from images. Garg and Nayar <a ref-type=bibr anchor=ref7 id=context_ref_7_1a>[7]</a> and Barnum <i>et al</i>. <a ref-type=bibr anchor=ref1 id=context_ref_1_1a>[1]</a> address airborne rain. The former uses defocus, while the latter uses frequency-domain filtering. Both require video sequences rather than a single image, however. Roser and Geiger <a ref-type=bibr anchor=ref17 id=context_ref_17_1a>[17]</a> detect raindrops in single images; although they do not demonstrate removal, their approach could be paired with a standard inpainting algorithm. As discussed above, our approach combines detection and inpainting.<p>Closely related to our application is Gu <i>et al</i>. <a ref-type=bibr anchor=ref9 id=context_ref_9_1a>[9]</a>, who show how lens dust and nearby occluders can be removed, but their method requires extensive calibration or a video sequence, as opposed to a single frame. Wilson <i>et al</i>. <a ref-type=bibr anchor=ref19 id=context_ref_19_1a>[19]</a> and Zhou and Lin <a ref-type=bibr anchor=ref22 id=context_ref_22_1a>[22]</a> demonstrate dirt and dust removal. The former removes defocused dust for a Mars Rover camera, while the latter removes sensor dust using multiple images and a physics model.</p></div></div>
<div class=section id=sec2><div class="header article-hdr"><div class=kicker>
 SECTION 2.</div><h2>Approach</h2></div><p>To restore an image from a corrupt input, we predict a clean output using a specialized form of convolutional neural network <a ref-type=bibr anchor=ref12 id=context_ref_12_2>[12]</a>. The same network architecture is used for all forms of corruption; however, a different network is trained for dirt and for rain. This allows the network to tailor its detection capabilities for each task.<div class=section_2 id=sec2a><h3>2.1. Network Architecture</h3><p>Given a noisy image <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>x</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-1-Frame tabindex=0></span></tex-math></inline-formula>, our goal is to predict a clean image <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-2-Frame tabindex=0></span></tex-math></inline-formula> that is close to the true clean image <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y^{\ast}</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-3-Frame tabindex=0></span></tex-math></inline-formula>. We accomplish this using a multilayer convolutional network, <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y=F(x)</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-4-Frame tabindex=0></span></tex-math></inline-formula>. The network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-5-Frame tabindex=0></span></tex-math></inline-formula> is composed of a series of layers <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F_{l}</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-6-Frame tabindex=0></span></tex-math></inline-formula>, each of which applies a linear convolution to its input, followed by an element-wise sigmoid (implemented using hyperbolic tangent). Concretely, if the number of layers in the network is <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>L</span><span class="MathJax MathJax_Processed sf-hidden" id=MathJax-Element-7-Frame tabindex=0></span></tex-math></inline-formula>, then
<disp-formula class=display-formula><tex-math notation=TeX><span class=MathJax_Preview>\eqalignno{F_{0}(x)&amp;=x\cr F_{l}(x)&amp;=\tanh(W_{l}\ast F_{l-1}(x)+b_{l}),\quad l=1,\ldots,L-1\cr F(x)&amp;={{1}\over{m}}(W_{L}\ast F_{L-1}(x)+b_{L})}</span></tex-math></disp-formula><div class="MathJax_Display MathJax_Processing sf-hidden"></div><span class=formula><span class=link>View Source</span><img class="document-ft-image load-shimmer" aria-describedby=qtip-0 style=display:inline title="Right-click on figure or equation for MathML and additional features." data-hasqtip=0 alt src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-lazy=/assets/img/icon.support.gif data-alt="Right-click on figure for MathML and additional features." width=24 height=20 border=0><span class="tex tex2jax_ignore" style=display:none>\eqalignno{F_{0}(x)&amp;=x\cr F_{l}(x)&amp;=\tanh(W_{l}\ast F_{l-1}(x)+b_{l}),\quad l=1,\ldots,L-1\cr F(x)&amp;={{1}\over{m}}(W_{L}\ast F_{L-1}(x)+b_{L})}</span></span> Here, <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>x</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-9-Frame tabindex=0></span></tex-math></inline-formula> is the RGB input image, of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>N\times M\times 3</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-10-Frame tabindex=0></span></tex-math></inline-formula>. If <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>n_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-11-Frame tabindex=0></span></tex-math></inline-formula> is the output dimension at layer <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>l</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-12-Frame tabindex=0></span></tex-math></inline-formula>, then <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>W_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-13-Frame tabindex=0></span></tex-math></inline-formula> applies <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>n_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-14-Frame tabindex=0></span></tex-math></inline-formula> convolutions with kernels of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{l}\times p_{l}\times n_{l-1}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-15-Frame tabindex=0></span></tex-math></inline-formula>, where <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-16-Frame tabindex=0></span></tex-math></inline-formula> is the spatial support. <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>b_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-17-Frame tabindex=0></span></tex-math></inline-formula> is a vector of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>n_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-18-Frame tabindex=0></span></tex-math></inline-formula> containing the output bias (the same bias is used at each spatial location).<p><p>While the first and last layer kernels have a nontrivial spatial component, we restrict the middle layers <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>(2\leq l\leq L-1)</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-19-Frame tabindex=0></span></tex-math></inline-formula> to use <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{l}=1</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-20-Frame tabindex=0></span></tex-math></inline-formula>, i.e. they apply a linear map at each spatial location. We also element-wise divide the final output by the overlap mask<a ref-type=fn anchor=fn1 class=footnote-link><sup>1</sup></a> <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>m</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-21-Frame tabindex=0></span></tex-math></inline-formula> to account for different amounts of kernel overlap near the image boundary. The first layer uses a valid convolution, while the last layer uses a full (these are the same for the middle layers since their kernels have <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>1\times 1</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-22-Frame tabindex=0></span></tex-math></inline-formula> support).
<div class="figure figure-full" id=fig2><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-2-source-large.gif data-fig-id=fig2><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-2-source-small.gif data-alt="Figure 2. - A subset of rain model network weights, sorted by $l_{2}$-norm. Left: first layer filters which act as detectors for the rain drops. Right: top layer filters used to reconstruct the clean patch."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 2. </b><fig>A subset of rain model network weights, sorted by <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>l_{2}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-23-Frame tabindex=0></span></tex-math></inline-formula>-norm. Left: first layer filters which act as detectors for the rain drops. Right: top layer filters used to reconstruct the clean patch.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p><p>In our system, the input kernels' support is <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{1}=16</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-24-Frame tabindex=0></span></tex-math></inline-formula>, and the output support is <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{L}=8</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-25-Frame tabindex=0></span></tex-math></inline-formula>. We use two hidden layers (i.e. <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>L=3</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-26-Frame tabindex=0></span></tex-math></inline-formula>), each with 512 units. As stated earlier, the middle layer kernel has support <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p_{2}=1</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-27-Frame tabindex=0></span></tex-math></inline-formula>. Thus, <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>W_{1}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-28-Frame tabindex=0></span></tex-math></inline-formula> applies 512 kernels of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>16\times 16\times 3, W_{2}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-29-Frame tabindex=0></span></tex-math></inline-formula> applies 512 kernels of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>1\times 1\times 512</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-30-Frame tabindex=0></span></tex-math></inline-formula>, and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>W_{3}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-31-Frame tabindex=0></span></tex-math></inline-formula> applies 3 kernels of size <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>8\times8\times512</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-32-Frame tabindex=0></span></tex-math></inline-formula>. <a ref-type=fig anchor=fig2 class=fulltext-link>Fig. 2</a> shows examples of weights learned for the rain data.</p></div><div class=section_2 id=sec2b><h3>2.2. Training</h3><p>We train the weights <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>W_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-33-Frame tabindex=0></span></tex-math></inline-formula> and biases <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>b_{l}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-34-Frame tabindex=0></span></tex-math></inline-formula> by minimizing the mean squared error over a dataset <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>D=(x_{i},y_{i}^{\ast})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-35-Frame tabindex=0></span></tex-math></inline-formula> of corresponding noisy and clean image pairs. The loss is
<disp-formula class=display-formula><tex-math notation=TeX><span class=MathJax_Preview>J(\theta)={{1}\over{2\vert D\vert}}\sum_{i\in D}\vert\vert F(x_{i})-y_{i}^{\ast}\vert\vert^{2}</span></tex-math></disp-formula><div class="MathJax_Display MathJax_Processing sf-hidden"></div><span class=formula><span class=link>View Source</span><img class="document-ft-image load-shimmer" aria-describedby=qtip-0 style=display:inline title="Right-click on figure or equation for MathML and additional features." data-hasqtip=0 alt src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-lazy=/assets/img/icon.support.gif data-alt="Right-click on figure for MathML and additional features." width=24 height=20 border=0><span class="tex tex2jax_ignore" style=display:none>J(\theta)={{1}\over{2\vert D\vert}}\sum_{i\in D}\vert\vert F(x_{i})-y_{i}^{\ast}\vert\vert^{2}</span></span> where <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\theta=(W_{1},\ldots, W_{L}, b_{1},\ldots,b_{L})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-37-Frame tabindex=0></span></tex-math></inline-formula> are the model parameters. The pairs in the dataset <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>D</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-38-Frame tabindex=0></span></tex-math></inline-formula> are random <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>64\times 64</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-39-Frame tabindex=0></span></tex-math></inline-formula> pixel subregions of training images with and without corruption (see <a ref-type=fig anchor=fig4 class=fulltext-link>Fig. 4</a> for samples). Because the input and output kernel sizes of our network differ, the network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-40-Frame tabindex=0></span></tex-math></inline-formula> produces a <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>56 \times 56</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-41-Frame tabindex=0></span></tex-math></inline-formula> pixel prediction <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{i}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-42-Frame tabindex=0></span></tex-math></inline-formula>, which is compared against the middle <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>56\times 56</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-43-Frame tabindex=0></span></tex-math></inline-formula> pixels of the true clean subimage <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{i}^{\ast}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-44-Frame tabindex=0></span></tex-math></inline-formula>.<p><p>We minimize the loss using Stochastic Gradient Descent (SGD). The update for a single step at time <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>t</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-45-Frame tabindex=0></span></tex-math></inline-formula> is
<disp-formula class=display-formula><tex-math notation=TeX><span class=MathJax_Preview>\theta^{t+1}\leftarrow\theta^{t}-\eta_{t}(F(x_{i})-y_{i}^{\ast})^{T}{{\partial}\over{\partial\theta}}F(x_{i})</span></tex-math></disp-formula><div class="MathJax_Display MathJax_Processing sf-hidden"></div><span class=formula><span class=link>View Source</span><img class="document-ft-image load-shimmer" aria-describedby=qtip-0 style=display:inline title="Right-click on figure or equation for MathML and additional features." data-hasqtip=0 alt src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-lazy=/assets/img/icon.support.gif data-alt="Right-click on figure for MathML and additional features." width=24 height=20 border=0><span class="tex tex2jax_ignore" style=display:none>\theta^{t+1}\leftarrow\theta^{t}-\eta_{t}(F(x_{i})-y_{i}^{\ast})^{T}{{\partial}\over{\partial\theta}}F(x_{i})</span></span> where <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\eta_{t}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-47-Frame tabindex=0></span></tex-math></inline-formula> is the learning rate hyper-parameter and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>i</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-48-Frame tabindex=0></span></tex-math></inline-formula> is a randomly drawn index from the training set. The gradient is further backpropagated through the network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-49-Frame tabindex=0></span></tex-math></inline-formula>.<p><p>We initialize the weights at all layers by randomly drawing from a normal distribution with mean 0 and standard deviation 0.001. The biases are initialized to O. The learning rate is 0.001 with decay, so that <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\eta_{t}=0.001/(1+5t\cdot 10^{-7})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-50-Frame tabindex=0></span></tex-math></inline-formula>. We use no momentum or weight regularization.
<div class="figure figure-full" id=fig3><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-3-source-large.gif data-fig-id=fig3><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-3-source-small.gif data-alt="Figure 3. - Denoising near a piece of noise. (a) shows a $64\times 64$ image region with dirt occluders (top), and target ground truth clean image (bottom). (b) and (c) show the results obtained using non-convolutional and convolutionally trained networks, respectively. The top row shows the full output after averaging. The bottom row shows the signed error of each individual patch prediction for all $8\times 8$ patches obtained using a sliding window in the boxed area, displayed as a montage. The errors from the convolutionally-trained network (c) are less correlated with one another compared to (b), and cancel to produce a better average."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 3. </b><fig>Denoising near a piece of noise. (a) shows a <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>64\times 64</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-51-Frame tabindex=0></span></tex-math></inline-formula> image region with dirt occluders (top), and target ground truth clean image (bottom). (b) and (c) show the results obtained using non-convolutional and convolutionally trained networks, respectively. The top row shows the full output after averaging. The bottom row shows the signed error of each individual patch prediction for all <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>8\times 8</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-52-Frame tabindex=0></span></tex-math></inline-formula> patches obtained using a sliding window in the boxed area, displayed as a montage. The errors from the convolutionally-trained network (c) are less correlated with one another compared to (b), and cancel to produce a better average.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p></p></div><div class=section_2 id=sec2c><h3>2.3. Effect of Convolutional Architecture</h3><p>A key improvement of our method over <a ref-type=bibr anchor=ref2 id=context_ref_2_2c>[2]</a> is that we minimize the error of the final image prediction, where as <a ref-type=bibr anchor=ref2 id=context_ref_2_2c>[2]</a> minimizes the error only of individual patches. We found this difference to be crucial to obtain good performance on the corruption we address.<p>Since the middle layer convolution in our network has <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>1\times 1</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-53-Frame tabindex=0></span></tex-math></inline-formula> spatial support, the network can be viewed as first patchifying the input, applying a fully-connected neural network to each patch, and averaging the resulting output patches. More explicitly, we can split the input image <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>x</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-54-Frame tabindex=0></span></tex-math></inline-formula> into stride-1 overlapping patches <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\{x_{p}\}={\rm patchify}(x)</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-55-Frame tabindex=0></span></tex-math></inline-formula>, and predict a corresponding clean patch <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{p}=f(x_{p})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-56-Frame tabindex=0></span></tex-math></inline-formula> for each <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>x_{p}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-57-Frame tabindex=0></span></tex-math></inline-formula> using a fully-connected multilayer network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>f</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-58-Frame tabindex=0></span></tex-math></inline-formula>. We then form the predicted image <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y={\rm depatchify}(\{y_{p}\})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-59-Frame tabindex=0></span></tex-math></inline-formula> by taking the average of the patch predictions at pixels where they overlap. In this context, the convolutional network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-60-Frame tabindex=0></span></tex-math></inline-formula> can be expressed in terms of the patch-level network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>f</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-61-Frame tabindex=0></span></tex-math></inline-formula> as <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F(x)={\rm depatchify}(\{f(x_{p}):x_{p}\in {\rm patchify}(x)\})</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-62-Frame tabindex=0></span></tex-math></inline-formula>.<p>In contrast to <a ref-type=bibr anchor=ref2 id=context_ref_2_2c>[2]</a>, our method trains the full network <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>F</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-63-Frame tabindex=0></span></tex-math></inline-formula>, <i>including patchification and depatchification</i>. This drives a decorrelation of the individual predictions, which helps both to remove occluders as well as reduce blur in the final output. To see this, consider two adjacent patches <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{1}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-64-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{2}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-65-Frame tabindex=0></span></tex-math></inline-formula> with overlap regions <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{o1}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-66-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{o2}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-67-Frame tabindex=0></span></tex-math></inline-formula>, and desired output <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>y_{o}^{\ast}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-68-Frame tabindex=0></span></tex-math></inline-formula>. If we were to train according to the individual predictions, the loss would minimize <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>(y_{o1}-y_{o}^{\ast})^{2}+(y_{o2}-y_{o}^{\ast})^{2}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-69-Frame tabindex=0></span></tex-math></inline-formula>, the sum of their error. However, if we minimize the error of their average, the loss becomes <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\left({{y_{o1}+y_{o2}}\over{2}}-y_{o}^{\ast}\right)^{2}= {{1}\over{4}}[(y_{o1}-y_{o}^{\ast})^{2}+(y_{o2}-y_{o}^{\ast})^{2}+2(y_{o1}-y_{o}^{\ast})(y_{o2}-y_{o}^{\ast})]</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-70-Frame tabindex=0></span></tex-math></inline-formula>. The new mixed term pushes the individual patch errors in opposing directions, encouraging them to decorrelate.<p><a ref-type=fig anchor=fig3 class=fulltext-link>Fig. 3</a> depicts this for a real example. When trained at the patch level, as in the system described by <a ref-type=bibr anchor=ref2 id=context_ref_2_2c>[2]</a>, each prediction leaves the same residual trace of the noise, which their average then maintains (b). When trained with our convolutional network, however, the predictions decorrelate where not perfect, and average to a better output (c).</p></div><div class=section_2 id=sec2d><h3>2.4. Test-Time Evaluation</h3><p>By restricting the middle layer kernels to have <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>1\times 1</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-71-Frame tabindex=0></span></tex-math></inline-formula> spatial support, our method requires no synchronization until the final summation in the last layer convolution. This makes our method natural to parallelize, and it can easily be run in sections on large input images by adding the outputs from each section into a single image output buffer. Our Matlab GPU implementation is able to restore a <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>3888\times 2592</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-72-Frame tabindex=0></span></tex-math></inline-formula> color image in 60s using a nVidia GTX 580, and a <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>1280\times 720</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-73-Frame tabindex=0></span></tex-math></inline-formula> color image in 7s.</p></div></div>
<div class=section id=sec3><div class="header article-hdr"><div class=kicker>
 SECTION 3.</div><h2>Training Data Collection</h2></div><p>The network has 753,664 weights and 1,216 biases which need to be set during training. This requires a large number of training patches to avoid over-fitting. We now describe the procedures used to gather the corrupted/clean patch pairs<a ref-type=fn anchor=fn2 class=footnote-link><sup>2</sup></a> used to train each of the dirt and rain models.<div class=section_2 id=sec3a><h3>3.1. Dirt</h3><p>To train our network to remove dirt noise, we generated clean/noisy image pairs by synthesizing dirt on images. Similarly to <a ref-type=bibr anchor=ref9 id=context_ref_9_3a>[9]</a>, we also found that dirt noise was well-modeled by an opacity mask and additive component, which we extract from real dirt-on-glass panes in a lab setup. Once we have the masks, we generate noisy images according to
<disp-formula class=display-formula><tex-math notation=TeX><span class=MathJax_Preview>I^{\prime}=p\alpha D+(1-\alpha)I</span></tex-math></disp-formula><div class="MathJax_Display MathJax_Processing sf-hidden"></div><span class=formula><span class=link>View Source</span><img class="document-ft-image load-shimmer" aria-describedby=qtip-0 style=display:inline title="Right-click on figure or equation for MathML and additional features." data-hasqtip=0 alt src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-lazy=/assets/img/icon.support.gif data-alt="Right-click on figure for MathML and additional features." width=24 height=20 border=0><span class="tex tex2jax_ignore" style=display:none>I^{\prime}=p\alpha D+(1-\alpha)I</span></span><p><p>Here, <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>I</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-75-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>I^{\prime}</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-76-Frame tabindex=0></span></tex-math></inline-formula> are the original clean and generated noisy image, respectively. <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\alpha</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-77-Frame tabindex=0></span></tex-math></inline-formula> is a transparency mask the same size as the image, and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>D</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-78-Frame tabindex=0></span></tex-math></inline-formula> is the additive component of the dirt, also the same size as the image. <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-79-Frame tabindex=0></span></tex-math></inline-formula> is a random perturbation vector in RGB space, and the factors <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p\alpha D</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-80-Frame tabindex=0></span></tex-math></inline-formula> are multiplied together element-wise. <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>p</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-81-Frame tabindex=0></span></tex-math></inline-formula> is drawn from a uniform distribution over (0.9, 1.1) for each of red, green and blue, then multiplied by another random number between 0 and 1 to vary brightness. These random perturbations are necessary to capture natural variation in the corruption and make the network robust to these changes.<p>To find <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\alpha</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-82-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\alpha D</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-83-Frame tabindex=0></span></tex-math></inline-formula>, we took pictures of several slide-projected backgrounds, both with and without a dirt-on-glass pane placed in front of the camera. We then solved a linear least-squares system for <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\alpha</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-84-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\alpha D</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-85-Frame tabindex=0></span></tex-math></inline-formula> at each pixel; further details are included in the supplementary material.
<div class="figure figure-full" id=fig4><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-4-source-large.gif data-fig-id=fig4><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-4-source-small.gif data-alt="Figure 4. - Examples of clean (top row) and corrupted (bottom row) patches used for training. The dirt (left column) was added synthetically, while the rain (right column) was obtained from real image pairs."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 4. </b><fig>Examples of clean (top row) and corrupted (bottom row) patches used for training. The dirt (left column) was added synthetically, while the rain (right column) was obtained from real image pairs.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p></p></div><div class=section_2 id=sec3b><h3>3.2. Water Droplets</h3><p>Unlike the dirt, water droplets refract light around them and are not well described by a simple additive model. We considered using the more sophisticated rendering model of <a ref-type=bibr anchor=ref8 id=context_ref_8_3b>[8]</a>, but accurately simulating outdoor illumination made this inviable. Thus, instead of synthesizing the effects of water, we built a training set by taking photographs of multiple scenes with and without the corruption present. For corrupt images, we simulated the effect of rain on a window by spraying water on a pane of anti-reflective MgF<sub>2</sub>-coated glass, taking care to produce drops that closely resemble real rain. To limit motion differences between clean and rainy shots, all scenes contained only static objects. Further details are provided in the supplementary material.</p></div></div>
<div class=section id=sec4><div class="header article-hdr"><div class=kicker>
 SECTION 4.</div><h2>Baseline Methods</h2></div><p>We compare our convolutional network against a non-convolutional patch-level network similar to <a ref-type=bibr anchor=ref2 id=context_ref_2_4>[2]</a>, as well as three baseline approaches: median filtering, bilateral filtering <a ref-type=bibr anchor=ref18 id=context_ref_18_4>[18]</a>, <a ref-type=bibr anchor=ref15 id=context_ref_15_4>[15]</a>, and BM3D <a ref-type=bibr anchor=ref3 id=context_ref_3_4>[3]</a>. In each case, we tuned the algorithm parameters to yield the best qualitative performance in terms of visibly reducing noise while keeping clean parts of the image intact. On the dirt images, we used an <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>8\times 8</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-86-Frame tabindex=0></span></tex-math></inline-formula> window for the median filter, parameters <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma_{s}=3</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-87-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma_{r}=0.3</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-88-Frame tabindex=0></span></tex-math></inline-formula> for the bilateral filter, and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma=0.15</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-89-Frame tabindex=0></span></tex-math></inline-formula> for BM3D. For the rain images, we used similar parameters, but adjusted for the fact that the images were downsampled by half: <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>5\times 5</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-90-Frame tabindex=0></span></tex-math></inline-formula> for the median filter, <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma_{s}=2</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-91-Frame tabindex=0></span></tex-math></inline-formula> and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma_{r}=0.3</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-92-Frame tabindex=0></span></tex-math></inline-formula> for the bilateral filter, and <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>\sigma=0.15</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-93-Frame tabindex=0></span></tex-math></inline-formula> for BM3D.
<div class="figure figure-full" id=fig5><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-5-source-large.gif data-fig-id=fig5><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-5-source-small.gif data-alt="Figure 5. - Example image containing dirt, and the restoration produced by our network. Note the detail preserved in high-frequency areas like the branches. The nonconvolutional network leaves behind much of the noise, while the median filter causes substantial blurring."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 5. </b><fig>Example image containing dirt, and the restoration produced by our network. Note the detail preserved in high-frequency areas like the branches. The nonconvolutional network leaves behind much of the noise, while the median filter causes substantial blurring.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p></p></div>
<div class=section id=sec5><div class="header article-hdr"><div class=kicker>
 SECTION 5.</div><h2>Experiments</h2></div><div class=section_2 id=sec5a><h3>5.1. Dirt</h3><p>We tested dirt removal by running our network on pictures of various scenes taken behind dirt-on-glass panes. Both the scenes and glass panes were not present in the training set, ensuring that the network did not simply memorize and match exact patterns. We tested restoration of both real and synthetic corruption. Although the training set was composed entirely of synthetic dirt, it was representative enough for the network to perform well in both cases.<p>The network was trained using 5.8 million examples of <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>64\times 64</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-94-Frame tabindex=0></span></tex-math></inline-formula> image patches with synthetic dirt, paired with ground truth clean patches. We trained only on examples where the variance of the clean <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>64\times 64</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-95-Frame tabindex=0></span></tex-math></inline-formula> patch was at least 0.001, and also required that at least 1 pixel in the patch had a dirt -mask value of at least 0.03. To compare to <a ref-type=bibr anchor=ref2 id=context_ref_2_5a>[2]</a>, we trained a non-convolutional patch-based network with patch sizes corresponding to our convolution kernel sizes, using 20 million <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>16\times 16</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-96-Frame tabindex=0></span></tex-math></inline-formula> patches.<div class=section_2 id=sec5a1><h4>5.1.1 Synthetic Dirt Results</h4><p>We first measure quantitative performance using synthetic dirt. The results are shown in <a ref-type=table anchor=table1 class=fulltext-link>Table 1</a>. Here, we generated test examples using images and dirt masks held out from the training set, using the process described in <a ref-type=sec anchor=sec3a class=fulltext-link>Section 3.1</a>. Our convolutional network substantially outperforms its patch-based counterpart. Both neural networks are much better than the three baselines, which do not make use of the structure in the corruption that the networks learn.
<div class="figure figure-full table" id=table1><div class=figcaption><b class=title>Table 1. </b>PSNR for our convolutional neural network, nonconvolutional patch-based network, and baselines on a synthetically generated test set of 16 images (8 scenes with 2 different dirt masks). Our approach significantly outperforms the other methods.</div><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-table-1-source-large.gif><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-table-1-source-small.gif data-alt="Table 1.- PSNR for our convolutional neural network, nonconvolutional patch-based network, and baselines on a synthetically generated test set of 16 images (8 scenes with 2 different dirt masks). Our approach significantly outperforms the other methods."><div class=zoom title="View Larger Image"></div></a></div></div><p><p>We also applied our network to two types of artificial noise absent from the training set: synthetic snow made from small white line segments, and scratches of random cubic splines. An example region is shown in <a ref-type=fig anchor=fig6 class=fulltext-link>Fig. 6</a>. In contrast to the gain of +6.50 dB for dirt, the network leaves these corruptions largely intact, producing near-zero PSNR gains of 0.10 and +0.30 dB, respectively, over the same set of images. This demonstrates that the network learns to remove dirt specifically.</p></div><div class=section_2 id=sec5a2><h4>5.1.2 Dirt Results</h4><p><a ref-type=fig anchor=fig5 class=fulltext-link>Fig. 5</a> shows a real test image along with our output and the output of the patch-based network and median filter. Because of illumination changes and movement in the scenes, we were not able to capture ground truth images for quantitative evaluation. Our method is able to remove most of the corruption while retaining details in the image, particularly around the branches and shutters. The non-convolutional network leaves many pieces of dirt behind, while the median filter loses much detail present in the original. Note also that the neural networks leave already-clean parts of the image mostly untouched.
<div class="figure figure-full" id=fig6><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-6-source-large.gif data-fig-id=fig6><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-6-source-small.gif data-alt="Figure 6. - Our dirt-removal network applied to an image with (a) no corruption, (b) synthetic dirt, (c) artificial snow and (d) random scratches. Because the network was trained to remove dirt, it successfully restores (b) while leaving the corruptions in (c,d) largely untouched. Top: Original images. Bottom: Output."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 6. </b><fig>Our dirt-removal network applied to an image with (a) no corruption, (b) synthetic dirt, (c) artificial snow and (d) random scratches. Because the network was trained to remove dirt, it successfully restores (b) while leaving the corruptions in (c,d) largely untouched. Top: Original images. Bottom: Output.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p><p>Two common causes of failure of our model are large corruption, and very oddly-shaped or unusually colored corruption. Our <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>16\times 16</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-97-Frame tabindex=0></span></tex-math></inline-formula> input kernel support limits the size of corruption recognizable by the system, leading to the former. The latter is caused by a lack of generalization: although we trained the network to be robust to shape and color by supplying it a range of variations, it will not recognize cases too far from those seen in training. Another interesting failure of our method appears in the bright orange cones in <a ref-type=fig anchor=fig5 class=fulltext-link>Fig. 5</a>, which our method reduces in intensity  this is due to the fact that the training dataset did not contain any examples of such fluorescent objects. More examples are provided in the supplementary material.</p></div></div><div class=section_2 id=sec5b><h3>5.2. Rain</h3><p>We ran the rain removal network on two sets of test data: (<i>i</i>) pictures of scenes taken through a pane of glass on which we sprayed water to simulate rain, and (<i>ii</i>) pictures of scenes taken while it was actually raining, from behind an initially clean glass pane. Both sets were composed of real-world outdoor scenes not in the training set.<p>We trained the network using 6.5 million examples of <inline-formula><tex-math notation=TeX><span class=MathJax_Preview>64\times 64</span><span class="MathJax MathJax_Processing sf-hidden" id=MathJax-Element-98-Frame tabindex=0></span></tex-math></inline-formula> image patch pairs, captured as described in <a ref-type=sec anchor=sec3b class=fulltext-link>Section 3.2</a>. Similarly to the dirt case, we used a variance threshold of 0.001 on the clean images and required each training pair to have at least 1 pixel difference over 0.1.<div class=section_2 id=sec5b1><h4>5.2.1 Water Droplets Results</h4><p>Examples of our network removing sprayed-on water is shown in <a ref-type=fig anchor=fig7 class=fulltext-link>Fig. 7</a>. As was the case for the dirt images, we were not able to capture accurate ground truth due to illumination changes and subject motion. Since we also do not have synthetic water examples, we analyze our method in this mode only qualitatively.
<div class="figure figure-full" id=fig7><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-7-source-large.gif data-fig-id=fig7><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-7-source-small.gif data-alt="Figure 7. - Our network removes most of the water while retaining image details; the non-convolutional network leaves more droplets behind, particularly in the top image, and blurs the subject's fingers in the bottom image. The median filter blurs many details, but still cannot remove much of the noise"><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 7. </b><fig>Our network removes most of the water while retaining image details; the non-convolutional network leaves more droplets behind, particularly in the top image, and blurs the subject's fingers in the bottom image. The median filter blurs many details, but still cannot remove much of the noise</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div>
<div class="figure figure-full" id=fig8><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-8-source-large.gif data-fig-id=fig8><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-8-source-small.gif data-alt="Figure 8. - Shot from the rain video sequence (see supplementary video), along with the output of our network. Note each frame is processed independently, without using any temporal information or background subtraction."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 8. </b><fig>Shot from the rain video sequence (see supplementary video), along with the output of our network. Note each frame is processed independently, without using any temporal information or background subtraction.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p><p>As before, our network is able to remove most of the water droplets, while preserving finer details and edges reasonably well. The non-convolutional network leaves behind additional droplets, e.g. by the subject's face in the top image; it performs somewhat better in the bottom image, but blurs the subject's hand. The median filter must blur the image substantially before visibly reducing the corruption. However, the neural networks mistake the boltheads on the bench for raindrops, and remove them.<p>Despite the fact that our network was trained on static scenes to limit object motion between clean/noisy pairs, it still preserves animate parts of the images well: The face and body of the subject are reproduced with few visible artifacts, as are grass, leaves and branches (which move from wind). Thus the network can be applied to many scenes substantially different from those seen in training.</p></div><div class=section_2 id=sec5b2><h4>5.2.2 Real Rain Results</h4><p>A picture taken using actual rain is shown in <a ref-type=fig anchor=fig8 class=fulltext-link>Fig. 8</a>. We include more pictures of this time series as well as a video in the supplementary material. Each frame of the video was presented to our algorithm independently; no temporal filtering was used. To capture the sequence, we set a clean glass pane on a tripod and allowed rain to fall onto it, taking pictures at 20s intervals. The camera was placed 0.5m behind the glass, and was focused on the scene behind.<p>Even though our network was trained using sprayed-on water, it was still able to remove much of the actual rain. The largest failures appear towards the end of the sequence, when the rain on the glass is very heavy and starts to agglomerate, forming droplets larger than our network can handle. Although this is a limitation of the current approach, we hope to address such cases in future work.<p>Lastly, in addition to pictures captured with a DSLR, in <a ref-type=fig anchor=fig9 class=fulltext-link>Fig. 9</a> we apply our network to a picture taken using a smart-phone on a train. While the scene and reflections are preserved, raindrops on the window are removed, though a few small artifacts do remain. This demonstrates that our model is able to restore images taken by a variety of camera types.</p></div></div></div>
<div class=section id=sec6><div class="header article-hdr"><div class=kicker>
 SECTION 6.</div><h2>Summary</h2></div><p>We have introduced a method for removing rain or dirt artifacts from a single image. Although the problem appears underconstrained, the artifacts have a distinctive appearance which we are able to learn with a specialized convolutional network and a carefully constructed training set. Results on real test examples show most artifacts being removed without undue loss of detail, unlike existing approaches such as median or bilateral filtering. Using a convolutional network accounts for the error in the final image prediction, providing a significant performance gain over the corresponding patch-based network.<p>The quality of the results does however depend on the statistics of test cases being similar to those of the training set. In cases where this does not hold, we see significant artifacts in the output. This can be alleviated by expanding the diversity and size of the training set. A second issue is that the corruption cannot be much larger than the training patches. This means the input image may need to be down-sampled, e.g. as in the rain application, leading to a loss of resolution relative to the original.<p>Although we have only considered day-time outdoor shots, the approach could be extended to other settings such as indoor or night-time, given suitable training data. It could also be extended to other problem domains such as scratch removal or color shift correction.<p>Our algorithm provides the underlying technology for a number of potential applications such as a digital car windshield to aid driving in adverse weather conditions, or enhancement of footage from security or automotive cameras in exposed locations. These would require real-time performance not obtained by our current implementation. High-performance low-power neural network implementations such as the NeuFlow FPGA/ASIC <a ref-type=bibr anchor=ref6 id=context_ref_6_6>[6]</a> would make real-time embedded applications of our system feasible.
<div class="figure figure-full" id=fig9><div class=img-wrap><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-9-source-large.gif data-fig-id=fig9><img class="document-ft-image load-shimmer" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt data-lazy=/mediastore_new/IEEE/content/media/6750807/6751100/6751188/6751188-fig-9-source-small.gif data-alt="Figure 9. - Top: Smartphone shot through a rainy window on a train. Bottom: Output of our algorithm."><div class=zoom title="View Larger Image"></div></a></div><div class=figcaption><b class=title>Figure 9. </b><fig>Top: Smartphone shot through a rainy window on a train. Bottom: Output of our algorithm.</fig></div><p class=links><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/6751188/all-figures class=all>Show All</a></p></div><p></p></div>
<h3>ACKNOWLEDGEMENTS</h3><p>The authors would like to thank Ross Fadeley and Dan Foreman-Mackay for their help modeling, as well as David W. Hogg and Yann LeCun for their insight and suggestions. Financial support for this project was provided by Microsoft Research and NSF IIS 1124794 &amp; IIS 1116923.</p></div></div>
</div><xpl-reference-pop-up _ngcontent-xhp-c158 _nghost-xhp-c149></xpl-reference-pop-up><span _ngcontent-xhp-c158 id=full-text-footer></span></div></div><div _ngcontent-xhp-c158 class="col-3-24 u-pr-1 u-pl-1 col-buttons stats-document-container-rh u-printing-invisible-ie u-printing-invisible-ff"><xpl-document-buttons _ngcontent-xhp-c158 _nghost-xhp-c157><div _ngcontent-xhp-c157 xplscrollsnapmigr cssclasstostick=document-side-menu-stick fromelementid=toc-wrapper tillelementid=full-text-footer offsetfrom=150 offsetto=-800 scrollreset=true id=scroll-snap-buttons-container class="document-doc-buttons stats-document-container-buttons"><ul _ngcontent-xhp-c157 class=tools><li _ngcontent-xhp-c157 id=search-popover xplpopoveranimateonscroll animateelementidposition=1 animatecontainerelementid=search-popover class="blue-tooltip increased-width special-left-tooltip"><a _ngcontent-xhp-c157 triggers=click placement=left><i _ngcontent-xhp-c157 class="fas fa-search icon-size-md color-gray-dark"></i></a><li _ngcontent-xhp-c157 id=resizer-popover xplpopoveranimateonscroll animateelementidposition=1 animatecontainerelementid=resizer-popover class="blue-tooltip special-left-tooltip"><a _ngcontent-xhp-c157 min-size=10 max-size=20 placement=left triggers=click><i _ngcontent-xhp-c157 class="far fa-text-size icon-size-md color-gray-dark"></i></a></ul><xpl-back-to-top-button _ngcontent-xhp-c157 section=full-text-header _nghost-xhp-c82><ul _ngcontent-xhp-c82 class="back-to-top sf-hidden"></ul></xpl-back-to-top-button></div></xpl-document-buttons></div></div></section></xpl-document-full-text><xpl-accordian-section _ngcontent-xhp-c191 _nghost-xhp-c183><div _ngcontent-xhp-c183 role=tablist class="document-accordion-section-container hide-mobile"><xpl-document-accordion _ngcontent-xhp-c183 class=accordion-panel-container _nghost-xhp-c163><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=authors-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=authors class="accordion-link text-base-md-lh">Authors</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=figures-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=figures class="accordion-link text-base-md-lh">Figures</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=references-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=references class="accordion-link text-base-md-lh">References</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=citations-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=citations class="accordion-link text-base-md-lh">Citations</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=keywords-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=keywords class="accordion-link text-base-md-lh">Keywords</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=metrics-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=metrics class="accordion-link text-base-md-lh">Metrics</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=media-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=media class="accordion-link text-base-md-lh">Media</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div><div _ngcontent-xhp-c163><div _ngcontent-xhp-c163 role=tab class="accordion-header accordion-button" id=footnotes-header aria-expanded=false aria-disabled=false><a _ngcontent-xhp-c183 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/ id=footnotes class="accordion-link text-base-md-lh">Footnotes</a><div _ngcontent-xhp-c163 class=accordion-chevron><i _ngcontent-xhp-c163 class="fa fa-angle-down"></i></div></div></div></xpl-document-accordion></div></xpl-accordian-section></div></section></div><div _ngcontent-xhp-c191 class="document-disqus-container col-24-24"><div _ngcontent-xhp-c191 class=row></div></div></div></div><div _ngcontent-xhp-c191 class="document-sidebar global-right-rail top-spacing"><div _ngcontent-xhp-c191 class=header-rel-art-toggle-mobile><i _ngcontent-xhp-c191 class=header-rel-art-toggle-icon></i></div><div _ngcontent-xhp-c191 class=document-sidebar-content><div _ngcontent-xhp-c191 class="document-sidebar-serp-nav hide-mobile"><span _ngcontent-xhp-c191> &nbsp;<a _ngcontent-xhp-c191 target=_self href="https://ieeexplore-ieee-org.thi.idm.oclc.org/search/searchresult.jsp?contentType=all&amp;queryText=6751188">&nbsp;Back to Results&nbsp;</a>&nbsp; </span></div><div _ngcontent-xhp-c191 class=hide-mobile><xpl-leaderboard-ad _ngcontent-xhp-c191 _nghost-xhp-c124><div _ngcontent-xhp-c124 class="Ads-leaderboard ad-panel"><div _ngcontent-xhp-c124 class="row u-flex-wrap-nowrap"></div><div _ngcontent-xhp-c124 class=ad-leaderboard-ad-container><div _ngcontent-xhp-c124 xplgoogleadmigr><div id=div-gpt-ad-1606861783116-0 style="width:300px;height:250px;display:none;margin:0px auto"></div></div></div></div></xpl-leaderboard-ad></div><div _ngcontent-xhp-c191 class=document-sidebar-rel-art><xpl-related-article-list _ngcontent-xhp-c191 _nghost-xhp-c189><div _ngcontent-xhp-c189 class=stats-document-header-relatedArticles><div _ngcontent-xhp-c189 class=header-rel-art><div _ngcontent-xhp-c189 class="header-rel-art-title text-base-md-lh"> More Like This </div><div _ngcontent-xhp-c189 class=header-rel-art-list><div _ngcontent-xhp-c189 class=header-rel-art-item><div _ngcontent-xhp-c189 class="row text-base-md-lh"><a _ngcontent-xhp-c189 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/8964437/><span _ngcontent-xhp-c189>Residual Dense Network for Image Restoration</span></a></div><p _ngcontent-xhp-c189 class="header-rel-art-pub text-sm-md-lh">IEEE Transactions on Pattern Analysis and Machine Intelligence<p _ngcontent-xhp-c189 class="header-rel-art-pub text-sm-md-lh">Published: 2021</p></div><div _ngcontent-xhp-c189 class=header-rel-art-item><div _ngcontent-xhp-c189 class="row text-base-md-lh"><a _ngcontent-xhp-c189 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/1621238/><span _ngcontent-xhp-c189>PDE-based image restoration: a hybrid model and color image denoising</span></a></div><p _ngcontent-xhp-c189 class="header-rel-art-pub text-sm-md-lh">IEEE Transactions on Image Processing<p _ngcontent-xhp-c189 class="header-rel-art-pub text-sm-md-lh">Published: 2006</p></div></div><div _ngcontent-xhp-c189 class="header-rel-art-action text-base-md-lh"><a _ngcontent-xhp-c189 href=https://ieeexplore-ieee-org.thi.idm.oclc.org/document/>Show More</a></div></div></div></xpl-related-article-list></div><div _ngcontent-xhp-c191 class=hide-mobile><xpl-leaderboard-middle-ad _ngcontent-xhp-c191 _nghost-xhp-c187><div _ngcontent-xhp-c187 class="Ads-leaderboard ad-panel"><div _ngcontent-xhp-c187 class="row u-flex-wrap-nowrap"></div><div _ngcontent-xhp-c187 class=ad-leaderboard-ad-container><div _ngcontent-xhp-c187 xplgoogleadmigr><div id=div-gpt-ad-1606861708157-0 style="width:300px;height:600px;display:none;margin:0px auto"></div></div></div></div></xpl-leaderboard-middle-ad></div></div></div><xpl-reference-panel _ngcontent-xhp-c191 _nghost-xhp-c190><section _ngcontent-xhp-c190 id=references-anchor class="document-all-references hide-mobile panel-closed"><div _ngcontent-xhp-c190 class=header><h1 _ngcontent-xhp-c190>References</h1><a _ngcontent-xhp-c190><i _ngcontent-xhp-c190 class="fas fa-times"></i></a></div><div _ngcontent-xhp-c190 id=references-section-container class=document-ft-section-container><div _ngcontent-xhp-c190><b _ngcontent-xhp-c190>References is not available for this document.</b></div></div></section></xpl-reference-panel></div></xpl-document-details></div><xpl-footer _ngcontent-xhp-c451 _nghost-xhp-c450><footer _ngcontent-xhp-c450 id=xplore-footer class="stats-footer footer-new"><div _ngcontent-xhp-c450 class=footer-wrapper><div _ngcontent-xhp-c450 class=flexible-row-col><div _ngcontent-xhp-c450 class=footer-col><h3 _ngcontent-xhp-c450 class=text-base-md-lh>IEEE Personal Account</h3><ul _ngcontent-xhp-c450 class=text-sm-md-lh><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://www.ieee.org/profile/changeusrpwd/showChangeUsrPwdPage.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Change username/password</a></ul></div><div _ngcontent-xhp-c450 class=footer-col><h3 _ngcontent-xhp-c450 class=text-base-md-lh>Purchase Details</h3><ul _ngcontent-xhp-c450 class=text-sm-md-lh><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://www.ieee.org/profile/payment/showPaymentHome.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Payment Options</a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href=https://ieeexplore-ieee-org.thi.idm.oclc.org/articleSale/purchaseHistory.jsp>View Purchased Documents</a></ul></div><div _ngcontent-xhp-c450 class=footer-col><h3 _ngcontent-xhp-c450 class=text-base-md-lh>Profile Information</h3><ul _ngcontent-xhp-c450 class=text-sm-md-lh><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://www.ieee.org/ieee-privacyportal/app/ibp?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Communications Preferences</a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://www.ieee.org/profile/profedu/getProfEduInformation.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Profession and Education</a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://www.ieee.org/profile/tips/getTipsInfo.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Technical interests</a></ul></div><div _ngcontent-xhp-c450 class="footer-col need-help"><h3 _ngcontent-xhp-c450 class=text-base-md-lh>Need Help?</h3><ul _ngcontent-xhp-c450 class=text-sm-md-lh><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 href=tel:+1-800-678-4333> US &amp; Canada: +1 800 678 4333 </a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 href=tel:+1-732-981-0060> Worldwide: +1 732 981 0060 </a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/contact> Contact &amp; Support </a></ul></div><div _ngcontent-xhp-c450 class="footer-col follow"><h3 _ngcontent-xhp-c450 class=text-base-md-lh>Follow</h3><ul _ngcontent-xhp-c450 class=icon-size-md><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href=https://www.facebook.com/IEEEXploreDigitalLibrary/><i _ngcontent-xhp-c450 aria-hidden=true class="fab fa-facebook-f"></i></a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href=https://www.linkedin.com/showcase/ieee-xplore><i _ngcontent-xhp-c450 aria-hidden=true class="fab fa-linkedin-in"></i></a><li _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_blank href="https://twitter.com/IEEEXplore?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor"><i _ngcontent-xhp-c450 aria-hidden=true class="fab fa-twitter"></i></a></ul></div></div><div _ngcontent-xhp-c450 class=footer-bottom-section><p _ngcontent-xhp-c450 class=text-sm-md-lh><span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/about-ieee-xplore.html>About IEEE <em _ngcontent-xhp-c450>Xplore</em></a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/contact>Contact Us</a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/Help_start.html>Help</a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/accessibility-statement.html>Accessibility</a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/Help_Terms_of_Use.html>Terms of Use</a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=http://www.ieee.org/web/aboutus/whatis/policies/p9-26.html>Nondiscrimination Policy</a></span> | <span _ngcontent-xhp-c450 class=ethics-reporting-link><a _ngcontent-xhp-c450 target=_blank href=http://www.ieee-ethics-reporting.org/>IEEE Ethics Reporting<i _ngcontent-xhp-c450 class="fa fa-external-link-alt"></i></a></span> | <span _ngcontent-xhp-c450><a _ngcontent-xhp-c450 target=_self href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/overview-of-ieee-xplore/ieee-xplore-sitemap>Sitemap</a></span> | <span _ngcontent-xhp-c450 class=nowrap><a _ngcontent-xhp-c450 target=_self href=http://www.ieee.org/about/help/security_privacy.html>Privacy &amp; Opting Out of Cookies</a></span><p _ngcontent-xhp-c450> A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. <p _ngcontent-xhp-c450>  Copyright 2022 IEEE - All rights reserved. </p></div></div></footer></xpl-footer></xpl-root>
 </div>
 
 
 
</div>
 
<section id=xploreFooter class=hide-desktop>
 
 <div class="Footer stats-footer hide-mobile">
 <div class="pure-g Footer-sections">
 <div class=pure-u-1-4>
 <h3 class=Footer-header>IEEE Account</h3>
 <ul class=Footer-list>
 <li><a href="https://www.ieee.org/profile/changeusrpwd/showChangeUsrPwdPage.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Change Username/Password</a></li>
 <li><a href="https://www.ieee.org/profile/address/getAddrInfoPage.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Update Address</a></li>
 </ul>
 </div>
 <div class=pure-u-1-4>
 <h3 class=Footer-header>Purchase Details</h3>
 <ul class=Footer-list>
 <li><a href="https://www.ieee.org/profile/payment/showPaymentHome.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Payment Options</a></li>
 <li><a href="https://www.ieee.org/profile/vieworder/showOrderHistory.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Order History</a></li>
 <li><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/articleSale/purchaseHistory.jsp>View Purchased Documents</a></li>
 </ul>
 </div>
 <div class=pure-u-1-4>
 <h3 class=Footer-header>Profile Information</h3>
 <ul class=Footer-list>
 <li><a href="https://www.ieee.org/ieee-privacyportal/app/ibp?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Communications Preferences</a></li>
 <li><a href="https://www.ieee.org/profile/profedu/getProfEduInformation.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Profession and Education</a></li>
 <li><a href="https://www.ieee.org/profile/tips/getTipsInfo.html?refSite=http://ieeexplore.ieee.org.thi.idm.oclc.org&amp;refSiteName=IEEE%20Xplore">Technical Interests</a></li>
 </ul>
 </div>
 <div class=pure-u-1-4>
 <h3 class=Footer-header>Need Help?</h3>
 <ul class=Footer-list>
 <li><strong>US &amp; Canada:</strong> +1 800 678 4333</li>
 <li><strong>Worldwide: </strong> +1 732 981 0060<br>
 </li>
 <li><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/contact>Contact &amp; Support</a></li>
 </ul>
 </div>
 </div>
 <div class=row>
 <div class="col-12 Footer-bottom">
 <div class="Footer-bottom-inner-div row">
 <div class=col>
 <ul class="Menu Menu--horizontal Menu--dividers u-mb-1">
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/about-ieee-xplore.html>About IEEE <em>Xplore</em></a></li>
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/contact>Contact Us</a></li>
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/Help_start.html target=blank>Help</a></li>
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/accessibility-statement.html target=blank>Accessibility</a></li> 
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/Xplorehelp/Help_Terms_of_Use.html target=_blank>Terms of Use</a></li>
 <li class=Menu-item><a href=http://www.ieee.org/web/aboutus/whatis/policies/p9-26.html>Nondiscrimination Policy</a></li>
 <li class=Menu-item><a href=https://ieeexplore-ieee-org.thi.idm.oclc.org/xpl/sitemap.jsp>Sitemap</a></li>
 <li class=Menu-item><a href=http://www.ieee.org/about/help/security_privacy.html target=blank>Privacy &amp; Opting Out of Cookies</a></li>
 </ul>
 <p class=Footer-bottom-terms>
 A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.<br> Copyright 2022 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.
 </p>
 </div>
 <div><i class=logo-ieee-white></i></div>
 </div>
 
 </div>
 </div>
 </div>
 
 
</section>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
<style>--></style>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
<div style=width:1263px id=popup_overlay></div>
<g:compress>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
</g:compress>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </div>
 </div>
 </div>
 
 
 
 </div>
 
<div id=cboxOverlay style=display:none></div><div id=colorbox role=dialog tabindex=-1 style=display:none></div><div class=usabilla_live_button_container id=usabilla_live_button_container_798027181 role=button tabindex=0 aria-label="Usabilla Feedback Button"><style nonce=e9930a118e08 class=sf-hidden>div.usabilla_live_button_container#usabilla_live_button_container_798027181[role="button"]{width:125px;height:50px;position:fixed;z-index:999;bottom:0;left:95%;margin-left:-62.5px}</style></div><div style="position:absolute;width:0px;height:0px;overflow:hidden;padding:0px;border:0px none;margin:0px"><div id=MathJax_Font_Test style="position:absolute;visibility:hidden;top:0px;left:0px;width:auto;min-width:0px;max-width:none;padding:0px;border:0px none;margin:0px;white-space:nowrap;text-align:left;text-indent:0px;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;font-size:40px;font-weight:normal;font-style:normal;font-size-adjust:none;font-family:MathJax_Main,sans-serif" class=sf-hidden></div></div>