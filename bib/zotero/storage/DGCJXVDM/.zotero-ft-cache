IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Typesetting math: 32%

Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

    Cart 
    Create Account
    Personal Sign In

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
Access provided by:
Technische Hochschule Ingolstadt
Sign Out
ADVANCED SEARCH
Journals & Magazines > IEEE Robotics and Automation ... > Volume: 2 Issue: 2
Estimation, Control, and Planning for Aggressive Flight With a Small Quadrotor With a Single Camera and IMU
Publisher: IEEE
Cite This
PDF
  << Results   
Giuseppe Loianno ; Chris Brunner ; Gary McGrath ; Vijay Kumar
All Authors
View Document
155
Paper
Citations
6231
Full
Text Views

    Alerts
    Alerts
    Manage Content Alerts
    Add to Citation Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    System Overview
    III.
    Modeling and Control
    IV.
    State Estimation
    V.
    Planning for Aggressive Maneuvers

Show Full Outline
Authors
Figures
References
Citations
Keywords
Metrics
Media
More Like This
Footnotes

    Download PDF
    View References
    Request Permissions
    Save to
    Alerts 

Abstract: We address the state estimation, control, and planning for aggressive flight with a 150 cm diameter, 250 g quadrotor equipped only with a single camera and an inertial me... View more
Metadata
Abstract:
We address the state estimation, control, and planning for aggressive flight with a 150 cm diameter, 250 g quadrotor equipped only with a single camera and an inertial measurement unit (IMU). The use of smartphone grade hardware and the small scale provides an inexpensive and practical solution for autonomous flight in indoor environments. The key contributions of this paper are: 1) robust state estimation and control using only a monocular camera and an IMU at speeds of 4.5 m/s, accelerations of over 1.5 g, roll and pitch angles of up to 90°, and angular rate of up to 800°/s without requiring any structure in the environment; 2) planning of dynamically feasible three-dimensional trajectories for slalom paths and flights through narrow windows; and 3) extensive experimental results showing aggressive flights through and around obstacles with large rotation angular excursions and accelerations.
Published in: IEEE Robotics and Automation Letters ( Volume: 2 , Issue: 2 , April 2017 )
Page(s): 404 - 411
Date of Publication: 29 November 2016
ISSN Information:
INSPEC Accession Number: 16561034
DOI: 10.1109/LRA.2016.2633290
Publisher: IEEE
Funding Agency:
Contents
SECTION I.
Introduction

Micro Aerial Vehicles (MAVs) equipped with on-board sensors, are ideal platforms for autonomous navigation in complex and confined environments for solving tasks such as exploration  [1] , inspection  [2] , [3] , mapping  [4] , interaction with the environment  [5] , [6] and, search and rescue  [7] .

In this work, we analyze the problem of aggressive maneuvers with a small and lightweight quadrotor platform using on-board sensing capabilites such as a single camera and IMU. Aggressive and fast maneuvers have always been considered an active research area from a control and estimation perspectives due to the extreme flight conditions, an underactuated system as a quadrotor, is subjected to. The ability to fly fast and maneuver aggressively is useful in tasks with time constraints and in search and rescue applications. A number of groups have demonstrated aggressive maneuvers with aerial vehicles such as quadrotors  [8] – [10] . These works mostly show strategies for generating sequences of controllers that stabilize the robot to a desired state. In  [9] , the authors focus on the hovering stabilization problem after a flip maneuver, whereas  [8] , [10] address the learning and adaptive iteration of the control law, which is refined based on different flight trials. Excellent results, showing aggressive maeuvers with a quadrotor have been obtained in  [11] . Compared to previous works, the main difference is in the use of the property of differential flatness and the development of an efficient planning algorithm to generate trajectories for a quadrotor without the limitation to first order dynamics. The aggressive motion task is solved via the composition of three control modes. The main drawbacks of this approach are the use of a motion capture systems for localization and linearized controllers.

In this work, we solve the aggressive maneuvering task using only on-board sensing capabilities. The minimal sensor suite for autonomous localization consists of two inexpensive, lightweight and widely available sensors, a monocular camera and an IMU as shown in  [12] – [15] . The observability analysis applied to aerial navigation is discussed in  [16] , [17] . Relevant to this work, are also results focusing on vision-based fast navigation with MAVs. In  [18] , a quadrotor equipped with a stereo camera and IMU is able to fly at 4 m/s, whereas in  [19] , a smartphone is able to provide the necessary computation capabilities to fly up to 3 m/s using the single camera and IMU available on the device. The setup in  [18] leverages a stereo camera configuration, which facilitates the handling of the scaling problems that arise with monocular camera systems. In  [20] the authors focus on the 6-DOF pose tracking with a DVS camera. This method works only with planar shapes or gradient maps that are known a priori. In addition, the estimated pose is not used for closed loop control. Instead an external motion capture system is used. Finally, in  [21] an approach for automatically recover from any unknown initial attitude is proposed. However, the system employs a downward pointing laser for scale estimation and only focuses on the specific maneuver for recovery.

In this paper, we address the perception, control and planning problems to enable autonomous aggressive maneuver with small scale, low power and lightweight quadrotor with limited computational capabilities. Our platform of choice is a 0.15 m diameter, 250 g quadrotor using Qualcomm Snapdragon TM Flight TM (see Fig. 1 ). To validate the proposed strategy, we focus on aggressive flights with large operating envelope and with significant excursions in roll and pitch angles such as flights through narrow window gaps with different orientations as shown in Fig. 2 . Compared to previous approaches, our solution relies on a nonlinear controller and on on-board capabilities without requiring the need of external motion capture systems. Moreover, we do not rely on switching and learning strategies, but we propose a deterministic trajectory planning approach to generate aggressive maneuvers with a small quadrotor. These motions require fast and large rotations and accelerations. Finally, in all previous works medium size quadrotor, weighing more than 500 g, are used. We believe this is the smallest, fully autonomous flying robot in which all sensing and computing is done on-board without GPS.
Fig. 1.

A 250 gram quadrotor equipped with a single downward-facing camera, a forward-facing stereo camera (not used in this paper), an IMU, and a Qualcomm Snapdragon TM and Hexagon TM DSP.

Show All
Fig. 2.

The platform traversing a vertical narrow window gap.

Show All

This work presents multiple contributions. First, we develop the control, estimation pipelines to enable vision-based aggressive maneuvers with a single camera and IMU. Second, we show how to generate dynamically feasible trajectories enabling flights through and around obstacles in constrained trajectories without the need to switch between different control modes. Finally, this is the first time that perception, planning and control are combined for autonomous navigation and aggressive maneuvers of a small lightweight aerial vehicle without relying on GPS and on any external motion capture system, but just using on-board computation. The proposed operating conditions require perception, state estimation, environment reconstruction, obstacle avoidance and trajectory planning algorithms with large accelerations and rotations over short ranges and time scales. Thus, the perception, planning and control subproblems have to be solved concurrently as a single problem. Our solution enables vision-based closed loop control flights with roll and pitch angular values up to 90 ∘ without using surfaces with special texture.

The paper is organized as follows. Section II shows a general overview of our framework. In Section III , the dynamics of the quadrotor and the control framework are provided, whereas in Section IV , the strategy to obtain the pose of the vehicle at high rate, enabling autonomous flight, is shown. Section V , presents our methodology to generate dynamically feasible trajectories through and around obstacles in constrained trajectories. Section VI presents extensive results on navigation with the proposed prototype. Section VII concludes the work and provides an overview of the multiple future scenarios.
SECTION II.
System Overview

Our platform of choice is a quadrotor due to its mechanical simplicity  [22] due to its ability to operate in confined spaces, hover in place and perch or land on flat surfaces.
A. Hardware Architecture

The experimental platform shown in Fig. 2 is equipped with 4 brushless motors and a Qualcomm Snapdragon TM board. This board features a Qualcomm Hexagon TM DSP, Wi-Fi, Bluetooth connectivity, 802.11n Wi-Fi, and GPS, all packed into a board ( 58 mm × 40 mm ). Based on the Snapdragon TM 801 processor, the system just uses 1 core of the total CPU. The board is equipped with a downward facing VGA camera with 160 ∘ field of view, a VGA stereo camera, and a 4 K camera.
B. Software Architecture

The software components are a position and attitude controller (see Fig. 3 ), a state estimation algorithm composed of VIO described in Section IV , which processes images at 30 Hz and an Unscented Kalman Filter (UKF) to deal with control constraints for fast motions (see green box in Fig. 3 ). The control receives the estimated pose at 500 Hz from the UKF and sends the attitude commands to the DSP. It is worth to specify that the presented approach, for state estimation employs only the downward facing camera and the IMU available on the Qualcomm Snapdragon TM Flight TM . The framework has been developed in ROS. 1 All the tasks are then executed on-board the vehicle in separate threads with state estimation and control at a fixed rate of 500 Hz.
Fig. 3.

The architecture overview.

Show All
SECTION III.
Modeling and Control

We introduce the system dynamics and the control employed to execute aggressive maneuvers.
A. Dynamic Model

Consider an inertial reference frame denoted by [ e 1 , e 2 , e 3 ] and a body reference frame centered in the center of mass of the vehicle denoted by R = [ b 1 , b 2 , b 3 ] (see Fig. 4 ) where R ∈ S O ( 3 ) . The system dynamic model is
x ˙ R ˙ = = v , m v ˙ = R τ e 3 − m g e 3 , R Ω ^ , J Ω ˙ + Ω × J Ω = M , (1)
View Source \begin{eqnarray} \dot{\boldsymbol {x}} &=& \boldsymbol {v},m\dot{\boldsymbol {v}} = \boldsymbol {R}\tau \boldsymbol {e}_3 - mg\boldsymbol {e}_3, \nonumber\\ \dot{\boldsymbol {R}}&=&\boldsymbol {R}\hat{\boldsymbol {\Omega }},\boldsymbol {J}\dot{\boldsymbol {\Omega }} + \boldsymbol {\Omega } \times \boldsymbol {J}\boldsymbol {\Omega } = \boldsymbol {M}, \end{eqnarray} where x ∈ R 3 is the Cartesian position of the vehicle expressed in the inertial frame, v ∈ R 3 is the velocity of the vehicle in the inertial frame, m ∈ R is the mass, Ω ∈ R 3 is the angular velocity and J ∈ R 3 × 3 is the inertia matrix both with respect to the body frame. The hat symbol ⋅ ^ denotes the skew-symmetry operator according to x ^ y = x × y for all x , y ∈ R 3 , g is the standard gravitational acceleration.

Fig. 4.

The quadrotor model and its reference frames.

Show All
B. Position and Attitude Controllers

In most previous works, a back-stepping approach is used for control because the attitude dynamics can be assumed to be faster than the position dynamics, and linearized controllers are used for both loops  [16] , [22] . In this work, because we need to model aggressive maneuvers and large excursions from the hover position, we use a nonlinear controller based on  [23] , [24] .

The control inputs τ , M are chosen as
M τ = = − k R e R − k Ω e Ω + Ω × J Ω − J ( Ω ^ R ⊤ R C Ω C − R ⊤ R C Ω ˙ C ) , ( − k x e x − k v e v + m g e 3 + m x ¨ d ) ⋅ R e 3 , (2)
View Source \begin{eqnarray} \boldsymbol {M}&=&-k_R\boldsymbol {e}_R-k_\Omega \boldsymbol {e}_\Omega + \boldsymbol {\Omega }\times J\boldsymbol {\Omega } \nonumber\\ &&-\,\boldsymbol {J}\left(\hat{\boldsymbol {\Omega }}\boldsymbol {R}^\top \boldsymbol {R}_C\boldsymbol {\Omega }_C-\boldsymbol {R}^\top \boldsymbol {R}_C\dot{\boldsymbol {\Omega }}_C\right), \nonumber\\ \tau &=&\left(-k_x\boldsymbol {e}_x-k_v\boldsymbol {e}_v+mg\boldsymbol {e}_3+m\ddot{\boldsymbol {x}}_d\right)\cdot \boldsymbol {R}\boldsymbol {e}_3, \end{eqnarray} with x ¨ d the desired acceleration, k x , k v , k R , k Ω positive definite terms. The subscript C denotes a commanded value. The relationship between single motor force f j , the total thrust τ and the total moment M can be inverted for non-zero values of the distance from the center of mass to the center of each rotor. Our assumption that τ and M are the inputs of the plant is therefore valid. The quantities e R , e Ω , e x , e v are the orientation, angular rate, and translation errors respectively, defined in  [19] , [23] , [24] . If the initial attitude error is between 90 ∘ and 180 ∘ , the zero equilibrium of the tracking errors is almost globally exponentially attractive  [23] .

SECTION IV.
State Estimation

In this section, we describe the different steps that enable to recover the 6-DOF (Degree Of Freedom) pose of the vehicle, necessary to control the vehicle. Our pipeline uses an EKF combining visual and IMU data (VIO block in Fig. 3 ). In this work, to enable aggressive maneuvers, we need a high level of robustness and high control rates. In addition to the EKF, an Unscented Kalman Filter (UKF) is able to estimate the full state of the vehicle at 500 Hz. We use an UKF, instead of an EKF because of the need to operate over a large envelope with significant excursions in roll and pitch angles from the hover configuration and velocities up to 5 m/s. The separation of the VIO and UKF is useful to keep the CPU usage limited. The state size of the VIO algorithm is not constant, since image features are part of it. For this reason, considering a prediction at 500 Hz is more expensive than 30 Hz. In this way, we obtain similar performances satisfying at the same time the control rate constraints. The state estimation rate (over 100 Hz) also guarantees small integration errors and thus better accuracy.
A. Visual Inertial Odometry

The VIO system localizes the rigid body with respect to the inertial frame using accelerometers, gyroscopes and camera sensors. The navigation state vector x ( t ) ∈ R 12 × s e ( 3 ) is
x = [ x ⊤ Θ ⊤ v ⊤ γ ⊤ b ⊤ g b ⊤ a ] ⊤ , (3)
View Source \begin{equation} \mathbf {x}= \left[ \begin{array}{cccccc}\boldsymbol {x}^\top & \boldsymbol {\Theta }^\top & \boldsymbol {v}^\top & \boldsymbol {\gamma }^\top & \boldsymbol {b}_g^\top & \boldsymbol {b}_a^\top \end{array} \right]^\top, \end{equation} where x ∈ R 3 , v denote the robot's position and velocity respectively as expressed in Section III-A , The term Θ is the attitude R expressed in exponential coordinates, γ is the unknown gravity vector in the inertial frame, and b a and b g denote accelerometer and gyroscope biases modeled as random walk processes. The prediction step is based on the IMU integration. The measurement update step is given by the standard 3D landmark perspective projection onto the image plane leading to the EKF updates, assuming that distinguishable features that can be tracked over time using a camera. In the past decade, camera measurements have been effectively used to aid Inertial Navigation Systems  [12] – [14] . The setup also estimates the calibration parameters, such as inertial sensor scale factor, non-orthogonality, camera-accelerometer transformation by appending them to the state. We also employ an inverse depth parametrization  [25] , which facilitates feature initialization and the convergence of the corresponding 3D point. If the stationary feature is found to be persistent, then we augment the state with the feature vector along with the pose of the body frame at which it was first observed in order to correctly account for correlations of errors in subsequent measurements of the feature to errors in the state.

B. Unscented Kalman Filter

To enable on–board control, an UKF is used to estimate the full state of the vehicle at 500 Hz. The state is represented by \begin{equation} \mathbf {x}_{f}={\left[\begin{array}{cccc} \boldsymbol {x}^\top & \boldsymbol {v}^\top & \Phi ^\top & \boldsymbol {b}_a^\top \end{array}\right]}^\top, \end{equation}
View Source \begin{equation} \mathbf {x}_{f}={\left[\begin{array}{cccc} \boldsymbol {x}^\top & \boldsymbol {v}^\top & \Phi ^\top & \boldsymbol {b}_a^\top \end{array}\right]}^\top, \end{equation} where \boldsymbol {x} , \boldsymbol {v} have been defined in Section III-A , \Phi is the quaternion and \mathbf {b}_a the accelerometer biases. The prediction step uses the input \boldsymbol {y}_{a}, \boldsymbol {y}_{g} \in \mathbb {R}^3 linear acceleration and angular velocity measurements given by the IMU. The VIO pose estimates, are then used to update the state estimate using a linear measurement model. The measurement delay due to the image processing is compensated accumulating the IMU values till a new measurement from the VIO block is provided.

SECTION V.
Planning for Aggressive Maneuvers

The trajectory planning has to generate dynamically feasible trajectories that will take the quadrotor to its destination. In this section, we focus on two types of aggressive maneuvers.
A. Dynamically Feasible Trajectories

Similar to  [24] , we use the differential flatness property, which facilitates the computation of trajectories for the underactuated quadrotor system. We propose the a set of variables called flat outputs, the Cartesian position vector \boldsymbol {x} and the yaw angle \psi , which will be used to show that the system's state and the control inputs can be written in terms of this subset of variables and their derivatives. Considering (1) , the nominal force is \begin{equation} \tau = m \left\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\right\Vert, \end{equation}
View Source \begin{equation} \tau = m \left\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\right\Vert, \end{equation} and the orientation of the third axis of body frame, \boldsymbol {b}_3 is \begin{equation} \boldsymbol {b}_3 = \frac{\ddot{\boldsymbol {x}} + g\boldsymbol {e}_3}{\left\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\right\Vert }. \end{equation}
View Source \begin{equation} \boldsymbol {b}_3 = \frac{\ddot{\boldsymbol {x}} + g\boldsymbol {e}_3}{\left\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\right\Vert }. \end{equation} The rest of the rotation matrix, \boldsymbol {R} , can be determined by defining a vector \boldsymbol {b}_{c} , using the yaw angle \psi , to determine \boldsymbol {b}_2 \begin{equation} \boldsymbol {b}_2 = \frac{\boldsymbol {b}_3 \times \boldsymbol {b}_c}{\Vert \boldsymbol {b}_3 \times \boldsymbol {b}_c\Vert },\boldsymbol {b}_{c} = {\left[\begin{array}{ccc}\cos \psi & \sin \psi & 0\end{array}\right]}. \end{equation}
View Source \begin{equation} \boldsymbol {b}_2 = \frac{\boldsymbol {b}_3 \times \boldsymbol {b}_c}{\Vert \boldsymbol {b}_3 \times \boldsymbol {b}_c\Vert },\boldsymbol {b}_{c} = {\left[\begin{array}{ccc}\cos \psi & \sin \psi & 0\end{array}\right]}. \end{equation} Then \boldsymbol {b}_2 \times \boldsymbol {b}_3 gives \boldsymbol {b}_1 . Differentiating again (1) we obtain \begin{eqnarray} m \boldsymbol {x}^{\left(3\right)} &= -\tau \dot{\boldsymbol {R}} \boldsymbol {e}_3 - \dot{\tau } \boldsymbol {R} \boldsymbol {e}_3 = -\tau \boldsymbol {R} \hat{\boldsymbol {\Omega }} \boldsymbol {e}_3 - \dot{\tau } \boldsymbol {b}_3 \end{eqnarray}
View Source \begin{eqnarray} m \boldsymbol {x}^{\left(3\right)} &= -\tau \dot{\boldsymbol {R}} \boldsymbol {e}_3 - \dot{\tau } \boldsymbol {R} \boldsymbol {e}_3 = -\tau \boldsymbol {R} \hat{\boldsymbol {\Omega }} \boldsymbol {e}_3 - \dot{\tau } \boldsymbol {b}_3 \end{eqnarray} and the scalar projection onto \boldsymbol {b}_3 reveals that \begin{equation} \dot{\tau } = \boldsymbol {b}_3 \cdot m \boldsymbol {x}^{(3)}. \end{equation}
View Source \begin{equation} \dot{\tau } = \boldsymbol {b}_3 \cdot m \boldsymbol {x}^{(3)}. \end{equation} Next, we can determine the first two terms of the angular body rates \boldsymbol {\Omega } , by solving (8) for \hat{\boldsymbol {\Omega }} \boldsymbol {e}_3 \begin{equation} {\left[\begin{array}{c}\Omega _1 \\ \Omega _2 \end{array}\right]} = \frac{m}{\tau } {\left[\begin{array}{c}-\boldsymbol {b}_2^\top \\ \boldsymbol {b}_1^\top \end{array}\right]}\boldsymbol {x}^{\left(3\right)}. \end{equation}
View Source \begin{equation} {\left[\begin{array}{c}\Omega _1 \\ \Omega _2 \end{array}\right]} = \frac{m}{\tau } {\left[\begin{array}{c}-\boldsymbol {b}_2^\top \\ \boldsymbol {b}_1^\top \end{array}\right]}\boldsymbol {x}^{\left(3\right)}. \end{equation} The third term of \boldsymbol {\Omega } depends on the yaw angle derivative \dot{\psi } . Decomposing \boldsymbol {R} by the Euler angles Z\left(\psi \right)-X\left(\phi \right)-Y\left(\theta \right) parametrization we obtain \begin{equation} \Omega _3 = \Omega _1\tan \theta + \frac{\cos \phi }{\cos \theta }\dot{\psi } \end{equation}
View Source \begin{equation} \Omega _3 = \Omega _1\tan \theta + \frac{\cos \phi }{\cos \theta }\dot{\psi } \end{equation} Differentiating again (8) and similar to before, we can solve for the first two component of {\dot{\hat{\boldsymbol {\Omega }}}} . The third element will require the 2^\text{nd} derivative of the yaw angle. With this angular acceleration, we can solve for the required moments. Thus, the control inputs can be computed in terms of the flat outputs and their derivatives. The 4^{th} derivative of position appears in the control inputs and the 2^{nd} derivative of the yaw appears in the moments. An optimal motion plan is defined as one that that minimizes the cost function \Gamma \begin{eqnarray} \Gamma = \int _{t_0}^{t_f} &\left\Vert \frac{d^{4}\boldsymbol {x}(t)}{dt^{4}} \right\Vert ^2 dt + \left\Vert \frac{d^{2}\psi (t)}{dt^{2}} \right\Vert ^2 dt. \end{eqnarray}
View Source \begin{eqnarray} \Gamma = \int _{t_0}^{t_f} &\left\Vert \frac{d^{4}\boldsymbol {x}(t)}{dt^{4}} \right\Vert ^2 dt + \left\Vert \frac{d^{2}\psi (t)}{dt^{2}} \right\Vert ^2 dt. \end{eqnarray} Considering a n^\text{th} order time-parametrized polynomial trajectories for each Cartesian coordinate d and the yaw \begin{equation} \alpha _d\left(t\right) = \sum _{i=0}^n c_{i_d}t^i = \boldsymbol {c}_d^\top \boldsymbol {t}, \,d=1,\cdots, 4, \end{equation}
View Source \begin{equation} \alpha _d\left(t\right) = \sum _{i=0}^n c_{i_d}t^i = \boldsymbol {c}_d^\top \boldsymbol {t}, \,d=1,\cdots, 4, \end{equation} the problem in eq. (12) can be formulated as a Quadratic Programming (QP), with the initial t_0 and the final t_f times \begin{eqnarray} \min \boldsymbol {c}_d^\top \left(\int _{t_0}^{t_f}\frac{d^{4}}{dt^{4}} \boldsymbol {t} \left(\frac{d^{4}}{dt^{4}} \boldsymbol {t}\right)^\top dt\right)\boldsymbol {c}_d = \min \boldsymbol {c}_d^\top \mathcal {T}_d\boldsymbol {c}_d \end{eqnarray}
View Source \begin{eqnarray} \min \boldsymbol {c}_d^\top \left(\int _{t_0}^{t_f}\frac{d^{4}}{dt^{4}} \boldsymbol {t} \left(\frac{d^{4}}{dt^{4}} \boldsymbol {t}\right)^\top dt\right)\boldsymbol {c}_d = \min \boldsymbol {c}_d^\top \mathcal {T}_d\boldsymbol {c}_d \end{eqnarray} and in the general form \begin{eqnarray} && \min C^\top \mathcal {T}C, \nonumber\\ && \text{subject to}\,AC \leqslant B,A_eC = B_e, \end{eqnarray}
View Source \begin{eqnarray} && \min C^\top \mathcal {T}C, \nonumber\\ && \text{subject to}\,AC \leqslant B,A_eC = B_e, \end{eqnarray} with \begin{eqnarray*} C = {\left[\begin{array}{cccc} \boldsymbol {c}_1^\top &\boldsymbol {c}_2^\top &\boldsymbol {c}_3^\top &\boldsymbol {c}_4^\top \end{array}\right]}^\top,\mathcal {T} = \text{diag}{\left[\begin{array}{cccc}\mathcal {T}_1 & \mathcal {T}_2 & \mathcal {T}_3 & \mathcal {T}_4 \end{array}\right]}. \end{eqnarray*}
View Source \begin{eqnarray*} C = {\left[\begin{array}{cccc} \boldsymbol {c}_1^\top &\boldsymbol {c}_2^\top &\boldsymbol {c}_3^\top &\boldsymbol {c}_4^\top \end{array}\right]}^\top,\mathcal {T} = \text{diag}{\left[\begin{array}{cccc}\mathcal {T}_1 & \mathcal {T}_2 & \mathcal {T}_3 & \mathcal {T}_4 \end{array}\right]}. \end{eqnarray*} The matrix A \in \mathbb {R}^{k\times 4n} and B \in \mathbb {R}^k , where k is the total number of linear constraints. The matrix A_e \in \mathbb {R}^{p\times 4n} and vector B_e \in \mathbb {R}^p can be used to impose p equality constraints. Generally, a trajectory is divided into segments. The coefficients for each segment can be easily incorporated into the QP. The equality constraints are used to guarantee during the trajectory the continuity of position and its derivatives and to specify a constraint at a desired time. We also consider a maximum velocity bound \boldsymbol {v}_\text{max} .

It is also necessary to consider constraints imposed by the mechanics and sensors of the system since we are focusing on aggressive maneuvers. Specifically, the maximum thrust imposes a constraint of the type \begin{equation} m\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\Vert \leqslant \tau _{\rm max},\forall t\in \left[t_0,t_f\right], \end{equation}
View Source \begin{equation} m\Vert \ddot{\boldsymbol {x}} + g\boldsymbol {e}_3\Vert \leqslant \tau _{\rm max},\forall t\in \left[t_0,t_f\right], \end{equation} where \tau _{\rm max}= \sum _{j = 1}^4 f_{j_{\rm max}} = 4k_f\omega _{m_{\rm max}}^2 is the total thrust acting in the \boldsymbol {b}_3 direction, whereas k_f is the thrust coefficient and \omega _{m_{\rm max}} the maximum single motor speed.

In addition, a constraint on the jerk is induced by the maximum angular speed detectable by the gyros as \begin{equation} f_1\left(\boldsymbol {x}^{\left(3\right)}, \ddot{\boldsymbol {x}}, \dot{\psi }\right)\leqslant \omega _{\rm max},\,\forall t\in \left[t_0,\,t_f\right], \end{equation}
View Source \begin{equation} f_1\left(\boldsymbol {x}^{\left(3\right)}, \ddot{\boldsymbol {x}}, \dot{\psi }\right)\leqslant \omega _{\rm max},\,\forall t\in \left[t_0,\,t_f\right], \end{equation} and the maximum moment M_{\rm max} , on one body axis, induces a constraint as \begin{equation} f_2\left(\boldsymbol {x}^{\left(4\right)}, \boldsymbol {x}^{\left(3\right)}, \ddot{\boldsymbol {x}}, \dot{\psi }, \ddot{\psi }\right)\leqslant M_{\rm max},\,\forall t\in \left[t_0,\,t_f\right], \end{equation}
View Source \begin{equation} f_2\left(\boldsymbol {x}^{\left(4\right)}, \boldsymbol {x}^{\left(3\right)}, \ddot{\boldsymbol {x}}, \dot{\psi }, \ddot{\psi }\right)\leqslant M_{\rm max},\,\forall t\in \left[t_0,\,t_f\right], \end{equation} where M_{\rm max} = l\left(\omega _{m_{\rm max}} - \omega _{m_{\rm min}}\right) , with l the vehicle arm length. Practically, the constraints expressed by (16) , (17) , (18) are nonlinear, thus they cannot be directly incorporated in the QP problem. However, to take advantage of the QP formulation, it is still possible to consider them indirectly with upper bounds on the acceleration, jerk and snap respectively and then verifying a-posteriori they are respected.

B. Slalom Path

We consider maneuvers with increasing degree of difficulties in term of acceleration, velocity and attitude angles. In this case, we assume to know the obstacles’ locations with respect to the robot's starting position. We consider the starting point P_1 and the final point P_5 . A set of obstacles is located between these two points (in our case 2 static obstacles are located between P_1-P_3 and P_3-P_5 see Fig. 6 left). The obstacle's position imposes some constraints on the planned trajectory. We consider a set of virtual waypoints P_{v_{i}}(P_{v_{i_{x}}},\,P_{v_{i_{y}}},\,P_{v_{i_{z}}}) located at the obstacle positions ( P_2 and P_4 in the considered case) and their corresponding times instants t_{v_{i}} . In addition to the constraints specified in the previous paragraph, we can then impose in our QP problem a bound on each of the Cartesian dimension \left(x, y,z\right) around the obstacles’ positions as \begin{eqnarray} x\left(t\right) \geqslant P_{v_{i_{x}}} + \epsilon _x,&&\,y\left(t\right) \geqslant P_{v_{i_{y}}} + \epsilon _y,\,z\left(t\right) \geqslant P_{v_{i_{z}}} + \epsilon _z, \nonumber\\ \forall t &&\in \left(t_{v_{i}}- \delta, t_{v_{i}} + \delta \right), \end{eqnarray}
View Source \begin{eqnarray} x\left(t\right) \geqslant P_{v_{i_{x}}} + \epsilon _x,&&\,y\left(t\right) \geqslant P_{v_{i_{y}}} + \epsilon _y,\,z\left(t\right) \geqslant P_{v_{i_{z}}} + \epsilon _z, \nonumber\\ \forall t &&\in \left(t_{v_{i}}- \delta, t_{v_{i}} + \delta \right), \end{eqnarray} where \delta is a time interval and \epsilon _i,\,\epsilon _y,\,\epsilon _z indicate the thresholds the vehicle's center of mass should respect to be safe.

C. Planning Trajectories through a Narrow Gap

Let us consider a narrow obstacle like a window. We assume the window gap is in the field of view at the robot's starting position. The stereo configuration available on the board allows to identify the window using a planar homography algorithm. This gives as output the rotation \boldsymbol {R}^B_{W} = [\boldsymbol {x}_W\;\boldsymbol {y}_W\; \boldsymbol {z}_W] and the translation \boldsymbol {t}_{W} of the window with respect to the initial robot frame B . Without loss of generality let us decompose the rotation using the Z\left(\psi \right)-X\left(\phi \right)-Y\left(\theta \right) Euler angles parametrization. It is worth specifying that our approach does not depend on the Euler parametrization since it is based on a geometric control approach as shown in Section III . However, it is necessary to employ a parametrization in case a yaw angle has to be planned. The parametrization of choice should then be the same used for the differential flatness in Section V-A . It is useful to clarify again that neither the stereo camera nor the shape of the window is used to solve for visual scale. Since the gap is narrow, the vehicle can only traverse it such that the main body plane (the plane defined by the centers of the four propellers) is orthogonal to the window planar surface defined by the \boldsymbol {y}_W-\boldsymbol {z}_W axes (see Fig. 5 ). However, the user can decide if the yaw should be zero at the traversing point. In that case, the vehicle will traverse the window with the x body axis in the same direction of the window axis (see Fig. 5 left), otherwise the vehicle will have to keep constant yaw during the trajectory and it should then use both roll and pitch to traverse the window (see Fig. 5 right) such to respect that the body plane is orthogonal to the \boldsymbol {y}_W-\boldsymbol {z}_W plane. Since we are planning already aggressive trajectories we opt for the fist solution and solve the yaw offset between the window and the vehicle during the takeoff phase. All the information to plan the trajectory through the window is then available. We define the traversing window point as \boldsymbol {t}_{W} and we enforce the orientation \boldsymbol {R}^B_{W} at the gap with the following acceleration constraint \begin{equation} \boldsymbol {a}_{W_{\rm des}} = \boldsymbol {R}{^B_{W}}^\top \boldsymbol {a}_{W} - \gamma \boldsymbol {e}_3, \end{equation}
View Source \begin{equation} \boldsymbol {a}_{W_{\rm des}} = \boldsymbol {R}{^B_{W}}^\top \boldsymbol {a}_{W} - \gamma \boldsymbol {e}_3, \end{equation} where the \boldsymbol {a}_{W} = a\boldsymbol {e}_3 is chosen by the user according to what the desired vertical acceleration is. The trajectory is planned through points P_1-P_5 (see Fig. 6 ) with P_1 and P_5 the starting and landing point respectively. This constraint is derived from (6) . The third body axis is acceleration and gravity vectors dependent. This guarantees to plan \boldsymbol {b}_3 as in (6) and also \boldsymbol {b}_2 as in (7) . Then, \boldsymbol {b}_1 is chosen as \boldsymbol {b}_2\times \boldsymbol {b}_3 . We estimate that an orientation time change by \pi /2 radians using our robots takes approximately 0.2 s. Thus, during the portion of the trajectory corresponding to the gap, we specify an acceleration such that \boldsymbol {b}_3 is in the same direction of the \boldsymbol {z}_W window axis.

Fig. 5.

The planned trajectory over the window with \text{45}^\circ roll and \text{20}^\circ pitch angles, planning (left) and without (right) planning the yaw angle.

Show All
Fig. 6.

The slalom path with two poles obstacles in red (left) and the planned trajectory over the narrow window gap at \text{0}^\circ \,\text{green}-\text{45}^\circ \,\text{orange}-\text{90}^\circ \,\text{blue} (right) with the arrow indicating the desired acceleration direction in 3D Cartesian space.

Show All
SECTION VI.
Experimental Results

In this section, we report on the experiments that have been performed at the PERCH lab (Penn Engineering Research Collaboration Hub) at the University of Pennsylvania indoor testbed. The total flying area is a volume of \text{20}\times \text{6}\times \text{4}\;\text{m}^3 . The algorithms for odometry estimation and control are running on-board. A Qualisys 2 motion capture system with 22 Oqus cameras running at 100 Hz is used for ground-truth comparison. We evaluate the two previous aggressive trajectory tasks under different conditions. The VIO module is set to track an average of 20–30 features each frame. A good pose estimation is obtained when this number does not drop below 2. The initialization requires around 10 features.

We consider slalom paths around poles that are (a) 3 m and (b) 1.5 m apart requiring the quadrotor to maintain a clearance distance around the poles. The results are reported in Table I . For the first test we reach a maximum speed of 4.5 m/s whereas in the second case 3 m/s with a maximum acceleration of 5 \text{m}/\text{s}^2 in both cases. Despite only the initial information about obstacles’ positions, the vehicle is still able to avoid them. This validates the precision and robustness of our localization strategy. Moreover, it is noticeable that despite the trajectories having different velocities, accelerations, and thus angles, the results are in the same range of values both for Root Mean Square Error (RMSE) and Standard Deviation (STD). For brevity, we do not report on the control error values, which are similar to the estimated ones as visible from Figs. 7 ,  8 ,  9 . The reader can also notice that the VIO and UKF modules have similar errors with the separation strategy providing the benefits already discussed. The orientation errors in Table II have been computed according to  [26] . The attached multimedia material shows that each experiment has been repeated multiple times with different safety distances of up to 0.5 m and with similar performances to the results in Table I .
Fig. 7.

Ground truth (blue), estimated (green), desired (magenta) trajectories for the 6 m slalom trajectory

Show All
Fig. 8.

Ground truth (blue), estimated (green), desired (magenta) Cartesian position for the 6 m slalom trajectory.

Show All
Fig. 9.

Ground truth (blue), estimated (green), desired (magenta) Cartesian velocities for the 6 m slalom trajectory.

Show All
TABLE I Position and Velocity RMSE and STD of the Estimates Compared to Motion Capture System at for the Slalom Case
TABLE II Orientation RMSE and STD in Radians of the Estimates Compared to Motion Capture System for the Slalom Case

The results for the narrow gap experiment are reported in Table III . The experiment has been repeated considering different maximum rotation angles on one of the window's axis. The results show that our methodology gives similar results despite different operating conditions and increased level of difficulty induced by a higher values of acceleration, platform angles and larger operating envelope. The traversing gap of the trajectory is encapsulated between the take-off and landing phase that have an average duration of 2.5 s each. The traversing path has a length of 6 m along the x Cartesian axis and a duration of 5 s (see Figs. 10 – 12 , between 5 and 10 s). In all cases, the vehicle reaches an average maximum speed of 4.5 m/s, accelerations of up to 15 \text{m/s}^2 and angular rotations of up to \text{800}\,\text{deg/s} . For brevity, we omit the orientation errors since similar to the slalom task. The reader will notice from the attached multimedia material the successful accomplishment of multiple trials. The acceleration \boldsymbol {a}_{W} is set to be half of the available thrust.
Fig. 10.

Ground truth (blue), estimated (green), desired (magenta) trajectories over the window at 90 degrees.

Show All
Fig. 11.

Ground truth (blue), estimated (green), desired (magenta) Cartesian positions over the window at 90 degrees.

Show All
Fig. 12.

Ground truth (blue), estimated (green), desired (magenta) Cartesian velocities over the window at 90 degrees.

Show All
TABLE III Position and Velocity RMSE and STD of the Estimates Compared to Motion Capture for the Window Case
SECTION VII.
Conclusion

In this work, we presented the system architecture and methodologies to enable vision-based high speed and aggressive flight with a small scale quadrotor equipped only with a single camera and an IMU as sensors. We demonstrated the algorithm framework for estimation, control and trajectory generation, and experimental performance of our autonomous navigation solution based on camera and IMU with slalom trajectories and flight through narrow windows (gaps) at different angles. We successfully achieve the desired control, state estimation, and trajectory planning through constrained environments, even with limited on-board computational capabilities derived from smartphone grade hardware. Our results reveal the feasibility and correctness of the proposed approach. Specifically we reach speeds of 5 m/s, roll and pitch angles of 90 degrees, accelerations of up to 15 \text{m/s}^2 and angular velocities of up to 800 \text{deg/s} . Our ongoing work addresses the use of the small baseline, stereo camera for real-time dense mapping to allow obstacle detection and mapping for planning.
ACKNOWLEDGMENT

The authors would like to thank for helpful discussions with Dr. D. Mellinger and his team at Qualcomm Research Philadelphia.

Authors
Figures
References
Citations
Keywords
Metrics
Media
Footnotes
   Back to Results   
More Like This
Incremental Path Planning Using Partial Map Information for Mobile Robots

2006 9th International Conference on Control, Automation, Robotics and Vision

Published: 2006
An Estimation Distribution Algorithm of Optimum Path Planning for Mobile Robots

2008 International Conference on Cyberworlds

Published: 2008
Show More
References
References is not available for this document.
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
IEEE Account

    Change Username/Password
    Update Address

Purchase Details

    Payment Options
    Order History
    View Purchased Documents

Profile Information

    Communications Preferences
    Profession and Education
    Technical Interests

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support

    About IEEE Xplore
    Contact Us
    Help
    Accessibility
    Terms of Use
    Nondiscrimination Policy
    Sitemap
    Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.
© Copyright 2022 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.
