Cluster Computing (2019) 22:S4745–S4766 https://doi.org/10.1007/s10586-018-2360-3
(0123456789().,-volV)(0123456789().,-volV)

Intelligent Be´zier curve-based path planning model using Chaotic Particle Swarm Optimization algorithm
Alaa Tharwat1,4 • Mohamed Elhoseny2,4 • Aboul Ella Hassanien3,4 • Thomas Gabel1 • Arun Kumar5
Received: 14 January 2018 / Revised: 13 February 2018 / Accepted: 1 March 2018 / Published online: 12 March 2018 Ó Springer Science+Business Media, LLC, part of Springer Nature 2018
Abstract Path planning algorithms have been used in different applications with the aim of ﬁnding a suitable collision-free path which satisﬁes some certain criteria such as the shortest path length and smoothness; thus, deﬁning a suitable curve to describe path is essential. The main goal of these algorithms is to ﬁnd the shortest and smooth path between the starting and target points. This paper makes use of a Be´zier curve-based model for path planning. The control points of the Be´zier curve signiﬁcantly inﬂuence the length and smoothness of the path. In this paper, a novel Chaotic Particle Swarm Optimization (CPSO) algorithm has been proposed to optimize the control points of Be´zier curve, and the proposed algorithm comes in two variants: CPSO-I and CPSO-II. Using the chosen control points, the optimum smooth path that minimizes the total distance between the starting and ending points is selected. To evaluate the CPSO algorithm, the results of the CPSO-I and CPSO-II algorithms are compared with the standard PSO algorithm. The experimental results proved that the proposed algorithm is capable of ﬁnding the optimal path. Moreover, the CPSO algorithm was tested against different numbers of control points and obstacles, and the CPSO algorithm achieved competitive results.
Keywords Particle Swarm Optimization (PSO) Á Be´zier curve Á Path planning Á Chaos

& Mohamed Elhoseny mohamed_elhoseny@mans.edu.eg
Alaa Tharwat aothman@fb2.fra-uas.de
Aboul Ella Hassanien aboitcairo@gmail.com http://www.egyptscience.net
Thomas Gabel tgabel@fb2.fra-uas.de
Arun Kumar arun.nura@gmail.com
1 Faculty of Computer Science and Engineering, Frankfurt University of Applied Sciences, 60318 Frankfurt am Main, Germany
2 Faculty of Computers and Information, Mansoura University, Mansoura, Egypt
3 Faculty of Computers and Information, Cairo University, Cairo, Egypt
4 Scientiﬁc Research Group in Egypt (SRGE), Cairo, Egypt 5 School of EEE, SASTRA University, Thanjavur, India

1 Introduction
Path planning technique is widely used in many applications such as mobile robotics and track trajectories [1]. The goal of path planning is to ﬁnd the optimal path which (1) minimizes the distance between the starting and target points, (2) avoids collisions with obstacles, and (3) increases the smoothness of the curve [2, 3]. Path planning can be formulated as an optimization problem on a set of indices, e.g., shortest distance, and under some constraints, e.g., collision-free path.
Path planning is also known to be an NP-hard optimization problem that can be solved using heuristic algorithms such as evolutionary algorithms [4–6]. There are many metaheuristic optimization algorithm that were employed to optimize the path planning problem such as Genetic Algorithms (GA) [7, 8], Particle Swarm Optimization (PSO) [9], Artiﬁcial Bee Colony Evolutionary Programming (ABC-EB) [10], PSO ? Gravitational Search Algorithm (GSA) [11], Tabu Search (TS) [12], and Fireﬂy Algorithm (FA) [13].
123

S4746

Cluster Computing (2019) 22:S4745–S4766

Traditional path planning algorithms assume that the environment is perfectly known and try to search for the optimal path that contains sharp turns and some polygonal lines. However, such algorithms are inﬂexible and have a negative inﬂuence on the smoothness of the generated curve which may add additional efforts on the mobile robot by switching between different modes such as stop, rotate, and restart to move along the polygonal lines. Hence, these algorithms are time and energy consuming, and the smooth movement is a requirement for some tasks [8].
Be´zier curve has been applied in the smooth path planning problem, and it generates free curves perfectly [14]. Be´zier curve can be drawn as a series of line segments that join the control points. Thus, choosing the control points controls the performance of the generated curve; hence, these control points are used to optimize the Be´zier curve. Several studies have focused on optimizing these control points using metaheuristic optimization algorithms such as GA [15], TS [12], and FA [13]. In this paper, we target the use of Particle Swarm Optimization to optimize Be´zier curve.
PSO has been used in many applications due to its simplicity [16]. For example, in image processing, the PSO algorithm was used to search for the optimal thresholding value in image segmentation [17, 18]. In machine learning, the PSO is widely used for parameter tuning of learning algorithms to improve the classiﬁcation performance [19, 20], for feature selection [21], and to search for the optimal centroids in clustering [22, 23]. PSO algorithm is also applied to solve mathematical problems [24]. In electrical and power applications, the PSO was used for different purposes such as searching for the maximum power point tracking of multiple photovoltaic [25], and for optimizing the size and location of distributed generation for loss reduction [26].
In general, PSO lends itself strongly to exploitation which may lead to local optima problem. Hence, in some cases, PSO fails to ﬁnd the global optimal solution(s). The search strategy used in standard PSO is mainly based on random walks; thus, it cannot always deal with the optimization problems successfully. Different strategies have been added to the optimization algorithms with the goal of improving its performance [27]. Chaos concept is one of these strategies that has been widely used in various applications, and it was already combined with some optimization algorithms [27]. This combination may generate solutions which may have higher mobility and diversity than standard optimization algorithms. Recently, the chaos theory has been combined with several metaheuristic optimization methods to solve the local optima problem [27, 28]. For example, chaos concept was used to tune the parameters of GA [29], Ant bee colony (ABC)

optimization [30], FA [31], and such combinations achieved promising results.
In this paper, the main contribution is to use Chaotic PSO (CPSO) algorithm to present a novel algorithm which is used to optimize Be´zier curve to get the shortest, smooth, and collision-free path, which can be applied in different applications. The optimal Be´zier curve can be obtained by searching for the optimal positions of the control points to draw shortest, smooth, and collision free path. As a consequence, the dimension of the search space depends mainly on the number of control points. As different chaotic maps may lead to different behavior of the proposed algorithm, we then have two chaos-based PSO algorithms, namely, CPSO-I and CPSO-II. In these algorithms, we used different chaotic maps to replace the parameters of the PSO. Hence, different methods that use chaotic maps as efﬁcient alternatives to pseudo-random sequences have been proposed. Many experiments have been conducted to (1) test the inﬂuence of different chaotic maps on the performance of the algorithm, (2) compare the proposed algorithms with the standard PSO, (3) examine the inﬂuence of the number of control points on the results of the CPSO algorithm, and (4) show the impact of the number of obstacles on the performance of the CPSO algorithm.
The rest of the paper is organized as follows: Sect. 2 summarizes the related work of the path planning and Be´zier curve. Section 3 gives overviews of the techniques and methods used for the proposed model. Section 4 explains in details the proposed CPSO-based method to get the optimal path. Experimental results and discussion are introduced in Sect. 5. Finally, Sect. 6 concludes the paper.
2 Related work
In the path planning problem, classical methods required a long time and huge storage memory [8]. Thus, metaheuristic optimization algorithms are used frequently to optimize the path planning problem [32]. For example, ABC-EB algorithm was employed to solve the path planning problem, and the results of ABC-EB were compared with the classical Probabilistic Road Map method (PRM) [10]. The results proved that the ABC-EB algorithm outperformed the PRM algorithm. GA was fused with PSO to optimize the path of a mobile robot in a 3D environment which contained static obstacles [9]. In another research, the PSO algorithm was hybridized with the Gravitational Search Algorithm (GSA) to minimize the path length; and hence, reduces the arrival time of all robots to their destination [11].
Several studies used metaheuristic algorithms with Be´zier curve for optimal path planning. FA and Be´zier

123

Cluster Computing (2019) 22:S4745–S4766

S4747

curve were combined to ﬁnd the shortest feasible (collision-free) path [13]. The results of FA were compared with GA and adaptive inertia weight PSO (PSO-w), and the FA achieved the highest success rates. Galvez et al. performed different experiments in 2D and 3D environments using Be´zier curve and TS, and their proposed algorithm achieved competitive results [12]. PSO was used to optimize three different curves, namely: Be´zier curve, Ferguson curve, and g3 curve [33], and the PSO with Be´zier curve achieved the best results. In another research, an improved dynamic multi-swarm PSO algorithm with crossover operator was proposed to optimize the Be´zier curve [13].
Be´zier curve also was utilized in many applications. For example, Ziolkowski et al. combined the GA and Be´zier curve to design a shape of a solenoid which produces a uniform magnetic ﬁeld on its axis [15]. Moreover, the parallel GA was employed with Be´zier curve to generate trajectories for multi-unmanned aerial vehicle (UAV) systems, where the Be´zier curve was used to enhance the smoothness of the obtained path [34]. Be´zier ? GA algorithm was also used to design a cambered airfoil and the proposed design achieved competitive results compared with some state-of-the-art methods [35]. Jolly et al. employed a Be´zier-curve-based model for path planning in a multi-agent robot soccer system, and the velocity of the proposed approach was updated within its allowable limits by keeping its acceleration within the predeﬁned safe limits [36]. Be´zier curve with GA model was used to design 2-D turbine blades using target pressure considerations [37], and the proposed model was applied to design a steam turbine blade. Be´zier curve was also used for generating the optimal trajectories [38]. Choi et al. used the Be´zier curve to generate the optimal trajectories for vehicles to satisfy the path constraints [39]. In another study, the Be´zier curve for path planning generated the reference trajectories, which are used by the intelligent wheelchair to pass a doorway [38].
3 Background
3.1 Be´zier curve
The Be´zier curve was proposed by Pierre Be´zier, who used the Be´zier curve to design the body of a car in 1962 [40]. Be´zier curve has been used in computer graphics applications [33]. The Be´zier curve is convex if the control points form a convex polygon, and it can express free curves and surfaces perfectly [33]. Mathematically, the Be´zier curve can be drawn as a series of line segments joining the control points as in Fig. 1.

Fig. 1 An example of a Be´zier curve

Assume we have n þ 1 points, i.e., Be´zier curve of

degree n, Pi; i ¼ 0; 1; . . .; n, the Be´zier curve is deﬁned as follow:

Xn

RðtÞ ¼ PiBi;nðtÞ; t 2 ½0; 1;

ð1Þ

i¼0

where t indicates the normalized time variable, Pi ¼ ½xi; yiT is the coordinate vector of the ith control point with xi and yi being the components corresponding to the X and Y coordinates, respectively, Bi;n is the Bernstein basis polynomials, which represents the base function in the expression of a Be´zier curve, and it is given by:

Bi;nðtÞ ¼ Cni tið1 À tÞnÀi

¼ n! tið1 À tÞnÀi; i ¼ 0; 1; . . .; n

ð2Þ

i!ðn À iÞ!

From Eqs. (1) and (2), the parameter equation (for the example shown in Fig. 1) for each control point can be generated as follows:
RðtÞ ¼ P0ð1 À tÞ3 þ 3P1tð1 À tÞ2 þ 3P2t2ð1 À tÞ þ P3t3; ð3Þ

where t is in the range of [0, 1]. The Be´zier curve is invariance under translation and rotation and this is called Geometry invariance property. Moreover, the Be´zier curve starts at the starting point, t ¼ 0, and stops at the ending/target, t ¼ 1. In other words, P0 ¼ Rð0Þ and Pn ¼ Rð1Þ. Be´zier curve has some control points which form a control polygon as shown in Fig. 1. As shown, the curve is tangent to the control polygon at the endpoints as in Eq. (4). Moreover, the ﬁrst derivatives of the starting and ending points of the curve are only related to the two nearest control points, and in the same direction of the line of the two points. The Be´zier curve can be formed by connecting several line segments of low-order Be´zier curves.

Rðt_Þ

¼

dRðtÞ dt

¼

n

X nÀ1
i¼0

DbiBi;nÀ1ðtÞ;

t

2

½0;

1;

ð4Þ

where Dbi ¼ biþ1 À bi.

123

S4748

Cluster Computing (2019) 22:S4745–S4766

Given two segments L1 ¼ fP10; P11; P12; P13g and L2 ¼ fP20; P21; P22; P23g. To form a continuous curve from these two points the following equation should be satisﬁed:

P13 À P12 ¼ P21 À P20; P13 ¼ P20:

ð5Þ

Hence, to satisfy the property of ﬁrst-order continuous

condition, l segments of Be´zier curve need 2l points and 4l

parameters and the path can be generated as follows:

RðtÞ

¼

8 >>>>>>>>>>>>>>>< >>>>>>>>>>>>>>>:

P0ð1 À tÞ3 þ 3Pi1tð1 À tÞ2 þ 3Pi2t2ð1 À tÞ þ Pi3t3; Pð3iÀ1Þð1 À tÞ3 þ3 ð2Pð3iÀ1Þ À Pð2iÀ1ÞÞtð1 À þ 3Pi2t2ð1 À tÞ þ Pi3t3; Pð3iÀ1Þð1 À tÞ3 þ 3ð2Pð3iÀ1Þ À Pð2iÀ1ÞÞtð1 À

tÞ2 tÞ2

þ 3Pi2t2ð1 À tÞ þ P1t3;

i¼1 1 i n i ¼ n;

ð6Þ

where P0 is the starting point and P1 is the ending point, and when the value of t changes in the interval (0, 1), we can get a cubic Be´zier curve of the ith segment. These n line segments of cubic Be´zier curve form the entire path of the curve.

3.2 Particle Swarm Optimization (PSO)

PSO is one of the well-known optimization algorithms, and it was implemented by Reynolds and Heppner, and then simulated by Kennedy and Eberhart [41–43]. The aim of the PSO is to search for optimal or near optimal solutions in the search space. Each particle in the PSO algorithm has its own (1) position (xi 2 Rn) which represents a point in the search space Rn, where n is the dimension of the search space, (2) velocity, i.e., rate of position change, (vi), and (3) the previous best positions (pi). These positions of the particles are initialized randomly, and the velocity values are initialized with zero. The current positions of all particles are evaluated using the ﬁtness function. The ﬁtness value of the current position for each particle is then compared with its best position, and best value is stored in (pi), i.e.,, the previous best positions store the positions of the particles that have better values. Moreover, in PSO, the global best position (G) represents the best ﬁtness value [44].
Each particle is moved by adding the velocity to the current position as follows:

xiðtþ1Þ ¼ xiðtÞ þ viðtþ1Þ;

ð7Þ

where xiðtÞ is the current position, xiðtþ1Þ is the new position,

and viðtþ1Þ indicates the new velocity. The velocity of each particle is adjusted as follows:

viðtþ1Þ ¼ wviðtÞ þ C1r1ðpiðtÞ À xiðtÞÞ þ C2r2ðG À xiðtÞÞ;

ð8Þ

where w represents the inertia weight, C1 is the cognition learning factor, C2 represents the social learning factor, and r1, r2 are the uniformly generated random numbers in the range of [0, 1]. According to Eq. (8), the new velocity for each particle is determined by:

1. The original velocity of the particle (wviðtÞ). 2. The position of the previous best position of that
particle, this is so-called particle memory or cognitive component. This term as in Eq. 8 is used to adjust the velocity towards the best position visited by that particle (C1r1ðpiðtÞ À xiðtÞÞ). 3. The position of the global best ﬁtness value, this is the so-called social component [C2r2ðG À xiðtÞÞ], and it is used to adjust the velocity towards the global best position of all particles [44].

Figure 2 illustrates an example of the movement of two particles in a one-dimensional search space. As shown, the two particles have three different velocities which are used to adjust the velocity.
High values of velocity make the particles very fast, which may prevent the particles from converging to the optimal solution; hence, the velocity of the particles could be limited to a range ½ÀVmax; Vmax. This is much similar the learning rate in learning algorithms. On the contrary, small values of velocity cause the particles to search within a small area; hence, it may lead to slow convergence [44].
The positions and velocities of all particles are updated iteratively until it reaches a predeﬁned stopping criterion

Current Position (x(t) )
Next Position (x(t+1)) Original Velocity (v(t) ) Velocity to P (vp) Velocity to G (vG) Adjusted Velocity (v(t+1) ) v(t)

v (t+1)

x(t+1)

P(t)

vG

x(t) vp

G

Fig. 2 Illustration of the movement of one particle using PSO algorithm in one-dimensional space

123

Cluster Computing (2019) 22:S4745–S4766
[43]. The details of the PSO algorithm are summarized in Algorithm (1).

Algorithm 1 : Particle Swarm Optimization (PSO)

1: Initialize the particles’ positions (xi), velocity (vi), previous best positions (pi), the number of particles (N ), and

maximum number of iterations (M axiter). 2: while (t < M axiter) do 3: for all Particles (i) do

4:

Evaluate the ﬁtness value for the current particle,

xi, (F (xi)).

5:

if (F (xi) < F (pi)) then

6:

pi = xi

7:

end if

8:

if (F (xi) < F (G)) then

9:

G = xi

10:

end if

11:

Adjust the velocity and position of the current par-

ticle according to Eqs. (7 and 8).

12: end for

13: Stop the algorithm if a suﬃciently good ﬁtness function

is met.

14: end while

3.3 Chaotic maps
In many metaheuristic optimization algorithms, the randomness can be achieved using normal or Gaussian distributions, i.e., some parameters of these algorithms are drawn randomly from uniform or Gaussian distribution. Chaos acts similar to randomness, but with better dynamical and statistical properties which are vital to ensure that the chaotic variables can go through all states in certain ranges without repetition [45]. Such dynamical properties are important to ensure that the generated solutions by the algorithm can be diverse enough to reach every mode in the multimodal objective search space potentially. Hence, chaos search can escape more easily from a local optimal solution than the standard stochastic search; and hence, the random parameters in optimization algorithms can be replaced with a one-dimensional chaotic map, this is socalled chaotic optimization. Due to the mixing property of chaos, chaotic optimization algorithms can converge faster than standard stochastic search [46].
In the rest of this section, eight well-known one-dimensional chaotic maps which are used in our experiments are outlined.
– Gauss map The Gauss or Mouse map generates sequence in (0, 1), and it can be deﬁned as follows [46]:

S4749

8

< 0;

xk ¼ 0

xkþ1

¼

:

1 xkmodð1Þ

;

otherwise;

ð9Þ

hi

where

1 xk modð1Þ

¼

1 xk

À

1 xk

, xk 2 ð0; 1Þ represents the kth

chaotic number, k is the iteration number, and the

generated sequence is in (0, 1).

– Singer map This map is deﬁned as follows [27]:

xkþ1 ¼ lð7:86xk À 23:31x2k þ 28:75x3k À 13:3x4kÞ; ð10Þ

where l is a parameter between 0.9 and 1.08.

– Tent map This map is similar to Logistic map and it can

be deﬁned as follows [27]:

xkþ1

¼

8 >< >:

xk ; 0:7 10 ð1 3

À

xkÞ;

xk \0:7 otherwise

ð11Þ

– Circle map The circle map is deﬁned as follows [27]:

a

xkþ1 ¼ xk þ b À 2p sinð2pxkÞ modð1Þ

ð12Þ

where a ¼ 0:5, b ¼ 0:2, and the generated sequence is in (0, 1). – Logistic map This map can be written as follows [27]:

xkþ1 ¼ axkð1 À xkÞ

ð13Þ

In our experiments a ¼ 4 was used, and also under the

condition that x0 62 ð0:0; 0:25; 0:5; 0:75; 1:0Þ. – Sine map Sine map is given by [45]:

a

xkþ1 ¼ 4 sinðpxkÞ;

ð14Þ

where 0\a 4.

– Piecewise map The Piecewise map is given by [45]:

xkþ1

¼

8 >>>>>>>>>< >>>>>>>>>:

xk ; P xk À P ; 0:5 À P 1 À P À xk
0:5 À P 1 À xk ;

;

P

P ! xk ! 0 0:5 ! xk ! P 1 À P ! xk ! 0:5 1 ! xk ! 1 À P;

ð15Þ

where P represents the control parameter between 0 and 0.5 and P 6¼ 0. – Sinusoidal map This map is deﬁned as in Eq. (16) [27]:

xkþ1 ¼ ax2ksinðpxkÞ

ð16Þ

Figure 3 visualizes the chaotic value distributions of 500 iterations for all eight maps with random initial values. As shown in the ﬁgure the behaviors of all maps are different,

123

S4750

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(a) Gauss map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(c) Tent map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(e) Logistic map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0 0

50

100 150 200 250 300 350 400 450 500

(g) Piecewise map

Fig. 3 Chaotic value distributions during 500 iterations.

Cluster Computing (2019) 22:S4745–S4766

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(b) Singer map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(d) Circle map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

300

350

400

450

500

(f) Sine map

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50 100 150 200 250 300 350 400 450 500

(h) Sinusoidal map

123

Cluster Computing (2019) 22:S4745–S4766

S4751

and each map can reach different modes in the search space. For example, the Gaussian map in Fig. 3a initially reached to a high or maximum value, but it drops dramatically after that and it ﬂuctuates between 0 and 0.7. This behavior can be employed in our optimization algorithm by maximizing the range of exploration capability at the beginning and then reduce that range to improve the current solutions. It is worth mentioning that the behaviors of chaotic maps are highly affected by the initial conditions.
4 Chaotic Particle Swarm Optimization (CPSO)
This section describes the proposed algorithms in detail. Generally speaking, the proposed algorithms depend on optimizing the Be´zier curve for path planning through searching for the optimal positions of the control points. In this study, CPSO algorithm was employed to optimize Be´zier curve to ﬁnd smooth and shortest Be´zier curve.
4.1 The CPSO algorithms
The optimization algorithms have two main phases: exploration and exploitation. In the exploration phase, the goal is to explore the search space for ﬁnding the optimal solutions, or simply this phase may lead to new search regions that may contain better solutions. In the exploitation phase, the aim is to search locally around the current good solution. The optimization algorithms should be balanced between random selection and greedy selection to bias the search towards better solutions, i.e., exploitation, while exploring the search space to ﬁnd different solutions, i.e., exploration.
In the PSO algorithm, the parameters r1 and r2 control the trade-off between exploration and exploitation phases. These two parameters control the movement of particles towards the previous best and global best positions. In other words, high values of r1 and r2 drive the particles to enhance the current solution by moving towards the best and global best positions, respectively. On the other hand, small values of r1 and r2 increase the exploration capabilities. However, although the PSO algorithm proved efﬁcient for solving different optimization problems, it still has the following drawbacks:
– Sub-optimal selection at the beginning of the optimization process, the random walk of the particles are fast in the search space, which allows the particles to walk randomly in almost the entire search space. This may cause the algorithm to select sub-optimal solutions.

– Stagnation this problem is one of the main problems in almost all optimization algorithms. This problem occurs when the algorithm falls into a trap of some local optima, and it cannot ﬁnd better solutions because its exploration capability is very limited. This makes the algorithm continue enhancing the existing solutions that have already been found, even if they are suboptimal.
These two problems motivate our work on adapting the parameters r1 and r2 to obtain successive periods of exploration and exploitation. In the PSO algorithm, when reaching a solution, exploitation phase will be employed to enhance the current solutions found, followed by another exploration, which may jump to another searching region, followed by using exploitation again to further enhance the current solution found, and so on. Chaotic maps with their properties (see Sect. 3.3), can be used to adapt these parameters, i.e., r1 and r2, allowing for the required mix between exploitation and exploration. The proposed CPSO algorithm has two variants as in Fig. 4.

4.1.1 CPSO-I algorithm

In this algorithm, the parameter r1 in Eq. (8) is modiﬁed by chaotic maps (f) during iterations, and the modiﬁed equation is given by:

viðtþ1Þ ¼ wviðtÞ þ C1ftðpiðtÞ À xiðtÞÞ þ C2r2ðG À xiðtÞÞ

ð17Þ

In the standard PSO, r1 is a random number between 0 and 1 and in the CPSO-I algorithm, it is a chaotic number between 0 and 1.

Initialize CPSO parameters Population/Solutions

Control Points (n)

Generates new solutions using CPSO
algorithm

Updating Positions

Velocity Adjustment

CPSO-I
Update r1 using Chaotic maps

CPSO-II
Update r2 using Chaotic maps

Draw Bezier Curve Fitness Evaluation
No Satisfying stopping criterion Yes
Optimal Curve

Fig. 4 Flowchart of the proposed path planning curve using CPSO algorithm

123

S4752

Cluster Computing (2019) 22:S4745–S4766

4.1.2 CPSO-II algorithm

In this algorithm, the parameter r2 in Eq. (8) is modiﬁed by chaotic maps (f) during iterations, and the velocity will be modiﬁed as follows:

viðtþ1Þ ¼ wviðtÞ þ C1r1ðpiðtÞ À xiðtÞÞ þ C2ftðG À xiðtÞÞ

ð18Þ

In the standard PSO, r2 is a random number between 0 and 1 and in the CPSO-II algorithm, it is a chaotic number between 0 and 1.

4.2 Optimizing Be´zier curve using CPSO algorithm

In this section, more details about how the CPSO algorithm was employed to optimize the Be´zier curve.

4.2.1 Parameters settings

In the proposed algorithm, the CPSO algorithm provides the Be´zier curve with the positions of the control points to draw a path. Hence, the dimension of the search space depends mainly on the number of control points. The positions of particles are initialized randomly, and the searching range of control points was bounded by the dimensions of our environment. Increasing these limits enlarges the search space; thus, more particles are needed to search for the optimal solution, which results in more computation and slow convergence rate. The solutions are then evaluated using a ﬁtness function that will be explained in the next section. The positions of particles are then updated as mentioned in Sect. 3.2.
When the termination criteria are satisﬁed, the process ends; otherwise, we proceed with the next iteration. In the proposed algorithm, the CPSO algorithm is terminated when a maximum number of iterations are reached or when the best solution is not modiﬁed for a given number of iterations.

4.2.2 Fitness function

In our proposed algorithm, the ﬁtness function should comply with the following goals.

– Shortest distance The ﬁrst goal is to minimize the distance between the starting point, s, and the target point, t. This can be achieved by selecting control points that minimize the total distance, kPðtÞk, between s and t, and this can be formulated as follows:

min kPðtÞk; 0 t 1

ð19Þ

– Collision-free The second goal is to obtain a collisionfree path. Assume the obstacle represents a rigid body

and it is denoted by ak. For simplicity, the obstacles are represented by circles, with the center qk, where k is the number of obstacles in our problem. To obtain a

collision-free path, the safe distance, Dsafe, between the

path and the obstacles should be larger than a threshold

dmin, which represents the minimum distance between

the path and obstacles.

qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

Dsafe ¼ ðPxðtÞ À akxÞ2 þ ðPyðtÞ À akyÞ2 À rak

ð20Þ

where PxðtÞ and PyðtÞ are the coordinates of the control points of Be´zier curve, akx and aky are position of the

obstacle k, and rak represents the radius of the obstacle k. The path is feasible only if Dsafe\dmin; otherwise,

the path is not feasible. This goal can be formulated

mathematically as follows:

 infeasible path; PðtÞ ¼

Dsafe\dmin

ð21Þ

feasible path; Dsafe ! dmin

– Smoothness The third aim was to get a smooth movement of the path. This objective is satisﬁed by the second-order continuity of the path which makes the transition from one line segment to the next smooth.

The objective function of the proposed algorithm aims to achieve all the three goals, and the objective function was formulated as follows:

fitness ¼ min kPðtÞk;

(

PðtÞ 2 C2

ð22Þ

s:t:

PðtÞ 2 Pfree;

where t 2 ½0; tf  and the path moves from the s at time t ¼ 0 to the target t at time tf , C2 indicates a set of secondorder differentiable function, Pfree represents a set of collision-free paths which satisfying the constraint in Eq. (21). As indicated in Eq. (22), the goal in the ﬁrst line is to ﬁnd a path with the shortest distance (min kPðtÞk). Moreover, there are two constraints; the ﬁrst one is to ﬁnd a smooth curve and this can be obtained by making the objective function satisfy the second-order continuity which makes the transition from line segment to the next one smooth. The second constraint is responsible for obtaining a collision free path.

5 Experimental results and discussion
The experiments were carried out to evaluate the performance of the proposed CPSO algorithms to ﬁnd the optimal path planning using Be´zier curve. In this section, the results and discussions of our experimental scenarios were presented. In the ﬁrst experiment (Sect. 5.3), a comparison

123

Cluster Computing (2019) 22:S4745–S4766

S4753

between the two proposed algorithms, i.e.,, CPSO-I and CPSO-II, was presented. In the second experiment (Sect. 5.4), a comparison between the standard PSO and the two proposed algorithms was introduced. The third experiment (Sect. 5.5) was conducted to test the inﬂuence of the number of control points of the Be´zier curve on the performance of the proposed algorithm. In the fourth experiment (Sect. 5.6), the inﬂuence of different numbers of obstacles on the proposed algorithm was tested.
5.1 Experimental setup

Table 1 The detailed settings
Name
Hardware CPU Frequency RAM Hard drive
Software Operating system Language

Detailed settings
Core (TM) i5-2400 3.10 GHz 4 GB 160 GB
Windows 7 MATLAB R2012a (7.14)

In all experiments, the environment or working ﬁeld was two-dimensional (x and y), and the domains of x and y were ranged from - 10 to 10. In the ﬁrst three experiments, there were three obstacles with the same sizes. Figure 5 shows the environment of the ﬁrst three experiments. In the fourth experiment, the proposed model was tested against different numbers of obstacles. Moreover, in the fourth experiment, the positions of the obstacles were initialized randomly. In all experiments, the position of the starting and ending points were (0, 0) and (4, 6), respectively; hence, the straight distance from the starting to the ending point is 7.21. In the ﬁrst, second, and fourth experiments, the number of control points of the Be´zier curve was three. The number of the control points in the third experiment has been varied from one to ten.
The CPSO algorithm is terminated when a maximum number of iterations is reached or when the best solution is not modiﬁed for ten iterations.
In order to get an unbiased comparison of CPU times, all the experiments are performed using the same PC with the detailed settings as shown in Table 1.
For a comparison between different algorithms, the average ranks were used [47]. For each run, the methods

6

5

4

3

2

1

0

0

2

4

6

Fig. 5 The environment, i.e., working ﬁeld, of our problem with three obstacles (in red circles), the starting point (blue star), and the target point (black star) (Color ﬁgure online)

are sorted from best to worst, and the best method receives rank 1, i.e.,, the highest or best rank, the second best method receives rank 2, and so on. The average ranks are assigned in case of a tie, e.g., if two methods tie for the top rank, they both receive rank 1.5. Average ranks of all algorithms are then calculated. Moreover, the average number of collisions was also used for further comparisons between different algorithms. For each algorithm, the average number of collisions that were occurred in all runs was calculated, and a small number of collisions indicates a good result. In addition, the average of the best ﬁtness values for each algorithm was also calculated.
5.2 Parameters setting for PSO algorithm
Tuning the parameters for any optimization algorithm is important as designing the algorithm itself. In this section, the effect of the number of particles, i.e., population size, and the number of iterations on the results and computational time of the proposed model (CPSO-II) with Singer map were investigated. In this experiment, the number of the control points was three, and the number of obstacles was also three.
5.2.1 Population size
The number of particles needs to be sufﬁcient for exploring the search space. In this experiment, the effect of the population size on the results and computational time of the proposed model (CPSO-II with Singer chaotic map) was investigated when the number of particles ranged from 5 to 50 particles. The ﬁtness value and computational time of three runs are shown in Fig. 6a and b, respectively. From the ﬁgure, it is clear that increasing the number of particles improves the results, but requires more computational time. Moreover, the minimum ﬁtness value was achieved when the number of particles was more than 20.

123

S4754
Fig. 6 Effect of the number of particles on the performance of CPSO-II model with Singer map: (a) ﬁtness value of the proposed model with different numbers of particles; (b) computational time of the proposed model using different numbers of particles

Computational Time (secs)

Fitness Value

Cluster Computing (2019) 22:S4745–S4766

9 First run

8.8

Second run

Third run

8.6

8.4

8.2

8

7.8

7.6

7.4

7.2

7

5

10

15

20

25

30

35

40

45

50

Population Size

(a)

25 First run Second run Third run
20

15

10

5

0

5

10

15

20

25

30

35

40

45

50

Population Size

(b)

5.2.2 Number of iterations
The number of iterations also has a great impact on the performance of the proposed model. In this experiment, the effect of the number of iterations on the ﬁtness value and computational time of the proposed model was tested when the number of iterations was ranged from 10 to 100. The ﬁtness value and computational time of three runs are shown in Fig. 7a and b, respectively. From the ﬁgure, it can be noticed that, when the number iterations was increased, the ﬁtness value was decreased until it reached an extent at which increasing the number of iterations did not affect the results. Moreover, the computational time increased when the number of iterations was increased.
On the basis of the above parameter analysis and research results, Table 2 lists the detailed settings for the PSO algorithm that were used in our model.

5.3 First experimental scenario: CPSO-I versus CPSO-II
In this experiment, a comparison between the two proposed algorithms, i.e., CPSO-I and CPSO-II, was performed. In this experiment, the chaotic maps that are mentioned in Sect. (3.3) were used. For fair comparisons, the CPSO-I and CPSO-II algorithms with all chaotic maps were started from the same positions. In other words, the initial solutions of the CPSO-I and CPSO-II algorithms were identical with all chaotic maps. Figures 8 and 9 compare the means of the results over 60 iterations for the CPSO-I and CPSOII algorithms, respectively, for the eight different chaotic maps. Moreover, Tables 3 and 4 list the total number of collisions, average ranks, and the average of the best results, i.e., best ﬁtness values, of the CPSO-I and CPSO-II algorithms, respectively.

123

Cluster Computing (2019) 22:S4745–S4766

S4755

Fig. 7 Effect of the number of iterations on the performance of CPSO-II model with Singer map: (a) ﬁtness value of the proposed model with different numbers of iterations; (b) computational time of the proposed model using different numbers of iterations

Fitness Value

11 First run

Second run

10.5

Third run

10

9.5

9

8.5

8

7.5

7

10

20

30

40

50

60

70

80

90

100

Number of Iterations

(a)

2.5

Computational Time (secs)

2

First run

1.5

Second run

Third run

1

0.5

0

10

20

30

40

50

60

70

80

90

100

Number of Iterations

(b)

Table 2 The initial parameters of the PSO algorithm
Parameter
C1 C2 Population size Maximum number of iterations Problem dimension

Value
1.5 1.5 20 60 n

As shown in Fig. 8, the CPSO-I model using Singer chaotic map achieved results better than the other chaotic maps. Further, the Logistic and Sine maps achieved the second and third best results, respectively. Additionally, the Tent and Piecewise maps yielded the worst results. Also, there are further conclusions can be drawn from Table 3.

1. In terms of the number of collisions, Piecewise and Sine maps achieved the minimum number of collisions, while the Gauss map yielded the maximum number of collisions.
2. Regarding the average ranks, Singer and Sine maps achieved the best, i.e., minimum, average ranks, and Piecewise map revealed the worst, i.e., highest, average rank.
3. Regarding the average best ﬁtness values, Singer and Sine maps achieved the best and second best values, respectively, and the Tent map achieved the worst results.
Figure 9 presents the results of the CPSO-II algorithm. As shown, the CPSO-II algorithm using Singer chaotic map achieved the best results, and the Sine map achieved the second best results. Also, the Gauss map yielded the worst results. Also, from Table 4, it can be noticed that the

123

S4756 40 35 30 25

Cluster Computing (2019) 22:S4745–S4766

Gauss

10

Singer

Tent

Circle

9.5

Logistic

Sine

Piecewise

9

Sinusoidal

Average of best fitness values

20

8.5

56

58

60

15

10

5

0

10

20

30

40

50

60

Number of Iterations

Fig. 8 Comparison of the mean best results for CPSO-I algorithm

40

13 35
12

30

11

Gauss Singer Tent Circle Logistic Sine Piecewise Sinusoidal

25

10

9 20
8 55 56 57 58 59 60 15

Average of best fitness values

10

0

10

20

30

40

50

60

Number of Iterations

Fig. 9 Comparison of the mean best results for CPSO-II algorithm

Table 3 Comparison of the average number of collisions, average ranks, and average of best results of the CPSO-I algorithm using different chaotic maps

Map name
Gauss Singer Tent Circle Logistic Sine Piecewise Sinusoidal

Average number of collisions
23.2 22.6 21.1 19.4 14.6 10.4 10.3 16.2

Average ranks
4.1 3.7 5.2 4.6 4.9 3.7 5.9 3.9

Average of the best results
10.883 10.51 11.49 11.18 10.77 10.60 10.95 11.02

123

Cluster Computing (2019) 22:S4745–S4766

Table 4 Comparison of the average number of collisions, average ranks, and average of best results of the CPSO-II algorithm using different chaotic maps

Map name
Gauss Singer Tent Circle Logistic Sine Piecewise Sinusoidal

Average number of collisions
14.1 11.2 19.1 18.9 22.9 12.2 20.9 15.0

Average ranks
5.1 3.9 5.2 4.1 4.3 3.8 5.8 3.9

S4757
Average of the best results
14.90 10.21 11.31 10.88 10.58 10.43 11.1 10.91

Fig. 10 Surface plot for the CPSO-II algorithm with Singer map

y

50

90

40

4500 504300

8

6

4

2

0

30 40

50

−2

60

50
−4

−6

60 40 30
20

30

50

80

10

20 10

60

60

40

60

60

534000 20

70

30

80 70

50

20 30 6050 40 4500

4020

20

340500

5400

30

80

80

70

70

10

60

4200

60

30

50

10 10

30

20

20

50

40 50 30

20 20

40
20
30

30 40
50

50 60
30 40

30 40 50
60

−8

30

60

20

50

−10

40

30

10

−10

−8

−6

−4

−2

0

2

4

6

8

x

Fig. 11 Contour plot for the CPSO-II algorithm with Singer map

123

S4758

Cluster Computing (2019) 22:S4745–S4766

CPSO-II algorithm with Singer map achieved the minimum number of collisions, while the Logistic map yielded the maximum number of collisions. Moreover, in terms of the average ranks, Singer, Sine, and Sinusoidal maps achieved the best average ranks, and Piecewise map achieved the worst average ranks. In addition, concerning to the average best ﬁtness values, Singer map achieved the best result, and the Gauss map achieved the worst results.
Figures 10 and 11 shows the surface and contour plot of the ﬁtness value of the CPSO-II algorithm with Singer map, where n ¼ 3 and the environment has three obstacles. Each node or point in the contour plot or surface represents the position of the control point. In the surfaces ﬁgure, the z-axis denotes the ﬁtness value with the control points’ positions in (x, y)-plane. As shown, the ﬁtness values are approximately like a bowl shape; hence, the global solution(s) can be reached. On the other hand, there are many local optimal solutions; thus, it is not easy to ﬁnd an optimal path planning. This means that the optimized procedure to search for the optimized control curve is feasible and achieved high results. Figure 12 shows how the solutions are converged to the optimal solution(s) with different runs. As shown, despite the different initial positions of the two solutions, which are indicated by black and red lines, both were converged to two different optimal solutions.
Figures 13 and 14 show the boxplot for the results of the CPSO-I and CPSO-II algorithms. The results in Figs. 13 and 14 are in agreement with our ﬁndings. As shown, the Singer map achieved the lowest median. In addition, the median of the results using Gauss map in Fig. 14 was

Fig. 13 Boxplot for the results of CPSO-I algorithm using eight chaotic maps (Piec. for Piecewise map and Sinu. for Sinusoidal map)
higher than the other maps, this also in agreement with Fig. 9 and reﬂects that the Gauss map achieved the worst results. Moreover, the interquartile range and overall range which represent the spread of the results, of Singer map was lower than the results of the other maps. This reﬂects that the stability of the proposed algorithm using Singer map compared with the other maps. As a consequence, the results of Singer map has no outliers as in both Figs. 13 and 14, while results of some of the other maps have outliers. This reﬂects how the results using Singer map have a high level of agreement with each other and have no outliers, while some of the other results are quite different or unstable.
To conclude, the Singer map achieved the best results in both CPSO-I and CPSO-II algorithms, and the Sine map

y

8 6 4 2 0 −2
60
−4 −6 40 −8 −10 −10

20

20

30

40

50

30

60

50 40

40

50

20

30

30

60 30

40

40

50

60

−8

−6

−4

30

50

10

60

80 60 10 70 30

20 304050

50

40 10

20

40 50
80 70

60 10 20

60 30

20 50 30

40 50

40 30

20

20 30

−2

0

x

60
2

40 50 60

40

50

20 30 40 50 50
30 40 40

30
40
50 30 40

50 50 60

40

50

530400

20

7070

60

60

10

20 80

20

30

4

6

8

Fig. 12 Illustration of how the CPSO-II algorithm with Singer map converged to two different optimal solutions using. Blue arrow with a small circle indicates the initial position of both solutions (Color ﬁgure online)

123

Cluster Computing (2019) 22:S4745–S4766

S4759

Fig. 14 Boxplot for the results of CPSO-II algorithm using eight chaotic maps (Piec. for Piecewise map and Sinu. for Sinusoidal map)
achieved the second best results. Moreover, the Tent and Gauss maps achieved the worst results. Based on the results of this experiment, the Singer and Sine maps will be used in the next experiment to compare between the CPSO-I, CPSO-II, and the standard PSO algorithms.
5.4 Second experiment: CPSO-I and CPSO-II versus PSO
In this experiment, a comparison between the two proposed algorithms, i.e., CPSO-I and CPSO-II, and the standard PSO algorithm was performed. In this experiment, only the Singer and Sine chaotic maps were used with the CPSO-I and CPSO-II algorithms. As in the ﬁrst experiment, the initial solutions of the CPSO-I, CPSO-II, and PSO algorithms were identical. Figure 15 shows the means of the

results over 60 iterations for the CPSO-I, CPSO-II, and PSO algorithms. Moreover, Table 5 illustrates the average number of collisions, average ranks, and the average of the best results of the CPSO-I, CPSO-II, and PSO algorithms.
As shown from Fig. 15, both CPSO algorithms achieved results better than the standard PSO, which reﬂects how the chaotic maps improved the standard PSO algorithm. Moreover, the Singer map in both CPSO-I and CPSO-I algorithms achieved results better than the Sine map. In addition, the CPSO-II algorithm with Singer map achieved the best results. Hence, replacing the r2 parameter in CPSO-II algorithm is more efﬁcient than the other algorithms. From Table 5 many conclusions can be drawn.
1. CPSO-I-Sine, PSO, and CPSO-II-Singer achieved a small number of collisions, while the CPSO-I-Singer achieved the maximum number of collisions.
2. The CPSO-II-Sine obtained the minimum average ranks, and also the PSO yielded the highest average ranks.
3. In terms of the average of best ﬁtness values, the CPSO-II-Singer achieved the best results, and the PSO achieved the worst results.
The results of this experiment indicate that the proposed CPSO-I and CPSO-II algorithms improved the performance of the standard PSO algorithm. Thus, replacing the r1 and r2 parameters in the CPSO-I and CPSO-II algorithms, respectively, is more powerful than the standard PSO algorithm. Moreover, the CPSO-II algorithm achieved results better than the CPSO-I algorithm, and the Singer map was the most suitable for CPSO-I and CPSO-II algorithms. It is worth mentioning that, although some

40

Average of best fitness values

35
9.2
30 9

25

8.8

8.6

20

56

58

60

15

10

0

10

20

30

40

Number of Iterations

Fig. 15 Comparison of the mean best results for CPSO-I, CPSO-II, and PSO algorithms

PSO CPSO−I−Singer CPSO−I−Sine CPSO−II−Singer CPSO−II−Sine

50

60

123

S4760
Table 5 Comparison of the average number of collisions, average ranks, and average of best results of the CPSO-I, CPSO-II, and PSO algorithm

Algorithm
PSO CPSO-I-Singer CPSO-I-Sine CPSO-II-Singer CPSO-II-Sine

Average number of collisions
11.1 22.6 10.4 11.2 12.2

Cluster Computing (2019) 22:S4745–S4766

Average ranks
3.6 2.6 3.1 2.4 2.1

Average of best results
11.15 10.51 10.60 10.21 10.43

Average of best fitness values

70

12

n=1

n=2

60

11

n=3

n=4

10

n=5

50

n=6

9 40
8

n=7 n=8 n=9 n=10

30

7

56

58

60

20

10

0

0

10

20

30

40

50

60

Number of Iterations

Fig. 16 The performance of the CPSO-II algorithm with Singer chaotic map using different numbers of control points (n) (population size ¼ 20)

Fig. 17 Computational time of the proposed algorithm CPSO-II with Singer chaotic map using different numbers of control points (n) and with population size (pop.) ¼ 20 and 40

Computational Time (Secs)

180 Pop.=40

160

Pop.=60

140

120

100

80

60

40

20

0

1

2

3

4

5

6

7

8

9

10

Number of control points (n)

chaotic maps improved the performance of the PSO algorithm, some of them are not suitable at all. Based on the results of this experiment, the CPSO-II algorithm with Singer map will be used in the next two experiments.

5.5 Third experiment: different numbers of control points
The aim of this experiment is to test the inﬂuence of the number of control points on the proposed algorithm CPSO-

123

Avgerage of best fitness values

Cluster Computing (2019) 22:S4745–S4766 70 60 50 40 30 20

9.5

9

8.5

8

7.5

7

56

58

60

S4761
n=1 n=2 n=3 n=4 n=5 n=6 n=7 n=8 n=9 n=10

10

0

10

20

30

40

50

60

Number of Iterations

Fig. 18 The performance of the proposed algorithm CPSO-II with Singer chaotic map using different numbers of control points (n) (population size ¼ 40)

6

6

6

6

6

5

5

5

5

5

4

4

4

4

4

3

3

3

3

3

2

2

2

2

2

1

1

1

1

1

0 −1

0

1

2

3

4

5

6

0 −1

0

1

2

3

4

5

6

0 −1

0

1

2

3

4

5

6

0 −1

0

1

2

3

4

5

0

6

−1

0

1

2

3

4

5

6

(a) n = 1

(b) n = 2

(c) n = 3

(d) n = 4

(e) n = 5

6

5

4

3

2

1

0

−1

0

1

2

3

4

5

(f) n = 6

6

5

4

3

2

1

0

−1

0

1

2

3

4

5

6

(g) n = 7

6

6

6

5

5

5

4

4

4

3

3

2

3

2

1

2

0

1

1

−1

0 −1

0

1

2

3

4

5

6

−2 −1 0 1 2 3 4 5 6 7

0 −1

0

1

2

3

4

5

6

(h) n = 8

(i) n = 9

(j) n = 10

Fig. 19 Simulation of one run for the proposed CPSO-II algorithm using Singer map with different numbers of control points

II with Singer chaotic map. In this experiment, the number of control points was ranged from one to ten control points. This experiment has two sub-experiments. In the ﬁrst subexperiment, the population size was 20. Figures 16 and 17 show the results of this sub-experiment. The number of population size increased to 60 in the second sub-experiment. Figures 17 and 18 present the results of the second sub-experiment.
Figure 16 shows the convergence curve of the CPSO-II algorithm when the number of control points was ranged from one to ten, and when the population size was 20. As shown, the best results achieved when the number of

control points was small, i.e., n ¼ 1; 2; 3; or 4 (see Fig. 19a–d, and the results dramatically decreased when the value of n was more than ﬁve (see Fig. 19e), and the worst results achieved when n ¼ 9 and n ¼ 10 (see Fig. 19i and j). A possible explanation for these results might be that increasing the number of control points increased the search space; hence, larger population is required to obtain good results. For this reason, the population size was increased to 40 in the second sub-experiment as shown in Fig. 18. Comparing the results in Figs. 16 and 18, it can be seen that the results when the population size increased to 40, as in Fig. 18, were much better than the results in the

123

S4762

Cluster Computing (2019) 22:S4745–S4766

ﬁrst sub-experiment, as in Fig. 16, when the population size was 20. Moreover, the results when the value of n was ﬁve and six improved. However, large search spaces may require a high number of particles which may need more computational time.
Figure 17 provides the computational time of the CPSOII algorithm using different values of n. A shown, the computational time is proportional with the number of control points. Moreover, the computational time rapidly increased when the population size increased from 20 to 40.
In summary, increasing the number of control points increases the search space by adding extra dimensions. Hence, a high number of the population size is required to perfectly scan the search space to ﬁnd the optimal or near optimal solution(s). However, increasing the search space and the population size requires high computational time.
5.6 Fourth experiment: different numbers of obstacles
The goal of this experiment is to test the inﬂuence of the number of obstacles on the CPSO-II algorithm with Singer map. In this experiment, the number of obstacles was ranged from one to ten, and all obstacles were in the same size. Moreover, the obstacles were positioned randomly in the search space. Figure 20 shows the convergence curve of the CPSO-II algorithm using different numbers of obstacles. Moreover, Fig. 21 depicts the simulation of the proposed algorithm using different numbers of obstacles. In addition, Table 6 shows a comparison between the

proposed algorithm when the number of obstacles was changed.
Many remarks can be drawn from Fig. 20.
1. Increasing the number of obstacles has a negative impact on the obtained results. As shown, the worst results achieved when the number of obstacles was nine and ten (see Fig. 21i and j), and the best results were achieved when small numbers of obstacles were used. This is because increasing the number of obstacles may increase the collisions (see Table 6, Fig. 21), which may increase the distance from the starting to the ending points.
2. As shown in Fig. 21, the CPSO-II algorithm reached to the near optimal solution faster when the number of obstacles was small. In other words, small number of obstacles may result in a straight line (see Fig. 21a and b), i.e., optimal solution, between the starting and ending points; on the other hand, increasing the number of obstacles increases the distance of the optimal curve (see Fig. 21g and i).
As illustrated in Table 6, the number of collisions is proportional with the number of obstacles, and the maximum number of collisions is achieved when the number of obstacles was ten. Moreover, from the table, the best average ranks and average best ﬁtness value were achieved when the number of obstacles was small. It seems possible that these high numbers of collisions are due to the small environment in our experiments. Despite this high collision numbers, our proposed algorithm found the optimal path in most cases, and the number of collisions may be reduced

Average of best fitness values

35

45 30

11

40

25

10.5

20

10

35

9.5

15

30

9

10

8.5

25

2

4

6

8

8

20

7.5

7

15

56

58

60

Obst=1 Obst=2 Obst=3 Obst=4 Obst=5 Obst=6 Obst=7 Obst=8 Obst=9 Obst=10

10

5

5

10

15

20

25

30

35

40

45

50

55

60

Number of Iterations

Fig. 20 The performance of the CPSO-II algorithm with Singer chaotic map using different numbers of obstacles

123

Cluster Computing (2019) 22:S4745–S4766

S4763

6

5

4

3

2

1

0

0

2

4

(a) n = 1

6

6

6

6

5

5

5

5

4

4

4

4

3

3

3

3

2

2

2

2

1

1

1

1

6

0 0

1

2

3

4

5

6

7

0 −1

0

1

2

3

4

5

6

7

0 0

1

2

3

4

5

6

0

7

−1

0

1

2

3

4

5

6

7

(b) n = 2

(c) n = 3

(d) n = 4

(e) n = 5

6

5

4

3

2

1

0

0

1

2

3

4

5

6

7

(f) n = 6

6
6 5
5 4
4 3
3
2 2

1

1

0 −1

0

1

2

3

4

5

6

0

0

1

2

3

4

5

6

7

(g) n = 7

(h) n = 8

6 6
5

4

5

3

4

2

3

1

2

0

1

−1

−1

0

1

2

3

4

5

6

7

0

0

1

2

3

4

5

6

7

(i) n = 9

(j) n = 10

Fig. 21 Simulation of one run for the proposed CPSO-II algorithm using Singer map with different numbers of obstacles

Table 6 The results (average number of collisions, average ranks, and average of best ﬁtness values) of the CPSO-II algorithm with Singer map using different numbers of obstacles

No. of obstacles
1 2 3 4 5 6 7 8 9 10

Average number of collisions
3.7 1.6 2.5 3.1 4.7 6.0 5.3 9.3 13.7 15.2

Average ranks
0.5 0.5 1.3 2.5 2.4 3.6 4 4.2 5.8 7.4

Average of best results
8.04 7.71 8.22 8.45 8.29 8.57 8.74 8.89 12.86 12.86

Fig. 22 Comparison between the proposed algorithms and the PRM and Ferguson curves. The unit of Path length depends on the scale of your problem [in our case the unit is meter (m)]
by extending the space of the environment to be consistent with real applications.

To sum up, increasing the number of obstacles increases the difﬁculty of the problem and may lead to a high number of collisions which is not feasible for real-time applications.
To further prove that our approach is better than other related work, as illustrated in Fig. 22, a comparison with two of the state-of-the-art algorithms, namely, Ferguson curve [33], and Probabilistic Road Map (PRM) [48] was conducted. As shown, this experiment was conducted using three, four, and ﬁve obstacles. From this ﬁgure, it can be remarked that both CPSO-I and CPSO-II achieved path shorter than the PRM and Ferguson curves.
To conclude, the proposed algorithm, i.e., CPSO, achieved results better than the standard PSO algorithm. Moreover, the CPSO-II algorithm achieved results better than the CPSO-I, and Singer map was suitable for both algorithms. In addition, the CPSO-II algorithm revealed competitive results with a high number of obstacles. However, due to the stochastic nature of CPSO algorithms, CPSO algorithms are never guaranteed to ﬁnd an optimal

123

S4764

Cluster Computing (2019) 22:S4745–S4766

solution for any problem, but they will often ﬁnd a good solution if one exists.
6 Conclusions
Path planning is widely used for different applications such as mobile robotics and tracking for nonholonomic vehicles. There are many algorithms used to ﬁnd the path planning such as Ferguson curve, PRM, and Be´zier curve. In this paper, Be´zier curve was used for path planning. However, the control points of the Be´zier curve have a signiﬁcant impact on ﬁnding the optimal smooth path that minimizes the total distance between the starting and ending points. This study proposes two variants of the Chaotic Particle Swarm Optimization (CPSO), namely, CPSO-I and CPSOII, algorithms that can be employed to search for the optimal path. In this paper, the ﬁrst experiment was conducted to test the results of the two proposed algorithms using different chaotic maps. The results of this experiment showed that the Singer and Sine maps were suitable for both algorithms. The second experiment was conducted to compare between the CPSO-I, CPSO-II, and PSO algorithms, and the results of this experiment revealed that (1) the CPSO-II algorithm achieved the best results, and (2) replacing random parameters with chaotic maps in the PSO algorithm improved the performance of the PSO. In the third experiment, the inﬂuence of the number of control points was tested. The results proved that increasing the number of control points extends the search space by adding extra dimensions; and hence, a high number of population size for the PSO are required to scan the search space perfectly. In the last experiment, the CPSO-II algorithm was tested against different numbers of obstacles, and the results proved that increasing the number of obstacles increases the difﬁculty of the problem. However, the proposed algorithm found the optimal path in most cases.
Several directions for future studies are suggested. First, the experiments in this paper were performed using only a static environment, but a dynamic environment, i.e., moving obstacles, should be tested in the future to verify and extend the proposed algorithm. Second, searching for the optimal path in a three-dimensional environment should be tested in the future to simulate real robots’ movements.
Compliance with ethical standards
Conflict of interest The authors declare that there is no conflict of interests regarding the publication of this paper.

References
1. Elhoseny, M., Tharwat, A., Farouk, A., Hassanien, A.E.: K-coverage model based on genetic algorithm to extend wsn lifetime. IEEE sensors letters 1(4), 1–4 (2017)
2. Li, R., Wu, W., Qiao, H.: The compliance of robotic hands-from functionality to mechanism. Assem. Autom. 35(3), 281–286 (2015)
3. Robinson, D.C., Sanders, D.A., Mazharsolook, E.: Ambient intelligence for optimal manufacturing and energy efﬁciency. Assem. Autom. 35(3), 234–248 (2015)
4. Manikas, T.W., Ashenayi, K., Wainwright, R.L.: Genetic algorithms for autonomous robot navigation. IEEE Instrum. Meas. Mag. 10(6), 26–31 (2007)
5. Metawa, N., Hassan, M.K., Elhoseny, M.: Genetic algorithm based model for optimizing bank lending decisions. Expert Syst. Appl. 80, 75–82 (2017)
6. Elhoseny, M., Shehab, A., Yuan, X.: Optimizing robot path in dynamic environments using genetic algorithm and bezier curve. J. Intell. Fuzzy Syst. 33(4), 2305–2316 (2017)
7. Tharwat, A.: Linear vs. quadratic discriminant analysis classiﬁer: a tutorial. Int. J. Appl. Pattern Recognit. 3(2), 145–180 (2016)
8. Elhoseny, M., Tharwat, A., Hassanien, A.E.: Bezier curve based path planning in a dynamic ﬁeld using modiﬁed genetic algorithm. J. Comput. Sci. (2017). https://doi.org/10.1016/j.jocs.2017. 08.004
9. Roberge, V., Tarbouchi, M., Labonte´, G.: Comparison of parallel genetic algorithm and particle swarm optimization for real-time uav path planning. IEEE Trans. Ind. Inform. 9(1), 132–141 (2013)
10. Contreras-Cruz, M.A., Ayala-Ramirez, V., Hernandez-Belmonte, U.H.: Mobile robot path planning using artiﬁcial bee colony and evolutionary programming. Appl. Soft Comput. 30, 319–328 (2015)
11. Das, P., Behera, H., Panigrahi, B.: A hybridization of an improved particle swarm optimization and gravitational search algorithm for multi-robot path planning. Swarm Evol. Comput. 28, 14–28 (2016)
12. Ga´lvez, A., Iglesias, A., Cabellos, L.: Tabu search-based method for Be´zier curve parameterization. Int. J. Softw. Eng. Appl. 7, 283–296 (2013)
13. Li, B., Liu, L., Zhang, Q., Lv, D., Zhang, Y., Zhang, J., Shi, X.: Path planning based on ﬁreﬂy algorithm and Bezier curve. In: IEEE International Conference on Information and Automation (ICIA), IEEE, pp. 630–633 (2014)
14. Arana-Daniel, N., Gallegos, A.A., Lo´pez-Franco, C., Alanis, A.Y.: Smooth global and local path planning for mobile robot using particle swarm optimization, radial basis functions, splines and Bezier curves. In: IEEE Congress on Evolutionary Computation (CEC), IEEE, pp. 175–182 (2014)
15. Ziolkowski, M., Gratkowski, S.: Genetic algorithm coupled with Be´zier curves applied to the magnetic ﬁeld on a solenoid axis synthesis. Arch. Electr. Eng. 65(2), 361–370 (2016)
16. Kennedy, J.: Particle swarm optimization. In: Encyclopedia of Machine Learning. Springer, New York, pp. 760–766 (2010)
17. Maitra, M., Chatterjee, A.: A hybrid cooperative-comprehensive learning based pso algorithm for image segmentation using multilevel thresholding. Expert Syst. Appl. 34(2), 1341–1350 (2008)
18. Ibrahim, A., Tharwat, A., Gaber, T., Hassanien, A.E.: Optimized superpixel and adaboost classiﬁer for human thermal face recognition. Signal Image Video Process. (2017). https://doi.org/ 10.1007/s11760-017-1212-6

123

Cluster Computing (2019) 22:S4745–S4766

S4765

19. Tharwat, A., Hassanien, A.E., Elnaghi, B.E.: A ba-based algorithm for parameter optimization of support vector machine. Pattern Recogn. Lett. 93, 13–22 (2017)
20. Tharwat, A., Gaber, T., Ibrahim, A., Hassanien, A.E.: Linear discriminant analysis: a detailed tutorial. AI Commun. 30(2), 169–190 (2017)
21. Subasi, A.: Classiﬁcation of emg signals using pso optimized svm for diagnosis of neuromuscular disorders. Comput. Biol. Med. 43(5), 576–586 (2013)
22. Van der Merwe, D., Engelbrecht, A.P.: Data clustering using particle swarm optimization. In: The 2003 Congress on Evolutionary Computation, CEC’03, vol. 1., IEEE, pp. 215–220 (2003)
23. Tharwat, A.: Principal component analysis-a tutorial. Int. J. Appl. Pattern Recogn. 3(3), 197–240 (2016)
24. Vesterstrom, J., Thomsen, R.: A comparative study of differential evolution, particle swarm optimization, and evolutionary algorithms on numerical benchmark problems. In: Congress on Evolutionary Computation, CEC2004, vol. 2, IEEE, pp. 1980–1987 (2004)
25. Miyatake, M., Veerachary, M., Toriumi, F., Fujii, N., Ko, H.: Maximum power point tracking of multiple photovoltaic arrays: a pso approach. IEEE Trans. Aerosp. Electron. Syst. 47(1), 367–380 (2011)
26. Molazei, S., Ghazizadeh-Ahsaee, M.: Mopso algorithm for distributed generator allocation. In: Fourth International Conference on Power Engineering, Energy and Electrical Drives (POWERENG), IEEE, pp. 1340–1345 (2013)
27. Gandomi, A.H., Yang, X.S.: Chaotic bat algorithm. J. Comput. Sci. 5(2), 224–232 (2014)
28. Wang, G.G., Guo, L., Gandomi, A.H., Hao, G.S., Wang, H.: Chaotic krill herd algorithm. Inf. Sci. 274, 17–34 (2014)
29. Gharooni-fard, G., Moein-darbari, F., Deldari, H., Morvaridi, A.: Scheduling of scientiﬁc workﬂows using a chaos-genetic algorithm. Proc. Comput. Sci. 1(1), 1445–1454 (2010)
30. Talatahari, S., Azar, B.F., Sheikholeslami, R., Gandomi, A.: Imperialist competitive algorithm combined with chaos for global optimization. Commun. Nonlinear Sci. Numer. Simul. 17(3), 1312–1319 (2012)
31. Gandomi, A., Yang, X.S., Talatahari, S., Alavi, A.: Fireﬂy algorithm with chaos. Commun. Nonlinear Sci. Numer. Simul. 18(1), 89–98 (2013)
32. Ma, Y., Zamirian, M., Yang, Y., Xu, Y., Zhang, J.: Path planning for mobile objects in four-dimension based on particle swarm optimization method with penalty function. In: Mathematical Problems in Engineering (2013)
33. Liang, J., Song, H., Qu, B., Liu, Z.: Comparison of three different curves used in path planning problems based on particle swarm optimizer. In: Mathematical Problems in Engineering (2014)
34. Sahingoz, O.K.: Generation of Bezier curve-based ﬂyable trajectories for multi-uav systems with parallel genetic algorithm. J. Intell. Robotic Syst. 74(1–2), 499–511 (2014)
35. Gardner, B., Selig, M.: Airfoil design using a genetic algorithm and an inverse method. In: 41st Aerospace Sciences Meeting and Exhibit, pp. 1–12 (2003)
36. Jolly, K., Kumar, R.S., Vijayakumar, R.: A Bezier curve based path planning in a multi-agent robot soccer system without violating the acceleration limits. Robot. Auton. Syst. 57(1), 23–33 (2009)
37. Giannakoglou, K.: A design method for turbine-blades using genetic algorithms on parallel computers. Comput. Fluid Dyn. 98(1), 1–2 (1998)
38. Chen, L., Wang, S., Hu, H., McDonald-Maier, K.: Be´zier curve based trajectory planning for an intelligent wheelchair to pass a doorway. In: International Conference on Control (CONTROL), IEEE, pp. 339–344 (2012)

39. Choi, J.w., Curry, R., Elkaim, G.: Path planning based on Be´zier curve for autonomous ground vehicles. In: Advances in Electrical and Electronics Engineering-IAENG Special Edition of the World Congress on Engineering and Computer Science, (WCECS’08), IEEE, pp. 158–166 (2008)
40. Wagner, R., Birbach, O., Frese, U.: Rapid development of manifold-based graph optimization systems for multi-sensor calibration and slam. In: 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, pp. 3305–3312 (2011)
41. Heppner, F., Grenander, U.: A stochastic nonlinear model for coordinated bird ﬂocks. Ubiquity Chaos 99, 233–238 (1990)
42. Reynolds, C.W.: Flocks, herds and schools: a distributed behavioral model. ACM Siggraph Comput. Graph. 21(4), 25–34 (1987)
43. Eberhart, R.C., Kennedy, J.: A new optimizer using particle swarm theory. In: Proceedings of the 6th International Symposium on Micro Machine and Human Science, vol. 1., New York, pp. 39–43 (1995)
44. Yang, X.S.: Nature-Inspired Optimization Algorithms, 1st edn. Elsevier, Amsterdam (2014)
45. Ren, B., Zhong, W.: Multi-objective optimization using chaos based pso. Inf. Technol. J. 10(10), 1908–1916 (2011)
46. Vohra, R., Patel, B.: An efﬁcient chaos-based optimization algorithm approach for cryptography. Commun. Netw. Secur. 1(4), 75–79 (2012)
47. Demsˇar, J.: Statistical comparisons of classiﬁers over multiple data sets. J. Mach. Learn. Res. 7, 1–30 (2006)
48. Masehian, E., Sedighizadeh, D.: A multi-objective pso-based algorithm for robot path planning. In: Proceedings of IEEE International Conference on Industrial Technology (ICIT), IEEE, pp. 465–470 (2010)
Alaa Tharwat is a lecturer at the Faculty of Engineering, Suez Canal University, Ismailia, Egypt. His research interest includes evolutionary computing, image processing, and quantum computing. He has several Publications in reputed and high impact journals like Nature Scientiﬁc Reports, QINP, and Security and Communications. He has publications in international conferences held by IEEE, Springer and ACM.
Mohamed Elhoseny received his Ph.D. in Computer and Information Sciences from Mansoura University Egypt (in a scientiﬁc research channel with Department of Computer Science and Engineering, University of North Texas, USA ). His Ph.D. thesis was awarded the best Ph.D. thesis prize (2016) at Mansoura University. Dr. Elhoseny is currently an Assistant Professor at the Faculty of Computers and Information, Mansoura University, Egypt Collectively, Dr. Elhoseny authored/co-authored over 50 International Journal articles, Conference Proceedings, Book Chapters, and 1

123

S4766

Cluster Computing (2019) 22:S4745–S4766

Springer brief book. His research interests include Network Security, Cryptography, Machine Learning Techniques, Internet of Things, and Quantum Computing. He has several publications in reputed and high impact journals published by IEEE, Elsevier, Springer, and others. Dr. Elhoseny is a TPC Member or Reviewer in 30? International Conferences and Workshops. Furthermore, he has been reviewing papers for 20? International Journals.
Aboul Ella Hassanien is a Professor at Cairo University, Faculty of Computers & Information. He is the founder and Chair of the Scientiﬁc Research Group in Egypt (SRGE). He is the Ex-Dean of faculty of computers and Information, Beni-Suef University, Egypt.

foundations of machine learning, multi-agent systems and decentralized control as well as on the practical implementation and deployment of adaptive agent-based applications in domains like recommender systems, mobile applications, robotics, or computer games.

researchers across the globe.

Arun Kumar has completed in his B.E., M.E. and Ph.D. in Electronics and Communication Engineering with specialization in Biomedical Engineering. He has a strong academic teaching and research experience of more than 10 years in SASTRA University, India. He is appreciated for his innovative research oriented teaching related practical life experiences to the principles of engineering. He is active in research and has been giving directions to active

Thomas Gabel is a Professor for Computer Science and Mathematics with focus on machine learning and artiﬁcial intelligence at the Faculty of Computer Science and Engineering at Frankfurt University of Applied Sciences. Thomas’ interests in research and development cover various aspects of learning and intelligent systems. He is fascinated by the idea of creating adaptive software that learns autonomously how to solve a task or how to support a human in a smart way. He has focused on both, theoretical

123

