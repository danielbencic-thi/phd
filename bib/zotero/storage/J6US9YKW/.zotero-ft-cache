IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Loading [MathJax]/extensions/MathZoom.js

Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

    Cart 
    Create Account
    Personal Sign In

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
ADVANCED SEARCH
Conferences > 2021 IEEE/RSJ International C...
Unsupervised Path Regression Networks
Publisher: IEEE
Cite This
PDF
Michal Pándy ; Daniel Lenton ; Ronald Clark
All Authors
30
Full
Text Views

    Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Related Work
    III.
    Approach
    IV.
    Datasets and baselines
    V.
    Evaluation

Show Full Outline
Authors
Figures
References
Keywords
Metrics
Abstract:
We demonstrate that challenging shortest path problems can be solved via direct spline regression from a neural network, trained in an unsupervised manner (i.e. without requiring ground truth optimal paths for training). To achieve this, we derive a geometry-dependent optimal cost function whose minima guarantees collision-free solutions. Our method beats state-of-the-art supervised learning baselines for shortest path planning, with a much more scalable training pipeline, and a significant speedup in inference time.
Published in: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Date of Conference: 27 Sept.-1 Oct. 2021
Date Added to IEEE Xplore : 16 December 2021
ISBN Information:
ISSN Information:
INSPEC Accession Number: 21406990
DOI: 10.1109/IROS51168.2021.9636818
Publisher: IEEE
Conference Location: Prague, Czech Republic
SECTION I.
Introduction

Motion planning is essential for most robotics and embodied AI applications, but is also an exceptionally difficult problem for multiple reasons. Firstly, the planner is often required to find paths of minimal length in order to minimize power consumption and execution time. Secondly, a usable path must avoid obstacles (taking quadcopter as an example, a collision might cause fatal damage). Thirdly, the motion of many real systems (e.g., robot arms) is limited by the controllable actuators and this limits the set of feasible trajectories. Finally, real-world robots are limited to partial observations of their surroundings, acquired from on-board sensors.

Existing methods based on sampling, grid, or tree searches successfully avoid obstacles by querying points in the configuration space and checking whether collisions occur. These approaches are accurate and have high success rates, but their run-time can be prohibitive. These limitations are addressed by gradient-based planners , which can efficiently find smooth trajectories. However, formulating a suitable cost function for these approaches is challenging as the two terms, collision cost and path length, are inherently conflicting. The collision cost is a hard binary constraint that is non-differentiable by nature. The most common approach to address this is to relax the collision cost by a soft signed distance function, but this has two major disadvantages:

    The relaxed cost function does not guarantee the shortest paths to be found at its optimum.

    A hyperparameter which trades between collision and path length needs to be tuned (see Fig. 1 ).

In this paper we propose to train a network that directly regresses an entire path from start to goal in a single forward pass, by minimising a novel unsupervised cost function at training time. The cost function we propose is similar in form to those in the optimization-based planning literature [40] , [29] , but unlike existing methods, our novel formulation guarantees collision-free shortest paths to be found at the minima, which is the main contribution of this work. The trained network is conditioned on some form of scene description, but our method does not limit the parameterization of the scene description. For example, we show that our method works with scenes specified as a list of objects (their locations and shapes), and also with scenes parameterized as an RGBD image. This makes our approach applicable for sim-to-real learning, where we can leverage the full state of the simulator to construct the optimal loss at training time, to train a network which only receives image observations at inference time.
Fig. 1:

Path length and collision cost are conflicting objectives. Here, we show an application of motion planning where a robot arm needs to estimate a path to move the cup from a start configuration to a target configuration. Most planning methods tune a weighted combination of path length l and collision c to find a path. In this paper, we design l and c to guarantee collision-free paths to be found at the optimum of the cost function and avoid the need for a weighting between the two objectives.

Show All

We demonstrate state-of-the-art performance for learning-only approaches on benchmark tasks, including point-mass path-planning in 3D space and reaching target joint configurations in the presence of obstacles for a 6-DoF robotic manipulator. Importantly, our method does not need to pre-compute a dataset of shortest paths for training, so we are also able to reduce total training time by almost two orders of magnitude compared to supervised approaches.
SECTION II.
Related Work

For low-dimensional problems ( < 3 DoF), graph-based planners are efficient and can find optimal solutions. These approaches construct a graph by discretizing the space and connecting neighboring cells. The shortest path can then be found using variations of dynamic programming [8] , [13] , [14] , [7] . However, these approaches quickly become intractable when moving to higher dimensions.

For a problem with more degrees of freedom ( > 3 DoF), sample-based planners such as rapidly-exploring random tree (RRT) and probabilistic roadmap (PRM) are the most popular approaches. These planners dynamically build a network of paths at run-time by attempting to connect nodes which are sampled in continuous space [2] , [22] , [20] , [21] . Although these methods exhibit probabilistic convergence guarantees, their runtime performance is prohibitive for many real-world applications, and the paths produced are generally jerky, requiring post-processing.

Continuous planners that do not rely on discretizing the space can find smooth solutions more efficiently. Potential field planners , for example, model obstacles as a repulsive force and model path length as an attractive force [31] , [5] , [12] . However, these methods easily get stuck in local minima and typically require a good initial path estimate from sample-based planners.

Advances in optimization -based planners [40] , [19] , [30] , [34] have demonstrated that paths can be optimized directly from naive initial guesses, with no sample-based planners involved. Apart from the difficulty with tuning a cost function for a specific scene, the requirement for multiple gradient steps at inference time can be prohibitive in dynamic contexts requiring fast robotic responses.

Deep learning -based methods such as [32] , [35] , [3] , [4] , [38] train networks to iteratively predict trajectories that bring the agents closer to target state. These methods use ground-truth paths computed using a standard planner to serve as training examples. Apart from the significant computational overhead associated with generating such ground-truth paths, these approaches may also be susceptible to biases created by employing traditional planners to generate the training samples [18] .

The need for ground-truth paths can be overcome by using reinforcement learning. [9] , [28] , [16] , [25] , [1] . However, reinforcement learning-based approaches are often very sample-inefficient, particularly when learning from sparse rewards, requiring many trials to train. These approaches can also often struggle to generalize between different tasks and environments.
SECTION III.
Approach

In this section, we describe our approach for learning to find shortest collision-free paths. A high-level overview of our approach is illustrated in Figure 2 . We use a neural network (described in Section III-C ) to regress a path parameterized as a spline (further described in Section III-B ). Finally, we calculate the path’s cost using our novel cost function (derived in Section III-A ) and update the network weights using stochastic gradient descent. In the next sections, we give a detailed description of each of these three components.
Fig. 2:

Overview of our method. The solid green arrows indicate data flow at inference time. The solid red arrows indicate data flow at training time. The dotted red arrows indicate gradient flow, which is used to update the weights of the network. If a scene description is available at run-time, the weights can also be updated at test time to refine the path.

Show All
A. Cost function derivation

In this section, we outline the full derivation of our cost function. As mentioned before, the critical challenge in formulating a smooth cost function for shortest path planning lies in the fact that collision avoidance is a hard constraint, which is often replaced by soft penalty terms. Finding a weighting between collision and path length terms is challenging, as they are not directly comparable. For this reason, standard optimization-based methods [34] , [40] require per-task or per-scene calibration, limiting their ability to generalize across diverse sets of scenes. Hence, we derive a novel formulation that guarantees collision-free paths, invariant to scene scaling.

Let O be a set of arbitrary obstacles, Π be a set of corresponding obstacle observations, s ∈ ℝ d be a start configuration, t ∈ ℝ d be a target configuration, and θ p ∈ Θ p a path parameterization. We aim to optimize the path planning function:
f θ ( Π , s , t ) = θ p (1)
View Source \begin{equation*}{f_\theta }(\Pi ,s,t) = {\theta _p}\tag{1}\end{equation*}

To successfully optimize f θ , we define a loss function:
C ( O , θ p ) (2)
View Source \begin{equation*}\mathcal{C}\left( {O,{\theta _p}} \right)\tag{2}\end{equation*}

In our work, we aim to optimize f θ to converge to paths that are shortest and collision-free. This assumption naturally leads to C having components penalising collisions and path lengths. Hence, we write:
C ( O , θ p ) = l ( θ p ) + c ( O , θ p ) (3)
View Source \begin{equation*}\mathcal{C}\left( {O,{\theta _p}} \right) = l\left( {{\theta _p}} \right) + c\left( {O,{\theta _p}} \right)\tag{3}\end{equation*} where l and c are length and collision penalty measures, respectively. While the exact structure of c is unknown for now, we can already point out useful properties it should have. Suppose the optimization problem has an optimal path parameterized by θ opt ∈ Θ p . Then, we require:

    Minimum property (MP) :
    ∀ θ p ∈ Θ p : c ( O , θ o p t ) ≤ c ( O , θ p )
    View Source \begin{equation*}\forall {\theta _p} \in {\Theta _p}:c\left( {O,{\theta _{opt}}} \right) \leq c\left( {O,{\theta _p}} \right)\end{equation*}

    Non-colliding property (NP) :
    ∀ θ p ∈ Θ p : θ p  does not collide  ⇔ c ( O , θ p ) = 0
    View Source \begin{equation*}\forall {\theta _p} \in {\Theta _p}:{\theta _p}{\text{ does not collide }} \Leftrightarrow c\left( {O,{\theta _p}} \right) = 0\end{equation*}

Further, since we require that C is a valid cost function, we have:

    Global optima property (GP) :
    ∀ θ p ∈ Θ p : C ( O , θ o p t ) ≤ C ( O , θ p ) ⇔ l ( θ o p t ) + c ( O , θ o p t ) ≤ l ( θ p ) + c ( O , θ p ) ⇔ l ( θ o p t ) − l ( θ p ) ≤ c ( O , θ p )
    View Source \begin{equation*}\begin{array}{c} {\forall {\theta _p} \in {\Theta _p}:\mathcal{C}\left( {O,{\theta _{opt}}} \right) \leq \mathcal{C}\left( {O,{\theta _p}} \right)} \\ { \Leftrightarrow l\left( {{\theta _{opt}}} \right) + c\left( {O,{\theta _{opt}}} \right) \leq l\left( {{\theta _p}} \right) + c\left( {O,{\theta _p}} \right)} \\ { \Leftrightarrow \quad l\left( {{\theta _{opt}}} \right) - l\left( {{\theta _p}} \right) \leq c\left( {O,{\theta _p}} \right)} \end{array}\end{equation*}

In general, we have an underlying assumption that a non-colliding solution to the planning problem exists. We propose that any formulation of C with c satisfying the three properties above, will have its minima in paths which are non-colliding and shortest possible. To show that θ opt is non-colliding, assume for contradiction that θ opt is colliding and take an arbitrary θ′ ∈ Θ p that is non-colliding. Then, by NP we have c ( O, θ opt ) > 0, and so by MP necessarily also c ( O, θ′ ) > 0. This by NP however means that θ′ is colliding and we have a contradiction. To show that θ opt is shortest possible, we show that ∀ θ′ ∈ Θ p : l ( θ′ ) < l ( θ opt ) ⇒ θ′ collides. Hence, for arbitrary θ′ ∈ Θ p assume that l ( θ′ ) < l ( θ opt ). Then by GP and our assumption, we have 0 < l ( θ opt ) −l ( θ′ ) ≤ c ( O, θ′ ). By NP and c ( O, θ′ ) > 0 we finally have that θ′ collides.

Now, to define a loss function C which we can optimize, we have to define c that satisfies NP, MP, GP. One option for picking c is:
c ( O , θ p ) = ∑ o ∈ O 1 o ( θ p ) ∗ R ( o ) 1 o ( θ p ) = { 1 if path given by  θ p  collides with  o 0 otherwise (4) (5)
View Source \begin{align*} & c\left( {O,{\theta _p}} \right) = \sum\limits_{o \in O} {{1_o}} \left( {{\theta _p}} \right)*R(o)\tag{4} \\ & {1_o}\left( {{\theta _p}} \right) = \begin{cases} 1\quad{{\text{if path given by }}{\theta _p}{\text{ collides with }}o} \\ 0\quad{{\text{otherwise}}} \end{cases}\tag{5}\end{align*} where R ( o ) is defined to be the bounding sphere circumference of object o ∈ O. It is possible to formally show that this formulation satisfies NP, MP, and GP. The intuition behind the proof is that object circumference collision penalties always yield non-colliding minimal paths, as the path can simply travel around the obstacle to minimize the cost. Therefore, the loss function that we propose takes the form:
C ( O , θ p ) = l ( θ p ) + ∑ o ∈ O 1 o ( θ p ) ∗ R ( o ) (6)
View Source \begin{equation*}\mathcal{C}\left( {O,{\theta _p}} \right) = l\left( {{\theta _p}} \right) + \sum\limits_{o \in O} {{1_o}} \left( {{\theta _p}} \right)*R(o)\tag{6}\end{equation*}

B. Path Parameterization

In the previous section, we describe a cost function C which we can use to optimize a planning function f θ not requiring any additional hyperparameter tuning. In this section, we consider a possible parameterization of θ p so that C is differentiable, and we may optimize f θ using stochastic gradient descent.

As noted in the introduction, we are aiming to train path regression networks. In contrast to iterative approaches such as [32] , [38] , which require input from the previous agent state s t ∈ ℝ d to infer the next state s t+1 ∈ ℝ, we instead use f θ to predict paths from the start configuration to the goal configuration in one inference step. This way, we can ensure a good f θ inference speed both at train and at test time. While letting θ p ∈ Θ p be a fixed sized unrolling of states in the task space is possible, this would require a large cardinality of θ p , for f θ to be able to express complex smooth paths. This approach in practice is hard to optimize and would incur significant inference speed penalties. As with other works [17] , [26] , [39] , [27] , we consider a parameterization where θ p = { ( p k , w k ) ∣ p k ∈ R d , w k ∈ [ 0 , 1 ] , k ∈ { 1 , 2 , … , n } } and n ∈ N > 0 is a problem specific task complexity parameter. With such parameterization, we can use θ p to define a path in the form of a non-uniform rational B-spline (NURBS) with control points p k , control point weights w k , a default open-uniform knot vector to anchor the spline in the start and goal configurations, and a degree parameter p ∈ N > 0 . In practice, p > 1 is sufficient for most setups.

Now, for an arbitrary θ p ∈ Θ p and object set O we show how to approximate C ( O , θ p ) using our NURBS parameterization. We achieve this by evaluating the θ p NURBS interpolation with a high enough sampling rate 1 /s for each value in B : = { s ∗ k ∣ 0 ≤ s ∗ k ≤ n − p , k ∈ N } . Let N : Θ p × B → R d be the NURBS interpolation.

In case of the length component l ( θ p ), we have:
l ( θ p ) = ∫ n − p 0 ∥ N ( θ p , x ) ∥ d x = lim δ x → 0 ∑ x = 0 n − p ∥ N ( θ p , x ) ∥ δ x ≈ ∑ x ∈ { 0 , s , 2 s , … } n − p − s ∥ N ( θ p , x + s ) − N ( θ p , x ) ∥ (7)
View Source \begin{equation*}\begin{array}{c} l\left( {{\theta _p}} \right) = \int_0^{n - p} {\left\| {N\left( {{\theta _p},x} \right)} \right\|} dx = \mathop {\lim }\limits_{\delta x \to 0} \sum\limits_{x = 0}^{n - p} {\left\| {N\left( {{\theta _p},x} \right)} \right\|} \delta x \\ \approx \sum\limits_{x \in \{ 0,s,2s, \ldots \} }^{n - p - s} {\left\| {N\left( {{\theta _p},x + s} \right) - N\left( {{\theta _p},x} \right)} \right\|} \end{array} \tag{7}\end{equation*}

In case of the collision component c ( O, θ p ), we first define an object selector function:
τ ( O , X p ) = arg min o ∈ O S D F ( o , X p ) (8)
View Source \begin{equation*}\tau \left( {O,{X_p}} \right) = \mathop {\arg \min }\limits_{o \in O} SDF\left( {o,{X_p}} \right)\tag{8}\end{equation*}

Where X p ∈ ℝ d and SDF is a differentiable signed distance function. Now, we define a point cost function:
c ^ ( X p , O , θ p ) = { R ( τ ( O , X p ) ) Δ ( X p , O , θ p ) SDF ( τ ( O , X p ) , X p ) < 0 0 o t h e r w i s e (9)
View Source \begin{equation*} \hat c\left( {{X_p},O,{\theta _p}} \right) = \begin{cases} {\frac{{R\left( {\tau \left( {O,{X_p}} \right)} \right)}}{{\Delta \left( {{X_p},O,{\theta _p}} \right)}}}\quad{\operatorname{SDF} \left( {\tau \left( {O,{X_p}} \right),{X_p}} \right) < 0} \\ 0\quad{otherwise} \end{cases}\tag{9}\end{equation*} with Δ providing the number of configurations along θ p which collide with the same object as a given configuration, simply defined as:
Δ ( X p , O , θ p ) = ∑ X ∈ { 0 , s , 2 s , … } n − p δ τ ( O , N ( θ p , X ) ) τ ( O , X p ) (10)
View Source \begin{equation*}\Delta \left( {{X_p},O,{\theta _p}} \right) = \sum\limits_{X \in \{ 0,s,2s, \ldots \} }^{n - p} {\delta _{\tau \left( {O,{X_p}} \right)}^{\tau \left( {O,N\left( {{\theta _p},X} \right)} \right)}} \tag{10}\end{equation*}

Note that Δ is always greater than 0, due to the branching condition in c p , as every colliding point has at least itself as a corresponding colliding point with the same object. Hence, we can finally write c under the NURBS parameterization as:
c ( O , θ p ) = ∑ o ∈ O 1 o ( θ p ) ∗ R ( o ) = ∑ x ∈ { 0 , s , 2 s , … } n − p c ^ ( N ( θ p , x ) , O , θ p ) (11)
View Source \begin{equation*}\begin{array}{c} c\left( {O,{\theta _p}} \right) = \sum\limits_{o \in O} {{1_o}} \left( {{\theta _p}} \right)*R(o) \\ = \sum\limits_{x \in \{ 0,s,2s, \ldots \} }^{n - p} {\hat c} \left( {N\left( {{\theta _p},x} \right),O,{\theta _p}} \right) \end{array} \tag{11}\end{equation*}

Although we can now easily compute c using NURBS parameterized θ p , we can not use gradient descent to optimize f θ using c just yet, as the gradients of c are undefined. To provide gradients for c , we further upper bound it as:
∑ x ∈ { 0 , s , 2 s , … } n − p c ^ ( N ( θ p , x ) , O , θ p ) ∗ H ( min o ∈ O S D F ( o , N ( θ p , x ) ) ) H ( x ) = 2 1 + e x − δ (12)
View Source \begin{equation*}\begin{array}{c} \sum\limits_{x \in \{ 0,s,2s, \ldots \} }^{n - p} {\hat c} \left( {N\left( {{\theta _p},x} \right),O,{\theta _p}} \right)*H\left( {\mathop {\min }\limits_{o \in O} SDF\left( {o,N\left( {{\theta _p},x} \right)} \right)} \right) \\ H(x) = \frac{2}{{1 + {e^{x - \delta }}}} \\ \end{array} \tag{12}\end{equation*} where H : ℝ → ℝ is a smooth approximation of a step function and δ is a safe distance parameter, which controls the extent to which the paths should avoid the obstacles. H could in practice be any function with H ( δ ) = 1, ∀ x ≤ δ : H ( x ) ≥ 1, and lim x→∞ H ( x ) = 0. The intuition behind the given approximation of c lies in the fact that ĉ provides the scaling of the gradient that ensures obstacle avoidance, while the gradient of H directs path points outside of objects. Note that δ is not a parameter intended to be tuned, but rather a way to control how far optimal solutions are expected to lie from objects. Further, note that although we derived an approximation to the optimal cost function from Section III-A , the approximate collision cost is at least the true collision cost and the approximate length cost is at most the true length cost. This ensures that in the approximate setting, optimal paths are guaranteed to be non-colliding.

C. Network

The network architecture we use in our approach depends on the particular planning domain. In case of planning from images (V-C), we use a convolutional input layer to process the RGBD images, followed by a ResNet50 [15] backbone. In case of 6 DoF (V-D) and 3D planning (V-B), we utilise vectorized scene descriptions (these descriptions are ∈ ℝ k×d , where k is the obstacle count and d is the dimension of the obstacle properties) which are processed by a fully connected input layer, followed by 10 highway layers [36] . The output layer in general consists of n fully connected networks for each spline anchor point. Our architecture is visualised in Figure 3 .
Fig. 3:

General network architecture used in our experiments.

Show All
SECTION IV.
Datasets and baselines

We compare our approach against representative sampling-based planners, an optimization-based planner, and a learning-based planner.

RRT* [20] , Informed-RRT* [10] , and BIT* [11] : are perhaps the most widely used sampling-based planning algorithms in use today. These methods are optimized versions of RRT that guarantee to find the shortest path when run for an indefinite amount of time.

CHOMP [40] : is a well-performing gradient-based motion planning algorithm. Similar to ours, CHOMP’s cost function has terms resembling our length term and collision term, scaled by a hyperparameter.

MPNet [32] : is a state-of-the-art learning-based planner.Given a point cloud scene representation with the current agent state, MPNet outputs the next agent state that will bring it closer to the goal configuration. The MPNet method further employs lazy state contraction and re-planning, which are algorithmic methods for refining the paths. In our experiments however, we focus the learning-based components of MPNet, as our method can be easily extended with algorithmic path corrections such as re-planning, and these algorithmic corrections are generally not applicable in partially observable environments.

We test our approach using both synthetic and real-world data. Specifically, we use the following six datasets.

simple-2D : We randomly sample a rectangle and a sphere in a 2D scene, together with a start and target position, such that a straight line path would collide with either of the objects. This simple dataset is only used for comparing the characteristics of our cost function to others and to give an intuitive visualisation.

Complex3D [32] : This dataset contains 110 scenes with 5000 near-optimal paths generated using RRT* (note, unlike [32] our approach does not need these paths for training). The training split contains 100 scenes with 4000 ground truth paths. The testing split consists of 100 scenes (contained in the training set) but with 200 unseen paths. There is also a test set of 10 unseen environments with 2000 paths.

Table-top shapes : We generate a table-top RGBD dataset using CoppeliaSim [33] by randomly placing floating cuboids, cylinders, and spheres such that they intersect with the ground plane of a large bounding cuboid. They are also permitted to intersect with each other. We randomized camera positions and focal lengths for each image, with a bias to face towards the ground plane, where the objects are spawned. We plan to release this dataset for reproducibility and to allow others to train and benchmark their approaches.

RGB-D Scenes Dataset v.2 : [23] : This dataset contains RGBD images of real-world table-top scenes that we use for testing our approach.

all-6DoF and difficult-6DoF : We generate these datasets for comparing our method on 6 DoF robotic manipulator planning problems. The datasets assume a 6 DoF Kinova Mico [6] manipulator tasked to reach specified target configurations in the presence of a fixed-sized box obstacle of dimensions 0.2m x 0.2m x 0.2m, 0.29m away from the robot base. For all-6DoF , we sample random start and target manipulator configurations such that these configurations do not collide with the box. For difficult-6DoF , we likewise sample such configurations, but with the additional constrain that a linear interpolation in the start & target join angles does not solve the planning problem.
SECTION V.
Evaluation

In this section, we evaluate our cost function together with the proposed parameterization in various domains. Our goal is to focus on answering the following:

    How does our cost function perform in comparison to related methods? (V-A)

    Does our method perform up to par with state-of-the-art approaches when planning from full scene descriptions and from images? (V-B, V-C)

    How does our method perform in higher-dimensions with robotic manipulators? (V-D)

A. Cost function evaluation

In this section, we assess how our cost, C , compares to the CHOMP collision cost [40] . For a single sample point x ∈ ℝ d , the CHOMP collision term is as follows, with ε ∈ ℝ being a calibrated constant:
c C H O M P ( x ) = ⎧ ⎩ ⎨ ⎪ ⎪ − S D F ( x ) + 1 2 ε  if  S D F ( x ) < 0 1 2 ε ( S D F ( x ) − ε ) 2 if  0 < S D F ( x ) ≤ ε 0 otherwise (13)
View Source \begin{equation*} {c_{CHOMP}}(x) = \begin{cases} { - SDF(x) + \frac{1}{2}\varepsilon }\quad{{\text{ if }}SDF(x) < 0} \\ {\frac{1}{{2\varepsilon }}{{(SDF(x) - \varepsilon )}^2}}\quad{{\text{if }}0 < SDF(x) \leq \varepsilon } \\ 0\quad{{\text{otherwise}}} \end{cases}\tag{13}\end{equation*}

We choose compare to the cost functions on simple-2D in order to make brute-force optimization tractable.

Setup: As a first step, we calibrate λ (collision weight hyperparameter) and ε in the CHOMP collision cost for a simple sphere problem in our dataset, as seen in Figure 4a . We perform this calibration so that the optimal CHOMP cost path is collision-free, with the same length as our cost’s optimal path.

Results: In this setup, out of 150 planning problems, C achieves a 100% success rate, while the calibrated CHOMP [40] cost achieves a 79.33% success rate, and an uncalibrated CHOMP [40] cost, with default λ = 1, ε = 1 achieves a 40.66% success rate. These simple results underline our cost function’s innate ability for generalization across different scenes.

Figure 4 presents examples of planning problems where our cost outperforms that of CHOMP calibrated on the example from Figure 4a .

Discussion: In general, the need to calibrate the CHOMP cost is a direct consequence of the global optima property (III-A), which our cost satisfies by definition. Although the calibrated CHOMP cost performs reasonably well on these simple examples, the calibration process relies on our ability to cherry-pick difficult examples from the dataset to calibrate on, as the global optima property (III-A) needs to be satisfied across all examples in a dataset. However, without the inclusion of an object-specific size parameter in the loss function, CHOMP path lengths are necessarily compromised on "easier" examples when calibrating for the "hardest", to guarantee no collisions across the entire dataset. For these reasons, the CHOMP cost needs to be calibrated per scene [40] , while as we further demonstrate in experiments (V-B, V-C), our formulation generalizes across diverse scenes and planning setups with no need for calibration.
B. 3D planning from full-state

In this experiment, we test the performance of our approach against learning-based planners using a complete description ("full-state") of the scene as input. Specifically, we compare with MPNet on the Complex 3D dataset [32] .

Setup: We train f θ on Π ∈ ℝ 10 × 6 vectorized scene descriptors, as each box has its own translation and dimensions. We randomly sample Π in a scene of size 20, with each dimension of each of the boxes being either 5 or 10, just as in the Complex 3D training set. Further, to train f θ we randomly sample start and target configurations s, t ∈ ℝ 3 so that there is a 50/50 breakdown between examples which would or would not collide by simply following a straight-line path. We use a simple fully connected network architecture of depth 15, with 10 highway layers [36] of width 256, 2 input layers of width 128, and 3 output layers of width 128. The parameters of C and Θ p were set to s = 0.05, p = 2, δ = 5, and n = 10.

Results: Table I presents the performance of each method on 2000 planning problems from the unseen Complex 3D [32] test set. In our experiment, we measure the rate of collision-free paths, the length of the predicted paths with respect to RRT*, and the planner’s inference speed. In our primary experiment seen in Table I , our method outperforms the learning-based component of MPNet for an arbitrary number of MPNet’s replanning attempts in terms of all measured metrics.

In terms of inference speed comparison with respect to classical planners on the Complex 3D dataset, Informed-RRT* takes an average of 15.54 seconds to plan, and BIT* an average 8.86 seconds. While both BIT* and Informed-RRT* are probabilistically complete planning methods, their inference speed is much slower than our method’s. Hence, we can conclude that our method is preferable for applications where rapid path planning is necessary.
C. 3D planning from images

In this experiment, we show how our approach can be used to plan from images. Using our cost function, we train our network to predict collision-free paths conditioned on RGBD images of scenes.

Setup: In this case, we have Π ∈ R 448 × 448 ≥ 0 , representing a depth image from the robot’s viewpoint, with the control points of θ p being in the camera frame of the scene. We use the Table-top shapes dataset for this experiment.

The architecture we chose for f θ is a ResNet-50 [15] backbone, followed by a 4 layer fully-connected network of width 256. To train our network, similarly as in V-B, we sample start and end configurations so that there is a 50/50 breakdown between examples where a straight-line path would or would not collide. The parameters of θ p and C are set to n = 3, s = 0.05, p = 2, δ = 0. Further, we apply thresholded perlin noise to our RGBD images, with the aim to assess the generalization of our method to real-world images.
Fig. 4:

Comparing our cost function to that of CHOMP [40] . In each image pair, we show the result of optimizing C (green) on the left, and the result of optimizing the CHOMP collision cost (purple) on the right. In all examples, we use a single control point NURBS parameterization. The background heat maps represent the cost function’s values at different control point positions, with red regions being the maxima and blue areas being the minima. The paths obtained by minimizing C are collision-free with the shortest possible lengths for the given number of control points.

Show All
TABLE I: Quantitative comparisons with MPNet on the Complex 3D w/o lazy state contraction
TABLE II: RRT* motion length (len) and success rate (succ) on 6 DoF planning problems from all-6DoF and difficult-6DoF test sets with 1ms, 10ms, 100ms, 1s, 10s of planning time. Note that we set N/A where RRT* fails to find a solution to any planning problem.

Results: On 2000 unseen examples from our synthetic test set, our method achieves an 89.05% success rate on problems where a straight-line path is expected to collide and 1.39 times longer than start-to-goal distance on problems where a straight-line path is optimal. Figure 5 presents examples of path planning problems solved on table-top scenes from the RGB-D Scenes Dataset v.2 [23] , and Figure 6 showcases the predicted paths on our Table-top shapes test set.
D. 6 DoF planning

This experiment demonstrates how our approach can be used to plan motions for a 6-DoF Kinova Mico arm.

Setup: We train our method by sampling random manipulator start and target configurations and regressing to spline joint angles. We set s = 0.05, p = 2, δ = 0, and n = 3. To compute our cost, we integrate it over the full manipulator motion in Cartesian space by uniformly sampling both through time and between the link positions. We use the same network architecture as in V-B. We compare our method with OMPL’s [37] RRT* [20] on a test set of 2000 planning problems from all-6DoF and on a test set of 2000 planning problems from difficult-6DoF. Further, we showcase the use of our method for finding good initial planning solutions for downstream optimization. We achieve this by comparing the path initialization obtained from our network against linear interpolation in the start and target joint angles on the difficult-6DoF dataset. We perform several gradient steps using the collision component of the cost, and compare the resulting success rates.
Fig. 5:

Predicting paths from real-world RGB-D images. This figure shows paths on real table-top scenes from the RGB-D Scenes Dataset v.2 [23] . The model is trained on purely synthetic scenes from Table-top shapes dataset.

Show All
Fig. 6:

Predicting paths from synthetic RGB-D images. This figure shows predicted paths on our Table-top shapes test set.

Show All
Fig. 7:

Controlling a robotic manipulator. Using Ivy [24] , we demonstrate a 6 DoF Kinova Mico robotic manipulator utilizing our proposed method for planning around a box. The arm motion is shown in g r e e n .

Show All
Fig. 8:

A network trained using our method provides superior path initializations compared with linear interpolation in the joint angles.

Show All

Results: Our method achieves a 56% success rate on difficult-6DoF with a 26.72 motion length, and a 73% success rate on all-6DoF with a 25.2 motion length. We measure motion length by sampling anchor points on the arm and computing their distances across time. Our method’s planning time per problem is 0.95ms. We compare with RRT* by letting RRT* plan up to 1ms, 10ms, 100ms, 1s, and 10s on the same problems. The results of RRT* performance can be seen in Table II and an example trajectory of our method is in Figure 7 . Based on the results from Table II , although RRT* can catch up with our method in terms of success rate within 10s of planning time, the resulting RRT* planner motions are longer than our method’s. For a planning setup up to 1s, our planner can provide superior results both in terms of length and success rates. Overall, our approach consistently provides superior length per planning time and success rate per planning time ratios.

Further, Figure 8 demonstrates the use of our method for good path initializations. We observe that after 6 gradient steps on the paths provided by our network, the planning solutions were close to optimal in terms of success rate. While our method can be used to optimize paths initialised with linear interpolation, more gradient steps are needed to achieve similar success rates.
SECTION VI.
Conclusion

In this paper, we presented an optimal cost function for learning to find the shortest collision-free paths from images. The key to our approach is a novel cost formulation which guarantees collision-free shortest paths at the optimum. Our experimental results demonstrate that our method outperforms other optimization-based planners, performs on par with supervised learning based-planners, and is effective at planning in higher-dimensions such as on a 6 DoF robotic manipulator.

Authors
Figures
References
Keywords
Metrics
   Back to Results   
More Like This
Path Planning of Lunar Rover Group Based on Theory of Dynamic Programming and Multi-objective Optimization

2007 2nd IEEE Conference on Industrial Electronics and Applications

Published: 2007
Integrated Path Planning and Tracking Control of an AUV: A Unified Receding Horizon Optimization Approach

IEEE/ASME Transactions on Mechatronics

Published: 2017
Show More
References
References is not available for this document.
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
