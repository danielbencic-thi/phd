IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Typesetting math: 69%

Skip to Main Content
Scheduled Maintenance: On Tuesday, August 23, IEEE Xplore will undergo scheduled maintenance from 1:00-5:00pm ET. During this time, there may be intermittent impact on performance. We apologize for any inconvenience.

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

        Cart 
        Create Account
        Personal Sign In 

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
Access provided by:
Technische Hochschule Ingolstadt
Sign Out
ADVANCED SEARCH
Conferences > 2014 IEEE/RSJ International C...
Informed RRT: Optimal sampling-based path planning focused via direct sampling of an admissible ellipsoidal heuristic
Publisher: IEEE
Cite This
PDF
Jonathan D. Gammell ; Siddhartha S. Srinivasa ; Timothy D. Barfoot
All Authors
View Document
281
Paper
Citations
4824
Full
Text Views

    Alerts
    Alerts
    Manage Content Alerts
    Add to Citation Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Background
    III.
    Analysis of the Ellipsoidal Informed Subset
    IV.
    Direct Sampling of an Ellipsoidal Subset
    V.
    Informed RRT*

Show Full Outline
Authors
Figures
References
Citations
Keywords
Metrics
Media
More Like This
Footnotes

    Download PDF
    View References
    Request Permissions
    Save to
    Alerts 

Abstract: Rapidly-exploring random trees (RRTs) are popular in motion planning because they find solutions efficiently to single-query problems. Optimal RRTs (RRT*s) extend RRTs to... View more
Metadata
Abstract:
Rapidly-exploring random trees (RRTs) are popular in motion planning because they find solutions efficiently to single-query problems. Optimal RRTs (RRT*s) extend RRTs to the problem of finding the optimal solution, but in doing so asymptotically find the optimal path from the initial state to every state in the planning domain. This behaviour is not only inefficient but also inconsistent with their single-query nature.
Published in: 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems
Date of Conference: 14-18 September 2014
Date Added to IEEE Xplore : 06 November 2014
ISBN Information:
ISSN Information:
INSPEC Accession Number: 14718246
DOI: 10.1109/IROS.2014.6942976
Publisher: IEEE
Conference Location: Chicago, IL, USA
Contents
SECTION I.
Introduction

The motion-planning problem is commonly solved by first discretizing the continuous state space with either a grid for graph-based searches or through random sampling for stochastic incremental searches. Graph-based searches, such as A* [1] , are often resolution complete and resolution optimal . They are guaranteed to find the optimal solution, if a solution exists, and return failure otherwise (up to the resolution of the discretization). These graph-based algorithms do not scale well with problem size (e.g., state dimension or problem range).

Stochastic searches, such as Rapidly-exploring Random Trees (RRTs) [2] , Probabilistic Roadmaps (PRMs) [3] , and Expansive Space Trees (ESTs) [4] , use sampling-based methods to avoid requiring a discretization of the state space. This allows them to scale more effectively with problem size and to directly consider kinodynamic constraints; however, the result is a less-strict completeness guarantee. RRTs are probabilistically complete , guaranteeing that the probability of finding a solution, if one exists, approaches unity as the number of iterations approaches infinity.
Fig. 1. - Solutions of equivalent cost found by RRT* and Informed RRT* on a random world. After an initial solution is found, Informed RRT* focuses the search on an ellipsoidal informed subset of the state space, $x_{\hat{f}}\subseteq X$, that contains all the states that can improve the current solution regardless of homotopy class. This allows Informed RRT* to find a better solution faster than RRT* without requiring any additional user-tuned parameters.
Fig. 1.

Solutions of equivalent cost found by RRT* and Informed RRT* on a random world. After an initial solution is found, Informed RRT* focuses the search on an ellipsoidal informed subset of the state space, x f ^ ⊆ X , that contains all the states that can improve the current solution regardless of homotopy class. This allows Informed RRT* to find a better solution faster than RRT* without requiring any additional user-tuned parameters.

Show All

Until recently, these sampling-based algorithms made no claims about the optimality of the solution. Urmson and Simmons [5] had found that using a heuristic to bias sampling improved RRT solutions, but did not formally quantify the effects. Ferguson and Stentz [6] recognized that the length of a solution bounds the possible improvements from above, and demonstrated an iterative anytime RRT method to solve a series of subsequently smaller planning problems. Karaman and Frazzoli [7] later showed that RRTs return a suboptimal path with probability one, demonstrating that all RRT-based methods will almost surely be suboptimal and presented a new class of optimal planners. They named their optimal variants of RRTs and PRMs, RRT* and PRM*, respectively. These algorithms are shown to be asymptotically optimal , with the probability of finding the optimal solution approaching unity as the number of iterations approaches infinity.

RRTs are not asymptotically optimal because the existing state graph biases future expansion. RRT* overcomes this by introducing incremental rewiring of the graph. New states are not only added to a tree, but also considered as replacement parents for existing nearby states in the tree. With uniform global sampling, this results in an algorithm that asymptotically finds the optimal solution to the planning problem by asymptotically finding the optimal paths from the initial state to every state in the problem domain . This is inconsistent with their single-query nature and becomes expensive in high dimensions.

In this paper, we present the focused optimal planning problem as it relates to the minimization of path length in R n . For such problems, a necessary condition to improve the solution at any iteration is the addition of states from an ellipsoidal subset of the planning domain [6] , [8] – [9] [10] . We show that the probability of adding such states through uniform sampling becomes arbitrarily small as the size of the planning problem increases or the solution approaches the theoretical minimum, and present an exact method to sample the ellipsoidal subset directly. It is also shown that with strict assumptions (i.e., no obstacles) that this direct sampling results in linear convergence to the optimal solution.
Fig. 2. - The solution cost versus computational time for RRT* and Informed RRT* on a random world problem. Both planners were run until they found a solution of the same cost. Figs. (a, c) show the final result, while fig. (b) shows the solution cost versus computational time. From fig. (a), it can be observed that RRT* spends significant computational resources exploring regions of the planning problem that cannot possibly improve the current solution, while fig. (c) demonstrates how informed RRT* focuses the search.
Fig. 2.

The solution cost versus computational time for RRT* and Informed RRT* on a random world problem. Both planners were run until they found a solution of the same cost. Figs. (a, c) show the final result, while fig. (b) shows the solution cost versus computational time. From fig. (a), it can be observed that RRT* spends significant computational resources exploring regions of the planning problem that cannot possibly improve the current solution, while fig. (c) demonstrates how informed RRT* focuses the search.

Show All

This direct-sampling method allows for the creation of informed-sampling planners. Such a planner, Informed RRT*, is presented to demonstrate the advantages of informed incremental search ( Fig. 1 ). Informed RRT* behaves as RRT* until a first solution is found, after which it only samples from the subset of states defined by an admissible heuristic to possibly improve the solution. This subset implicitly balances exploitation versus exploration and requires no additional tuning (i.e., there are no additional parameters) or assumptions (i.e., all relevant homotopy classes are searched). While heuristics may not always improve the search, their prominence in real-world planning demonstrates their practicality. In situations where they provide no additional information (e.g., when the informed subset includes the entire planning problem), Informed RRT* is equivalent to RRT*.

Informed RRT* is a simple modification to RRT* that demonstrates a clear improvement. In simulation, it performs as well as existing RRT* algorithms on simple configurations, and demonstrates order-of-magnitude improvements as the configurations become more difficult ( Fig. 2 ). As a result of its focused search, the algorithm has less dependence on the dimension and domain of the planning problem as well as the ability to find better topologically distinct paths sooner. It is also capable of finding solutions within tighter tolerances of the optimum than RRT* with equivalent computation, and in the absence of obstacles can find the optimal solution to within machine zero in finite time ( Fig. 3 ). It could also be used in combination with other algorithms, such as path-smoothing, to further reduce the search space.

The remainder of this paper is organized as follows. Section II presents a formal definition of the focused optimal planning problem and reviews the existing literature. Section III presents a closed-form estimate of the subset of states that can improve a solution for problems seeking to minimize path length in R n and analyzes the implications on RRT*-style algorithms. Section IV presents a method to sample this subset directly. Section V presents the Informed RRT* algorithm and Section VI presents simulation results comparing RRT* and Informed RRT* on simple planning problems of various size and configuration and random problems of various dimension. Section VII concludes the paper with a discussion of the technique and some related ongoing work.
SECTION II.
Background
A. Problem Definition

We define the optimal planning problem similarly to [7] . Let X ⊆ R n be the state space of the planning problem. Let X o b s ⊊ X be the states in collision with obstacles and X f r e e = X ∖ X o b s be the resulting set of permissible states. Let x s t a r t ∈ X f r e e be the initial state and x g o a l ∈ X f r e e be the desired final state. Let σ : [ 0 , 1 ] ↦ X be a sequence of states (a path) and Σ be the set of all nontrivial paths.

The optimal planning problem is then formally defined as the search for the path, σ ∗ , that minimizes a given cost function, c : Σ ↦ R ≥ 0 , while connecting x s t a r t to x g o a l through free space, σ ∗ = arg min σ ∈ Σ { c ( σ )   |   σ ( 0 ) = x s t a r t , σ ( 1 ) = x g o a l , ∀ s ∈ [ 0 , 1 ] , σ ( S ) ∈ X f r e e } , View Source Right-click on figure for MathML and additional features. \eqalignno{\sigma^{\ast}=\mathop{\arg\min}\limits_{\sigma\in\Sigma} \{c(\sigma)\ \vert\ \sigma&(0)={\bf x}_{{\rm start}}, \sigma(1)={\bf x}_{{\rm goal}},\cr &\forall s\in[0,1], \sigma(S)\in X_{{\rm free}}\},} where R ≥ 0 is the set of non-negative real numbers.

Let f ( x ) be the cost of an optimal path from x s t a r t to x g o a l constrained to pass through x . Then the subset of states that can improve the current solution, X f ⊆ X , can be expressed in terms of the current solution cost, c b e s t , X f = { x ∈ X   |   f ( x ) < c b e s t } . (1) View Source Right-click on figure for MathML and additional features. X_{f}=\{{\bf x}\in X\ \vert\ f({\bf x})<c_{{\rm best}}\}.\eqno{\hbox{(1)}}

The problem of focusing RRT*'s search in order to increase the convergence rate is equivalent to increasing the probability of adding a random state from X f .

As f ( ⋅ ) is generally unknown, a heuristic function, f ^ ( ⋅ ) , may be used as an estimate. This heuristic is referred to as admissible if it never overestimates the true cost of the path, i.e., ∀ x ∈ X ,   f ^ ( x ) ≤ f ( x ) . An estimate of X f ,   X f ^ , can then be defined analogously to (1) . For admissible heuristics, this estimate is guaranteed to completely contain the true set, X f ^ ⊇ X f , and thus inclusion in the estimated set is also a necessary condition to improving the current solution.
Fig. 3. - Informed RRT* converging to within machine zero of the optimum in the absence of obstacles. The start and goal states are shown as green and red, respectively, and are 100 units apart. The current solution is highlighted in magenta, and the ellipsoidal sampling domain, $x_{\hat{f} }$, is shown as a grey dashed line for illustration. Improving the solution decreases the size of the sampling domain, creating a feedback effect that converges to within machine zero of the theoretical minimum. Fig. (a) Shows the first solution at 59 iterations, (b) after 175 iterations, and (c), the final solution after 1142 iterations, at which point the ellipse has degenerated to a line between the start and goal.
Fig. 3.

Informed RRT* converging to within machine zero of the optimum in the absence of obstacles. The start and goal states are shown as green and red, respectively, and are 100 units apart. The current solution is highlighted in magenta, and the ellipsoidal sampling domain, x f ^ , is shown as a grey dashed line for illustration. Improving the solution decreases the size of the sampling domain, creating a feedback effect that converges to within machine zero of the theoretical minimum. Fig. (a) Shows the first solution at 59 iterations, (b) after 175 iterations, and (c), the final solution after 1142 iterations, at which point the ellipse has degenerated to a line between the start and goal.

Show All

B. Prior Work

Prior work to focus RRT and RRT* has relied on sample biasing, heuristic-based sample rejection, heuristic-based graph pruning, and/or iterative searches.
1) Sample Biasing

Sample biasing attempts to increase the frequency that states are sampled from X f by biasing the distribution of samples drawn from X . This continues to add states from outside of X f that cannot improve the solution. It also results in a nonuniform density over the problem being searched, violating a key RRT* assumption.
a) Heuristic-Biased Sampling

Heuristic-biased sampling attempts to increase the probability of sampling X f by weighting the sampling of X with a heuristic estimate of each state. It is used to improve the quality of a regular RRT by Urmson and Simmons [5] in the Heuristically Guided RRT (hRRT) by selecting states with a probability inversely proportional to their heuristic cost. The hRRT was shown to find better solutions than RRT; however, the use of RRTs means that the solution is almost surely suboptimal [7] .

Kiesel et al. [11] use a two-stage process to create an RRT* heuristic in their f-biasing technique. A coarse abstraction of the planning problem is initially solved to provide a heuristic cost for each discrete state. RRT* then samples new states by randomly selecting a discrete state and sampling inside it with a continuous uniform distribution. The discrete sampling is biased such that states belonging to the abstracted solution have the highest probability of selection. This technique provides a heuristic bias for the full duration of the RRT* algorithm; however, to account for the discrete abstraction it maintains a nonzero probability of selecting every state. As a result, states that cannot improve the current solution are still sampled.
b) Path Biasing

Path-biased sampling attempts to increase the frequency of sampling X f by sampling around the current solution path. This assumes that the current solution is either homotopic to the optimum or separated only by small obstacles. As this assumption is not generally true, path-biasing algorithms must also continue to sample globally to avoid local optima. The ratio of these two sampling methods is frequently a user-tuned parameter.

Alterovitz et al. [12] use path biasing to develop the Rapidly-exploring Roadmap (RRM). Once an initial solution is found, each iteration of the RRM either samples a new state or selects an existing state from the current solution and refines it. Path refinement occurs by connecting the selected state to its neighbours resulting in a graph instead of a tree.

Akgun and Stilman [13] use path biasing in their dual-tree version of RRT*. Once an initial solution is found, the algorithm spends a user-specified percentage of its iterations refining the current solution. It does this by randomly selecting a state from the solution path and then explicitly sampling from its Voronoi region. This increases the probability of improving the current path at the expense of exploring other homotopy classes. Their algorithm also employs sample rejection in exploring the state space ( Section II-B.2 ).

Nasir et al. [14] combine path biasing with smoothing in their RRT*-Smart algorithm. When a solution is found, RRT*-Smart first smooths and reduces the path to its minimum number of states before using these states as biases for further sampling. This adds the complexity of a path-smoothing algorithm to the planner while still requiring global sampling to avoid local optima. While the path smoothing quickly reduces the cost of the current solution, it may also reduce the probability of finding a different homotopy class by removing the number of bias points about which samples are drawn and further violates the RRT* assumption of uniform density.

Kim et al. [15] use a visibility analysis to generate an initial bias in their Cloud RRT* algorithm. This bias is updated as a solution is found to further concentrate sampling near the path.
2) Heuristic-Based Sample Rejection

Heuristic-based sample rejection attempts to increase the real-time rate of sampling X f by using rejection sampling on X to sample X f ^ . Samples drawn from a larger distribution are either kept or rejected based on their heuristic value. Akgun and Stilman [13] use such a technique in their algorithm. While this is computationally inexpensive for a single iteration, the number of iterations necessary to find a single state in X f ^ is proportional to its size relative to the sampling domain. This becomes nontrivial as the solution approaches the theoretical minimum or the planning domain grows.

Otte and Correll [8] draw samples from a subset of the planning domain in their parallelized C-FOREST algorithm. This subset is defined as the hyperrectangle that bounds the prolate hyperspheroidal informed subset. While this improves the performance of sample rejection, its utility decreases as the dimension of the problem increases ( Remark 2 ).
3) Graph Pruning

Graph pruning attempts to increase the real-time exploration of X f by using a heuristic function to limit the graph to X f ^ . States in the planning graph with a heuristic cost greater than the current solution are periodically removed while global sampling is continued. The space-filling nature of RRTs biases the expansion of the pruned graph towards the perimeter of X f ^ . After the subset is filled, only samples from within X f ^ itself can add new states to the graph. In this way, graph pruning becomes a rejection-sampling method after greedily filling the target subset. As adding a new state to an RRT requires a call to a nearest-neighbour algorithm, graph pruning will be more computationally expensive than simple sample rejection while still suffering from the same probabilistic limitations.

Karaman et al. [16] use graph pruning to implement an anytime version of RRT* that improves solutions during execution. They use the current vertex cost plus a heuristic estimate of the cost from the vertex to the goal to periodically remove states from the tree that cannot improve the current solution. As RRT* asymptotically approaches the optimal cost of a vertex from above , this is an inadmissible heuristic for the cost of a solution through a vertex ( Section III ). This can overestimate the heuristic cost of a vertex resulting in erroneous removal, especially early in the algorithm when the tree is coarse. Jordan and Perez [17] use the same inadmissible heuristic in their bidirectional RRT* algorithm.

Arslan and Tsiotras [18] use a graph structure and lifelong planning A* (LPA*) [19] techniques in the RRT# algorithm to prune the existing graph. Each existing state is given a LPA*-style key that is updated after the addition of each new state. Only keys that are less than the current best solution are updated, and only up-to-date keys are available for connection with newly drawn samples.
4) Anytime RRTs

Ferguson and Stentz [6] recognized that a solution bounds the subset of states that can provide further improvement from above. Their iterative RRT method, Anytime RRTs, solves a series of independent planning problems whose domains are defined by the previous solution. They represent these domains as ellipses [6] , Fig. 2 ], but do not discuss how to generate samples. Restricting the planning domain encourages each RRT to find a better solution than the previous; however, to do so they must discard the states already found in X f ^

The algorithm presented in this paper calculates X f ^ explicitly and samples from it directly. Unlike path biasing it makes no assumptions about the homotopy class of the optimum and unlike heuristic biasing does not explore states that cannot improve the solution. As it is based on RRT*, it is able to keep all states found in X f ^ for the duration of the search, unlike Anytime RRTs. By sampling X f ^ directly, it always samples potential improvements regardless of the relative size of X f ^ to X . This allows it to work effectively regardless of the size of the planning problem or the relative cost of the current solution to the theoretical minimum, unlike sample rejection and graph pruning methods. In problems where the heuristic does not provide any additional information, it performs identically to RRT*.
Fig. 4. - The heuristic sampling domain, $x_{\hat{f}}$ for a ${\BBR}^{2}$ problem seeking to minimize path length is an ellipse with the initial state, ${\bf x}_{{\rm start}}$, and the goal state, ${\bf x}_{{\rm goal}}$ as focal points. The shape of the ellipse depends on both the initial and goal states, the theoretical minimum cost between the two, $c_{\min}$, and the cost of the best solution found to date, $c_{{\rm best}}$. The eccentricity of the ellipse is given by $c_{\min}/c_{{\rm best}}$.
Fig. 4.

The heuristic sampling domain, x f ^ for a R 2 problem seeking to minimize path length is an ellipse with the initial state, x s t a r t , and the goal state, x g o a l as focal points. The shape of the ellipse depends on both the initial and goal states, the theoretical minimum cost between the two, c min , and the cost of the best solution found to date, c b e s t . The eccentricity of the ellipse is given by c min / c b e s t .

Show All

SECTION III.
Analysis of the Ellipsoidal Informed Subset

Given a positive cost function, the cost of an optimal path from x s t a r t to x g o a l constrained to pass through x ∈ X , f ( x ) , is equal to the cost of the optimal path from x s t a r t to x ,   g ( x ) , plus the cost of the optimal path from x to x g o a l , h ( x ) . As RRT*-based algorithms asymptotically approach the optimal path to every state from above , an admissible heuristic estimate, f ^ ( ⋅ ) , must estimate both these terms. A sufficient condition for admissibility is that the components, g ^ ( ⋅ ) and h ^ ( ⋅ ) , are individually admissible heuristics of g ( ⋅ ) and h ( ⋅ ) , respectively.

For problems seeking to minimize path length in R n , Euclidean distance is an admissible heuristic for both terms (even with motion constraints). This informed subset of states that may improve the current solution, X f ^ ⊇ X f , can then be expressed in closed form in terms of the cost of the current solution, c b e s t , as X f ^ = { x ∈ X   |   ∥ x s t a r t − x ∥ 2 + ∥ x − x g o a l ∥ 2 ≤ c b e s t } , View Source Right-click on figure for MathML and additional features. X_{\hat{f}}=\{{\bf x}\in X\ \vert\ \Vert {\bf x}_{{\rm start}}-{\bf x}\Vert _{2}+\Vert {\bf x}-{\bf x}_{{\rm goal}}\Vert_{2}\leq c_{{\rm best}}\}, which is the general equation of an n-dimensional prolate hyperspheroid (i.e., a special hyperellipsoid). The focal points are x s t a r t and x g o a l , the transverse diameter is c b e s t , and the conjugate diameters are c 2 b e s t − c 2 min − − − − − − − − − √ ( Fig. 4 ).

Admissibility of f ^ ( ⋅ ) makes adding a state in X f ^ a necessary condition to improve the solution. With the space-filling nature of RRT, the probability of adding such a state quickly becomes the probability of sampling such a state 1 . Thus, the probability of improving the solution at any iteration by uniformly sampling a larger subset, x i + 1 ∼ U ( X s ) ,   X s ⊇ X f ^ , is less than or equal to the ratio of set measures λ ( ⋅ ) , P ( c i + 1 b e s t < c i b e s t ) ≤ P ( x i + 1 ∈ X f ) ≤ P ( x i + 1 ∈ X f ^ ) = λ ( X f ^ ) λ ( X s ) . (2) View Source Right-click on figure for MathML and additional features. \eqalignno{P(c_{{\rm best}}^{i+1}<c_{{\rm best}}^{i})&\leq P({\bf x}^{i+1}\in X_{f})\cr &\leq P\left({\bf x}^{i+1}\in X_{\hat{f}}\right)={\lambda(X_{\hat{f}})\over \lambda(X_{{\rm s}})}.&\hbox{(2)}}

Using the volume of a prolate hyperspheroid in R n gives P ( c i + 1 b e s t < c i b e s t ) ≤ c i b e s t ( c i 2 b e s t − c 2 min ) n − 1 2 ζ n 2 n λ ( X s ) , (3) View Source Right-click on figure for MathML and additional features. P\left(c_{{\rm best}}^{i+1}<c_{{\rm best}}^{i}\right)\leq{c_{{\rm best}}^{i}\left(c_{{\rm best}}^{i^{2}}-c_{\min}^{2}\right)^{{n-1\over 2}}\zeta_{n}\over 2^{n}\lambda(X_{{\rm s}})},\eqno{\hbox{(3)}} with ζ n being the volume of a unit n-ball.
Remark 1: (Rejection sampling)

From (3) it can be observed that the probability of improving a solution through uniform sampling becomes arbitrarily small for large subsets (e.g., global sampling) or as the solution approaches the theoretical minimum.
Remark 2: (Rectangular rejection sampling)

Let X s be a hyperrectangle that tightly bounds the informed subset (i.e., the widths of each side correspond to the diameters of the prolate hyperspheroid) [8] . From (3) , the probability that a sample drawn uniformly from X s will be in X f ^ is then ζ n 2 n , which decreases rapidly with n . For example, with n = 6 this gives a maximum 8% probability of improving a solution at each iteration through rejection sampling regardless of the specific solution, problem, or algorithm parameters.
Theorem 1 (Obstacle-free linear convergence)

With uniform sampling of the informed subset, x ∼ U ( X f ^ ) , the cost of the best solution, c b e s t , converges linearly to the theoretical minimum, c min , in the absence of obstacles.
Proof

The heuristic value of a state is equal to the transverse diameter of a prolate hyperspheroid that passes through the state and has focal points at x s t a r t and x g o a l . With uniform sampling, the expectation is then [20] E [ f ^ ( x ) ] = n c 2 b e s t + c 2 min ( n + 1 ) c b e s t . (4) View Source Right-click on figure for MathML and additional features. E\left[\hat{f}({\bf x})\right]={nc_{{\rm best}}^{2}+c_{\min}^{2}\over (n+1)c_{{\rm best}}}.\eqno{\hbox{(4)}}

We assume that the RRT* rewiring parameter is greater than the diameter of the informed subset, similarly to how the proof of the asymptotic optimality of RRT* assumes that η is greater than the diameter of the planning problem [7] . The expectation of the solution cost, c i b e s t , is then the expectation of the heuristic cost of a sample drawn from a prolate hyperspheroid of diameter c i − 1 b e s t , i.e., E [ c i b e s t ] = E [ f ^ ( x i ) ] . From (4) it follows that the solution cost converges linearly with a rate, μ , that depends only on the state dimension [20] , μ = ∂ E [ c i b e s t ] ∂ c i − 1 b e s t ∣ ∣ ∣ c i − 1 b e s t = c min = n − 1 n + 1 . View Source Right-click on figure for MathML and additional features. \mu=\left.{\partial E[c_{{\rm best}}^{i}]\over \partial c_{{\rm best}}^{i-1}}\right\vert_{c_{{\rm best}}^{i-1}=c_{\min}}={n-1\over n+1}.

While the obstacle-free assumption is impractical, Thm. 1 illustrates the fundamental effectiveness of direct informed sampling and provides possible insight for future work.
SECTION IV.
Direct Sampling of an Ellipsoidal Subset

Uniformly distributed samples in a hyperellipsoid, x e l l i p s e ∼ U ( X e l l i p s e ) , can be generated by transforming uniformly distributed samples from the unit n -ball, x b a l l ∼ U ( X b a l l ) , x e l l i p s e = L x b a l l + x c e n t r e , View Source Right-click on figure for MathML and additional features. {\bf x}_{{\rm ellipse}}={\bf Lx}_{{\rm ball}}+{\bf x}_{{\rm centre}}, where x c e n t r e = ( x f 1 + x f 2 ) / 2 is the centre of the hyper-ellipsoid in terms of its two focal points, x f 1 and x f 2 , and X b a l l = { x ∈ X   |   ∥ x ∥ 2 ≤ 1 } [21] .

This transformation can be calculated by Cholesky decomposition of the hyperellipsoid matrix, S ∈ R n × n , L L T ≡ S , View Source Right-click on figure for MathML and additional features. {\bf LL}^{T}\equiv {\bf S}, where ( x − x c e n t r e ) T S ( x − x c e n t r e ) = 1 , View Source Right-click on figure for MathML and additional features. ({\bf x}-{\bf x}_{{\rm centre}})^{T}{\bf S}({\bf x}-{\bf x}_{{\rm centre}})=1, with S having eigenvectors corresponding to the axes of the hyperellipsoid, { a i } , and eigenvalues corresponding to the squares of its radii, { r 2 i } . The transformation, L , maintains the uniform distribution in X e l l i p s e [22] .

For prolate hyperspheroids, such as X f ^ , the transformation can be calculated from just the transverse axis and the radii. The hyperellipsoid matrix in a coordinate system aligned with the transverse axis is the diagonal matrix S = d i a g { c 2 b e s t 4 ,   c 2 b e s t − c 2 min 4 , … , c 2 b e s t − c 2 min 4 } , View Source Right-click on figure for MathML and additional features. {\bf S}= {\rm diag}\left\{{c_{{\rm best}}^{2}\over 4},\ {c_{{\rm best}}^{2}-c_{\min}^{2}\over 4}, \ldots, {c_{{\rm best}}^{2}-c_{\min}^{2}\over 4}\right\}, with a resulting decomposition of L = d i a g ⎧ ⎩ ⎨ ⎪ ⎪ c b e s t 2 , c 2 b e s t − c 2 min − − − − − − − − − √ 2 , ⋯ , c 2 b e s t − c 2 min − − − − − − − − − √ 2 ⎫ ⎭ ⎬ ⎪ ⎪ , (5) View Source Right-click on figure for MathML and additional features. {\bf L}={\rm diag}\left\{{c_{{\rm best}}\over 2}, {\sqrt{c_{{\rm best}}^{2}-c_{\min}^{2}}\over 2},\cdots, {\sqrt{c_{{\rm best}}^{2}-c_{\min}^{2}}\over 2}\right\},\eqno{\hbox{(5)}} where diag {·} denotes a diagonal matrix.

The rotation from the hyperellipsoid frame to the world frame, C ∈ S O ( n ) , can be solved directly as a general Wahba problem [23] . It has been shown that a valid solution can be found even when the problem is underspecified [24] . The rotation matrix is given by C = U   d i a g { 1 , … , 1 , det ( U ) det ( V ) } V T , (6) View Source Right-click on figure for MathML and additional features. {\bf C}={\bf U}\ {\rm diag} \{1, \ldots, 1, \det({\bf U})\det({\bf V})\}{\bf V}^{T},\eqno{\hbox{(6)}} where det ( ⋅ ) is the matrix determinant and {\bf U}\in {\BBR}^{n\times n} and {\bf V}\in {\BBR}^{n\times n} are unitary matrices such that {\bf U}{\bf \Sigma}{\bf V}^{T}\equiv {\bf M} via singular value decomposition. The matrix {\bf M} is given by the outer product of the transverse axis in the world frame, {\bf a}_{1} , and the first column of the identity matrix, 1 1 , {\bf M}={\bf a}_{1}1_{1}^{T}, View Source Right-click on figure for MathML and additional features. {\bf M}={\bf a}_{1}1_{1}^{T}, where {\bf a}_{1}=({\bf x}_{{\rm goal}}-{\bf x}_{{\rm start}})/\Vert {\bf x}_{{\rm goal}}-{\bf x}_{{\rm start}}\Vert_{2}. View Source Right-click on figure for MathML and additional features. {\bf a}_{1}=({\bf x}_{{\rm goal}}-{\bf x}_{{\rm start}})/\Vert {\bf x}_{{\rm goal}}-{\bf x}_{{\rm start}}\Vert_{2}.

A state uniformly distributed in the informed subset, {\bf x}_{\hat{f}}\sim {\cal U}\left(X_{\hat{f}}\right) , can thus be calculated from a sample drawn uniformly from a unit n -ball, {\bf x}_{{\rm ball}}\sim {\cal U}(X_{{\rm ball}}) , through a transformation (5) , rotation (6) , and translation, {\bf x}_{\hat{f}}={\bf CLx}_{{\rm ball}}+{\bf x}_{{\rm centre}}.\eqno{\hbox{(7)}} View Source Right-click on figure for MathML and additional features. {\bf x}_{\hat{f}}={\bf CLx}_{{\rm ball}}+{\bf x}_{{\rm centre}}.\eqno{\hbox{(7)}}

This procedure is presented algorithmically in Alg. 2 .
SECTION V.
Informed RRT*

An example algorithm using direct informed sampling, Informed RRT*, is presented in Algs. 1 and 2 . It is identical to RRT* as presented in [7] , with the addition of lines 3, 6, 7, 30, and 31. Like RRT*, it searches for the optimal path, \sigma^{\ast} , to a planning problem by incrementally building a tree in state space, {\cal T}=(V, E) , consisting of a set of vertices, V\subseteq X_{{\rm free}} , and edges, E\subseteq X_{{\rm free}}\times X_{{\rm free}} . New vertices are added by growing the graph in free space towards randomly selected states. The graph is rewired with each new vertex such that the cost of the nearby vertices are minimized.

The algorithm differs from RRT* in that once a solution is found, it focuses the search on the part of the planning problem that can improve the solution. It does this through direct sampling of the ellipsoidal heuristic. As solutions are found (line 30), Informed RRT* adds them to a list of possible solutions (line 31). It uses the minimum of this list (line 6) to calculate and sample X_{\hat{f}} directly (line 7). As is conventional, we take the minimum of an empty set to be infinity. The new subfunctions are described below, while descriptions of subfunctions common to RRT* can be found in [7] :
SECTION Algorithm 1:
Informed {\bf RRT}{^\ast} ({\bf x}_{{\rm start}}, {\bf x}_{{\rm goal}})

Algorithm
Sample

Given two poses, {\bf x}_{{\rm from}},\ {\bf x}_{{\rm to}}\in X_{{\rm free}} and a maximum heuristic value, c_{\max} \in {\BBR} , the function Sample ({\bf x}_{{\rm from}}, {\bf x}_{{\rm to}}, c_{\max}) returns independent and identically distributed ({\rm i}.{\rm i}.{\rm d}.) samples from the state space, {\bf x}_{{\rm new}}\in X , such that the cost of an optimal path between {\bf x}_{{\rm from}} and {\bf x}_{{\rm to}} that is constrained to go through {\bf x}_{{\rm new}} is less than c_{\max} as described in Section III and Alg. 2 . In most planning problems, {\bf x}_{{\rm from}}\equiv{\bf x}_{{\rm start}},\ {\bf x}_{{\rm to}}\equiv {\bf x}_{{\rm goal}} , and lines 2 to 4 of Alg. 2 can be calculated once at the start of the problem.
InGoalRegion

Given a pose, {\bf x}\in X_{{\rm free}} , the function InGoalRegion (x) returns True if and only if the state is in the goal region, X_{{\rm goal}} , as defined by the planning problem, otherwise it returns False. One common goal region is a ball of radius r_{{\rm goal}} centred about the goal, i.e., X_{{\rm goal}}=\{{\bf x}\in X_{{\rm free}}\ \vert\ \Vert{\bf x}-{\bf x}_{{\rm goal}}\Vert_{2}\leq r_{{\rm goal}}\}. View Source Right-click on figure for MathML and additional features. X_{{\rm goal}}=\{{\bf x}\in X_{{\rm free}}\ \vert\ \Vert{\bf x}-{\bf x}_{{\rm goal}}\Vert_{2}\leq r_{{\rm goal}}\}.
RotationToWorldFrame

Given two poses as the focal points of a hyperellipsoid, {\bf x}_{{\rm from}},\ {\bf x}_{{\rm to}}\in X , the function RotationToWorldFrame ({\bf x}_{{\rm from}}, {\bf x}_{{\rm to}}) returns the rotation matrix, {\bf C}\in SO(n) , from the hyperellipsoid-aligned frame to the world frame as per (6) . As previously discussed, in most planning problems this rotation matrix only needs to be calculated at the beginning of the problem.
Algorithm 2: Sample ({\bf x}_{{\rm start}}, {\bf x}_{{\rm goal}}, c_{\max})

Algorithm
SampleUnitNBall

The function, SampleUnitNBall returns a uniform sample from the volume of an n-ball of unit radius centred at the origin, i.e. {\bf x}_{{\rm ball}}\sim {\cal U}(X_{{\rm ball}}) .
A. Calculating the Rewiring Radius

At each iteration, the rewiring radius, r_{{\rm RRT}^{\ast}} , must be large enough to guarantee almost-sure asymptotic convergence while being small enough to only generate a tractable number of rewiring candidates. Karaman and Frazzoli [7] present a lower-bound for this rewiring radius in terms of the measure of the problem space and the number of vertices in the graph. Their expression assumes a uniform distribution of samples of a unit square. As Informed RRT* uniformly samples the subset of the planning problem that can improve the solution, a rewiring radius can be calculated from the measure of this informed subset and the related vertices inside it. This updated radius reduces the amount of rewiring necessary and further improves the performance of Informed RRT*. Ongoing work is focused on finding the exact form of this expression, but the radius provided by [7] appears appropriate. There also exists a k -nearest neighbour version of this expression.
SECTION VI.
Simulations

Informed RRT* was compared to RRT* on a variety of simple planning problems ( Figs. 5 to 7 ) and randomly generated worlds (e.g., Figs. 1 , 2 ). Simple problems were used to test specific challenges, while the random worlds were used to provide more challenging problems in a variety of state dimensions.

Fig. 5(a) was used to examine the effects of the problem range and the ability to find paths within a specified tolerance of the true optimum, with the width of the obstacle, w , selected randomly. Fig. 5(b) was used to demonstrate Informed RRT*'s ability to find topologically distinct solutions, with the position of the narrow passage, y_{g} , selected randomly. For these toy problems, experiments were ended when the planner found a solution cost within the target tolerance of the optimum. Random worlds, as in Fig. 2 , were used to test Informed RRT* on more complicated problems and in higher state dimensions by giving the algorithms 60 seconds to improve their initial solutions. For each variation of every experiment, 100 different runs of both RRT* and Informed RRT* were performed with a common pseudo-random seed and map.
Fig. 5. - The two planning problems used in Section VI. The width of the obstacle, $w$, and the location of the gap, $y_{g}$, were selected randomly for each experimental run.
Fig. 5.

The two planning problems used in Section VI . The width of the obstacle, w , and the location of the gap, y_{g} , were selected randomly for each experimental run.

Show All

The algorithms share the same unoptimized code, allowing for the comparison of relative computational time 2 . While further optimization would reduce the effect of graph size on the computational cost and reduce the difference between the two planners, as they have approximately the same cost per iteration it will not effect the order. To minimize the effects of the steer parameter on our results, we set it equal to the RRT* rewiring radius at each iteration calculated from \gamma_{{\rm RRT}}= 1.1\gamma_{{\rm RRT}}^{\ast} , a choice we found improved the performance of RRT*. As discussed in Section V-A , for Informed RRT* we calculated the rewiring radius for the subproblem defined by the current solution using the expression in [7] .

Experiments varying the width of the problem range, l , while keeping a fixed distance between the start and goal show that Informed RRT* finds a suitable solution in approximately the same time regardless of the relative size of the problem ( Fig. 8 ). As a result of considering only the informed subset once an initial solution is found, the size of the search space is independent of the planning range ( Fig. 6 ). In contrast, the time needed by RRT* to find a similar solution increases as the problem range grows as proportionately more time is spent searching states that cannot improve the solution ( Fig. 8 ).

Experiments varying the target solution cost show that Informed RRT* is capable of finding near-optimal solutions in significantly fewer iterations than RRT* ( Fig. 9 ). The direct sampling of the informed subset increases density around the optimal solution faster than global sampling and therefore increases the probability of improving the solution and further focusing the search. In contrast, RRT* has uniform density across the entire planning domain and improving the solution actually decreases the probability of finding further improvements ( Fig. 6 ).

Experiments varying the height of h_{g} in Fig. 5(b) demonstrate that Informed RRT* finds difficult passages that improve the current solution, regardless of their homotopy class, quicker than RRT* ( Fig. 10 ). Once again, the result of considering only the informed subset is an increased state density in the region of the planning problem that includes the optimal solution. Compared to global sampling, this increases the probability of sampling within difficult passages, such as narrow gaps between obstacles, decreasing the time necessary to find such solutions ( Fig. 7 ).
Fig. 6. - An example of Fig. 5(a) after 5 seconds for a problem with an optimal solution cost of 112.01. Note that the presence of an obstacle provides a lower bound on the size of the ellipsoidal subset but that Informed RRT* still searches a significantly reduced domain than RRT*, increasing both the convergence rate and quality of final solution.
Fig. 6.

An example of Fig. 5(a) after 5 seconds for a problem with an optimal solution cost of 112.01. Note that the presence of an obstacle provides a lower bound on the size of the ellipsoidal subset but that Informed RRT* still searches a significantly reduced domain than RRT*, increasing both the convergence rate and quality of final solution.

Show All
Fig. 7. - An example of Fig. 5(b) for a 3% off-centre gap. By focusing the search space on the subset of states that may improve an initial solution flanking the obstacle, Informed RRT* is able to find a path through the narrow opening in 4.00 seconds while RRT* requires 12.32 seconds.
Fig. 7.

An example of Fig. 5(b) for a 3% off-centre gap. By focusing the search space on the subset of states that may improve an initial solution flanking the obstacle, Informed RRT* is able to find a path through the narrow opening in 4.00 seconds while RRT* requires 12.32 seconds.

Show All

Finally, experiments on random worlds demonstrate that the improvements of Informed RRT* apply to a wide range of planning problems and state dimensions ( Fig. 11 ).
SECTION VII.
Discussion & Conclusion

In this paper, we discuss that a necessary condition for RRT* algorithms to improve a solution is the addition of a state from a subset of the planning problem, X_{f}\subseteq X . For problems seeking to minimize path length in {\BBR}^{n} , this subset can be estimated, X_{\hat{f}}\supseteq X_{f} , by a prolate hyperspheroid (a special type of hyperellipsoid) with the initial and goal states as focal points. It is shown that the probability of adding a new state from this subset through rejection sampling of a larger set becomes arbitrarily small as the dimension of the problem increases, the size of the sampled set increases, or the solution approaches the theoretical minimum. A simple method to sample X_{\hat{f}} directly is presented that allows for the creation of informed-sampling planners, such as Informed RRT*. It is shown that Informed RRT* outperforms RRT* in the ability to find near-optimal solutions in finite time regardless of state dimension without requiring any assumptions about the optimal homotopy class.

Informed RRT* uses heuristics to shrink the planning problem to subsets of the original domain. This makes it inherently dependent on the current solution cost, as it cannot focus the search when the associated prolate hyperspheroid is larger than the planning problem itself. Similarly, it can only shrink the subset down to the lower bound defined by the optimal solution. We are currently investigating techniques to focus the search without requiring an initial solution. These techniques, such as Batch Informed Trees (BIT*) [25] , incrementally increase the search subset. By doing so, they prioritize the initial search of low-cost solutions.
Fig. 8. - The median computational time needed by RRT* and Informed RRT* to find a path within 2% of the optimal cost in ${\BBR}^{2}$ for various map widths, $l$, for the problem in Fig. 5(a). Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.
Fig. 8.

The median computational time needed by RRT* and Informed RRT* to find a path within 2% of the optimal cost in {\BBR}^{2} for various map widths, l , for the problem in Fig. 5(a) . Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.

Show All
Fig. 9. - The median computational time needed by RRT* and Informed RRT* to find a path within the specified tolerance of the optimal cost, $c^{\ast}$, in ${\BBR}^{2}$ for the problem in Fig. 5(a). Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.
Fig. 9.

The median computational time needed by RRT* and Informed RRT* to find a path within the specified tolerance of the optimal cost, c^{\ast} , in {\BBR}^{2} for the problem in Fig. 5(a) . Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.

Show All
Fig. 10. - The median computational time needed by RRT* and Informed RRT* to find a path cheaper than flanking the obstacle for various gap ratios, $h_{g}/h$ for the problem defined in Fig. 5(b). Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.
Fig. 10.

The median computational time needed by RRT* and Informed RRT* to find a path cheaper than flanking the obstacle for various gap ratios, h_{g}/h for the problem defined in Fig. 5(b) . Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.

Show All
Fig. 11. - The median performance of RRT* and Informed RRT* 60 seconds after finding an initial solution for random worlds (e.g., Figs. 1, 2) in ${\BBR}^{n}$. Plotted as the relative difference in cost, $(c_{{\rm best}}^{{\rm RRT}^{\ast}}-c_{{\rm best}}^{{\rm Informed\ RRT}^{\ast}})/(c_{{\rm best}}^{{\rm RRT}^{\ast}})$. Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.
Fig. 11.

The median performance of RRT* and Informed RRT* 60 seconds after finding an initial solution for random worlds (e.g., Figs. 1 , 2 ) in {\BBR}^{n} . Plotted as the relative difference in cost, (c_{{\rm best}}^{{\rm RRT}^{\ast}}-c_{{\rm best}}^{{\rm Informed\ RRT}^{\ast}})/(c_{{\rm best}}^{{\rm RRT}^{\ast}}) . Error bars denote a nonparametric 95% confidence interval for the median number of iterations calculated from 100 independent runs.

Show All

An open motion planning library (OMPL) implementation of Informed RRT* is described at http://asrl.utias.utoronto.ca/code .
ACKNOWLEDGMENT

This research was funded by contributions from the Natural Sciences and Engineering Research Council of Canada (NSERC) through the NSERC Canadian Field Robotics Network (NCFRN), the Ontario Ministry of Research and Innovation's Early Researcher Award Program, and the Office of Naval Research (ONR) Young Investigator Program.

Authors
Figures
References
Citations
Keywords
Metrics
Media
Footnotes
More Like This
Informed Sampling for Asymptotically Optimal Path Planning

IEEE Transactions on Robotics

Published: 2018
Optimal control-based UAV path planning with dynamically-constrained TSP with neighborhoods

2017 17th International Conference on Control, Automation and Systems (ICCAS)

Published: 2017
Show More
References
1.
P. E. Hart, N. J. Nilsson and B. Raphael, "A formal basis for the heuristic determination of minimum cost paths", TSSC , vol. 4, no. 2, pp. 100-107, Jul. 1968.
Show in Context CrossRef Google Scholar
2.
S. M. LaValle and J. J. Kuffner, "Randomized kinodynamic planning", IJRR , vol. 20, no. 5, pp. 378-400, 2001.
Show in Context CrossRef Google Scholar
3.
L. E. Kavraki, P. Svestka, J.-C. Latombe and M. H. Overmars, "Probabilistic roadmaps for path planning in high-dimensional configuration spaces", TRA , vol. 12, no. 4, pp. 566-580, 1996.
Show in Context View Article
Google Scholar
4.
D. Hsu, R. Kindel, J.-C. Latombe and S. Rock, "Randomized kinodynamic motion planning with moving obstacles", IJRR , vol. 21, no. 3, pp. 233-255, 2002.
Show in Context CrossRef Google Scholar
5.
C. Urmson and R. Simmons, "Approaches for heuristically biasing RRT growth", IROS , vol. 2, pp. 1178-1183, 2003.
Show in Context CrossRef Google Scholar
6.
D. Ferguson and A. Stentz, "Anytime RRTs", IROS , pp. 5369-5375, 2006.
Show in Context CrossRef Google Scholar
7.
S. Karaman and E. Frazzoli, "Sampling-based algorithms for optimal motion planning", IJRR , vol. 30, no. 7, pp. 846-894, 2011.
Show in Context CrossRef Google Scholar
8.
M. Otte and N. Correll, "C-FOREST: Parallel shortest path planning with superlinear speedup", TRO , vol. 29, no. 3, pp. 798-806, Jun. 2013.
Show in Context View Article
Google Scholar
9.
Y. Gabriely and E. Rimon, "CBUG: A quadratically competitive mobile robot navigation algorithm", TRO , vol. 24, no. 6, pp. 1451-1457, Dec. 2008.
Show in Context View Article
Google Scholar
10.
N. Gasilov, M. Dogan and V. Arici, "Two-stage shortest path algorithm for solving optimal obstacle avoidance problem", IETE Jour. of Research , vol. 57, no. 3, pp. 278-285, May 2011.
Show in Context CrossRef Google Scholar
11.
S. Kiesel, E. Burns and W. Ruml, "Abstraction-guided sampling for motion planning", SoCS , 2012.
Show in Context Google Scholar
12.
R. Alterovitz, S. Patil and A. Derbakova, "Rapidly-exploring roadmaps: Weighing exploration vs. refinement in optimal motion planning", ICRA , pp. 3706-3712, 2011.
Show in Context View Article
Google Scholar
13.
B. Akgun and M. Stilman, "Sampling heuristics for optimal motion planning in high dimensions", IROS , pp. 2640-2645, 2011.
Show in Context CrossRef Google Scholar
14.
J. Nasir, F. Islam, U. Malik, Y. Ayaz, O. Hasan, M. Khan, et al., "RRT*-SMART: A rapid convergence implementation of RRT*", Int. Jour. of Adv. Robotic Systems , vol. 10, 2013.
Show in Context CrossRef Google Scholar
15.
D. Kim, J. Lee and S. Yoon, "Cloud RRT*: Sampling cloud based RRT*", ICRA , 2014.
Show in Context View Article
Google Scholar
16.
S. Karaman, M. R. Walter, A. Perez, E. Frazzoli and S. Teller, "Anytime motion planning using the RRT*", ICRA , pp. 1478-1483, 2011.
Show in Context View Article
Google Scholar
17.
M. Jordan and A. Perez, "Optimal bidirectional rapidly-exploring random trees", CSAIL MIT MIT-CSAIL-TR-2013-021 , 2013.
Show in Context Google Scholar
18.
O. Arslan and P. Tsiotras, "Use of relaxation methods in sampling-based algorithms for optimal motion planning", ICRA , 2013.
Show in Context CrossRef Google Scholar
19.
S. Koenig, M. Likhachev and D. Furcy, "Lifelong planning A*", Artificial Intelligence , vol. 155, no. 1–2, pp. 93-146, 2004.
Show in Context CrossRef Google Scholar
20.
J. D. Gammell, S. S. Srinivasa and T. D. Barfoot, "On recursive random prolate hyperspheroids", Autonomous Space Robotics Lab University of Toronto TR-2014-JDG002 , 2014.
Show in Context Google Scholar
21.
H. Sun and M. Farooq, "Note on the generation of random points uniformly distributed in hyper-ellipsoids", Fifth Int. Conf. on Information Fusion , vol. 1, pp. 489-496, 2002.
Show in Context Google Scholar
22.
J. D. Gammell and T. D. Barfoot, "The probability density function of a transformation-based hyperellipsoid sampling technique", Autonomous Space Robotics Lab University of Toronto TR-2014-JDG004 , 2014.
Show in Context Google Scholar
23.
G. Wahba, "A least squares estimate of satellite attitude", SIAM Review , vol. 7, pp. 409, 1965.
Show in Context CrossRef Google Scholar
24.
A. H. J. de Ruiter and J. R. Forbes, "On the solution of Wahba's problem on SO(n)", Jour. of the Astronautical Sciences , 2014.
Show in Context Google Scholar
25.
J. D. Gammell, S. S. Srinivasa and T. D. Barfoot, "BIT*: Batch informed trees for optimal sampling-based planning via dynamic programming on implicit random geometric graphs", Autonomous Space Robotics Lab University of Toronto TR-2014-JDG006 , 2014.
Show in Context Google Scholar
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
IEEE Account

    Change Username/Password
    Update Address

Purchase Details

    Payment Options
    Order History
    View Purchased Documents

Profile Information

    Communications Preferences
    Profession and Education
    Technical Interests

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support

    About IEEE Xplore
    Contact Us
    Help
    Accessibility
    Terms of Use
    Nondiscrimination Policy
    Sitemap
    Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.
© Copyright 2022 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.
