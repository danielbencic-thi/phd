Lectures on
Robotic Planning and Kinematics
Francesco Bullo Stephen L. Smith

Lectures on Robotic Planning and Kinematics Francesco Bullo and Stephen L. Smith Version v0.93 – Jan 1, 2022.
This work is licensed under the Creative Commons Attribution-NonCommercialShareAlike 4.0 International License. A summary (not a substitute) of the license is as follows: You are allowed to
• share, that is, copy and redistribute this work in any medium or format, and • adapt, that is, remix, transform, and build upon this work, provided (i) appropriate attribution is given, (ii) the material is not used for commercial purposes, and (iii) the adapted material is distributed under the same license as the original. Exceptions to this license are the Figures 3.2, 3.3, 3.5, 3.15 and 8.4. Permission is granted to reproduce these figures as part of this work in both print and electronic formats, for distribution worldwide in the English language. All other copyrights for Figures 3.2, 3.3, 3.5, 3.15 and 8.4 belong to their respective owners. Links are provided throughout the text to Wikipedia articles, which are released under the Creative Commons Attribution-Share-Alike License 3.0.
This book was typeset using LATEX. Cover art is courtesy of openclipart.
We are thankful for any feedback information, including suggestions, errors, or comments about teaching or research uses.

To Lily, Marcello and Gabriella To Julia

Contents

Contents

iv

Preface

vii

I Planning

1

1 Sensor-based Planning

3

1.1 Problem setup and modeling assumptions . . . . . . . . . . . . . . . 3

1.2 The Bug 0 algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

1.3 The Bug 1 algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

1.4 The Bug 2 algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

1.5 The completeness of the Bug 1 algorithm . . . . . . . . . . . . . . . 17

1.6 Appendix: Operations on sets . . . . . . . . . . . . . . . . . . . . . . 19

1.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

2 Motion Planning via Decomposition and Search

29

2.1 Problem setup and modeling assumptions . . . . . . . . . . . . . . . 29

2.2 Workspace decomposition . . . . . . . . . . . . . . . . . . . . . . . . 32

2.3 Search algorithms over graphs . . . . . . . . . . . . . . . . . . . . . 39

2.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

3 Configuration Spaces

55

3.1 Problem setup: Multi-body robots in realistic workspaces . . . . . . 55

3.2 The configuration space . . . . . . . . . . . . . . . . . . . . . . . . . 57

3.3 Example configuration spaces . . . . . . . . . . . . . . . . . . . . . . 60

3.4 Forward and inverse kinematic maps . . . . . . . . . . . . . . . . . . 65

3.5 Appendix: Inverse trigonometric problems . . . . . . . . . . . . . . . 68

iv

Contents

3.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72

4 Free Configuration Spaces via Sampling and Collision Detection 77 4.1 The free configuration space . . . . . . . . . . . . . . . . . . . . . . . 77 4.2 Numerical computation of the free configuration space . . . . . . . . 84 4.3 Sampling methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 4.4 Collision detection methods . . . . . . . . . . . . . . . . . . . . . . . 91 4.5 Appendix: Runtime of the numerical computation of the free configuration space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

5 Motion Planning via Sampling

105

5.1 Roadmaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

5.2 Complete planners on exact roadmaps . . . . . . . . . . . . . . . . . 107

5.3 General-purpose planners via sampling-based roadmaps . . . . . . . 109

5.4 Incremental sampling-based planning . . . . . . . . . . . . . . . . . 112

5.5 Appendix: Shortest paths in weighted graphs via Dijkstra’s algorithm 116

5.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120

II Kinematics

121

6 Introduction to Kinematics and Rotation Matrices

123

6.1 Geometric objects and their algebraic representation . . . . . . . . . 124

6.2 Geometric properties of rotations . . . . . . . . . . . . . . . . . . . . 127

6.3 Representing reference frames . . . . . . . . . . . . . . . . . . . . . 129

6.4 Appendix: A brief review of matrix theory . . . . . . . . . . . . . . . 133

6.5 Appendix: The theory of groups . . . . . . . . . . . . . . . . . . . . 135

6.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137

7 Rotation Matrices

139

7.1 From reference frames to general rotation matrices . . . . . . . . . . 139

7.2 Composition of rotations . . . . . . . . . . . . . . . . . . . . . . . . 143

7.3 Parametrization of rotation matrices . . . . . . . . . . . . . . . . . . 147

7.4 Appendix: Properties of skew symmetric matrices . . . . . . . . . . 153

7.5 Appendix: Proof of Rodrigues’ formula and of its inverse . . . . . . . 155

7.6 Appendix: Unit quaternions to represent rotations . . . . . . . . . . 156

7.7 Appendix: From a noisy measurement to an exact rotation matrix . . 159

7.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

8 Displacement Matrices and Inverse Kinematics

167

Contents

8.1 Displacements as matrices . . . . . . . . . . . . . . . . . . . . . . . . 167 8.2 Basic and composite displacements . . . . . . . . . . . . . . . . . . . 171 8.3 Inverse kinematics on the set of displacements . . . . . . . . . . . . 174 8.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

9 Linear and Angular Velocities of a Rigid Body

183

9.1 Angular velocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184

9.2 Linear and angular velocities . . . . . . . . . . . . . . . . . . . . . . 187

9.3 Vehicle motion models and integration . . . . . . . . . . . . . . . . . 189

9.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191

Bibliography

193

Algorithm Index

197

Symbol Index

199

Preface
Topics These undergraduate level lecture notes cover motion planning and kinematics with an emphasis on geometric reasoning, programming and matrix computations. In the context of motion planning, we present sensor-based planning, configuration spaces, decomposition and sampling methods. In the context of kinematics, we present reference frames, rotation matrices and their properties, displacement matrices, and kinematic motion models.
This book is a collection of lecture notes and is not meant to provide a comprehensive treatment of any topic in particular. For more comprehensive textbooks and more advanced research monographs, we refer the reader to a rich growing literature, including the treatments by Choset et al. (2005); Corke (2011); Craig (2003); Dudek and Jenkin (2010); Jazar (2010); Kelly (2013); LaValle (2006); Mason (2001); Murray et al. (1994); Niku (2010); Selig (1996); Siciliano et al. (2009); Siegwart et al. (2011); Spong et al. (2006); Thrun et al. (2005).
The intended audience and use of these lectures These lecture notes are intended for undergraduate students pursuing a 4-year degree in mechanical, electrical or related engineering disciplines. Computer Science students will find that the chapters on motion planning overlap with their courses on data structures and algorithms. Prerequisites for these lecture notes include a course on programming, a basic course on linear algebra and matrix theory, and basic knowledge of ordinary differential equations.
These lecture notes are intended for use in a course with approximately 30-36 contact hours (e.g., roughly one chapter per week in a 10-week long course). Student homework includes standard textbook exercises as well as an extensive set of programming exercises (focused on motion planning). We envision this textbook to be used with weekly homework assignments, weekly computer laboratory assignments, a midterm exam, and a final exam.
vii

Preface
For the benefit of instructors, these lecture notes are supplemented by two documents. First, a solutions manual, including programming solutions, is available upon request free of charge to instructors at accredited institutions. Second, these lecture notes are also available in “slide/landscape” format especially suited for classroom teaching with projectors or screens.
Learning Objectives Course learning outcomes, i.e., skills that students should possess at the end of a 10-week course based upon these lectures, include:
(i) an ability to apply knowledge of geometry, graph algorithms, and linear algebra to robotic systems,
(ii) an ability to use a numerical computing and programming environment to solve engineering problems,
(iii) an ability to formulate, and solve motion planning problems in robotics, and (iv) an ability to formulate and solve kinematics problems in robotics.
Implementation via Programming These notes contain numerous algorithms written in pseudocode and numerous programming assignments. We ask the reader to choose a programming language and environment capable of numerical computation and graphical visualization. Typical choices may be Matlab and Python (with its packages numpy and scipy). Later programming assignments depend upon earlier ones and so readers are advised to complete the programming assignments in the order in which they appear.
Readers should be informed that the purpose of the programming assignments is to develop their understanding of algorithms and their programming ability. For more advanced purposes (e.g., commercial enterprises or research projects), we refer to CGAL for an efficient and reliable algorithm library available as open source software; see (Fabri and Pion, 2009) or (The CGAL Project, 2015), and to the “The Motion Strategy Library” and the “Open Motion Planning Library” for motion planning libraries by LaValle et al. (2003) and Şucan et al. (2012), respectively.
Acknowledgments First, we wish to thank Joey W. Durham, who designed and implemented the first version of many exercises and programming assignments, and Patrick Therrien, who prepared a comprehensive set of programming solutions in Matlab and Python. We are also very thankful to all instructors who were early adopters of these lecture notes and provided useful feedback, including Professors Sonia Martínez and Fabio Pasqualetti. Finally, it is our pleasure to thank Anahita Mirtabatabaei, Rush Patel, Giulia Piovan, Cenk Oguz Saglam, Sepehr Seifi and Carlos Torres for having contributed in various ways to the material in these notes and in the assignments.

Preface
Santa Barbara, California, USA Waterloo, Ontario, Canada Jul 6, 2010 — Jan 1, 2022

Francesco Bullo Stephen L. Smith

Part I
Planning
1

1 Chapter
Sensor-based Planning
In this chapter we begin our investigation into motion planning problems for mobile robots. We consider the fundamental robotic task of moving from a starting point A to goal point B in an environment with obstacles. This chapter focuses on sensorbased motion planning, where the obstacles are initially unknown to the robot, and the robot acquires information about its surroundings using onboard sensors as it moves. Whether or not a robot can succeed at navigating from start to goal will depend on its sensors and capabilities. In this chapter we
(i) introduce three bug algorithms for sensor-based motion planning, (ii) define notions of optimality and completeness for motion planning algorithms,
and (iii) study the completeness of the three bug algorithms.
1.1 Problem setup and modeling assumptions
Motion planning is an important and common problem in robotics. In its simplest form, the motion planning problem is: how to move a robot from a “start” location to a “goal” location avoiding obstacles. This problem is sometimes referred to as the “move from A to B” or the “piano movers problem” (how do you move a complex object like a piano in an environment with lots of obstacles, like a house).
In this first chapter, we consider a sensor-based planning problem for a point moving in the plane R2. In other words, we assume the robot has a sensor and, based on the sensor measurements, it plans its motion from start to goal. To properly describe the motion planning problem, we need to specify: what capacities does the robot have? What information does the robot have?
In this chapter, we make the following assumptions on the robot and its environment. As illustrated in Figure 1.1, we are given
3

Chapter 1. Sensor-based Planning

O1

pgoal

O2

pstart
W
Figure 1.1: The environment for sensor-based planning
• a workspace W that is a subset of R2 or R3, often just a rectangle; • some obstacles O1, O2, . . . , On; • a start point pstart and a goal point pgoal; and • a robot described by a moving point (that is, the robot has zero size).
We define the free workspace Wfree = W \ (O1 ∪ O2 ∪ · · · ∪ On) as the set of points in W that are outside all obstacles. (Recall the definition of the set A \ B = {a ∈ A | a ̸∈ B}, that is, all points in A that are not in B.)
Robot Assumptions We also make some assumptions on the capabilities and knowledge of the robot. We assume the robot:
• knows the direction towards the goal, • knows the straight-line distance between itself and the goal, • does not know anything about the obstacles (number, location, shape, etc), • has a contact sensor that allows it to locally detect obstacles, • can move either in a straight line towards the goal or can follow an obstacle
boundary (possibly by using its contact sensor), and • has limited memory in which it can store distances and angles.
We discuss in more detail later what these robot capabilities imply in terms of robot sensors and knowledge.
Our task is to plan the robot motion from the start point to the goal point. This plan is not a precomputed sequence of steps to be executed, but rather a policy to deal with the possible obstacles that the robot may encounter along the way.

1.2. The Bug 0 algorithm

Environment Assumptions Finally, we make some assumptions on the workspace and obstacles:
• the workspace is bounded, • there are only a finite number of obstacles, • the start and goal points are in the free workspace Wfree, and • any straight line drawn in the environment crosses the boundary of each
obstacle only a finite number of times. (This assumption is easily satisfied for “normal objects” and we will use it later on to establish the correctness of our algorithms.)
In the next sections we see three different algorithms for planning the robot motion from start to goal, called Bug 0, Bug 1, and Bug 2. Each algorithm has slightly different requirements on the robot’s capabilities and knowledge. As a result, we will also see that they have different performance in finding paths from start to goal.

1.2 The Bug 0 algorithm

Starting from the scenario illustrated in Figure 1.1, suppose the robot heads towards the goal position from the start position. How does the robot handle collisions with obstacles? (Note that the robot sensor is local so that the robot only knows it has hit an obstacle.) We need a strategy to avoid the obstacle and move towards the goal destination.
What follows is our first motion planning algorithm.

Bug 0 algorithm

1: while not at goal :

2: move towards the goal

3: if hit an obstacle :

4:

while not able to move towards the goal :

5:

follow the obstacle’s boundary moving to the left

Moving to the left means that the robot is just sliding along the obstacle boundary, i.e., circumnavigating the obstacle boundary in a clockwise fashion. The moving direction, left or right, is fixed but irrelevant. We only need to designate one
preferred direction to turn once the robot hits an obstacle. A right-turning robot will circumnavigate an obstacle in a counterclockwise fashion. A right-turning robot follows the same path as a left-turning robot in a reflected world.
As shown in Figure 1.2 we label the point on the obstacle boundary where the robot hits the obstacle as phit and the point on the obstacle boundary where the robot leaves as pleave.

Chapter 1. Sensor-based Planning

pgoal

pleave

phit pstart

Figure 1.2: A successful execution of the Bug 0 algorithm

Note: we are not being very careful clarifying whether the robot moves in discrete steps or in continuous time. For now imagine that the robot can move smoothly, visit all boundary points, take a measurement at each point and store the distance from the closest boundary point.

The Bug 0 algorithm does not always find a path to the goal Unfortunately, our Bug 0 algorithm does not work properly in the sense that there are situations (workspaces, obstacles, start and goal positions) for which there exists a solution (a path from start to goal) but the Bug 0 Algorithm does not find it. We will talk more later about the correctness of an algorithm and in particular about the notion of completeness.
This example in the Figure 1.3 illustrates a periodic loop generated by the Algorithm Bug 0. At the end of each loop there is no complete progress to goal.

pstart

pgoal

Figure 1.3: An unsuccessful execution of the Bug 0 Algorithm

1.3. The Bug 1 algorithm

1.3 The Bug 1 algorithm

The fact that Bug 0 does not always find a path to the goal may not be too surprising: The algorithm is not making use of all of the capabilities of the robot. In particular, the algorithm does not use any memory, nor does it use the distance to the goal. This observation motivates our second smarter sensor-based algorithm for a more capable bug.

Bug 1 algorithm

1: while not at goal :

2: move towards the goal 3: if hit an obstacle :

4:

circumnavigate it (moving to the left or right is unimportant). While cir-

cumnavigating, store in memory the minimum distance from the obstacle

boundary to the goal

5:

follow the boundary back to the boundary point with minimum distance to

the goal

pgoal

pstart

pgoal

pstart
Figure 1.4: Two successful executions of the Bug 1 Algorithm
Note: the only difference between Bug 0 and Bug 1 is the reaction to the obstacle encounter, i.e., the behavior inside the if command.
1.3.1 Implementing Bug 1 The Bug 1 algorithm can be implemented as follows. In the simplest version, when the robot hits an obstacle at phit, it records the distance and direction to the goal. The robot then circumnavigates the obstacle, storing in memory a variable containing the minimum distance from its current position along the obstacle boundary to the goal. Regarding instruction 4:, the circumnavigation is complete when the robot returns to the distance and direction it recorded at phit. The robot then partially

Chapter 1. Sensor-based Planning
circumnavigates the obstacle a second time until its distance to goal matches the minimum distance it has stored in memory.
In a more sophisticated version, the robot would additionally measure the distance it travels while circumnavigating the obstacle and therefore return to the closest point along the boundary using the shorter of the clockwise and counterclockwise paths. An instrument for measuring distance traveled is known as a linear odometer. If the robot moves at constant speed, then a clock suffices as a linear odometer: distance traveled is equal to speed times travel time. If the robot’s speed is variable, then one typically uses encoders in the robot wheels to measure the number of wheel rotations.
In summary, the Bug 1 robot must have memory for storing information about phit and for computing pleave and it benefits from (but does not require) a linear odometer, i.e., an instrument to measure traveled distance.
1.3.2 Flowcharts
Before we proceed any further, it is useful to stop and discuss how to represent algorithms. So far we have adopted the pseudocode representation, i.e., a simplified English-like language that is midway between English and computer programming. It is also useful to understand how to represent our algorithms using flowcharts. Since flowchart representations can become quite large, they are typically useful for only simple programs.
According to Wikipedia:pseudocode, “pseudocode is compact and informal highlevel description of a computer programming algorithm that uses the structural conventions of a programming language, but is intended for human reading rather than machine reading.”
According to Wikipedia:flowchart, “a flowchart is a type of diagram that represents an algorithm or process, showing the steps as boxes of various kinds, and their order by connecting these with arrows.”
The four constitutive elements of a flowchart A flowchart consists of four symbols shown in Figure 1.5, which can be thought of as a graphical language.
Note: The dominant convention in drawing flowcharts is to have the flow of control go from top to bottom and left to right.
Flowchart representation for the Bug 1 Algorithm If you examine carefully the Bug 1 flowchart, you can clearly see that the algorithm may end in failure. This is indeed possible if the workspace is composed of disconnected components (that is, pieces of the free workspace that can not be connected with a path), and the

1.3. The Bug 1 algorithm

start/end Process/Action

Circles represent the start and terminating points Arrows indicate the flow of control Rectangles represent a single command

Decision

Diamonds output 2 paths based on a binary question

Figure 1.5: The four elements of a flowchart
start

yes reached goal?
no
take step towards
goal

end in success

no

hit obstacle?

yes

circumnavigate obstacle

move to point closest to goal

yes

able to step

no

end in

towards

failure

goal?

Figure 1.6: Flowchart representation for the Bug 1 Algorithm

start and goal locations belong to distinct disconnected components as shown in Figure 1.7.
1.3.3 The performance of the Bug 1 algorithm Next, let us begin to rigorously analyze the Bug 1 algorithm. There are 2 desirable properties we wish to establish:
• optimality (with respect to some desirable metric), and • completeness (i.e., correctness in an appropriate sense).

Chapter 1. Sensor-based Planning

pstart

Goal

pgoal

Figure 1.7: Environment for which no path exists from start to goal
We begin with the simpler analysis, i.e., the study of optimality. We are interested in seeing how efficient is the algorithm in completing its task in a workspace with arbitrary obstacles.
The question is: what is the length of the path generated by the Bug 1 Algorithm in going from start to goal? While a precise answer is hard to obtain in general, we can ask three more specific questions:
(i) Will Bug 1 find the shortest path from start to goal? (ii) How long will the path found by Bug 1 be? Can we find a lower bound and an
upper bound on the path length generated by Bug 1? (iii) Is there a workspace where the upper bound is required?
In order to answer these mathematical questions, it is good to have some notation:
D = length of straight segment from start to goal, perimeter(Oi) = length of perimeter of the ith obstacle.

Theorem 1.1 (Performance of Bug 1). Consider a workspace with n obstacles and assume that the Bug 1 algorithm finds a path to the goal. Assuming the robot is not equipped with a linear odometer, the following properties hold:

(i) Bug 1 does not find the shortest path in general;

(ii) the path length generated by Bug 1 is lower bounded by D;

(iii) the path length generated by Bug 1 is upper bounded by D+2

n i=1

perimeter(Oi

);

and

(iv) the upper bound is reached in the workspace described in Figure 1.8.

Note: Assume now that the robot is equipped with a linear odometer. After circumnavigating an obstacle, the robot can therefore move along the shorter of the two paths from hit point to leave point. In this case, the robot will travel at most

1.4. The Bug 2 algorithm

pstart

pgoal

pstart

pgoal

Figure 1.8: An example environment where the upper bound on the performance of Bug 1 is achieved, as stated in Theorem 1.1(iii).

Figure 1.9: An example environment where the upper bound on the performance of Bug 1 is achieved for a robot with a linear odometer.

1/2 of the perimeter to return to the leave point and the upper bound on the path

length

can

be

strengthened

to

D

+

3 2

n i=1

perimeter(Oi).

An

example

environment

achieving this bound is shown on the right of Figure 1.9.

1.4 The Bug 2 algorithm
Let us now try to design a new algorithm that generates shorter paths than Bug 1. The perceived problem with Bug 1 is that each obstacle needs to be fully explored before the robot can proceed towards the goal. Can we do better, i.e., can we decide to leave the obstacle without traversing all its boundary?
We use the term start-goal line to refer to the unique line that passes through the start point and goal point. The start-goal line is the dashed line intersecting the two obstacles as shown on the left of Figure 1.10. To aid in the design of Bug 2, we begin with a preliminary version.

pgoal

pgoal

pstart

pstart

pstart

pgoal

Figure 1.10: The start-goal line, a successful execution of the Bug2.prelim algorithm, and an unsuccessful execution of the Bug 2.prelim algorithm

Chapter 1. Sensor-based Planning

Bug 2.prelim algorithm

1: while not at goal :

2: move towards the goal (along the start-goal line) 3: if hit an obstacle :

4:

follow the obstacle’s boundary (moving either left or right), until you en-

counter the start-goal line again and are able to move towards the goal

The example execution on the right of Figure 1.10 amounts to an undesired periodic cyclic trap again. How do we improve and possibly fix this misbehavior in our algorithm? It turns out that a small fix is sufficient. For convenience we repeat the entire algorithm, but the only difference is the addition of the requirement that the leave point be closer to the goal than the hit point!

Bug 2 algorithm

1: while not at goal :

2: move towards the goal (along the start-goal line) 3: if hit an obstacle :

4:

follow the obstacle’s boundary (the turn direction is irrelevant), until you

encounter the start-goal line again closer to the goal and are able to move

towards the goal

From the left of Figure 1.11 we see that Bug 2 finds a path to the goal where Bug 2.prelim did not. Let us briefly mention the requirements of Bug 2, although we will compare them more carefully in Section 1.4.3. For Bug 0, we assumed the robot can sense direction towards the goal, and it knows when it has reached the goal. For Bug 1 and 2, we assumed the robot can measure and store in memory the distances and directions to goal point that it senses along the boundary. In particular, Bug 2 stores distance and direction at the hit point and compares these two quantities with the ones it senses along the boundary.

1.4.1 Monotonic performance and its implications
Here we briefly discuss why our correction to the Bug 2.prelim algorithm is indeed helpful and has a chance to render the algorithm correct. Consider the function of time equal to the distance between the robot and the goal point (this distance is a function of time because the robot is moving). Let us plot this distance function of time along the execution of the Bug 2 algorithm.
As Figure 1.11 illustrates, the leave point pleave is closer to the goal than the hit point phit. Of course, throughout the search phase (while the robot is moving along the boundary to find the optimal leave point) the distance function may not always

1.4. The Bug 2 algorithm

3

4

pstart

1 6 7
10 pgoal

2 O1 5
8 O2
9

distance from robot to goal 3 4

start

12

56

89

7

following O1

10 goal time
following O2

Figure 1.11: The monotonic performance of Bug 2

decrease, but after the search phase is complete, the robot will indeed be closer to the goal.
This discussion establishes that the distance between the robot and the goal is a monotonically decreasing function of time, when the robot is away from any obstacles.
Monotonicity immediately implies that there can be no cycles (and therefore no infinite cycles) in the execution of the algorithm. The lack of such cycles is true because (1) the leave point is closer to the goal than the hit point and (2) when the robot moves away from the obstacle the distance continues to decrease. Therefore, it is impossible for the robot to hit the same obstacle again at the same hit point.
1.4.2 The performance of the Bug 2 algorithm
Let us now analyze the performance of the Bug 2 algorithm. With the usual convention (D is the distance between start and goal and perimeter(Oi) is the perimeter of the ith obstacle), we have the following results.
Theorem 1.2 (Performance of Bug 2). Consider a workspace with n obstacles and assume that the Bug 2 algorithm finds a path to the goal. The following properties hold:
(i) Bug 2 does not find the shortest path in general; (ii) the path length generated by Bug 2 is lower bounded by D; (iii) the path length generated by Bug 2 is upper bounded by
n
D + ci perimeter(Oi)/2,
i=1
where ci is the number of intersections of the start-goal line with the boundary of obstacle Oi.

Chapter 1. Sensor-based Planning

Proof. The first statement is obvious. Regarding the second statement, the lower

bound is the same as that for Bug 1 – no surprise here. Regarding the third statement,

the upper bound is different from that for Bug 1 and is due to the following fact:

each time Bug 2 hits an obstacle (at a hit point), it might need to travel the entire

obstacle’s perimeter before finding an appropriate leave point. So for each pair of hit point and leave point (2 intersection points), the Bug 2 travels at most the obstacle’s

perimeter.

■

1.4.3 Comparison between bug algorithms
After introducing the Bug 1 and Bug 2 algorithms, let us compare in terms of path length. We ignore Bug 0 in this discussion because we already established it is not correct via the example in Figure 1.3. Without losing any generality, let us assume both the Bug 1 and Bug 2 algorithms are left-turning.

Example where Bug 2 finds shorter path than Bug 1 Recall that the Bug 2 algorithm was introduced in an attempt to find shorter paths by not fully exploring the boundary of each encountered obstacle. Indeed it appears that Bug 2 works better in our running example, as shown in Figure 1.12.

Bug 1

Bug 2

pgoal

pgoal

pstart

pstart

Figure 1.12: Example environment in which Bug 2 is better than Bug 1

However, it is not clear that this fact must hold true for any problem (remember that a problem is determined by the workspace, the obstacles, and start and goal positions).

Counterexample where instead Bug 1 is better than Bug 2 Looking at the environment in Figure 1.13, we see that Bug 1 explores the entire perimeter of the obstacle only once and then moves to point pleave before leaving the obstacle for

1.4. The Bug 2 algorithm

Bug 1

pleave

pgoal

phit
pstart

Bug 2
pgoal
pleave,4 phit,4 pleave,3
phit,3 pleave,2
phit,2 pleave,1
phit,1
pstart

Figure 1.13: Example environment where Bug 1 is better than Bug 2. Bug 1 has one pair of hit and leave points. Bug 2 hits and then leaves the obstacle four times, as shown by the sequence of hit and leave points.
the goal. Bug 2, on the other hand, takes a much longer path. Indeed, whenever a robot implementing Bug 2 encounters a “left finger” in the environment, it ends up traveling all the way back near to the start position.
Summary of path length Bug 1 performs an exhaustive search by examining all possible leave points before committing to the optimal choice. Bug 2 is a greedy algorithm that takes the first-available leave point that is closer to the goal without any specific performance guarantee. While it is impossible to predict which of the two will outperform in an arbitrary environment, we may say that Bug 2 will outperform Bug 1 in many simple environments but Bug 1 has more predictable performance.
Summary of robot capabilities The bug algorithms have slightly different assumptions on the sensors and capabilities needed by the robot. Table 1.1 summarizes these capabilities: direction to goal, distance to goal, memory, linear odometer, and a new capability called an angular odometer or a compass. Recall that a linear odometer was an optional sensor/capability for Bug 1 and it allowed the robot to return to the leave point using the shorter of the two paths along the boundary.
The new sensor/capability of an “angular odometer or compass" is needed in order for the robot to store the direction to goal in memory. This is required in

Chapter 1. Sensor-based Planning

Sensor/Capability direction to goal distance to goal memory linear odometer angular odometer or compass

Bug 0 yes no no no no

Bug 1 yes yes yes
optional yes

Bug 2 yes yes yes no yes

Table 1.1: Summary of the robot capabilities needed to implement each bug algorithm

Bug 1 to determine when circumnavigation is complete, and in Bug 2 to determine when the start-goal line is encountered. The direction to goal must be stored in a known reference frame (for example, as a counterclockwise angle relative to a fixed x-axis) so that measured directions can be compared to the stored directions. The robot could define a local reference frame based on its heading, but this frame would rotate with the robot. It is not useful to store a direction in such a frame, unless the robot also somehow records the orientation of the frame when the direction was measured.
There are two possible fixes for this problem, illustrated in Figure 1.14. The first option is that the robot has a compass, and can then record the direction to goal relative to a fixed orientation as given by the compass. This is shown as the angle α1 relative to north on the left of Figure 1.14. The second option is that the robot can use an angular odometer to measure changes in its heading. The robot can use its initial heading at pstart as the orientation for its reference frame. The direction to goal can be specified in this initial frame as the sum of two angles, as shown on the right of Figure 1.14: the angle α2 can be measured with the aid of an angular odometer, and the angle α3 is the output of the “direction to goal” sensor.

Compass

north

pgoal

Angular Odometer
pgoal

↵1

pstart

initial heading

current

↵3

heading

↵2

Figure 1.14: Left figure: the robot records the direction to goal as an angle α1 relative to north. Right figure: the robot measures the direction to goal as α2 + α3, where α2 must be measured from angular odometer. The angle α3 is what is given by the “direction to goal”
sensor.

This discussion highlights some subtleties in the assumptions we have made

1.5. The completeness of the Bug 1 algorithm
on robot capabilities. While the Bug algorithms seem very simple at first glance, they actually require fairly strong assumptions on the sensing and knowledge of the robot. These assumptions are discussed in more detail by Taylor and LaValle (2009).
1.5 The completeness of the Bug 1 algorithm
Here we follow up on our previous discussions and formally define the completeness of an algorithm. Definition 1.3. An algorithm is complete if, in finite time,
(i) it finds a solution (i.e., a path), if a solution exists, or (ii) it terminates with a failure decision, if no solution exists.
Next, we establish that one of our proposed algorithms is indeed complete. This result was originally obtained by Lumelsky and Stepanov (1987). Theorem 1.4 (Completeness for Bug 1). The Bug 1 algorithm is complete (under the modeling assumptions stated early in the chapter).
1.5.1 On the geometry of closed curves To prove Theorem 1.4, we start by introducing a wonderful and useful geometric result. Theorem 1.5 (The Jordan Curve Theorem). Every non-self-intersecting continuous closed curve divides the plane into two connected parts. One part is bounded (called the inside) and the other part is unbounded (called the outside) and the curve is the boundary of both parts.

Outside

Inside

Figure 1.15: A closed curve divides the plane into two parts: the inside and the outside.
Next, consider the following. Imagine that the curve describes the boundary of the obstacle. Given a start and goal point outside the curve (obstacle), connect the two points using a straight segment and count the number of intersections between the segment and the boundary of the obstacle.
It is easy to see that this number of intersections must be even (where we regard 0 as an even number). Each time the segment enters the inside of the curve, it must then return to the outside. A few examples are given in Figure 1.16.

Chapter 1. Sensor-based Planning

pstart

0 intersections pgoal

pstart
pstart

pgoal

2 intersections

even number of intersections
pgoal

Figure 1.16: The number of intersections between a line segment and a closed curve, where the endpoints of the segment lie on the outside of the curve, is even.
1.5.2 Proof of the completeness theorem Here we prove Theorem 1.4. Recall that the Bug 1 algorithm is presented in pseudocode on page 7 and in flowchart on page 8.
By contradiction, assume Bug 1 does not find a path, even if a path exists Let us prove the theorem by contradiction. That is, we assume that Bug 1 is incomplete and we find a contradiction. Consider the situation when a path from start to goal does exist, but Bug 1 does not find it. The flowchart description of Bug 1 implies the following statement: if Bug 1 does not find the path, then necessarily Bug 1 will either terminate in failure in finite time or keep cycling forever.
Bug 1 cannot keep cycling forever Suppose Bug 1 cycles forever. Because there is a finite number of obstacles, the presence of an infinite cycle implies the robot must hit the same obstacle more than once. Now, during the execution of Bug 1, the distance to the goal is a function of time that is monotonically decreasing when the robot is away from any obstacle. Moreover, when the robot hits an obstacle, the distance from pleave to the goal is strictly lower than the distance from phit to the goal

1.6. Appendix: Operations on sets
(this fact can be seen geometrically). Therefore, when the robot leaves an obstacle it is closer to the goal than any point on the obstacle. Hence, Bug 1 cannot hit the same obstacle twice.
Bug 1 cannot end in failure, if a path exists If Bug 1 is incomplete and a path actually exists, then the only possible result is that it terminates in failure. According to the Bug 1 flowchart, failure occurs when: the robot visits all the obstacle boundary points reachable from the hit point, moves to the boundary point pleave closest to the goal, and is unable to move towards the goal. Consider now the segment from pleave to the goal point. Because a path exists from start to goal, a path must also exists between pleave and goal. By the Jordan Curve Theorem 1.5, there must be an even number of intersections between this segment and the obstacle boundary. Since pleave is one intersection, there must exist at least another one. Let pother be the intersection point closest to the goal. Now: the point pother has the following properties:
(i) lies on the obstacle boundary, (ii) is reachable from pleave (because it is reachable from the goal), and (iii) is closer to the goal than pleave. These facts are a contradiction with the definition of pleave.
Path from start to goal

pleave
phit
pstart

pother pgoal

Figure 1.17: An illustration of the two points pleave and pother

1.6 Appendix: Operations on sets
A set is a collection of objects. For example, using standard conventions, N is the set of natural numbers, R is the set of real numbers, and C is the set of complex numbers.
If a is a point in A, we write a ∈ A. Sets may be defined in one of two alternative ways. A set is defined by either listing the items, e.g., A = {1, 2, 3}, or by describing

Chapter 1. Sensor-based Planning

the items via a condition they satisfy, e.g.,
A = {n ∈ N | n < 4}.
By convention, the empty set is denoted by ∅. The cardinality of a set A is the number of elements in A. The set of natural
numbers has infinite cardinality. As illustrated in Figure 1.18, the three core set operations are union, intersection, and set-theoretic difference.

AB AB

The union of two sets A and B is the collection of points which are in A or in B (or in both): A ∪ B = {x | x ∈ A or x ∈ B}.
The intersection of two sets A and B is the set that contains all elements of A that also belong to B: A ∩ B = {x | x ∈ A and x ∈ B}.

AB

The set-theoretic difference of two sets A and B, also known as the relative complement of B in A is the set of elements in A that are not in B: A \ B = {a ∈ A | a ∈/ B}.

Figure 1.18: The three set operations: union, intersection, and set-theoretic difference.

A set A is a subset of B, written A ⊂ B, if and only if any member of A is a member of B, that is, a ∈ A implies a ∈ B. Intervals are subsets of the set of real numbers R and are denoted as follows: for any a < b ∈ R, we define
[a, b] = {x | a ≤ x ≤ b}, ]a, b[ = {x | a < x < b}, ]a, b] = {x | a < x ≤ b}, [a, b[ = {x | a ≤ x < b}.
From these interval definitions we have that [a, ∞[ = {x | a ≤ x}, and ] − ∞, b] = {x | x ≤ b}.
The Cartesian product of two sets A and B is the set of all possible ordered pairs whose first component is a member of A and the second component is a member of B: A × B = {(a, b) | a ∈ A and b ∈ B}. An example is the 2-dimensional plane R2 = R × R. We denote the unit circle on the plane by S1, the unit sphere in R3 by S2. We denote the 2-torus by T2 = S1 × S1.
A set S ⊂ Rd is convex if for every pair of points p and q within S, every point on the straight line segment that joins them (pq) is also within S: If p ∈ S and q ∈ S ⇒ pq ⊂ S, where pq = {αp + (1 − α)q | α ∈ [0, 1]}.

1.6. Appendix: Operations on sets
Notes and further reading
This chapter is inspired by the original article by Lumelsky and Stepanov (1987), the treatment by Lumelsky (2006), the first chapter by Choset et al. (2005) and the lecture slides by Hager (2006) and Dodds (2006).

Chapter 1. Sensor-based Planning

1.7 Exercises

E1.1 On the right-turning Bug 0 algorithm (25 points).

(i) (10 points) For the following loose pseudo-code implementation of a right-turning Bug 0 algorithm, draw a flowchart (as discussed in Section 1.3):

1: while not at goal location :

2: move towards goal

3:

if hit an obstacle :

4:

while not able to move towards goal :

5:

follow obstacle moving to the right until can head towards goal

(ii) (5 points) Draw an environment for which the right-turning Bug 0 algorithm never reaches the goal location, even though a path from start to goal does exist. Include both start and goal locations along with arrows indicating the path of the robot. Label several notable points along the path with the letters (A, B, C, . . . ).
(iii) (5 points) Sketch a graph of the distance between the robot and the goal location along the path you drew for part (ii). Use the labels from part (ii) to clarify the distance to the goal at the several notable points along the path.
(iv) (5 points) Draw an environment which contains a path from start to goal, but for which both the left and right turning Bug 0 algorithms fail to find it. Include two sketches, showing the path of the left-turning algorithm and the path of the right-turning algorithm.

E1.2 A switching Bug 0 algorithm (25 points).

(i) (10 points) Draw a flowchart for the following pseudo-code implementation of the switching Bug 0 algorithm:

1: choose an initial direction (either left or right)

2: while not at goal :

3: move towards the goal

4:

if hit an obstacle :

5:

while not able to move towards goal :

6:

take a step along the obstacle boundary moving in the chosen

direction

7:

if hit the hitting point again :

8:

switch direction

9: switch the choice of direction

(ii) (5 points) Draw an environment for which the switching Bug 0 algorithm never reaches the goal location, even though a path from start to goal does exist. Include both start
and goal locations along with arrows indicating the path of the robot. Label several notable points along the path with the letters (A, B, C, . . . ). (iii) (5 points) Sketch a graph of the distance between the robot and the goal location along the path you drew for part (ii). Use the labels from part (ii) to clarify the distance to
the goal at the several notable points along the path.

E1.3 The Bug 2 algorithm (25 points).

(i) (10 points) Draw a flowchart for the Bug 2 algorithm (the correct version, not the first attempt Bug 2.prelim).

Exercises for Chapter 1

(ii) (5 points) Draw the path of a robot using the Bug 2 algorithm for the environment in the following figure. Label several notable points along the path with the letters (A, B, C, . . . ).

pstart

pgoal

(iii) (5 points) Sketch a graph of the distance between the robot and the goal location along the path you drew for part (ii). Use the labels from part (ii) to clarify the distance to the goal at different points along the path.
(iv) (5 points) Explain in a few accurate sentences why the Bug 2 algorithm will always reach the goal location when it is possible to do so. Hint: Consider making a monotonicity argument based on your graph for part (iii).
E1.4 On the completeness of the Bug 2 algorithm (5 points). Consider the Bug 2 algorithm as described by the pseudocode in Section 1.4. Do the following:
(i) state what properties render an algorithm complete,
(ii) explain why the Bug 2 algorithm is not complete,
(iii) explain how to revise the pseudocode presented in Section 1.4 so that the revised Bug 2 is complete,
(iv) provide the flowchart for the revised Bug 2 algorithm.
E1.5 On the Jordan Curve Theorem (15 points). (i) (5+5 points) Given a workspace with n convex obstacles and start and goal points in the free workspace, let k denote the number of times that the straight segment from start to goal crosses an obstacle boundary. What is a lower bound and what is an upper bound on k? For each bound, sketch an example where the bound is achieved. (ii) (5 points) What if the obstacles are arbitrary polygons (not necessarily convex) with 5 edges – what are the lower and upper bounds in this case? Sketch an example where the upper bound is achieved.
E1.6 Programming: Lines and segments (30 points). In this exercise you are asked to begin implementing a number of basic algorithms that perform geometric computations. Consider the following planar geometry functions:
computeLineThroughTwoPoints (10 points) Input: two distinct points p1 = (x1, y1) and p2 = (x2, y2) on the plane. Output: parameters (a, b, c) defining the line {(x, y) | ax + by + c = 0} that passes through both p1 and p2. Normalize the parameters so that a2 + b2 = 1.
computeDistancePointToLine (10 points) Input: a point q and two distinct points p1 = (x1, y1) and p2 = (x2, y2) defining a line. Output: the distance from q to the line defined by p1 and p2.
computeDistancePointToSegment (10 points) Input: a point q and a segment defined by two distinct points (p1, p2).

Chapter 1. Sensor-based Planning
Output: (d, w), where d is the distance from q to the segment with extreme points (p1, p2) and w ∈ {0, 1, 2} has the following meaning: w = 0 if the segment point closest to q is strictly inside the segment, w = 1 if the closest point is p1, and w = 2 if the closest point is p2.
For each function, do the following:
(i) explain how to implement the function, possibly deriving analytic formulas, and characterize special cases,
(ii) program the function, including correctness checks on the input data and appropriate error messages, and
(iii) verify your function is correct on a broad range of test inputs. Hint: To check two points are distinct, use a tolerance equal to 10−8. Regarding the function computeDistancePointToLine, compute the orthogonal projection of q onto the line. Regarding computeDistancePointToSegment, the distance depends on whether or not the orthogonal projection of q onto the line defined by p1 and p2 belongs or not to the segment between p1 and p2.
E1.7 Programming: Polygons (30 points). Requires Exercise (E1.6). A polygon with n vertices is represented as an array with n rows and 2 columns. Consider the following functions:
computeDistancePointToPolygon (15 points) Input: a polygon P and a point q. Output: the distance from q to the closest point in P , called the distance from q to the polygon.
computeTangentVectorToPolygon (15 points) Input: a polygon P and a point q. Output: the unit-length vector u tangent at point q to the polygon P in the following sense: (i) if q is closest to a segment of the polygon, then u should be parallel to the segment, (ii) if q is closest to a vertex, then u should be tangent to a circle centered at the vertex that passes through q, and (iii) the tangent should lie in the counter-clockwise direction. Hint: You are allowed to use the Matlab function inpolygon to check if the point is inside the polygon, but watch out that Matlab uses a different convention to describe polygons. Hint: Determine which segment or vertex of P is closest to q to determine whether to use the segment or vertex tangent case.
For each function, do the following:
(i) explain how to implement the function, possibly deriving analytic formulas, and characterize special cases,
(ii) program the function, including correctness checks on the input data and appropriate error messages, and
(iii) verify your function is correct on a broad range of test inputs.
Programming Note: It is convenient to learn to visualize points, vectors and polygons in your chosen programming environment. To visualize a red square in Matlab (RGB triplet [1,0,0]), one can execute the commands:

Exercises for Chapter 1
» mysquare = [0 0; 0 1; 1 1; 1 0]; » fill(mysquare(:,1), mysquare(:,2), [1,0,0]); » axis([-0.5 1.5, -0.5 1.5]); In Python, the plotting tools are provided in a module called matplotlib. We can plot the same red square as follows: » import matplotlib.pyplot as plt » mysquare = [[0, 0], [0, 1], [1, 1], [1, 0]] » square = plt.Polygon(mysquare, fc="r") » plt.gca().add_patch(square) » plt.axis([-0.5, 1.5, -0.5, 1.5]) » plt.show()

Chapter 1. Sensor-based Planning

E1.8 Programming Project: The Bug 1 algorithm (80 points). Requires Exercises (E1.6) and (E1.7).
In this programming project, you are asked to implement the Bug 1 algorithm. For your
convenience we provide below a detailed pseudocode implementation of a simple Bug algorithm called BugBase; this pseudocode implementation contains all detailed steps required to execute a bug algorithm, but does not have any logic for getting around obstacles. (The command “return mystring” ends the execution of the algorithm and returns the string mystring.)

BugBase algorithm

Input: Two locations start and goal in Wfree, a list of polygonal obstacles obstaclesList, and a length step-size

Output: A sequence, denoted path, of points from start to the first obstacle be-

tween start and goal (or from start to goal if no obstacle lies between them).

Successive points are separated by no more than step-size.

1: current-position := start 2: path := [start] 3: while distance(current-position, goal) > step-size :

4: compute candidate-current-position by taking a step of length

step-size towards goal

5: compute distance from candidate-current-position to each obstacle 6: if distance from candidate-current-position to closest obstacle <

tolerance :

7:

return “Failure: There is an obstacle lying between the start and goal”

and path 8: current-position := candidate-current-position 9: path := [path, current-position] 10: path := [path, goal]
11: return “Success” and path

Perform the following tasks and document them in a concise project report:
(i) (15 points) Sketch a flowchart and implement the BugBase algorithm. (ii) (5 points) Describe in a paragraph how you will modify BugBase to implement the Bug 1
algorithm. Explain the roles of the geometric functions in Exercises (E1.6) and (E1.7)
and what new logic will be needed. (iii) (40 points) Implement a fully-functioning version of Bug 1, described as follows:
computeBug1 Input: Two locations start and goal in Wfree, a list of polygonal obstacles obstaclesList, and a length step-size Output: A sequence, denoted path, of points from start to goal or returns an error message if such a path does not exists. Successive points are separated by no more than step-size and are computed according to the Bug 1 algorithm.
(iv) (20 points) Test your program on the following environment: start = (0, 0) and goal = (5, 3)

Exercises for Chapter 1
step-size = 0.1 obstaclesList = {(1, 2), (1, 0), (3, 0)}, {(2, 3), (4, 1), (5, 2)}
goal = (5, 3)
start = (0, 0)
Include in your report a plot of the path taken by your bug from start to goal, the total path length and the computing time, and a plot of the distance from the bug’s position to the goal as a function of time.

2 Chapter
Motion Planning via Decomposition
and Search
In this chapter we continue our investigation into motion planning problems. As motivation for our interest in planning problems, let us remind the reader that the ultimate goal in robotics is the design of autonomous robots, that is, the design of robots capable of executing high-level instructions without having to be programmed with extremely detailed commands. Moving from A to B is one such simple highlevel instruction. In this chapter we
(i) study techniques for decomposing the continuous robot workspace into convex regions,
(ii) define roadmaps, which encode the decomposed workspace, and (iii) introduce graph algorithms for computing point-to-point paths in roadmaps.
2.1 Problem setup and modeling assumptions
The sensor-based planning problems we studied in the previous chapter are also referred to as closed-loop planning problems in the sense that the robot actions were functions of the robot sensors. The loop here is the following: the robot moves, then it senses the environment, and then it decides how to move again.
In this chapter we begin our discussion about open-loop planning. By open-loop, as compared with sensor-based and closed-loop, we mean the design of algorithms for robots that do not have sensors, but rather have access to a map of the environment. Open-loop and closed-loop strategies are synonyms for feedforward and feedback control.
As in the previous chapter, we are given
29

Chapter 2. Motion Planning via Decomposition and Search
• a workspace that is a subset of R2 or R3, often just a rectangle, • some obstacles, say O1, . . . , On, • a start point and a goal point, and • a robot described by a moving point. As in the previous chapter, we define the free workspace Wfree = W \(O1 ∪ O2 ∪ · · · ∪ On), see Figure 2.1. We continue to postpone more realistic and complex problems where the robot has a shape, size and orientation.
pgoal
pstart
Figure 2.1: An example free workspace with start and goal locations
Our task is to plan the robot motion from the start point to the goal point via a precomputed open-loop sequence of steps to be executed. We want to design a motion plan under the following modeling assumptions.
Robot Assumptions The robot has the following capacities: • knows the start and goal locations, and • knows the workspace and obstacles.
World Assumptions The workspace has the following properties: • the workspace is a bounded polygon, • there are only a finite number of obstacles that are polygons inside the workspace, and • the start and goal points are inside the workspace and outside all obstacles.
It is instructive now to compare these new robot and world assumptions with the ones in the previous chapter for sensor-based closed-loop planning. The similarities are the following: (1) the robot is still just a point, it has no size, shape, or orientation, and (2) the robot’s motion is omni-directional (i.e., the robot can move in every possible direction). The differences are the following: (3) the robot has no sensors, but rather knowledge of the free workspace, and (4) planning is now a sequence of

2.1. Problem setup and modeling assumptions
pre-computed steps, whereas before sensor-based algorithms are a policy on how to deal with possible obstacles encountered along the way.
2.1.1 Polygons In these notes, a polygon is a plane figure composed by a finite chain of segments (called sides or edges) closing in a loop. The points where the segments meet are called vertices (or corners). Polygons are always assumed to be simple, i.e., their boundary does not cross itself. Programming-wise, it is convenient to represent a polygon by a counter-clockwise ordered sequence of vertices. (It is our convention not to repeat the first vertex as last.)
As illustrated in Figure 2.1, this chapter assumes that the workspace is a polygon, that each obstacle is a polygon (i.e., a polygonal hole inside the workspace), and that the total number of vertices in workspace and obstacles is n.
2.1.2 Run-time of an algorithm
In this chapter we will study the time it takes for a motion planning algorithm to run, called its run-time, rather than just the length of the path it produces. The run-time of an algorithm is given by the number of computer steps required to execute the code. For the purposes of these notes, we assume that addition, multiplication and division of two numbers can be performed in one computer step. Similarly, we assume a single computer step is required to test if one number is equal to, greater than, or less than another number.
The run-time of an algorithm is a function of the “size” of the input fed to it. If the input has a size n (for example, the input is a polygon with n vertices), the runtime is a function f (n). Counting the exact number of computation steps can be a complex endeavor, and so we instead focus on determining how the run-time scales with n. Rather than saying an algorithm takes exactly 5n2 + 4n + 1 computer steps, it is customary to drop all constants and all lower-order terms, and simply report the run-time as O(n2). Formally, the big-O notation is defined as follows.
Definition 2.1. Given two positive functions f (n) and g(n) of the natural numbers n, we write f ∈ O(g), if there exist a number n0 and a positive constant K such that f (n) ≤ Kg(n) for all n ≥ n0.
Intuitively, if f ∈ O(g), then we are saying that the function f is less than or equal to the function g (up to a multiplicative constant and for large n). In other words, when n gets large, g grows at least as fast as f . For example, in Figure 2.2 the function f (n) grows linearly with n and g(n) grows with the square of n, and we have f ∈ O(g).

Chapter 2. Motion Planning via Decomposition and Search

f (n) g(n)
n
Figure 2.2: The function f (n) grows linearly with n. The function g(n) grows with the square of n.
2.2 Workspace decomposition
We start with two useful geometric ideas.
Convexity As mentioned in Appendix 1.6, a set S is convex if for any two points p and q in S, the entire segment pq is also contained in S. Examples of convex and non-convex sets are drawn in Figure 2.3. (Here we assume that the set S is a subset of the Euclidean space Rd in some arbitrary dimension d.) For polygons, convexity is related to the interior angles at each vertex of the polygon (each vertex of a polygon has an interior and an exterior angle): a polygonal set is convex if and only if each vertex is convex, i.e., it has an interior angle less than π. A vertex is instead called non-convex if its interior angle is larger than π.

convex set

non-convex set

non-convex set

convex vertex

non-convex vertex

Figure 2.3: Examples of convex and non-convex sets. A convex set cannot have any hole. Polygons have convex and non-convex interior angles.

Planning in non-convex sets via convex decompositions Let us now use the notion of convexity for planning purposes. If the start point and the goal point belong to the same convex set, then the segment connecting the two points is an obstacle-free path. If, instead, the free workspace is not convex, then the following figure and algorithmic ideas provide a simple effective answer.

2.2. Workspace decomposition

pgoal

pgoal

pstart

pstart

Figure 2.4: Planning through a non-convex environment by moving from a convex subset to another

2.2.1 Decomposition into convex subsets
For complex non-convex environments, we use an algorithm to decompose the free workspace into the union of convex subsets, such as triangles, convex quadrilaterals or trapezoids (quadrilaterals with at least one pair of parallel sides). The following nomenclature is convenient:
(i) the triangulation of a polygon is the decomposition of the polygon into a collection of triangles, and
(ii) the trapezoidation of a polygon is the decomposition of the polygon into a collection of trapezoids. (We allow some trapezoids to have a side of zero length and therefore be triangles.)
It is easy to see that a polygon can be triangulated in multiple ways (e.g., consider the two possible diagonals of a square). In what follows we present an algorithm to trapezoidate, i.e., decompose into trapezoids, a polygon with polygonal holes.
sweeping trapezoidation algorithm Input: a polygon possibly with polygonal holes Output: a set of disjoint trapezoids, whose union equals the polygon
1: initialize an empty list T of trapezoids 2: order all vertices (of the obstacles and of the workspace) horizontally from left to right 3: for each vertex selected in a left-to-right sweeping order : 4: extend vertical segments upwards and downwards from the vertex until they
intersect an obstacle or the workspace boundary 5: add to T the new trapezoids, if any, generated by these segment(s)

The algorithm is among a class of algorithms studied in computational geometry; feel free to inform yourself about this topic at Wikipedia:computational geometry. An execution of the algorithm is illustrated in the Figure 2.5. Note that trapezoids T3 and T7 are degenerate, i.e., they are triangles.

Chapter 2. Motion Planning via Decomposition and Search

T4

T2

T1

T3

T6

T8

T7

T10

T9 T5
Figure 2.5: A trapezoidation of a workspace into trapezoids T1, . . . , T10, computed by the sweeping trapezoidation algorithm

2.2.2 The sweeping trapezoidation algorithm

To understand in more detail how the sweeping trapezoidation algorithm is imple-
mented, consider a workspace in which the boundary is an axis-aligned rectangle and every obstacle vertex has a unique x-coordinate, i.e., no obstacle segment is vertical. As an example, see Figure 2.5. Since all x-coordinates are unique, each line segment si describing an obstacle boundary has a left endpoint ℓi and a right endpoint ri, where the x-coordinate of the left endpoint is smaller than that of the right endpoint. We write this segment as si = [ℓi, ri].
To visualize the order in which vertices are processed by the algorithm in step 3:, we define a sweeping vertical line L moving from left to right. Recall, each environment vertex connects two line segments. When the line L hits an environment
vertex, we categorize it into one of six types (see Figure 2.6) as summarized in
Table 2.1.

Vertex Type Vertex as Endpoint of Two Vertex as Convex or

Segments

Non-Convex

Example

(i)

left/left

convex

p6 and p8

(ii)

left/left

non-convex

p3

(iii)

right/right

convex

p2 and p4

(iv)

right/right

non-convex

p7

(v)

left/right

convex

p1

(vi)

left/right

non-convex

p5

Table 2.1: The six vertex types encountered during the trapezoidal decomposition algorithm

To execute steps 4: and 5: of the sweeping trapezoidation algorithm, we maintain a list S of the obstacle segments intersected by the sweeping line L. The obstacle segments are stored in decreasing order of their y-coordinates at the intersection point with L. A key property of S is that it changes only when L hits a new vertex.

2.2. Workspace decomposition

s8 s9
s10 s3

s1 s7 s6 s5
s4
s2

p6

p4

p5

p7 p8

p3 p2

p1

Figure 2.6: The line segments s1, . . . , s10 and the obstacle vertices p1, . . . , p8 required by the algorithm

Thus, when the new vertex v is encountered, steps 4: and 5: update the list of trapezoids T and the list of obstacle segments S. The details of Steps 4: and 5: are as follow, and are illustrated in Figure 2.7 for each of the six vertex types of Table 2.1. 4.1: determine the type of vertex v, as shown in Table 2.1 4.2: update S by adding obstacle segments starting at v and removing obstacle
segments ending at v (i.e., add two segments, remove one segment and add one segment, or remove two segments, depending on vertex type as shown
in Figure 2.7) 4.3: use S to extend vertical segments upwards and downwards from v, that
is, to find intersection points pt and pb above and below v (if any) — more detail on this computation is given in the paragraph below 5.1: add to T zero, one or two new trapezoids depending on vertex type (see Figure 2.7) 5.2: update the left endpoints of the obstacle segments in S above and below the vertex v
The type of v can be determined by checking its convexity and looking at the number of obstacle segments in S that have v as an endpoint: zero obstacle segments implies v is of type (i) or (ii); one obstacle segment implies v is of type (v) or (vi); and two obstacle segments implies v is of type (iii) or (iv). The point pt (respectively, pb) is the defined as the point where the vertical segment extended upward (respectively, downward) from v intersects an obstacle. In types (i) and (iii) both pt and pb are defined. In types (ii) and (iv) neither are defined as the upward and downward vertical segments immediately enter obstacles. In types (v), and (vi) only one of pt and pb is defined.
Instruction 5.2: updates the obstacle segments in S to facilitate the following computations of trapezoids.

Chapter 2. Motion Planning via Decomposition and Search

Type (i): left/left convex vertex

pt

s1

s10

p8
<latexit sha1_base64="LMau5SeW3ziCSi0lK9/Raj/SbUU=">AAAB9HicbZDNSsNAFIVv6l+tf1WXbgaL4EJKIoJdFt24rGjaQhvKZDpJh04mYWZSLKGP4FY37sSt7yP4ME7TLLT1wsDHOfdy7xw/4Uxp2/6ySmvrG5tb5e3Kzu7e/kH18Kit4lQS6pKYx7LrY0U5E9TVTHPaTSTFkc9pxx/fzv3OhErFYvGopwn1IhwKFjCCtZEekkFjUK3ZdTsvtApOATUoqjWofveHMUkjKjThWKmeYyfay7DUjHA6q/RTRRNMxjikPYMCR1RdqEmYg5c95UfP0JnxhiiIpXlCo1z9PZvhSKlp5JvOCOuRWvbm4n9eL9VBw8uYSFJNBVksClKOdIzmCaAhk5RoPjWAiWTmakRGWGKiTU4VE4ez/PlVaF/WHbvu3F/VmjdFMGU4gVM4BweuoQl30AIXCITwDC/wak2sN+vd+li0lqxi5hj+lPX5AzA3keM=</latexit>
pb

s3

s2

Update S: [s1, s2] to [s1, s10, s3, s2] Add to T : [pt, ℓ1, ℓ2, pb] Update segment endpoints: ℓ1 := pt, and ℓ2 := pb

Type (ii): left/left non-convex vertex s1

s7 <latexit sha1_base64="DcZIdg1wcR62fZjAmX2qi67UX5A=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEaI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKD2ZQG5QrbtVdgKwTLycVyNEclL/6w5ilEVfIJDWm57kJ+hnVKJjks1I/NTyhbEJHvGepohE3frY4dUYurDIkYaxtKSQL9fdERiNjplFgOyOKY7PqzcX/vF6KYd3PhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+2rqudWvfvrSuMmj6MIZ3AOl+BBDRpwB01oAYMRPMMrvDnSeXHenY9la8HJZ07hD5zPHw0qjaE=</latexit> p3 <latexit sha1_base64="8lc7X5Q6yDnpkNh38LrHKJ13jqM=">AAAB9HicbZDLSsNAFIZP6q3WW9Slm8EiuJCSqKDLohuXFe0F2lAm00k6dDIJM5NiCX0Et7pxJ259H8GHcZpmoa0HBj7+/xzOmd9POFPacb6s0srq2vpGebOytb2zu2fvH7RUnEpCmyTmsez4WFHOBG1qpjntJJLiyOe07Y9uZ357TKVisXjUk4R6EQ4FCxjB2kgPSf+ib1edmpMXWga3gCoU1ejb371BTNKICk04VqrrOon2Miw1I5xOK71U0QSTEQ5p16DAEVVnahzm4GVP+dFTdGK8AQpiaZ7QKFd/z2Y4UmoS+aYzwnqoFr2Z+J/XTXVw7WVMJKmmgswXBSlHOkazBNCASUo0nxjARDJzNSJDLDHRJqeKicNd/PwytM5rrlNz7y+r9ZsimDIcwTGcggtXUIc7aEATCITwDC/wao2tN+vd+pi3lqxi5hD+lPX5Ayhxkd4=</latexit>

s6 <latexit sha1_base64="kJ+R5RWYp09R7sgLUuNGnbThuaM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPu1frniVt05yCrxclKBHI1++as3iFkaoTRMUK27npsYP6PKcCZwWuqlGhPKxnSIXUsljVD72fzUKTmzyoCEsbIlDZmrvycyGmk9iQLbGVEz0sveTPzP66YmvPYzLpPUoGSLRWEqiInJ7G8y4AqZERNLKFPc3krYiCrKjE2nZEPwll9eJa2LqudWvfvLSv0mj6MIJ3AK5+DBFdThDhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifPwumjaA=</latexit> s5 <latexit sha1_base64="oci8K9tiLrtX1zUACytrJrHVf1A=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0nEoseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPu1frniVt05yCrxclKBHI1++as3iFkaoTRMUK27npsYP6PKcCZwWuqlGhPKxnSIXUsljVD72fzUKTmzyoCEsbIlDZmrvycyGmk9iQLbGVEz0sveTPzP66YmvPYzLpPUoGSLRWEqiInJ7G8y4AqZERNLKFPc3krYiCrKjE2nZEPwll9eJa2LqudWvfvLSv0mj6MIJ3AK5+DBFdThDhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifPwoijZ8=</latexit>

s4 <latexit sha1_base64="OhGNErDDxqvMoUDJBTkED8s0e/k=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkUI9FLx4r2g9oQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJaPZpqgH9GR5CFn1FjpQQ9qg3LFrboLkHXi5aQCOZqD8ld/GLM0QmmYoFr3PDcxfkaV4UzgrNRPNSaUTegIe5ZKGqH2s8WpM3JhlSEJY2VLGrJQf09kNNJ6GgW2M6JmrFe9ufif10tNeO1nXCapQcmWi8JUEBOT+d9kyBUyI6aWUKa4vZWwMVWUGZtOyYbgrb68TtpXVc+teve1SuMmj6MIZ3AOl+BBHRpwB01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwiejZ4=</latexit>

s2 Update S: [s1, s7, s4, s2] to [s1, s7, s6, s5, s4, s2] Add to T : None Update segment endpoints: None

Type (iii): right/right convex vertex

s1

pt

s7 <latexit sha1_base64="DcZIdg1wcR62fZjAmX2qi67UX5A=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEaI9FLx4r2g9oQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1iNOE+xEdKREKRtFKD2ZQG5QrbtVdgKwTLycVyNEclL/6w5ilEVfIJDWm57kJ+hnVKJjks1I/NTyhbEJHvGepohE3frY4dUYurDIkYaxtKSQL9fdERiNjplFgOyOKY7PqzcX/vF6KYd3PhEpS5IotF4WpJBiT+d9kKDRnKKeWUKaFvZWwMdWUoU2nZEPwVl9eJ+2rqudWvfvrSuMmj6MIZ3AOl+BBDRpwB01oAYMRPMMrvDnSeXHenY9la8HJZ07hD5zPHw0qjaE=</latexit>

s6 <latexit sha1_base64="kJ+R5RWYp09R7sgLUuNGnbThuaM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPu1frniVt05yCrxclKBHI1++as3iFkaoTRMUK27npsYP6PKcCZwWuqlGhPKxnSIXUsljVD72fzUKTmzyoCEsbIlDZmrvycyGmk9iQLbGVEz0sveTPzP66YmvPYzLpPUoGSLRWEqiInJ7G8y4AqZERNLKFPc3krYiCrKjE2nZEPwll9eJa2LqudWvfvLSv0mj6MIJ3AK5+DBFdThDhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifPwumjaA=</latexit>

p4

pb

s5 <latexit sha1_base64="oci8K9tiLrtX1zUACytrJrHVf1A=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0nEoseiF48V7Qe0oWy2k3bpZhN2N0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4dua3n1BpHstHM0nQj+hQ8pAzaqz0oPu1frniVt05yCrxclKBHI1++as3iFkaoTRMUK27npsYP6PKcCZwWuqlGhPKxnSIXUsljVD72fzUKTmzyoCEsbIlDZmrvycyGmk9iQLbGVEz0sveTPzP66YmvPYzLpPUoGSLRWEqiInJ7G8y4AqZERNLKFPc3krYiCrKjE2nZEPwll9eJa2LqudWvfvLSv0mj6MIJ3AK5+DBFdThDhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifPwoijZ8=</latexit>

s4 <latexit sha1_base64="OhGNErDDxqvMoUDJBTkED8s0e/k=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkUI9FLx4r2g9oQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJaPZpqgH9GR5CFn1FjpQQ9qg3LFrboLkHXi5aQCOZqD8ld/GLM0QmmYoFr3PDcxfkaV4UzgrNRPNSaUTegIe5ZKGqH2s8WpM3JhlSEJY2VLGrJQf09kNNJ6GgW2M6JmrFe9ufif10tNeO1nXCapQcmWi8JUEBOT+d9kyBUyI6aWUKa4vZWwMVWUGZtOyYbgrb68TtpXVc+teve1SuMmj6MIZ3AOl+BBHRpwB01oAYMRPMMrvDnCeXHenY9la8HJZ07hD5zPHwiejZ4=</latexit>

s2
Update S: [s1, s7, s6, s5, s4, s2] to [s1, s5, s4, s2] Add to T : [pt, ℓ1, ℓ7, p4], and [p4, ℓ6, pb] Update segment endpoints: ℓ1 := pt, and ℓ5 := pb

Type (iv): right/right non-convex vertex s1
s8 s9
p7 s10
s3 s2
Update S: [s1, s8, s9, s10, s3, s2] to [s1, s8, s3, s2] Add to T : [p7, ℓ9, ℓ10] Update segment endpoints: None

Type (v): left/right convex vertex s1
s7

Type (vi): left/right non-convex vertex

s1

pt

s7

s8

p5

s4

s3

p1

s2 pb

Update S: [s1, s7, s3, s2] to [s1, s7, s4, s2] Add to T : [p1, ℓ3, ℓ2, pb] Update segment endpoints: ℓ2 := pb

s3 s2
Update S: [s1, s8, s3, s2] to [s1, s7, s3, s2] Add to T : [pt, ℓ1, ℓ8, p5] Update segment endpoints: ℓ1 := pt

Figure 2.7: Classification of the six types of vertices. For each vertex type, the figure illustrates
the actions performed in Step 4: and Step 5: to update list of trapezoids trapezoids T , the segment list S, and the segment endpoints.

2.2. Workspace decomposition
2.2.3 Run-time analysis of trapezoidation algorithm
Given a free workspace (i.e., workspace minus obstacles) with n vertices, the sweeping line is implemented (as in steps 1: and 2:) by sorting the vertices from left to right; that is, in increasing order of their x-coordinates. There are many well-known sorting algorithms including bubble sort, merge sort, quick sort, etc., and the best of these run in O(n log(n)), where n is the number of items to be sorted (Cormen et al., 2001).
Next, for each vertex v in the sorted list, we perform the steps detailed in Figure 2.7. The runtime of these steps is dominated by the time needed to insert new segments into S and delete old segments from S. There are exactly two insert/delete operations for each vertex v, one for each segment that has v as an endpoint. If we maintain S as a sorted array, then to insert/delete a segment, we need to scan through the array. Since there are n segments, the array can contain at most n entries, and insertion or deletion requires O(n) time. We repeat this procedure for each of the n vertices, giving a total runtime of O(n2).
We can improve the runtime by using a more sophisticated data structure for S that allows us to insert and delete segments more quickly. In particular, a binary search tree can be used to maintain the ordered segments in S. A segment can be inserted/deleted in O(log(n)), instead of O(n) time for the simple array implementation. With a binary tree, the sweeping decomposition algorithm can be implemented with a run-time belonging to O(n log(n)) for a free workspace with n vertices. The details of binary trees are beyond the scope of this book, but can be found in (Cormen et al., 2001), in (de Berg et al., 2000, Chapter 13), or at Wikipedia:binary search tree.
2.2.4 Navigation on roadmaps
Before proceeding, let us recall the three key ideas we introduced so far: (1) convexity leads to very simple paths, (2) if the free workspace is not convex, it is easy to navigate between neighboring convex sets, (3) a complex free workspace can be decomposed into convex subsets via, for example, the sweeping trapezoidation algorithm.
The next observation is that the sweeping trapezoidation algorithm (and other decomposition-into-convex-subsets procedures) can easily be modified to additionally provide a list of neighborhood relationships between trapezoids. In other words, we assume that we can compute an easy-to-navigate roadmap. The roadmap of a trapezoidation is computed as follows; an example is drawn in Figure 2.8.
As a result of this algorithm we obtain a roadmap specified as follows: (1) a collection of center points (one for each trapezoid), and (2) a collection of paths connecting center points (each path being composed of 2 segments, connecting a center to a midpoint and the same midpoint to a distinct center).

Chapter 2. Motion Planning via Decomposition and Search
roadmap-from-decomposition algorithm Input: the trapezoidation of a polygon (possibly with holes) Output: a roadmap
1: label the center of each trapezoid with the symbol ⋄ 2: label the midpoint of each vertical separating segment with the symbol • 3: for each trapezoid : 4: connect the center to all the midpoints in the trapezoid 5: return the roadmap consisting of centers and connections between them through
midpoints
pgoal

pstart
Figure 2.8: An example roadmap for a free workspace

Note: It is not important what precise point we select as center of a trapezoid. We will see in the next section that the roadmap can be represented as a special type of “graph” that is generated from an environment partition and is called the “dual graph of a partition.”
Consider now a motion planning problem in a free workspace Wfree that has been decomposed into convex subsets and that is now equipped with a roadmap. The planning-via-decomposition+search algorithm described below provides a solution to this problem by combining various useful concepts.

start

pgoal

pstart

goal

Figure 2.9: Illustration of the planning-via-decomposition+search algorithm

Note: by means of the decomposition, we have transformed a continuous planning problem into a discrete planning problem: a path in the free workspace is now computed by first computing a path in the discrete roadmap.

2.3. Search algorithms over graphs

planning-via-decomposition+search algorithm

Input: free workspace Wfree, start point pstart and goal point pgoal Output: a path from pstart to pgoal if it exists, otherwise a failure notice. Either outcome is

obtained in finite time.

1: compute a decomposition of Wfree and the corresponding roadmap

2: in the decomposition, find the start trapezoid ∆start containing pstart and the goal trape-

zoid ∆goal containing pgoal

3: in the roadmap, search for a path from ∆start to ∆goal

4: if no path exists from ∆start to ∆goal :

5:

return failure notice

6: else

7: return path by concatenating: the segment from pstart to the center of ∆start, the path from the ∆start to ∆goal, and the segment from the center of ∆goal to pgoal.

2.3 Search algorithms over graphs
2.3.1 Graphs
In the previous section and in the last algorithm, we did not specify how to mathematically represent the roadmap or how to search it. In short,
(i) a roadmap is a “graph” and
(ii) paths in roadmaps are computed via “graph search algorithm.”
A graph is a pair (V, E), where V is a set of nodes (also called vertices) and E is a set of edges (also called links or arcs). Every edge is a pair of nodes. (Note: A graph is not the graph of a function.) Often, the graph is denoted by the letter G, V is called the node set and E is called the edge set. If {u, v} is an edge, then u and v are said to be neighbors.
Note: graphs as defined here are sometimes referred to as unweighted and undirected graphs.
Figure 2.10 contains some basic graphs and a more complex example with node set V = {n1, . . . , n11} and edge set
E = {e1 = {n1, n2}, e2 = {n1, n3}, e3 = {n11, n5}, e4 = {n6, n7}, e5 = {n1, n4}, e6 = {n1, n6}, e7 = {n4, n10}, e8 = {n4, n6}, e9 = {n8, n10}, e10 = {n8, n9}, e11 = {n7, n9}, e12 = {n8, n11}}. (2.1)
Graphs are widely used in science and engineering in broad range of applications. Graphs are used to describe, for example,

Chapter 2. Motion Planning via Decomposition and Search

(a) Path graph on 4 nodes

(b) Circular graph (also called the ring graph) on 6 nodes

(c) A tree on 6 nodes (see definition below)

n2 e1

e5

n4

e7

n11

n10 e12

e3

e2

n1

e8

e9

n5

n3

e6 n6

n8

(d) A prototypical robotic roadmap generated by a grid

e4

e10

n7

e11

n9

(e) A sample graph from equation (2.1)

Figure 2.10: Example graphs.

(i) wireless communication networks (each node is an antenna and each edge is a wireless link), electric circuits (each node is a circuit node and each edge is either a resistor, a capacitor, an inductor, a voltage source or a current source),
(ii) power grids (each node is a power generator and each edge describes the corresponding pair-wise admittance),
(iii) transportation networks (each node is a location and each edge is a route), and
(iv) social networks (each node is an individual and each edge describes a relationship between individuals), etc.
It is a curious historical fact that Euler (1741) was perhaps the earliest scientist to study graphs and did so in the context of path planning problems (other early works include (Kirchhoff, 1847) and (Cayley, 1857) on electrical networks and theoretical chemistry, respectively). You are invited to read more at the wikipedia pages on Wikipedia:graph and Wikipedia:graph theory.
Now that we know what a graph is, we are interested in defining paths and their properties. We will need the following simple concepts from graph theory.

2.3. Search algorithms over graphs
(i) A path is an ordered sequence of nodes such that from each node there is an edge to the next node in the sequence. For example, in Figure 2.10e, a path from node n1 to node n5 is given by the sequence of nodes (n1, n4, n10, n8, n11, n5) or equivalently, by the sequence of edges (e5, e7, e9, e12, e3). The length of a path is the number of edges in the path from start node to end node.
(ii) Two nodes in a graph are path-connected if there is a path between them. A graph is connected if every two nodes are path-connected.
(iii) If a graph is not connected, it is said to have multiple connected components. More precisely, a connected component is a subgraph in which (1) any two nodes are connected to each other and (2) all nodes outside the subgraph are not connected to the subgraph. For example, if a free workspace is disconnected, then the roadmap resulting from any decomposition algorithm will contain multiple connected components.
(iv) A shortest path between two nodes is a path of minimum length between the two nodes. The distance between two nodes is the length of a shortest path connecting them, i.e., the minimum number of edges required to go from one node to the other. Note that a shortest path does not need to be unique, e.g., see Figure 2.10e and identify the two distinct shortest paths from node n8 to node n6.
(v) A cycle is a path with at last three distinct nodes and with no repeating nodes, except for the first and last node which are the same. A graph that contains no cycles and is connected is called a tree.
Roadmaps as dual graphs Having introduced some graph theory, let us review our definition of the roadmap. Given a decomposition of a workspace into a collection of trapezoids (or more general subsets), the dual graph of the decomposition is the graph whose nodes are the trapezoids and whose edges are defined as follows: there exists an edge between any two trapezoids if and only if the two trapezoids share a vertical segment. The roadmap generated by the workspace trapezoidation is the dual graph of the decomposition with the additional specifications: to each node of the dual graph (i.e., to each trapezoid) we associate a center location, and to each edge of the dual graph we associate a polygonal path that connects the two centers through the midpoint of the common vertical segment.
2.3.2 The breadth-first search algorithm
Now, let us turn our attention back to the topic of search. Search algorithms are a classic subject in computer science and operations research. Here we present a short description of one algorithm. We refer to (Cormen et al., 2001) for a comprehensive

Chapter 2. Motion Planning via Decomposition and Search

discussion about computationally-efficient algorithms for appropriately-defined data structures.
Problem 2.2 (The shortest-path problem). Given a graph with a start node and a goal node, find a shortest path from the start node to the goal node.

The breadth-first search algorithm, also called BFS algorithm, is one of the sim-
plest graph search strategy and is optimal in the sense that it computes shortest paths.
The algorithm proceeds in layers. We begin with the start node (Layer 0), and find
all of its neighbors (Layer 1). We then find all unvisited neighbors of Layer 1 (Layer 2), and so on, until we reach a layer that has no unvisited neighbors. Each vertex v in Layer k + 1 is discovered from a vertex u in Layer k; we refer u as the “parent” of v. An informal easy-to-understand description of this procedure is shown below. A corresponding execution is shown in Figure 2.11.
1: begin with the start node and mark as visited // The start node forms Layer 0 2: for each unvisited neighbor u of the start node : 3: mark u as visited, and set the start node as the parent of u. // The nodes
u form Layer 1 4: for each unvisited neighbor v of the nodes in Layer 1 : 5: mark v as visited and record the neighbor from Layer 1 as the parent of v 6: repeat the process until you reach a layer that has no unvisited neighbors 7: if the goal node has been visited : 8: follow the parent values back to the start node, and return this sequence of
vertices as the shortest path from start to goal 9: else 10: return a failure notice (i.e., the start and goal node are not path-connected)

layer:1 parent:n1
<latexit sha1_base64="(null)">(null)</latexit>
n3 <latexit sha1_base64="(null)">(null)</latexit>

layer:1 parent:n1
<latexit sha1_base64="(null)">(null)</latexit>
n4 <latexit sha1_base64="(null)">(null)</latexit>

layer:2 parent:n2
<latexit sha1_base64="(null)">(null)</latexit>
n5 <latexit sha1_base64="(null)">(null)</latexit>

n1 <latexit sha1_base64="(null)">(null)</latexit>
layer:0 parent:start
<latexit sha1_base64="(null)">(null)</latexit>

n2 <latexit sha1_base64="(null)">(null)</latexit>
layer:1 parent:n1
<latexit sha1_base64="(null)">(null)</latexit>

n6 <latexit sha1_base64="(null)">(null)</latexit>
layer:3 parent:n5
<latexit sha1_base64="(null)">(null)</latexit>

n7 <latexit sha1_base64="(null)">(null)</latexit>
layer:4 parent:n6
<latexit sha1_base64="(null)">(null)</latexit>

Figure 2.11: A sample execution of the breadth-first search strategy (in an unweighted graph).

Each vertex is labeled with (and shaded according to) its layer, which turns out to be equal

to the distance between that node and the start node, and with the identity of its parent

node.

2.3. Search algorithms over graphs

To efficiently implement the BFS algorithm we introduce a useful data structure. A queue (also called a first-in-first-out (FIFO) queue) is a variable-size data container, denoted Q, that supports two operations: 1) the operation insert(Q, v) inserts an item v into the back of the queue, and 2) the operation retrieve(Q) returns (and removes) the item that sits at the front of the queue. An example of a queue is shown
in Figure 2.12.

FIFO Queue Q

insert(Q, v)

v

u

Figure 2.12: In a FIFO queue, items can be in-
serted and retrieved: the items are retrieved
u = retrieve(Q)
in the order in which they were inserted.

A queue can be implemented such that each insert and retrieve operation runs in O(1) time; that is the runtime of each operation is independent of the number of items in the queue.
Programming Note: In Matlab, a simple way to manipulate a list and implement a FIFO queue is as follows. Define a queue as a row vector by: » queue = [20, 21]; Insert the element 22 into the queue by adding it to the end of the vector: » queue = [queue, 22]; Retrieve an element from the queue by: » element = queue(1); queue(1) = []; These same three commands in Python are: » queue = [20, 21] » queue.append(22) » element = queue.pop(0) Note: While these simple queue implementations in Matlab and Python will suffice in many applications, they are not efficient. In particular, the insert and retrieve operations are not constant time. The reason is that deleting the first element of an array (i.e., a vector) is a O(n) operation, where n is the length of the array: After the element at the front of the array is deleted, each remaining element is sequentially shifted one place to the left in memory. To correct this, one typically implements a queue using a fixed-length array along with two additional pieces of data. The first gives the location of the element at the front of the queue, and the second gives the location of the back of the queue. These locations are updated after each insertion and retrieval. Efficient queue implementations are available in Python using the queue module, which can be including using the command import queue.

Chapter 2. Motion Planning via Decomposition and Search

Here is another more-specific pseudocode version of the breadth-first search
strategy that lends itself to relatively-immediate implementation. The implementa-
tion uses an array parent that contains an entry for each node. The entry parent(u) records the node that lies immediately before u on the shortest path from vstart to u. We use NONE for parent values that have not yet been set, and SELF for the start node, whose parent is itself. Notice that the parent values also serve the purpose of marking nodes as visited or unvisited. A vertex u is unvisited if parent(u) is equal to NONE and visited otherwise.
In the algorithm we let x := a denote that the variable x acquires the value a and we let x == a be the binary true/false statement as to whether x is equal to a.

breadth-first search (BFS) algorithm

Input: a graph G, a start node vstart and goal node vgoal

Output: a path from vstart to vgoal if it exists, otherwise a failure notice

1: for each node v in G :

2:

parent(v) := NONE

3: parent(vstart) := SELF

4: create an empty queue Q and insert(Q, vstart)

5: while Q is not empty :

6:

v := retrieve(Q)

7: for each node u connected to v by an edge :

8:

if parent(u) == NONE :

9:

set parent(u) := v and insert(Q, u)

10:

if u == vgoal :

11:

run extract-path algorithm to compute the path from start to goal

12:

return success and the path from start to goal

13: return failure notice along with the parent values.

Figure 2.13 illustrates the execution of this algorithm. Note that the output of
this algorithm is not necessarily unique, since the order in which the edges are
considered in step 7: of the algorithm is not unique. At the successful completion of BFS, we can use the parent values to define a
set of edges {parent(u), u} for each node u for which parent(u) is different from NONE. These edges define a tree in the graph G. That is, they form a connected graph that does not contain any cycles, as shown in Figure 2.13.
The last piece we need is a method to use the parent values to reconstruct the sequence of nodes on the shortest path from vstart to vgoal. This can be done as follows:
Note: The extract-path algorithm is often implemented by inserting each u at the end of the array P (rather than at the beginning), and then reversing the order of P prior returning it.

2.3. Search algorithms over graphs

Before <latexit sha1_base64="WF9xC7tExy1SAOmq2mKbjN8FdY8=">AAACF3icbVA9TwJBEN3DL8Qv1NJmI5pYGHJHSLQk2lhiIkIChOwtc7Bh7/ayO4eQi3/Af+C/sNXGzthamvhjXJBCwZds8vLezOzM82MpDLrup5NZWl5ZXcuu5zY2t7Z38rt7t0YlmkONK6l0w2cGpIighgIlNGINLPQl1P3B5cSvD0EboaIbHMfQDlkvEoHgDK3UyR9dQKA0UBgBTyYSbSGM0A/Su76QcE+lUnEnX3CL7hR0kXgzUiAzVDv5r1ZX8SSECLlkxjQ9N8Z2yjQKbofmWomBmPEB60HT0oiFYE7NsDcl7XQ0veueHluvS+1+9kVIp+rv3pSFxoxD31aGDPtm3puI/3nNBIPzdiqiOEGI+M9HQSIpKjoJiXaFBo5ybAnjWtitKe8zzTjaKHM2Dm/++EVyWyp65WL5ulSoXMyCyZIDckhOiEfOSIVckSqpEU4eyBN5Ji/Oo/PqvDnvP6UZZ9azT/7A+fgG7+2glw==</latexit>

execution

while

loop

✏

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

✓

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

↵

p = SELF
<latexit sha1_base64="VVlTSnmRrkfVlsefm42vG/nDOjU=">AAACDXicbZDLSsNAFIYn9VbrLepON6lFcCElkYJuhIIoLlxUtBdoQplMp+3QyYWZk9ISAr6Bb+FWN+7Erc8g+DBO0yy0emDgm/8/h5nzuyFnEkzzU8stLC4tr+RXC2vrG5tb+vZOQwaRILROAh6Ilosl5cyndWDAaSsUFHsup013eDH1myMqJAv8e5iE1PFw32c9RjAoqaPv2UDHABCHiV08t4vpNb67vLlKOnrJLJtpGX/ByqCEsqp19C+7G5DIoz4QjqVsW2YITowFMMJpUrAjSUNMhrhP2wp97FF5LEf9FJx4nG6TGIfK6xq9QKjjg5GqP2dj7Ek58VzV6WEYyHlvKv7ntSPonTkx88MIqE9mD/UibkBgTKMxukxQAnyiABPB1K8NMsACE1ABFlQc1vzyf6FxUrYq5cptpVQ1s2DyaB8doCNkoVNURdeohuqIoAf0hJ7Ri/aovWpv2vusNadlM7voV2kf303hm9M=</latexit>

⇡
p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>



p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

After <latexit sha1_base64="N/A89qxAA5GlWkwtyT31GJOg7Uk=">AAACGnicbZDLSgMxFIYzXmu9VV26CRbRhZSZIuiy6sZlBdsKbSmZ9EwbzEyG5Iy2DH0E38C3cKsbd+LWjeDDmKmz8HYg8PH/5yQ5vx9LYdB1352Z2bn5hcXCUnF5ZXVtvbSx2TQq0RwaXEmlr3xmQIoIGihQwlWsgYW+hJZ/fZb5rRvQRqjoEscxdEM2iEQgOEMr9Up7JwGCpp5BCiPgSabSDsII/SC9HQoJEyqVinulsltxp0X/gpdDmeRV75U+On3FkxAi5JIZ0/bcGLsp0yi4vbTYSQzEjF+zAbQtRiwEc2BuBlPopqPpahO6a70+DZS2J0I6Vb/Ppiw0Zhz6tjNkODS/vUz8z2snGBx3UxHFCULEvx4KEklR0Swn2hcaOMqxBca1sL+mfMg04zYuU7RxeL+X/wvNasU7rBxeVMu10zyYAtkmO2SfeOSI1Mg5qZMG4eSOPJBH8uTcO8/Oi/P61Trj5DNb5Ec5b5/OnqGM</latexit>

1st

execution

while

loop

✏

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

✓

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

⇡
p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

↵

p = SELF
<latexit sha1_base64="VVlTSnmRrkfVlsefm42vG/nDOjU=">AAACDXicbZDLSsNAFIYn9VbrLepON6lFcCElkYJuhIIoLlxUtBdoQplMp+3QyYWZk9ISAr6Bb+FWN+7Erc8g+DBO0yy0emDgm/8/h5nzuyFnEkzzU8stLC4tr+RXC2vrG5tb+vZOQwaRILROAh6Ilosl5cyndWDAaSsUFHsup013eDH1myMqJAv8e5iE1PFw32c9RjAoqaPv2UDHABCHiV08t4vpNb67vLlKOnrJLJtpGX/ByqCEsqp19C+7G5DIoz4QjqVsW2YITowFMMJpUrAjSUNMhrhP2wp97FF5LEf9FJx4nG6TGIfK6xq9QKjjg5GqP2dj7Ek58VzV6WEYyHlvKv7ntSPonTkx88MIqE9mD/UibkBgTKMxukxQAnyiABPB1K8NMsACE1ABFlQc1vzyf6FxUrYq5cptpVQ1s2DyaB8doCNkoVNURdeohuqIoAf0hJ7Ri/aovWpv2vusNadlM7voV2kf303hm9M=</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>



p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

⌘

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

Q = {↵}
<latexit sha1_base64="wZ1hG1IN6rEXZEiLdNQjJj+oRyg=">AAAB83icdVDJSgNBEK2JW4xb1KOXxiB4GmZ0QD0IQS8eEzALZIbQ0+kkTXp6mu4eIQz5DS8eFPHqz3jzb+wsguuDgsd7VVTViyVn2njeu1NYWl5ZXSuulzY2t7Z3yrt7TZ1mitAGSXmq2jHWlDNBG4YZTttSUZzEnLbi0fXUb91RpVkqbs1Y0ijBA8H6jGBjpbB+GeYh5nKIw0m3XPHc4CLwTn30m/iuN0MFFqh1y29hLyVZQoUhHGvd8T1pohwrwwink1KYaSoxGeEB7VgqcEJ1lM9unqAjq/RQP1W2hEEz9etEjhOtx0lsOxNshvqnNxX/8jqZ6Z9HORMyM1SQ+aJ+xpFJ0TQA1GOKEsPHlmCimL0VkSFWmBgbU8mG8Pkp+p80T1w/cIN6UKleLeIowgEcwjH4cAZVuIEaNICAhHt4hCcncx6cZ+dl3lpwFjP78A3O6wc/MpHY</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

After <latexit sha1_base64="+EUZpZ/fTikOLX035e0wrLn99vc=">AAACGnicbZDLSgMxFIYzXmu9VV26CRbRhZSZIujSy8ZlBauFtpRMeqYNZpIhOaMtg4/gG/gWbnXjTty6EXwY08tCWw8EPv7/nCTnDxMpLPr+lzczOze/sJhbyi+vrK6tFzY2r61ODYcq11KbWsgsSKGgigIl1BIDLA4l3IS35wP/5g6MFVpdYT+BZsw6SkSCM3RSq7B3GiEYWlZtCj3g6UClDYQehlF23xUSHqjUOmkVin7JHxadhmAMRTKuSqvw3WhrnsagkEtmbT3wE2xmzKDg7tJ8I7WQMH7LOlB3qFgM9sDedYbQzHrD1R7orvPaNNLGHYV0qP6ezVhsbT8OXWfMsGsnvYH4n1dPMTpuZkIlKYLio4eiVFLUdJATbQsDHGXfAeNGuF9T3mWGcReXzbs4gsnlp+G6XAoOS4eX5eLJ2TiYHNkmO2SfBOSInJALUiFVwskjeSYv5NV78t68d+9j1DrjjWe2yJ/yPn8ArSuheA==</latexit>

2nd

execution

while

loop

✏

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

✓

p= <latexit sha1_base64="yW4q/8WYPdWRuSySaENEwTto6hE=">AAACB3icbZDJSgNBEIZ74hbjFpebl4lB8CBhRgb0IgS8eIxgFsgMoadTSZr0LHTXhMQhD+BbeNWLN/HqYwg+jJ1kDhr9oeGj/iqq6/djwRVa1qeRW1ldW9/Ibxa2tnd294r7Bw0VJZJBnUUiki2fKhA8hDpyFNCKJdDAF9D0hzczvzkCqXgU3uMkBi+g/ZD3OKOoS53ikYswRsQ0nrqla7fk+oC0UyxbFWsu8y/YGZRJplqn+OV2I5YEECITVKm2bcXopVQiZwKmBTdREFM2pH1oawxpAOpcjfpz8NLx/I6peaq9rtmLpH4hmvPqz9mUBkpNAl93BhQHatmbFf/z2gn2rryUh3GCELLFol4iTIzMWShml0tgKCYaKJNc/9pkAyopQx1dQcdhLx//FxoXFdupOHdOuepkweTJMTkhZ8Qml6RKbkmN1AkjD+SJPJMX49F4Nd6M90VrzshmDskvGR/fqpCZUA==</latexit>

⇡
p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

↵

p = SELF
<latexit sha1_base64="VVlTSnmRrkfVlsefm42vG/nDOjU=">AAACDXicbZDLSsNAFIYn9VbrLepON6lFcCElkYJuhIIoLlxUtBdoQplMp+3QyYWZk9ISAr6Bb+FWN+7Erc8g+DBO0yy0emDgm/8/h5nzuyFnEkzzU8stLC4tr+RXC2vrG5tb+vZOQwaRILROAh6Ilosl5cyndWDAaSsUFHsup013eDH1myMqJAv8e5iE1PFw32c9RjAoqaPv2UDHABCHiV08t4vpNb67vLlKOnrJLJtpGX/ByqCEsqp19C+7G5DIoz4QjqVsW2YITowFMMJpUrAjSUNMhrhP2wp97FF5LEf9FJx4nG6TGIfK6xq9QKjjg5GqP2dj7Ek58VzV6WEYyHlvKv7ntSPonTkx88MIqE9mD/UibkBgTKMxukxQAnyiABPB1K8NMsACE1ABFlQc1vzyf6FxUrYq5cptpVQ1s2DyaB8doCNkoVNURdeohuqIoAf0hJ7Ri/aovWpv2vusNadlM7voV2kf303hm9M=</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>



p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

⌘

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

Q={
<latexit sha1_base64="TWgZuyW2bmNX+f/Pe9aWASErLF4=">AAACC3icdVDLSgMxFM3UV62vqks3oUVwIWVGB9SFUHTjsgX7gE4pmfS2DU0yQ5IRytC9G3/FjQtF3PoD7vwb04fg80DIyTn3cnNPGHOmjeu+O5mFxaXllexqbm19Y3Mrv71T11GiKNRoxCPVDIkGziTUDDMcmrECIkIOjXB4OfEbN6A0i+S1GcXQFqQvWY9RYqzUyReq50EahGDIYdAnQtirC3zyglgzHslg3MkX3ZJ/5rvHHv5NvJI7RRHNUenk34JuRBMB0lBOtG55bmzaKVGGUQ7jXJBoiAkdkj60LJVEgG6n013GeN8qXdyLlD3S4Kn6tSMlQuuRCG2lIGagf3oT8S+vlZjeaTtlMk4MSDob1Es4NhGeBIO7TAE1fGQJoYrZv2I6IIpQY+PL2RA+N8X/k/pRyfNLftUvli/mcWTRHiqgA+ShE1RGV6iCaoiiW3SPHtGTc+c8OM/Oy6w048x7dtE3OK8fDnSbGg==</latexit>

,

, , ✏}

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

After <latexit sha1_base64="gTeU5iTlelr4LgIAliVz7mx3vXI=">AAACGnicbZDLSgMxFIYzXmu9VV26CRbRhZQZFXRZdeOyglWhHUomc6YNZiZDcqa2DH0E38C3cKsbd+LWjeDDmF4W3g4EPv7/nCTnD1IpDLruhzM1PTM7N19YKC4uLa+sltbWr4zKNIc6V1Lpm4AZkCKBOgqUcJNqYHEg4Tq4PRv6113QRqjkEvsp+DFrJyISnKGVWqWdkwhB0wMdUugBz4YqbSL0MIjyu46QMKBSqbRVKrsVd1T0L3gTKJNJ1Vqlz2aoeBZDglwyYxqem6KfM42C20uLzcxAyvgta0PDYsJiMHum2x6Bn/dGqw3otvVCGiltT4J0pH6fzVlsTD8ObGfMsGN+e0PxP6+RYXTs5yJJM4SEjx+KMklR0WFONBQaOMq+Bca1sL+mvMM04zYuU7RxeL+X/wtX+xXvsHJ4sV+unk6CKZBNskV2iUeOSJWckxqpE07uySN5Is/Og/PivDpv49YpZzKzQX6U8/4FtY2hfQ==</latexit>

3rd

execution

while

loop

✏

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

✓

p= <latexit sha1_base64="yW4q/8WYPdWRuSySaENEwTto6hE=">AAACB3icbZDJSgNBEIZ74hbjFpebl4lB8CBhRgb0IgS8eIxgFsgMoadTSZr0LHTXhMQhD+BbeNWLN/HqYwg+jJ1kDhr9oeGj/iqq6/djwRVa1qeRW1ldW9/Ibxa2tnd294r7Bw0VJZJBnUUiki2fKhA8hDpyFNCKJdDAF9D0hzczvzkCqXgU3uMkBi+g/ZD3OKOoS53ikYswRsQ0nrqla7fk+oC0UyxbFWsu8y/YGZRJplqn+OV2I5YEECITVKm2bcXopVQiZwKmBTdREFM2pH1oawxpAOpcjfpz8NLx/I6peaq9rtmLpH4hmvPqz9mUBkpNAl93BhQHatmbFf/z2gn2rryUh3GCELLFol4iTIzMWShml0tgKCYaKJNc/9pkAyopQx1dQcdhLx//FxoXFdupOHdOuepkweTJMTkhZ8Qml6RKbkmN1AkjD+SJPJMX49F4Nd6M90VrzshmDskvGR/fqpCZUA==</latexit>

⇡
p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

↵

p = SELF
<latexit sha1_base64="VVlTSnmRrkfVlsefm42vG/nDOjU=">AAACDXicbZDLSsNAFIYn9VbrLepON6lFcCElkYJuhIIoLlxUtBdoQplMp+3QyYWZk9ISAr6Bb+FWN+7Erc8g+DBO0yy0emDgm/8/h5nzuyFnEkzzU8stLC4tr+RXC2vrG5tb+vZOQwaRILROAh6Ilosl5cyndWDAaSsUFHsup013eDH1myMqJAv8e5iE1PFw32c9RjAoqaPv2UDHABCHiV08t4vpNb67vLlKOnrJLJtpGX/ByqCEsqp19C+7G5DIoz4QjqVsW2YITowFMMJpUrAjSUNMhrhP2wp97FF5LEf9FJx4nG6TGIfK6xq9QKjjg5GqP2dj7Ek58VzV6WEYyHlvKv7ntSPonTkx88MIqE9mD/UibkBgTKMxukxQAnyiABPB1K8NMsACE1ABFlQc1vzyf6FxUrYq5cptpVQ1s2DyaB8doCNkoVNURdeohuqIoAf0hJ7Ri/aovWpv2vusNadlM7voV2kf303hm9M=</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>



p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

Q={
<latexit sha1_base64="ETfJEN+ta3edurVa9t7KiRufKb4=">AAACDHicdVDLSiNBFK2O4ys+JupyNsUEYRYSup0GdSGIs3GpYKKQDnK7cpMUqapuqm4LockHuPFX3LhQBrd+gDv/ZiqPgXkeKOpwzrlU3ZPmSjoKw/egsvBhcWl5ZbW6tr6x+bG2td1yWWEFNkWmMnudgkMlDTZJksLr3CLoVOFVOvw28a9u0TqZmUsa5djR0DeyJwWQl25q9YvjpEz6oDXsJV1U5C/MnVSZ2UtogATJ2KfCRnwUh18j/jeJGuEUdTbH+U3tLelmotBoSChwrh2FOXVKsCSFwnE1KRzmIIbQx7anBjS6TjldZsx3vdLlvcz6Y4hP1V8nStDOjXTqkxpo4P70JuK/vHZBvcNOKU1eEBoxe6hXKE4ZnzTDu9KiIDXyBISV/q9cDMCCIN9f1Zfwc1P+f9Lab0RxI76I6yen8zpW2Cf2mX1hETtgJ+yMnbMmE+yOPbAn9hzcB4/B9+BlFq0E85kd9huC1x/8VZue</latexit>

,

, ✏, ✓}

⌘

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

⌘

p=
<latexit sha1_base64="fsXMWvJ5vQld4n4L1+rVWjvPIRE=">AAACCHicbZDLSsNAFIYn9VbrrSqu3EwtggspiQR0IxTcuKxgL9CUMplO0qEzSZg5KS2hL+BbuNWNO3HrWwg+jNPLQlt/GPg4/zmcOb+fCK7Btr+s3Nr6xuZWfruws7u3f1A8PGroOFWU1WksYtXyiWaCR6wOHARrJYoR6QvW9Ad3U785ZErzOHqEccI6koQRDzglYErd4okHbAQAWTLxSrdeyQuJlKRbLNsVeya8Cs4CymihWrf47fVimkoWARVE67ZjJ9DJiAJOBZsUvFSzhNABCVnbYEQk05d6GM6gk41mh0zwufF6OIiVeRHgWfX3bEak1mPpm05JoK+XvWnxP6+dQnDTyXiUpMAiOl8UpAJDjKep4B5XjIIYGyBUcfNrTPtEEQomu4KJw1k+fhUaVxXHrbgPbrnqLoLJo1N0hi6Qg65RFd2jGqojijL0jF7Qq/VkvVnv1se8NWctZo7RH1mfP3eamcE=</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

Q={
<latexit sha1_base64="NQ9qf4yMaZUx0nMY3iwX/8TbEvE=">AAACCnicdVDLSgNBEJz1GeMr6tHLaBA8SNjVBfUgBL14TMAkQjaE2UnHDM7OLjO9Qlhy9uKvePGgiFe/wJt/4+Qh+CxoqKnqZrorTKQw6LrvztT0zOzcfG4hv7i0vLJaWFuvmzjVHGo8lrG+DJkBKRTUUKCEy0QDi0IJjfD6bOg3bkAbEasL7CfQitiVEl3BGVqpXdiqngRZ0AGJbC+AxAgZq70AezB6IwsG7ULRLfnHvnvg0d/EK7kjFMkElXbhLejEPI1AIZfMmKbnJtjKmEbBJQzyQWogYfyaXUHTUsUiMK1sdMqA7lilQ7uxtqWQjtSvExmLjOlHoe2MGPbMT28o/uU1U+wetTKhkhRB8fFH3VRSjOkwF9oRGjjKviWMa2F3pbzHNONo08vbED4vpf+T+n7J80t+1S+WTydx5Mgm2Sa7xCOHpEzOSYXUCCe35J48kifnznlwnp2XceuUM5nZIN/gvH4AajuawQ==</latexit>

, ✏, ✓, ⌘}

After <latexit sha1_base64="e4TkEO7gUHkUJQSYLW1yDrPfqx8=">AAACG3icbZDLSgMxFIYz9VbrrerSTbAILqTMFEGXVTcuK9gLtKVk0jNtMDMZkjPaMvQVfAPfwq1u3IlbF4IPY3pZaOuBwMf/n5Pk/H4shUHX/XIyS8srq2vZ9dzG5tb2Tn53r2ZUojlUuZJKN3xmQIoIqihQQiPWwEJfQt2/uxr79XvQRqjoFocxtEPWi0QgOEMrdfLHFwGCpp6LfQoD4MlYpi2EAfpB+tAXEkZUKhV38gW36E6KLoI3gwKZVaWT/251FU9CiJBLZkzTc2Nsp0yj4PbSXCsxEDN+x3rQtBixEMyJue9NoJ0OJruN6JH1ujRQ2p4I6UT9PZuy0Jhh6NvOkGHfzHtj8T+vmWBw3k5FFCcIEZ8+FCSSoqLjoGhXaOAohxYY18L+mvI+04zbvEzOxuHNL78ItVLROy2e3pQK5ctZMFlyQA7JMfHIGSmTa1IhVcLJI3kmL+TVeXLenHfnY9qacWYz++RPOZ8/NIahuw==</latexit>

10th

execution

while

loop

✏

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

✓

p= <latexit sha1_base64="yW4q/8WYPdWRuSySaENEwTto6hE=">AAACB3icbZDJSgNBEIZ74hbjFpebl4lB8CBhRgb0IgS8eIxgFsgMoadTSZr0LHTXhMQhD+BbeNWLN/HqYwg+jJ1kDhr9oeGj/iqq6/djwRVa1qeRW1ldW9/Ibxa2tnd294r7Bw0VJZJBnUUiki2fKhA8hDpyFNCKJdDAF9D0hzczvzkCqXgU3uMkBi+g/ZD3OKOoS53ikYswRsQ0nrqla7fk+oC0UyxbFWsu8y/YGZRJplqn+OV2I5YEECITVKm2bcXopVQiZwKmBTdREFM2pH1oawxpAOpcjfpz8NLx/I6peaq9rtmLpH4hmvPqz9mUBkpNAl93BhQHatmbFf/z2gn2rryUh3GCELLFol4iTIzMWShml0tgKCYaKJNc/9pkAyopQx1dQcdhLx//FxoXFdupOHdOuepkweTJMTkhZ8Qml6RKbkmN1AkjD+SJPJMX49F4Nd6M90VrzshmDskvGR/fqpCZUA==</latexit>

⇡
p=
<latexit sha1_base64="olUJBLFFzx0MXrfBfWyDUrZTZ8E=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dBJMsyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/5AcKbAtr+Mwtr6xuZWcbu0s7u3f2AeHjVVnEhCGyTmsWwHWFHOItoABpy2haQ4DDhtBaO7ud8aU6lYHD3CVFA/xIOI9RnBoEtd88QDOgGAVMy88q1X9kZYCNw1K3bVzmStgpNDBeWqd81vrxeTJKQREI6V6ji2AD/FEhjhdFbyEkUFJiM8oB2NEQ6pulTjQQZ+OskOmVnn2utZ/VjqF4GVVX/PpjhUahoGujPEMFTL3rz4n9dJoH/jpywSCdCILBb1E25BbM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwCHP5nL</latexit>

↵

p = SELF
<latexit sha1_base64="VVlTSnmRrkfVlsefm42vG/nDOjU=">AAACDXicbZDLSsNAFIYn9VbrLepON6lFcCElkYJuhIIoLlxUtBdoQplMp+3QyYWZk9ISAr6Bb+FWN+7Erc8g+DBO0yy0emDgm/8/h5nzuyFnEkzzU8stLC4tr+RXC2vrG5tb+vZOQwaRILROAh6Ilosl5cyndWDAaSsUFHsup013eDH1myMqJAv8e5iE1PFw32c9RjAoqaPv2UDHABCHiV08t4vpNb67vLlKOnrJLJtpGX/ByqCEsqp19C+7G5DIoz4QjqVsW2YITowFMMJpUrAjSUNMhrhP2wp97FF5LEf9FJx4nG6TGIfK6xq9QKjjg5GqP2dj7Ek58VzV6WEYyHlvKv7ntSPonTkx88MIqE9mD/UibkBgTKMxukxQAnyiABPB1K8NMsACE1ABFlQc1vzyf6FxUrYq5cptpVQ1s2DyaB8doCNkoVNURdeohuqIoAf0hJ7Ri/aovWpv2vusNadlM7voV2kf303hm9M=</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>

p=↵
<latexit sha1_base64="40O5szoQBUGkgU7MUZcO5TMUy2w=">AAACCHicbZDLSsNAFIYn9VbrLSqu3KQWwYWURAK6EQpuXFawF2hCmUyn7dDJJMyclJbQF/At3OrGnbj1LQQfxmmahbb+MPBx/nM4c/4g5kyBbX8ZhbX1jc2t4nZpZ3dv/8A8PGqqKJGENkjEI9kOsKKcCdoABpy2Y0lxGHDaCkZ3c781plKxSDzCNKZ+iAeC9RnBoEtd88QDOgGANJ555Vuv7GEeD3HXrNhVO5O1Ck4OFZSr3jW/vV5EkpAKIBwr1XHsGPwUS2CE01nJSxSNMRnhAe1oFDik6lKNBxn46SQ7ZGada69n9SOpnwArq/6eTXGo1DQMdGeIYaiWvXnxP6+TQP/GT5mIE6CCLBb1E25BZM1TsXpMUgJ8qgETyfSvLTLEEhPQ2ZV0HM7y8avQvKo6btV9cCs1Nw+miE7RGbpADrpGNXSP6qiBCErRM3pBr8aT8Wa8Gx+L1oKRzxyjPzI+fwB8TpnE</latexit>



p=✓
<latexit sha1_base64="l9QN7oIR0CH2+RkEVu/1MFpdVPc=">AAACCHicbZDLSsNAFIYn9VbrrSqu3KQWwYWURAK6EQpuXFawF2hCmUxP26GTCzMnpSX0BXwLt7pxJ259C8GHcZp2oa0/DHyc/xzOnN+PBVdoWV9Gbm19Y3Mrv13Y2d3bPygeHjVUlEgGdRaJSLZ8qkDwEOrIUUArlkADX0DTH97N/OYIpOJR+IiTGLyA9kPe44yiLnWKJy7CGBHTeOqWbt2SiwNA2imWrYqVyVwFewFlslCtU/x2uxFLAgiRCapU27Zi9FIqkTMB04KbKIgpG9I+tDWGNAB1qUb9DLx0nB0yNc+11zV7kdQvRDOr/p5NaaDUJPB1Z0BxoJa9WfE/r51g78ZLeRgnCCGbL+olwsTInKVidrkEhmKigTLJ9a9NNqCSMtTZFXQc9vLxq9C4qthOxXlwylVnEUyenJIzckFsck2q5J7USJ0wkpJn8kJejSfjzXg3PuatOWMxc0z+yPj8AZVkmdQ=</latexit>

p=N
<latexit sha1_base64="Z97auqqBvB4XY6dtB8hKuWG8Kv0=">AAACAHicbVDLSsNAFJ3UV62vqAsXbqYWwVVJJKAboeDGlVSwD2hCmUyn7dDJg5kbsYRs/BU3LhRx62e482+cpllo64ELZ865l7n3+LHgCizr2yitrK6tb5Q3K1vbO7t75v5BW0WJpKxFIxHJrk8UEzxkLeAgWDeWjAS+YB1/cj3zOw9MKh6F9zCNmReQUciHnBLQUt88coE9AkAaZ271yq3mz/Q265s1q27lwMvELkgNFWj2zS93ENEkYCFQQZTq2VYMXkokcCpYVnETxWJCJ2TEepqGJGDKS/MDMnyqlQEeRlJXCDhXf0+kJFBqGvi6MyAwVoveTPzP6yUwvPRSHsYJsJDOPxomAkOEZ2ngAZeMgphqQqjkeldMx0QSCjqzig7BXjx5mbTP67ZTd+6cWsMp4iijY3SCzpCNLlAD3aAmaiGKMvSMXtGb8WS8GO/Gx7y1ZBQzh+gPjM8f9U+WmQ==</latexit>

Q = {}
<latexit sha1_base64="rq1b9fmXqMJRsLc0SJFioF50QLM=">AAAB7XicdVDJSgNBEK1xjXGLevTSGARPw4wOqAch6MVjAmaBzBB6Op2kTU/30N0jhCH/4MWDIl79H2/+jZ1FcH1Q8Hiviqp6ccqZNp737iwsLi2vrBbWiusbm1vbpZ3dhpaZIrROJJeqFWNNORO0bpjhtJUqipOY02Y8vJr4zTuqNJPixoxSGiW4L1iPEWys1KhdhHk47pTKnhucB96Jj34T3/WmKMMc1U7pLexKkiVUGMKx1m3fS02UY2UY4XRcDDNNU0yGuE/blgqcUB3l02vH6NAqXdSTypYwaKp+nchxovUoiW1ngs1A//Qm4l9eOzO9syhnIs0MFWS2qJdxZCSavI66TFFi+MgSTBSztyIywAoTYwMq2hA+P0X/k8ax6wduUAvKlct5HAXYhwM4Ah9OoQLXUIU6ELiFe3iEJ0c6D86z8zJrXXDmM3vwDc7rB7Gvjzo=</latexit>

⌘

p=
<latexit sha1_base64="fsXMWvJ5vQld4n4L1+rVWjvPIRE=">AAACCHicbZDLSsNAFIYn9VbrrSqu3EwtggspiQR0IxTcuKxgL9CUMplO0qEzSZg5KS2hL+BbuNWNO3HrWwg+jNPLQlt/GPg4/zmcOb+fCK7Btr+s3Nr6xuZWfruws7u3f1A8PGroOFWU1WksYtXyiWaCR6wOHARrJYoR6QvW9Ad3U785ZErzOHqEccI6koQRDzglYErd4okHbAQAWTLxSrdeyQuJlKRbLNsVeya8Cs4CymihWrf47fVimkoWARVE67ZjJ9DJiAJOBZsUvFSzhNABCVnbYEQk05d6GM6gk41mh0zwufF6OIiVeRHgWfX3bEak1mPpm05JoK+XvWnxP6+dQnDTyXiUpMAiOl8UpAJDjKep4B5XjIIYGyBUcfNrTPtEEQomu4KJw1k+fhUaVxXHrbgPbrnqLoLJo1N0hi6Qg65RFd2jGqojijL0jF7Qq/VkvVnv1se8NWctZo7RH1mfP3eamcE=</latexit>

p=⌘
<latexit sha1_base64="ZsWyKsTUbpmCrxARm/haTyPyBnI=">AAACBnicbZC7SgNBFIZn4y3G22pKm41BsJCwKwFthICNZQRzgWwIs5OTZMjshZmzIWFJ71vYamMntr6G4MM42WyhiT8MfJz/HM6c34sEV2jbX0ZuY3Nreye/W9jbPzg8Mo9PmiqMJYMGC0Uo2x5VIHgADeQooB1JoL4noOWN7xZ+awJS8TB4xFkEXZ8OAz7gjKIu9cyiizBFxCSau6Vbt+QC0p5Ztit2KmsdnAzKJFO9Z367/ZDFPgTIBFWq49gRdhMqkTMB84IbK4goG9MhdDQG1Ad1qSbDFLrJND1jbp1rr28NQqlfgFZa/T2bUF+pme/pTp/iSK16i+J/XifGwU034UEUIwRsuWgQCwtDa5GJ1ecSGIqZBsok17+22IhKylAnV9BxOKvHr0PzquJUK9WHarlWzYLJk1NyRi6IQ65JjdyTOmkQRmbkmbyQV+PJeDPejY9la87IZorkj4zPH+XKmOQ=</latexit>

Figure 2.13: Execution of the breadth-first search algorithm. In the leftmost frame, the start
node is colored in blue (Layer 0). The subsequent frames show Layers 1 to 4 as computed by BFS. We assume here that there is no goal node and just compute parent values, which are illustrated as blue directed edges. The blue edges define a subgraph called the BFS tree.

Note: Problem 2.2 is also referred to as the single-source single-destination shortest paths problem. Breadth-first search is also used to solve the single-source alldestination shortest paths problem. To do this, we remove the termination condition in line 10: of BFS and instead we terminate once Q is empty, returning the parent values. Then, for any node v we can extract the shortest path from vstart to v using the extract-path algorithm. The all-sources all-destinations shortest paths problem can be solved by running the single-source all-destination variation of BFS for each
node in the graph.
Note: We refer the reader interested in state-of-the-art implementations of graph
manipulation algorithms to the Boost Graph Library (Siek et al., 2007) and its Matlab
and Python packages called MatlabBGL and Boost.Python.

Chapter 2. Motion Planning via Decomposition and Search

extract-path algorithm

Input: a goal node vgoal, and the parent values

Output: a path from vstart to vgoal

1: create an array P := [vgoal]

2: set u := vgoal

3: while parent(u) ̸= SELF :

4:

u := parent(u)

5:

insert u at the beginning of P

6: return P

2.3.3 Representing a graph
One might wonder, how do we represent a graph that can be used as the input to the BFS algorithm. Recall that a graph G = (V, E) is described by a set of nodes and a set of edges. For simplicity, label the nodes 1, . . . , n, so that the question quickly reduces to: how do you represent the edge set E?

1

2

3

5

4
Figure 2.14: A sample graph for demonstrating graph representations
Representation #1 (Adjacency Table/List): The most common way to to represent the edge set is via a lookup table, that is, an array whose elements are lists of varying length. The lookup table contains the adjacency information as follows: the i-th entry is a list of all neighbors of node i. For example, for the graph above, the adjacency table (commonly called an adjacency list) would be
AdjTable[1] = [2] AdjTable[2] = [1, 3, 4] AdjTable[3] = [2, 5] AdjTable[4] = [2] AdjTable[5] = [3]
Representation #2 (Adjacency Matrix): In some mathematical and optimization problems, it is often convenient to represent the set of edges via the adjacency matrix, i.e., a symmetric matrix whose i, j entry is equal to 1 if the graph contains the edge {i, j} and is equal to 0 otherwise. For example, for the graph above, the adjacency

2.3. Search algorithms over graphs

matrix would be





01000

A = 100

0 1 1

1 0 0

1 0 0

010 .

00100

Representation #3 (Edge List): Finally, the set of edges may be represented as an
array, where each entry is an edge in the graph. This representation of edges is called an edge list. For example, for the graph below, the edge list would be [{1, 2}, {2, 3}, {2, 4}, {3, 5}].

Programming Note: In Matlab an adjacency table can be implemented using a structure called a cell array. Type help paren in Matlab for further information. For example, the adjacency table for the graph in Figure 2.14 would be specified
as » AdjTable{1} = [2]; » AdjTable{2} = [1, 3, 4]; » AdjTable{3} = [2, 5]; » AdjTable{4} = [2]; » AdjTable{5} = [3];
In Python there are two options to represent an adjacency table. The first is as a
list of lists »> AdjTable = [[2], [1, 3, 4], [2, 5], [2], [3]] Note that since Python indexes from zero (i.e., the first entry of a python list is indexed with 0), the neighbors of node number i are contained in AdjTable[i-1].
Alternatively, an adjacency list can implemented as a Python dictionary »> AdjTable = {1: [2], 2: [1, 3, 4], 3: [2, 5], 4: [2], 5: [3]} In this case the neighbors of node i are contained in AdjTable[i].

2.3.4 Runtime of BFS There are two questions that we will commonly ask when designing an optimization algorithm:
(i) Is the algorithm complete? and (ii) How quickly does it run?
The answer to the first question is that the algorithm is complete: If a path exists in the graph from the start to the goal, then the BFS algorithm will find the shortest

Chapter 2. Motion Planning via Decomposition and Search
such path; if a path does not exist, the algorithm returns a failure notice; in any case
the algorithm completes in a finite number of steps. We will skip the formal proof
of this, but an interested reader can refer to a book on algorithms such as (Cormen
et al., 2001) for a complete proof.
To answer the second question, we will determine the runtime of the algorithm as a function of the size of the input. In the case of BFS, the input is a graph G with node set V and edge set E. If we let n and m denote the number of vertices and the number edges in the graph G, respectively, then we can characterize the runtime of BFS as follows.
Theorem 2.3 (Run-time of the BFS algorithm). Consider a graph G = (V, E) with n vertices and m edges, along with a start and goal node. Then the runtime of the breadth-first-search algorithm is
• O(n + m) if G is represented as an adjacency table, • O(n2) if G is represented as an adjacency matrix, and • O(n · m) if G is represented as an edge list.
Proof. To analyze the run-time of our pseudocode for BFS, we will break it up into different pieces.
Initialization: First, initializing the queue and inserting vstart in step 4: can be done in O(1) time. Initializing the parent values for every node in steps 1: to 3: requires a O(1) time per node, for a total of O(n) time.
Outer while-loop: Notice that this loop runs at most n times: each node is inserted into the queue at most once (when it is first found by the search) and one node is
removed from the queue at each iteration of the while-loop. Thus, the algorithm spends O(1) time on step 6: at each iteration of the while-loop, or O(n) in total.
Inner for-loop: Now, let us look at step 7: of BFS. In each iteration of the whileloop this for-loop runs once for each neighbor node v. The time required for an iteration of the for-loop is O(1), since it consists of looking at the value of parent(u), and then possibly setting parent(u) to v and inserting u into the queue: all three operations require O(1) time. Notice that for each edge {u, v} in the graph, the node v will be listed as a neighbor of u and the node u will be listed as a neighbor of v. Thus, the number of iterations of the for-loop over the entire execution of BFS is at most 2m, which is O(m).
Extracting the path: The extract-path algorithm extracts the path from the parent values in O(n) time, since the while loop runs at most n times.
From this analysis we see that the overall runtime of BFS is O(n + m). However, notice that in this analysis we were implicitly assuming that our graph is represented as an adjacency table, since at step 7: we did not account for any extra computation

2.3. Search algorithms over graphs

in order to determine the neighbors of a given node: that is, we assumed that we

had a list of the neighbors of each node.
Adjacency matrix: If instead the graph were represented as an adjacency matrix, then we would require O(n) time to determine the neighbors of a node u: This would be done by searching through each of the n entries in the row of the adjacency matrix corresponding to node u. Thus, BFS runs in O(n2) when the graph is represented as

an adjacency matrix.

Edge list: If an edge list is used, then the run-time is even worse, as the entire

edge list must be searched at 7: to determine the neighbors of a node v. The run-time

of searching the edge list is O(m), giving a total runtime of O(n · m).

■

Note: If a graph is connected, then m ≥ n − 1. In addition, for any undirected graph, there can be at most n choose 2 edges, and thus m ≤ n(n − 1)/2. Thus, the number of edges is m ∈ O(n2). From this we see that the best graph representation
for BFS is an adjacency table, followed by an adjacency matrix, followed by an edge
list.

Notes and further reading
The first part of this chapter on decomposition is inspired by (de Berg et al., 2000, Chapter 13).

Chapter 2. Motion Planning via Decomposition and Search
2.4 Exercises
E2.1 Convexity (30 points). Convexity is a key concept, not just in analysis of robotic algorithms but in optimization, control and numerous other fields.
(i) (6 points) Explain in one paragraph (equal to a few sentences) when a set is convex and why it is useful for motion planning. Hint: The question talks about sets, not polygons, so your answer should not refer to internal angles.
(ii) (3 points each) For each of the following 5 properties, state if the property is true or false and provide a sketch supporting your statement.
a) The intersection of any two overlapping convex sets is convex. b) The union of two convex sets is convex. c) Take a set Q and a point p outside Q. If Q is convex, then there exists a unique
point in Q, say q, such that the distance between p and q is smaller than the distance between p and any other point in Q. d) Property (ii)c holds if Q is not convex. e) Take a line tangent to a convex set Q (that is, a line that just touches the boundary of Q but does not contain any point in the interior of Q). The line divides Q into two or more components.
(iii) (3 points each) Prove whether the statements (ii)a, (ii)c, and (ii)e are true or false.
E2.2 Partitions and roadmaps (20 points). For the free workspace in figure, do the following:

pstart

pgoal

(i) (5 points) Sketch the free workspace and trapezoidate it (using the sweeping trapezoidation algorithm).
(ii) (5 points) Sketch the dual graph for the trapezoidal partition and the roadmap (i.e., the dual graph with centers and with connecting polygonal paths through midpoints).
(iii) (5 points) In the dual graph, draw a Breadth-First-Search tree with start node being the trapezoid containing the start point. Number the nodes in the graph based on the number of hops required to reach each node from the start node.
(iv) (5 points) Sketch the continuous path from start point to goal point that a robot would actually follow in the workspace. The path depends upon the decomposition and upon the breadth-first search.

Exercises for Chapter 2
E2.3 The seven bridges of Königsberg (15 points). The city of Königsberg in Prussia (nowadays Kaliningrad in Russia) was founded on both sides of the Pregel River. The following figure (courtesy of Wikipedia) illustrates some main topographical features of this city, including four masses of land connected by seven bridges.
Here is the intriguing question that troubled the citizens of this small town during the 18th century:
Find a walk through the city that crosses each bridge exactly once. Here are the questions:
(i) How many vertices and edges are there? Draw a graph to represent the masses of land and the bridges connecting them, carefully label the vertices. Hint: For this exercise only, we accept graphs with multiple edges connecting the same two nodes. Such graphs are sometimes called multi-graphs or graphs with parallel edges.
(ii) Can you find the desired path? If so, please draw it and label the edges sequentially (1, 2, 3, .., etc). If not, describe informally why not.
(iii) Assuming that a single additional bridge can be constructed, modify the graph from part (i) and find a walk that crosses each bridge exactly once.
The comprehensive answer to these questions, given by Euler (1741), is today recognized as one of the earliest works on graph theory. (While the questions and the answers themselves are not all that important in general, Euler’s contribution was the introduction of graph theory.) E2.4 Counting triangles and trapezoids (15 points). For all of the following questions, explain your reasoning and provide an answer in terms of the numbers ℓ, n, and ki.
(i) (5 points) How many triangles are required to triangulate a polygonal workspace with ℓ vertices (and no obstacle inside)?
(ii) (5 points) How many triangles are required to triangulate a polygonal workspace with ℓ vertices and one polygonal obstacle inside (assume that the obstacle has k vertices)?
(iii) (5 points) How many trapezoids are required to trapezoidate a rectangular workspace (with 4 vertices) and n polygonal obstacles (each with ki vertices) using the sweeping algorithm, in the worst-case? Hint: Note that there are degenerate situations where the number of trapezoids is lower than for generic vertex positions. We are asking for the worst-case number, that is, for an upper bound.
E2.5 Computing time complexity (18 points). The time complexity of a program is the number steps or operations required for the program

Chapter 2. Motion Planning via Decomposition and Search

to execute. For the following brief programs, determine the order of their time complexity as a function of n, i.e., how the number of required operations scales with n. The
order of the time complexity should be given in “big O” notation, that is, for example, O(1), O(log n), O(n), O(n log n), O(n2), O(nn), etc. Hint: Count each addition, multiplication or division as having unit cost.

(i) (3 points)

1: a := 0

2: for i from 1 to n :

3:

a := a + 1

(ii) (3 points)

1: a := 0

2: for i from 1 to 10 :

3:

a := a + 1

(iii) (3 points)

1: a := 0

2: for i from 1 to n :

3:

a := a + 1

4: for j from 1 to n :

5:

a := a + 1

(iv) (3 points)

1: a := 0

2: for i from 1 to n :

3:

for j from 1 to n :

4:

a := a + 1

(v) (3 points)

1: a := 0

2: for i from 1 to n :

3:

for j from i to n :

4:

a := a + 1

(vi) (3 points)

1: a := n

2: while a > 1 :

3:

a := a/2

E2.6 On connected graphs and trees (10 points). Assume G is a connected graph with n nodes. Show that the following statements are equivalent:
(i) G is a tree, and (ii) G has exactly n − 1 edges. Hint: Prove the (i) ⇒ (ii) direction by induction.

E2.7 The BFS algorithm for disconnected graphs (15 points). Starting from the ideas in the BFS algorithm, provide a high-level algorithm in pseudocode that performs the following functions:

(i) verifies whether the graph is connected,

Exercises for Chapter 2
(ii) calculates how many connected components it has, and (iii) computes the number of nodes in each connected component. E2.8 Programming: BFS algorithm (30 points). Consider the following functions: computeBFStree (15 points)
Input: a graph described by its adjacency table AdjTable and a start node start Output: a vector of pointers parents describing the BFS tree rooted at start computeBFSpath (15 points) Input: a graph described by its adjacency table AdjTable, a start node start and a goal node goal Output: a path from start to goal along the BFS tree rooted at start For each function, do the following: (i) explain how to implement the function, possibly deriving analytic formulas, and characterize special cases, (ii) program the function, including correctness checks on the input data and appropriate error messages, and (iii) verify your function is correct on a broad range of test inputs and, specifically, on the graph and the start/goal problem drawn in figure.
start
goal
Hint: The function computeBFSpath should invoke the function computeBFStree. E2.9 Programming Project: The sweeping trapezoidation algorithm (60 points).
In this project you will write a function that, given as input a rectangular workspace with multiple polygonal obstacles (each described by a counter-clockwise sequence of vertices), computes the trapezoidal decomposition of the workspace and the associated roadmap graph. For simplicity, assume that the polygonal obstacles do not overlap and are strictly inside the rectangular workspace.
(i) Write in detailed pseudocode a function that classifies each obstacle vertex in the 6 possible types.
(ii) Implement the main function: SweepingTrapezoidation Input: a rectangle W with polygonal holes P , where P is a list of non-overlapping polygons inside W . Output: a collection of trapezoids (including the degenerate case of triangles), and a collection of edges (each describing a shared side between two trapezoids).

3 Chapter
Configuration Spaces
The previous chapters focused on planning paths for a robot modeled as a point in the plane. In this chapter we consider robots with physical size and robots composed of multiple moving bodies. In particular, we
(i) describe a robot as a single or multiple interconnected rigid bodies, (ii) define the configuration space of a robot, (iii) examine numerous example configuration spaces, and (iv) discuss forward and inverse kinematic maps that arise in robot motion plan-
ning.
3.1 Problem setup: Multi-body robots in realistic workspaces
Recall that we have worked so far with • a planar workspace W ⊂ R2, • some obstacles O1, . . . , On, and • a point robot with no shape, size or orientation.
We then defined the free workspace Wfree = W \ (O1 ∪ · · · ∪ On) as the set of locations where a point robot is not hitting any obstacle. A feasible motion plan for a point robot is computed as a path in Wfree. In this chapter we begin to consider robots that are more realistic than the point robot by considering robots with a finite shape and size. As illustrated in Figure 3.1, path planning algorithms for point robots are not immediately applicable to robots with a shape.
We start with some simple concepts: (i) a rigid body is a collection of particles whose position relative to one another
is fixed,
55

Chapter 3. Configuration Spaces

O1
O2 robot
O3

O1 collision!
O2 robot
O3

Figure 3.1: A path planned for a point robot (in left figure) will not work for a robot with the shape of a disk.

(ii) a robot is composed of a single rigid body or multiple interconnected rigid bodies,
(iii) robots are 3-dimensional in nature, but this chapter focuses on planar problems; we postpone 3-dimensional rigid bodies to the later chapters on kinematics.
Note: we do not consider flexible or deformable shapes, as in general an infinite number of variables is required to represent such robots.
Example systems Let us discuss a few preliminary examples of more complex robots. We consider only planar systems composed of either a single rigid body or multiple interconnected rigid bodies.

O1 O2
O1 O2

The disk robot has the shape of a disk and is characterized by just one parameter, its radius r > 0. The disk robot does not have an orientation. Accordingly, the disk robots only motion is translation in the plane: that is, translations in the horizontal and vertical directions.
The translating polygon robot or translating planar robot has a polygonal shape, e.g., a ship-like shape in the side figure. This robot is assumed to have a fixed orientation, and thus its only motion is translations in the plane.

3.2. The configuration space

O1 O2

The roto-translating polygon robot, with an arbitrary polygonal shape, is capable of translating in the horizontal and vertical directions as well as rotating.

A multi-link or multi-body robot is composed of multiple rigid bodies (or links) interconnected. Each link of the robot can rotate and translate in the plane, but these motions are constrained by connections to the other links and to the robot base. The 1-link robot is described by just a single angle. The 2-link robot is described by two angles.
Multi-body robots are commonly used in industrial manipulation tasks. An example of an industrial manipulator is shown in Figure 3.2. Robots with higher numbers of degrees of freedom are also of interest, e.g., see Figure 3.3.

3.2 The configuration space
In the rest of this chapter we study how to represent the position of robots composed of rigid bodies assuming no obstacles are present. We postpone the study of obstacles to the next chapter.
We start with a simple observation. To specify the position of every point belonging to a rigid body, it is equivalent to provide
• the position of a specific point and the orientation of the rigid body, plus a representation of the shape of the rigid body (which does not vary with time as the body is rigid), or, even more simply,
• a minimal set of variables that describe the position and orientation of the specific point.
This observation motivates the following definitions.

HP20 ROBOT
1417

1485

760

140 80

Chapter 3. Configuration Spaces

1717

2072

P-Point

Maximum Envelope

150

795

105

A

P-Point

VIEW A
0.5

Tapped holes M6 (Depth: 10mm) (Pitch: 1.0) (4 holes)

6

45°

6

PCD40

6 dia Depth: 6m

3063 25 dia 50 dia

505

B C

VIEW B

0

Internal user

air line 3/8” PT

(with plug)

559

260 180°

991 R1717

Internal user I/O connector is JL05-2A20-29PC (with cap) Mating connector will not be supplied, b complete cables are available as an opti

VIEW C

4-18 dia 313

375
335 200
60

R314 200
250 335 375

R421 180°

2-12 dia

All dimensions are metric (mm) and for reference only. Request detailed drawings for all design/engineering requirements.

Figure 3.2: The Motoman® HP20 manSiPpECuIFlIaCtAoTIrONiSs a multi-body robot versatile high-speed

industrial robot with a slim http://www.motoman.com.

base,

waist,
Axes

andMaaximrumm .
motion range [°]

Image courtesy of Yaskawa Motoman, Maximum speed
[°/sec.]
FS100 MLX200

Allowable moment Īđ)ī

Allowable moment of
inertia Ī'#đ)2]

Controlled axes Maximum payload [kg] Repeatability [mm]

Horizontal reach [mm]

S

±180

197

157.6

–

–

Vertical reach [mm]

L

-100/+155

175

175

–

–

Protection (IP rating)

(i) A configuration of a robot is a minimal set of variables that specifiesStantdharde

U

-165/+255

205

205

–

–

XP version

position and orientation of each rigid body composing the robot. The robot Weight [kg]

R

±200

400

400

39.2

configuration is usually denoteB d by the -50/+230 lette4r00q. 400

39.2

1.05

Power requirements

1.05

Power rating [kVA]

Standard

(ii)

The configuration space

is

the

T
set

of

±360

600

all possible

600

19.6

configurations

of

a0.75robot.XPTverhsioen

robot configuration space is usuOalPlTyIOdNenSoted by the letter Q, so that q ∈ Q.

(iii) The number of degrees of freedoEmxtenodefd laengrthombanoiptulaitsor ctahblees dimension of the configura-

tion

space,

i.e.,

the

minimum

MotoPick™ – scheduler and picking
nusomftwabreeinrtegoraftedvwaitrh ivaisiobnlaends

required

to

fully

AXES LEGEND
specify the S-Axis: Swivel Base L-Axis: Lower Arm

position and orientation of eacchonvreiyogr itrdackbingody belonging to the robot. U-Axis: Upper Arm

MotoSight™ – easy to integrate vision software

R-Axis: Arm Roll B-Axis: Wrist Bend

(iv)

Given that

the

robot

is at

configuration q,

we

know

where all

T-Axis: Tool Flange
points of the

robot are. In other words, there is a function B(q) as shown in Figure 3.4 that

specifies the position of each point belonging to the robot at configuration q.
TECHNICAL SPECIFICATIONS SUBJECT TO CHANGE WITHOUT NOTICE
The function B is called the configuration map, and it maps each point q in the DS-614 ©2014 YASKAWAAMERICA,INC. SEPTEMBER2014

configuration space Q to the set of all points B(q) of the workspace belonging

260
Body: Body: 3-phase; 2
Yaskawa A Motoman 100 Autom Miamisbu Tel: 937.8 Fax: 937.
moto
MOTO ALL OTHER REGISTERED TRADE

to the robot.

Note, one way to represent the position of every point of the robot at a configuration q is to specify the position, orientation, and shape of each rigid body belonging to the robot.

3.2. The configuration space

Figure 3.3: RoboSimian is an ape-like robot that moves around on four limbs. It was designed and built at NASA’s Jet Propulsion Laboratory in Pasadena, California. It competed in the 2015 DARPA Robotics Challenge Finals. Image courtesy of NASA/JPL-Caltech.

q conﬁguration map B

conﬁguration space Q

workspace W

Figure 3.4: Each configuration q determines the position and orientation of each rigid body composing the robot.

Note: The configuration space should not be confused with the workspace. As shown in Figure 3.4, the workspace is always the 2-dimensional Euclidean space R2 or the 3-dimensional space R3 where the robot moves. The configuration space instead is a space of variables that describe the position and orientation of each rigid body component of a robot.
To make these notions more concrete, let us now examine the configuration spaces of the robot examples introduced above. For example, we will learn that:
• a robot composed by a single rigid body (moving in the plane) has 3 degrees of freedom (2 due to translation and 1 due to rotation), and
• a robot composed by multiple rigid bodies (moving in the plane) has 3 degrees of freedom for each rigid body minus the number of constraints imposed by

Chapter 3. Configuration Spaces
the joints.
Several different types of joints are used to interconnect rigid bodies. Several different types of interconnection are shown in Figure 3.5. The most common joint types are prismatic, which allows one rigid body to translate relative to another (for example, an telescoping pole that can extend and retract), and revolute, which allows one rigid body to rotate about a single axis relative to another (for example, the elbow joint of a human arm). In the manipulator shown in Figure 3.2, the first three joints are each revolute: one connecting the base to the body of the robot, one connecting the body to the lower arm, and one connecting the lower arm to the upper arm. This is commonly referred to as the RRR configuration (each revolute joint is denoted by an R).

Planar 3 freedoms

Spherical 3 freedoms

Cylindrical 2 freedoms

Revolute 1 freedom

Prismatic 1 freedom

Helical 1 freedom

Figure 3.5: Example joints to interconnect rigid bodies. In classic kinematics, joints are called “kinematic pairs.” Each joint constrains the relative motion of the two rigid bodies being interconnected. This image is figure 2.21 in Mason (2001) © 2001 Massachusetts Institute of Technology; it is used with permission of The MIT Press.

3.3 Example configuration spaces
We now present some examples of configuration spaces for simple robots presented above.
3.3.1 Configuration space of translating planar robots In this first example we consider the disk robot and the polygonal robot that may only translate and not rotate. (For these two robots, we silently assume the existence

3.3. Example configuration spaces

2

B(1, 2)

1 B(0, 0)

B(2, 1)

1

2

Figure 3.6: The polygonal robot at distinct positions in the workspace

of a constraint prohibiting the robot from rotating.) As shown in Figure 3.6, we
designate a specific point of the robot to be the reference point (for example, the
center of the body).
Given a reference frame in space (we will discuss the concept of reference frame
further beginning in Chapter 6), place the robot such that its reference point lies at the origin of the reference frame. Let B(0, 0) denote the set of points belonging to the robot when the robot is at the reference position (0, 0). Any other placement B(q) of the robot is specified by two parameters, i.e., by a point q = (qx, qy) in the plane R2.
Therefore, the configuration space of the robot is Q = R2 and a configuration q = (qx, qy) ∈ Q is simply a point in the plane R2. The robot has 2 degrees of freedom since two parameters are required to specify its configuration.
3.3.2 Configuration space of the 1-link robot
The configuration q of the 1-link robot is given by the angle of the link relative to a reference axis (for example, the horizontal axis). The configuration space Q is then the set of angles.
There are two ways we can represent the set of angles. The first is simply as an interval [−π, π[, where the number −π is included in the interval and the number π is excluded. In this representation, one must remember that −π and π are the same angle as shown in Figure 3.7, which can cause problems when calculating distances
between angles.
The second way, as shown in Figure 3.7, is to represent the set of angles as the set of points on the unit-radius circle. We define the unit circle as S1 = {(x, y) ∈ R2 | x2 + y2 = 1}, where the symbol S1 is used because the unit-radius circle is also the unit-radius one-dimensional sphere. The circle naturally captures the fact that −π and π are the same angle.

y x

Chapter 3. Configuration Spaces

Figure 3.7: The circle S1 and its representation as an interval [−π, π[, with −π and π being the same angle. A circle is very different from a segment, when it comes to path planning.

conﬁguration map B(q)

Figure 3.8: The configuration map for the 1-link robot. The point (approximately 45◦ measured counterclockwise from positive horizontal axis) on the configuration space (left image) determines where the 1-link robot is in the workspace (right image).
In summary, the configuration space of the 1-link robot is the circle Q = S1, and a configuration q can be thought of either as a point (x, y) on the circle, or as the corresponding angle θ defined by x = cos(θ) and y = sin(θ); see Figure 3.8. We will usually write the configuration simply as an angle θ ∈ S1. The 1-link robot has 1 degree of freedom since its configuration can be described by a single angle.
3.3.3 Configuration space of roto-translating planar robots
The configuration of a planar object that translates and rotates is
q = (x, y, θ),
where (x, y) is the position of the reference point and θ is the angle of the body measured counterclockwise with respect to the positive horizontal axis. The configuration space of a roto-translating polygon is Q = R2 × S1. The robot has 3 degrees of freedom. Figure 3.9 illustrates the configuration map. (In the later chapters, we will study this configuration space as the matrix group of planar displacements.)
3.3.4 Configuration space of robots moving in 3-dimensions Robots moving in three dimensions may rotate or roto-translate in 3-dimensional Euclidean space. In Figure 3.10 we illustrate a three-dimensional robot composed of a single rigid body. We postpone a detailed treatment of the configuration space

3.3. Example configuration spaces
y conﬁguration map B(q)
x
Figure 3.9: The configuration map for a roto-translating planar robot. The point and the arrows on the configuration space (left image) describe the location of the rigid body and its motion in the workspace (right image).
z
`
y x Figure 3.10: A three-dimensional rigid body
for such robots to the later chapters on kinematics and rotation matrices. For now, let us just mention that an unconstrained single-rigid-body robot has 6 degrees of freedom: 3 degrees of translational freedom and 3 degrees of rotational freedom.
3.3.5 Configuration space of a multi-link robot The configuration space of the 2-link robot brings up some interesting issues. As in Figure 3.11, let ℓ1 and ℓ2 be the lengths of the first and second link. Let θ1 denote the angle of the first link measured counterclockwise with respect to the positive horizontal axis, and let θ2 denote the angle of the second link measure counterclockwise with respect to the first link.
Therefore, the configuration q of the 2-link robot is described by the two angles θ1 and θ2. The configuration space is then Q = S1 × S1. We will write (θ1, θ2) ∈ S1 × S1 or, slightly less precisely, (θ1, θ2) ∈ [−π, π[ × [−π, π[.
It is useful to define the 2-torus (or simply torus) as the product of two circles: T2 = S1 × S1. The torus can be depicted in two symbolic ways, see Figure 3.12. The left figure illustrates how the torus can be drawn as a square in the plane, but where (1) the vertical on the left is identified with the vertical segment on the right and (2) the horizontal segment on the top is identified with the horizontal segment on

Chapter 3. Configuration Spaces
(x, y)
2 2
1
1
Figure 3.11: A 2-link planar robot
the bottom. The right figure is the 2-torus drawn in three dimensions: the shape is often referred to as the doughnut.
Figure 3.12: The 2-torus T2, sometimes called just the torus. (In the left figure, the arrows in the left and right vertical segments point in the same upward direction meaning that the two segments are to be matched without any twist. For more on this concept, read Wikipedia:Klein bottle.)
Note: The doughnut shape is obtained by (1) preparing a square flat sheet, and (2) gluing together vertical left with vertical right and horizontal top with horizontal bottom segments.
Note: The 2-sphere (in 3-dimensions) is the set of points in R3 at unit distance from the origin. In a formula, S2 = {(x, y, z) ∈ R3 | x2 + y2 + z2 = 1}. The 2-torus and the 2-sphere are two sets that can be described by two angles. However, the 2-torus is substantially different from the 2-sphere. In S2 each closed path can be deformed continuously to a point because S2 has no holes. The 2-torus instead has a hole and it contains closed paths that cannot be continuously deformed to a point.

3.4. Forward and inverse kinematic maps

conﬁguration map B(q)

Figure 3.13: The configuration map for the 2-link robot. The point (approximately (40◦, 30◦)) on the configuration space (left image) determines the orientation of both robot links in the workspace (right image).
The 2-sphere is usually drawn quite differently from how the 2-torus is drawn, e.g., see Figure 3.14.
90
latitude 0

90

180

0

180

longitude

Figure 3.14: A world map as a 2-sphere Image courtesy of Wikipedia.

3.4 Forward and inverse kinematic maps
In this section we discuss how to transform motion planning problems from the workspace W to the configuration space Q via forward and inverse kinematics maps.
Given a motion planning problem in the workspace “move from point pstart ∈ W to point pgoal ∈ W ,” we need to translate this specification into the configuration space, i.e., move from a configuration qstart ∈ Q to a configuration qgoal ∈ Q.
Rather than presenting a general framework, we discuss a specific example, the 2-link robot, and a specific motivation. Figure 3.15 is the picture of a robotic manipulator commonly used in pick-up and place and assembly applications. Manipulators with this configuration are referred to as “Selective Compliance Assembly

Chapter 3. Configuration Spaces
Robot Arm,” or SCARA in brief. From Wikipedia:SCARA, “by virtue of the SCARA’s parallel-axis joint layout, the arm is slightly compliant in the X-Y direction but rigid in the Z direction, hence the term: Selective Compliant.” In a vertical view, this manipulator is equivalent to the 2-link robot we just studied. The end position of this manipulator is the position (x, y) (near the far end of the 2-link) is where the end-effector is attached: the end-effector is the device with which the manipulator interacts with the environment, e.g., a robot gripper (for pick-up and place applications), a welding head, or a spray painting gun.
p2 = (x, y)

p0 = (0, 0)

2 2
p1
1 1

Figure 3.15: The Yamaha© YK500XG is a high-speed SCARA robot with two revolute joints and a vertical prismatic joint. Image courtesy of Yamaha Motor Co., Ltd, http://global.yamaha-motor.com/ business/robot.

Figure 3.16: Vertical view of a SCARA robot,
with end-effector location (x, y). In the triangle (p0, p1, p2), define γ ∈ [0, π] as the angle opposite the side p0p2.

In short, we next consider the two following problems:

The forward kinematics problem: compute (x, y) as a function of (θ1, θ2), and The inverse kinematics problem: compute (θ1, θ2) as a function of (x, y).

Note in the forward kinematics problem we are given the joint angles and our goal is to find the position of the end effector. In contrast, in the inverse kinematics problem we are given a desired end effector position and our goal is to find joint angles that place the end effector at the desired position.

3.4. Forward and inverse kinematic maps
3.4.1 Forward and inverse kinematics for the 2-link robot
Consider the 2-link robot with configuration variables (θ1, θ2) and end-effector location (x, y) as in Figure 3.16. Because the two joint angles (θ1, θ2) are the configuration variables, it should be possible to express (x, y) as a function of (θ1, θ2). Some basic trigonometry leads to
x = ℓ1 cos(θ1) + ℓ2 cos(θ1 + θ2), (3.1)
y = ℓ1 sin(θ1) + ℓ2 sin(θ1 + θ2).
A function of the configuration variables that describes the position of a specific point of the robot body is usually called a forward kinematics map. So, equation (3.1) is the forward kinematics map for the 2-link robot.
Next, we are interested in computing what are possible configurations (θ1, θ2) when we know the end-effector is at position (x, y), in other words, we are interested in the inverse function. We start by noting that such a problem does not admit a unique solution, as illustrated in the following Figure 3.17.
p1,elbow-up

p0 = (0, 0)

p2 = (x, y)

p0 = (0, 0)

p2 = (x, y)

p1,elbow-down
Figure 3.17: Two different solutions to the same inverse kinematics problem (the endeffector locations in the figures are identical): the elbow-down configuration corresponds to θ2 = π − γ ∈ [0, π] and the elbow-up configurations corresponds to θ2 = −π + γ ∈ [−π, 0].

We compute the inverse kinematic map as follows. In the triangle defined by
(p0, p1, p2), define γ ∈ [0, π] as the angle opposite the side p0p2, see Figure 3.17. This triangle has sides of length a = ℓ1, b = ℓ2 and c = x2 + y2. For this triangle, the law of cosines (see Wikipedia), c2 = a2 + b2 − 2ab cos γ, leads to

x2 + y2 = ℓ21 + ℓ22 − 2ℓ1ℓ2 cos(γ),

and, in turn, to

cos(γ)

=

ℓ21

+

ℓ22

−

x2

−

y2 .

(3.2)

2ℓ1ℓ2

Chapter 3. Configuration Spaces

According to the discussion in Appendix 3.5, there are either zero, one or two solutions to this equality. The right hand side is in the range [−1, +1] if and only if

−1 ≤ x2 + y2 − ℓ21 − ℓ22 ≤ 1 2ℓ1ℓ2

⇐⇒ ⇐⇒ ⇐⇒

−2ℓ1ℓ2 ≤ x2 + y2 − ℓ21 − ℓ22 ≤ 2ℓ1ℓ2 (ℓ1 − ℓ2)2 ≤ x2 + y2 ≤ (ℓ1 + ℓ2)2 |ℓ1 − ℓ2| ≤ x2 + y2 ≤ (ℓ1 + ℓ2).

So, for end-effector positions (x, y) such that x2 + y2 is in the range [|ℓ1 − ℓ2|, ℓ1 + ℓ2], there always exists exactly one solution γ in the range [0, π] to equation (3.2) equal to
γ = arccos ℓ21 + ℓ22 − x2 − y2 . 2ℓ1ℓ2
Finally, it remains to compute θ2 as a function of γ. From Figure 3.17, it is clear that θ2 = π − γ for the configuration with “robot elbow down” and θ2 = −π + γ for the configuration with “robot elbow up.” We summarize this discussion in the following
proposition.

Proposition 3.1 (Inverse kinematics for 2-link robot). Consider the 2-link robot with configuration variables (θ1, θ2) and links lengths (ℓ1, ℓ2) as in Figure 3.16. Given a desired end-effector position (x, y) such that |ℓ1 − ℓ2| ≤ x2 + y2 ≤ (ℓ1 + ℓ2), there exist two (possibly coincident) solutions for the joint angle θ2 given by

θ2,elbow-down = π − arccos

ℓ21 + ℓ22 − x2 − y2 2ℓ1ℓ2

θ2,elbow-up = −π + arccos

ℓ21 + ℓ22 − x2 − y2 2ℓ1ℓ2

∈ [0, π], ∈ [−π, 0].

The two solutions correspond to the diagrams in Figure 3.17.

We leave to the reader in Exercise E3.8 the following tasks: (i) the interpretation
of the condition |ℓ1 − ℓ2| ≤ x2 + y2 ≤ (ℓ1 + ℓ2), and (ii) the computation of the other joint angle θ1.

3.5 Appendix: Inverse trigonometric problems
We review here some basic identities from trigonometry that are useful in a inverse kinematics problems.

3.5. Appendix: Inverse trigonometric problems

Solutions to basic trigonometric equalities
Given three numbers a, b, and c, we consider the following equations in the variables α, β and γ:
sin(α) = a, cos(β) = b, and tan(γ) = c.

sin(↵) a

arcsin(a)

arccos(b)

b

cos( )

Figure 3.18: The equations sin(α) = a and cos(β) = b

Because arcsin : [−1, 1] → [−π/2, π/2] (that is, the arcsin function computes a single angle always in the interval [−π/2, π/2]), we solve the first equation sin(α) = a as follows:
if |a| > 1, no solution, if |a| ≤ 1, two (possibly coincident) solutions: α1 = arcsin(a), α2 = π − arcsin(a),
(3.3)

so that, in particular, α1 = α2 = π/2 for a = +1, and α1 = α2 = −π/2 for a = −1. Because arccos : [−1, 1] → [0, π] (that is, the arccos function computes a single
angle always in the interval [0, π]), we solve the second equation cos(β) = b as follows:
if |b| > 1, no solution, if |b| ≤ 1, two (possibly coincident) solutions: β1 = arccos(b), β2 = − arccos(b),
(3.4)

so that, in particular, β1 = β2 = 0 for b = +1, and β1 = β2 = π for b = −1. Finally, the third equation tan(γ) = c admits two solutions for any c ∈ R:

γ1 = atan(c) and γ2 = atan(c) + π.

(3.5)

Four-quadrant arctangent function with two arguments
The four-quadrant arctangent function atan2 computes the inverse tangent map as follows: for any point (x, y) in the plane except for the origin, the value atan2(y, x)

Chapter 3. Configuration Spaces

(x2, y2)

(x1, y1)

✓2

✓1

✓1 = atan2(y1, x1) ✓2 = atan2(y2, x2) ✓3 = atan2(y3, x3)

✓3

(x3, y3)

Figure 3.19: The four-quadrant arctangent function

is the angle between the horizontal positive axis and the point (x, y) measured counterclockwise; see Figure 3.19. So, for example,

atan2(0, 1) = 0, atan2(1, 0) = π/2, atan2(0, −1) = π, atan2(−1, 0) = −π/2.

Two useful property of the four quadrant arctangent function are:

atan2(y, x) = π + atan2(−y, −x),

atan2(y, x)

=

−π 2

+

atan2(x, −y).

Also, it is easy to see that, for all angles θ, we have

θ = atan2(sin(θ), cos(θ)).

The order of the arguments is very important as there are two possible conventions: (y, x) or (x, y). In this class, we adopt the (y, x) convention.

Programming Note: In Matlab, the (y, x) convention is used. This can be seen by typing help atan2 , which produces

ATAN2 Four quadrant inverse tangent. ATAN2(Y,X) is the four quadrant arctangent of the real
parts of the elements of X and Y. -pi <= ATAN2(Y,X) <= pi.

In Python, atan2 is implemented in the math module as math.atan2 and also uses the (y, x) convention. Some texts and the program Mathematica use the (x, y) convention.

Alternative solutions to basic trigonometric equalities The four-quadrant arctangent function provides an alternative and sometimes easier way of computing solutions to
sin(α) = a, cos(β) = b, and tan(γ) = c,

3.5. Appendix: Inverse trigonometric problems

wh√ere we assume |a| ≤ 1 and |b| ≤ 1. Specifically, if sin(α) = a, then cos(α) = ± 1 − a2 and therefore

√

√

α1 = atan2(a, 1 − a2), and α2 = atan2(a, − 1 − a2).

(3.6)

√ Similarly, if cos(β) = b, then sin(β) = ± 1 − b2 and therefore

√

√

β1 = atan2( 1 − b2, b), and β2 = atan2(− 1 − b2, b).

(3.7)

Finally, tan(γ) = c is equivalent to

γ1 = atan2(c, 1), and γ2 = atan2(−c, −1).

Notes and further reading
This chapter is inspired by (de Berg et al., 2000, Chapter 13), (LaValle, 2006, Chapter 4), and (Hager, 2006).

Chapter 3. Configuration Spaces

3.6 Exercises

E3.1 Shortest paths and distances on the circle (15 points). Given two points on the circle θ1 and θ2 (represented as values in the interval [−π, π[), the counter-clockwise distance from θ1 to θ2, denoted by distcc(θ1, θ2), is the length of the counterclockwise arc starting at θ1 and ending at θ2. Similarly, the clockwise distance, denoted by distc(θ1, θ2), is the length of the clockwise arc from θ1 to θ2. Finally, the distance between θ1 to θ2 is the smallest of the two counter-clockwise and clockwise distances. Hint: On the unit circle, the length of an arc is equal to the angle subtended by the arc and is measured in radians.
(i) (2 points) Compute counter-clockwise and the clockwise distances between θ1 = π/3 and θ2 = −3π/4.
(ii) (5 points) Provide a formula for the counter-clockwise distance from arbitrary θ1 to arbitrary θ2. Hint: Recall the “modulo” operator: mod(θ, 2π) is the remainder of the division of θ by 2π.
(iii) (5 points) Provide a formula for the clockwise distance from θ1 to θ2, denoted by distc(θ1, θ2).
(iv) (3 points) Define the distance between two angles to be the smallest between their
counterclockwise and clockwise distance. Provide a formula for the distance between
θ1 and θ2, denoted by distcircle(θ1, θ2).
For further reference, note the following general properties:

distcc(θ1, θ2) ̸= distcc(θ2, θ1), distcc(θ1, θ2) = distc(θ2, θ1), distcircle(θ1, θ2) = distcircle(θ2, θ1),

lack of symmetry of distcc, relationship between distcc and distc, and symmetry of distcircle.

E3.2 Shortest paths and distances on the 2-torus (10 points). Requires Exercise E3.1. Consider the two points (α1, β1) and (α2, β2) in T2 as depicted in
the figure.

( 1, ⇥1)

( 2, ⇥2)

(i) (5 points) Sketch the shortest path between (α1, β1) and (α2, β2).
(ii) (5 points) Define the distance between two points to be the length of the shortest path between them. Provide a formula for the distance between (α1, β1) and (α2, β2), denoted by dist2-torus (α1, β1), (α2, β2) .

Exercises for Chapter 3
Hint: Your answer should include a square root. Gain deeper intuition into trajectories on the 2torus by practicing the classic arcade game Asteroids at http://www.freeasteroids.org. E3.3 Shortest paths and distances on the 2-sphere (10 points). The 2-sphere S2 is the set of points in R3 at unit distance from the origin.
(i) What do shortest paths between points look like? (ii) Given two points p = (p1, p2, p3) and q = (q1, q2, q3) in the 2-sphere (so that p21 +
p22 + p23 = 1 = q12 + q22 + q32), provide a formula for the distance between p and q, denoted by dist2-circle p, q). E3.4 Programming: Distances on the circle and the 2-torus (10 points). Requires Exercises E3.1 and E3.2. Write the following programs:
computeDistanceOnCircle (5 points) Input: two angles α and β in the interval [−π, π[ Output: the distance between α and β
computeDistanceOnTorus (5 points) Input: two points on the torus angles (α1, α2) and (β1, β2) Output: the distance between (α1, α2) and (β1, β2)
E3.5 Two-link configuration space (10 points). Consider a planar two-link manipulator as shown in the left figure (assume that the ground does not limit the motion of the links). The approximate configuration space for the manipulator in a workspace with obstacles is shown in the right figure.

2
O2

<latexit sha1_base64="m9ULOz1tX+FlqQmUKHW1TWFuaxM=">AAACo3icdVFtT9swEHazDVgYr/vIl4gKCSQoCULAxyL2AQkhAWsBqQnIdi6thZ1E9qVaFUX7G/u6/av9G9xQNF66k2w9vufuHt8dy6Uw6Pt/G86Hj59mZuc+u/NfFhaXlldWr01WaA5dnslM3zJqQIoUuihQwm2ugSom4YY9nIz5myFoI7K0g6McIkX7qUgEp2hdd5s7YS5297bre+t+uem3/Nq89yCYgCaZ2MX9SuNnGGe8UJAil9SYXuDnGJVUo+ASKjcsDOSUP9A+9CxMqQKzbYb9GkTlj7qBytuwXOwlmbYnRa/2vswtqTJmpJiNVBQH5i03dk7jegUmR1Ep0rxASPmTUFJIDzNvPA0vFho4ypEFlGthf+3xAdWUo53ZKxWmKtcNv4FtU8O5FTqW+YAywDKsZROBVdkJqjI0SQwJLaR9hyr+h418xm74HfB/NVgm4ymVWDK1kl1Z8HZB78H1Xis4aPmX+832/mR5c2SNrJNNEpBD0ian5IJ0CSea/CK/yR9nwzlzrpzOU6jTmOR8Ja/MiR4BYfjUnQ==</latexit>
(

⇡/2, ⇡/2)

1

O1
1

2

<latexit sha1_base64="IG9M6nU1/MNY80n7Egg1Rm3N8f8=">AAACp3icdVFNb9NAEN24hRbzlZYjF6sRUiuVYNMIOBbBgQuiiCaNFEfR7HqcrLprW7vjiMiy+CNc4T/xb9g4Qf0KI6327byZeTszvFDSUhj+aXlb2/fu7+w+8B8+evzkaXtvf2Dz0gjsi1zlZsjBopIZ9kmSwmFhEDRXeMEvPyz5izkaK/PsnBYFjjVMM5lKAeRck3b78CQu5Kve8cvVfTRpd8Ju2FhwF0Rr0GFrO5vstX7ESS5KjRkJBdaOorCgcQWGpFBY+3FpsQBxCVMcOZiBRnts59MGjKvvTRN18MJxSZDmxp2MgsZ7PbcCbe1CcxepgWb2Nrd0buJGJaXvxpXMipIwEyuhtFQB5cFyIkEiDQpSCwdAGOl+HYgZGBDk5nZDheva9+OP6No0+NkJvVfFDDhSFTeyqaS6Oo/qKrZpgimUyr1jnVxhq/5hP/6G9L8aPFfJhko83VjJrSy6vaC7YPC6G73phl97ndPeenm77Dk7YIcsYm/ZKfvEzlifCTZnP9kv9ts78r54A2+4CvVa65xn7IZ58BcqDdVM</latexit>
(3⇡

/4,

3⇡/4)

(i) (5 points) Sketch the two positions/orientation of the manipulator when the configuration is equal to (3π/4, −3π/4) and to (−π/2, π/2).
(ii) (5 points) On the sampled configuration space, draw the shortest safe path from (−π/2, π/2) to (3π/4, −3π/4). Assume that you can move in any direction.

E3.6 Mapping mother Earth onto a flat surface (10 points). Cartography, the science and practice of drawing maps, has always arisen the curiosity of mankind and played a key role in navigation.
(i) In the following world map, which points are drawn more than once? In other words, which points in the map correspond to the same physical location on mother Earth? Draw lines explaining the identifications, in the same style as we used for the 2-torus in Figure 3.12.

Chapter 3. Configuration Spaces
(ii) The following four figure show different ways of projecting the spherical world onto a flat surface and of computing straight-line paths from Santa Barbara, California, to Venice, Italy. Briefly explain why the four straight segments are not identical and how you would compute the actual length of each of them.

E3.7 Free configuration spaces (30 points).

Robot shapes:

a

r

b

Exercises for Chapter 3
(i) (10 points) Sketch the free configuration space for the disk robot (include the original obstacles and workspace). Hint: Consider the scale of the robot and workspace, and check the possibility of movement.
(ii) (10 points) Sketch the free configuration space for the rectangular robot assuming that the robot cannot rotate (include the original obstacles and workspace).
(iii) (10 points) While the free configuration space for the rectangular robot still has polygonal obstacles, the same is not true for the disk robot. The triangular and trapezoidal partitioning strategies discussed in Chapter 2 require polygonal obstacles. In a few sentences and a clarifying sketch, propose a solution to partitioning the free configuration space for the disk robot to enable the construction of a roadmap.
E3.8 Reachable workspace and inverse kinematics for 2-link manipulator (25 points).
p2 = (x, y)

p0 = (0, 0)

2 2
p1
1 1

This question deals with the inverse kinematics for the 2-link manipulator with link lengths
ℓ1 and ℓ2. We are interested in the following general question: Given the (x, y) location of the end effector, what are the values for the two joint angles (θ1, θ2)? Specifically, perform
the following tasks.
(i) (5 points) Call the point (x, y) reachable if there exists joint angles (θ1, θ2) such that the end effector is at (x, y). The set of reachable points is called the reachable workspace. Draw the reachable workspace for three cases: ℓ1 < ℓ2, ℓ1 = ℓ2 and ℓ1 > ℓ2. Are your pictures consistent with the condition given in Proposition 3.1 that x2 + y2 is in the range [|ℓ1 − ℓ2|, ℓ1 + ℓ2]?
(ii) (5 points) For the same three cases as in the previous questions, explain how many (θ1, θ2) solutions there are for each reachable (x, y).
Hint: In general, there could be no solutions, one solution, two solutions, or for special cases an infinite number of possible solutions. Also, think carefully about the boundary of the reachable workspace.
(iii) (15 points) Section 3.4 contains an expression for θ2. Using this expression and the results in Appendix 3.5 as a guide, derive an expression for θ1.
Hint: Make sure you use the correct order of arguments in your arctangent function

Chapter 3. Configuration Spaces

E3.9 Kinematic calculations for 3-link manipulator (25 points).

You are given a planar three-link manipulator with a gripper attached at the end of the

third link (i.e., the gripper is the end-effector). Assume the three links have unit length (i.e.,

ℓ1 = ℓ2 = ℓ3 = 1).

Let θ1 be the orientation

of the first link, measured

p1

2

p3 = (x, y)

counterclockwise from the
horizontal axis. Let θ2 and θ3 be the relative orienta-
tions of second and third

2

1

3

link, respectively, measured counterclockwise.

1
p0 = (0, 0)

3
p2

Let (x, y, ϕ) be the position and orientation of the gripper, where ϕ is measured counterclockwise relative
to the horizontal axis.

(i) (8 points) Write (x, y, ϕ) as a function of (θ1, θ2, θ3). (This is the forward kinematics map.)
(ii) (8 points) Given (x, y, ϕ), write a formula for the point (x2, y2) where the second and third link meet.
(iii) (9 points) Write (θ1, θ2, θ3) as a function of (x, y, ϕ). (This is the inverse kinematics map.) Hint: Make use of your answer for (ii).

4 Chapter
Free Configuration Spaces via Sampling and Collision Detection
In this chapter we complete the discussion of robot configuration spaces. We discuss the role of obstacles in both workspace and configuration space, the notion of free configuration space, and corresponding computational methods. In particular, we
(i) represent obstacles and the free space when the robot is composed of a single or multiple rigid bodies with proper shape, position and orientation,
(ii) compute free configuration spaces via sampling and collision detection, (iii) discuss sampling methods, and (iv) discuss collision detection methods.
4.1 The free configuration space
As in Chapter 3, the configuration of a robot is a minimal set of variables that describes the position of each rigid body component of the robot. Therefore, in the configuration space a robot position is just a single point.
In this section we discuss how to model obstacles in configuration space. The key problem is: what robot configurations correspond to feasible positions of the robot, i.e., configurations in Q such that the robot is not in collision with any obstacle in W.
Let us review the basic setup. We are given the workspace W with obstacles O1, . . . , On. Therefore, the free workspace is
Wfree = W \ (O1 ∪ · · · ∪ On).
77

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection
Second, we are given the robot configuration space Q and the configuration map B(q), which denotes the set of particles belonging to the robot in the workspace as a function of the robot configuration q.
(i) The free configuration space Qfree is the set of configurations q such that all points of the robot are inside Wfree. Because all points of the robot are given by B(q), we can write
Qfree = {q ∈ Q | B(q) is inside Wfree}.
(ii) Given an obstacle O in workspace, the corresponding configuration space obstacle OQ is the set of configurations q such that the robot at configuration q is in collision with the obstacle Q. In a formula, this is written as
OQ = {q ∈ Q | B(q) overlaps with O}.
Combining these two notions, if OQ,1, . . . , OQ,n are the configuration space representation of the obstacles O1, . . . , On, the free configuration space can be written as
Qfree = {q ∈ Q | B(q) ⊂ W } \ (OQ,1 ∪ · · · ∪ OQ,n).
4.1.1 Free configuration space for the disk robot
Consider a planar robot with the shape of a disk of radius r and with the ability to translate only. In the absence of obstacles, the configuration space and the workspace are identical: the configuration of the robot is given by the pair (x, y) that takes value in R2. We now imagine the disk robot is restricted to move inside a rectangle W and to avoid a rectangular obstacle O; as in Figure 4.1. Easily, the free workspace is the rectangle W minus the obstacle O.
To compute the free configuration space and the obstacles in configuration space we reason as follows: a disk with radius r is in collision with an obstacle if and only if the disk center is closer to the obstacle than r. Accordingly, we grow or “expand” the obstacle and, correspondingly, to “shrink” the workspace in the following manner: Using this key idea, the obstacle in configuration space is the expanded rectangle and the free configuration space of the disk robot is described in any of the two completely equivalent forms:
(i) the set of positions of the disk center such that the disk does not intersect the obstacle and is inside the workspace,
(ii) the shrunk workspace minus the expanded obstacle.

4.1. The free configuration space
W O
r
Figure 4.1: An example configuration space

r

r

Figure 4.2: Expanding an obstacle and shrinking a workspace

Free workspace

Free configuration space

Figure 4.3: It is equivalent to plan feasible paths for the disk robot moving in the free workspace (left figure) or for a point robot moving in the free configuration space (right figure).
Note: The disk robot moving in a workspace with obstacles is now understood as a configuration point moving in the free configuration space. Therefore, motion planning for the disk robot can again be performed via decomposition and search on the free configuration space.
Note: one problem with the expansion of polygonal obstacles is that their expansion is no longer a polygon. At the cost of over-estimating the obstacle and therefore over-constraining the robot motion, one can always render the expansion a polygon by “over-expanding” the corners as shown in Figure 4.4.

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection

r

r

Figure 4.4: Approximating expanded obstacles by a larger polygonal obstacle

4.1.2 Free configuration space for the translating polygon robot

Suppose our robot is polygonal and convex with

shape as shown in Figure 4.5. The robot has a fixed

orientation as shown in the figure, and moves by

translating in the plane. Now, given any polygo-

nal convex obstacle, how would you determine the configuration space obstacle for this robot? The “obstacle expansion” procedure is now more com-

Figure 4.5: A polygonal and convex robot in the plane

plicated than in the disk robot example, because

now both robot and obstacle are polygonal.

There is a simple graphical approach to computing the configuration space

obstacle illustrated in Figure 4.6 and described as follows:

Figure 4.6: The configuration space obstacle for a translating robot
(i) move the robot to touch the obstacle boundary (recall the robot is not allowed to rotate),
(ii) slide the robot body along the obstacle boundary, maintaining the contact between the robot boundary and the obstacle boundary,

4.1. The free configuration space

(iii) while sliding, store the location of the reference point of the robot: the resulting path encloses a convex polygon equal to the configuration space obstacle.

To turn this graphical procedure into a programmable algorithm, we introduce a useful operation. Given two sets S1 and S2 in R2, the Minkowski difference S1 ⊖ S2 is defined by
S1 ⊖ S2 = {p − q | p ∈ S1 and q ∈ S2}.

Proposition 4.1. Assume the robot body, with reference position B(0, 0) and the

obstacle O are convex polygons with n and m vertices respectively. Then the resulting

configuration space obstacle OQ is a convex polygon with at most n + m vertices and

satisfies

OQ = O ⊖ B(0, 0).

(4.1)

To see that this formula is correct and to gain intuition into the Minkowski
difference, let us reason as follows. Let w be one of the vertices of the body at reference position B(0, 0). When the body is at position q, the translated vertex is touching the vertex v of the obstacle precisely if q + w = v. In other words, q is a configuration of vertex-to-vertex contact precisely when q = v − w; we denote this configuration by qv,w and we illustrate the setting in the Figure 4.7. Therefore, body and obstacle are overlapping at all configurations q that are the sum of a point v in the obstacle minus a robot point w, as measured at the reference configuration B(0, 0).

B(0, 0) w

qv,w v

w O

Figure 4.7: Computing configuration space obstacles via Minkowski differences
Given convex polygons O and B(0, 0), we now present a simple algorithm to compute the Minkowski difference in equation (4.1). First, we define the convex hull of a group of points as the minimum-perimeter convex set containing them. The convex hull of a group of points is a convex polygon. Graphically, the convex hull can be obtained by snapping a tight rubber band around all the points (the length of the rubber band is the perimeter of the envelope) as shown in Figure 4.8. Each convex polygon is the convex hull of its vertices.

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection

Figure 4.8: Example convex hull of a set of points

Programming Note: The Matlab command convhull computes the convex hull in 2 and 3 dimensional spaces. In Python the convex hull of a set of
points can be computed using the scipy module. Import the module using from scipy.spatial import ConvexHull. The function operates on a numpy array of points. Numpy is imported via import numpy.

Finally, here is the promised algorithm for computing the configuration space obstacle using the Minkowski difference.

Minkowski-difference-via-convex-hull algorithm

Input: two convex polygonal subsets P1 and P2 of R2

Output: the Minkowski difference P1 ⊖ P2

1: for each vertex v of P1 :

2:

for each vertex w of P2 :

3:

compute the difference point v − w

4: return the convex hull of all difference points

To characterize the runtime of this algorithm, suppose that P1 has n vertices and P2 has m vertices. The algorithm will compute nm difference points. There are many algorithms for computing the convex hull of a set of points N points, the best of which run in O(N log(N )) time. Therefore, the runtime of the Minkowskidifference-via-convex-hull algorithm is in O(nm log(nm)).
However, recall that by Proposition 4.1, the resulting convex polygon will have at
most n + m vertices. Based on this fact, there exists a much more efficient algorithm. The idea is to directly compute the (at most) n + m points, rather than computing nm and then throwing all but n + m away via the convex hull computation. This more efficient algorithm can be implemented to run in O(n + m) time as detailed
by de Berg et al. (2000).

To conclude this section, we complete the discussion of the Minkowski difference with an example of its application. That is, a complete motion planning example for the translating polygon. Figure 4.9 shows a workspace containing a translating

4.1. The free configuration space

polygonal robot, along with the configuration space obstacles and one possible path from start to goal.

conﬁguration space obstacles

qgoal no passage

pgoal

qstart

free conﬁguration space

pstart

workspace space

Figure 4.9: Planning the motion of a translating polygonal robot from start to goal

4.1.3 Free configuration space for the 2-link robot
The 2-link robot in Figure 4.10 illustrates how, for general shapes of obstacles and robots and for robots that can rotate, it is complex to compute exactly the free configuration space. Consider the 2-link robot moving in a workspace with two

2
O2
O1
1
Figure 4.10: The two-link robot in a workspace with obstacles
obstacles O1 and O2 as depicted in Figure 4.10. Let us think about how to compute the free configuration space examining step-by-step the effect of the obstacles. Our three steps are depicted in the three images in Figure 4.11:
(i) in the first image we recall that the 2-link configuration space is a 2-torus,

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection

2

2

(0, 0)

2

2

(0, 0)

2

2

(0, 0)

1
2

1
2

1
2

Figure 4.11: Step-by-step graphical approximate computation of the free configuration space for the 2-link robot. The shaded regions are obstacles in configuration space. The dashed boundaries are highly approximate because of the complexity inherent in their computation.

(ii) in the second image we compute the set of angles θ1 at which the first link hits one of the two obstacles. This set is the union of two intervals: the obstacle O1 prohibits the angle θ1 from taking value in an interval around θ1 = 0, and, similarly, the obstacle O2 prohibits the angle θ1 from taking value in an interval around θ1 = π/2. The two intervals in θ1 are depicted as two vertical rectangles in the second image,
(iii) in the third image, we look to compute the effect of the obstacles on the allowable values of θ2. However, one can begin to see the difficulty in accurately estimating the free configuration space. Given an angle θ1 for which the first link is not in collision with O1 and O2, we can approximately compute what θ2 angles correspond to collision for the second link. This calculation is highly approximate as each choice of θ1 changes the allowable values of θ2. Consequently, this computation is very hard to perform exactly for general
shapes of the obstacles and of the robot links.
From this two-link robot example we can see that a more general method is
needed to compute free configuration spaces. The following section introduces the
idea of sampling.

4.2 Numerical computation of the free configuration space
By now we have studied multiple methods to describe the free configuration space. (1) For the disk robot and the translating polygon, we saw that we can explicitly characterize the free configuration space. (2) For the 2-link and the roto-translating polygon, it is hard to precisely compute the free configurations. In general, unfortunately, it is hard to have an explicit characterization of the obstacles in configuration space and, in turn, to decompose the free configuration space into convex subsets.

4.3. Sampling methods

Therefore, we study here an alternative numerical method, based on sampling and collision detection.

sampling & collision-detection algorithm
Input: A number of samples n, the free workspace Wfree, and the robot configuration map B(q)
Output: A set of configurations in the free configuration space 1: Initialize free-configs := ∅ 2: Compute a sequence of sample configurations q1, . . . , qn 3: for each configuration sample qi in the sequence : 4: compute the positions of the robot rigid bodies corresponding to the sample, B(qi)

5:

detect if the robot collides with the obstacles (i.e., test if B(qi) ⊂ Wfree)

6: if robot does not collide with obstacles and is inside the workspace :

7:

Add qi to free-configs

8: return free-configs

This numerical approach computes a “cloud representation” of the free configuration space for robots and obstacles of arbitrary shape, e.g., see Figure 4.12. Note that the method provides only an approximation to the free configuration space and while it often works well in practice with large clouds, the approximation could be a poor one. Motivated by this numerical approach, the next two sections study algorithms for sampling and collision detection.

Figure 4.12: An example free configuration space Qfree, a set of samples in Qfree, and a roadmap in Qfree. We will discuss how to compute a roadmap from a cloud in the next chapter.
4.3 Sampling methods
A sampling method should have certain properties:

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection

(i) Uniformity: the samples should provide a “good covering” of space. Mathematically, this can be formulated using the notion of dispersion; see below.
(ii) Incremental property: the sequence of samples should provide good coverage at any number n of samples. In other words, it should be possible to increase n continuously and not only in discrete large amounts.
(iii) Lattice structure: given a sample, the location of nearby samples should be computationally easy to determine.
Consider the d-dimensional unit cube X = [0, 1]d ⊂ Rd. The sphere-dispersion and the square-dispersion of a set of points P in the set X are defined by (see also Figure 4.13)

dispersion (P ) = radius of largest empty d-sphere with center in X, sphere

1

dispersionsquare(P )

=

(side 2

length

of

largest

empty

d-dimensional

cube

with center in X)

Typically, square dispersion is calculated with respect to a fixed coordinate frame. The sides of the square are aligned with the axes of this coordinate frame and cannot be rotated.

Figure 4.13: A set of points in the unit square with poor, that is, high sphere-dispersion (left figure) and square-dispersion (right figure)
More generally, given a distance metric defining the distance dist(x, y) between any two points x, y ∈ X, we can define the dispersion of P with respect to the distance metric as
dispersion(P ) = max min dist(x, p). x∈X p∈P
That is, the dispersion is defined as maximum distance from a point in X to its nearest sample in P . The sphere- and square-dispersion measures are given by the following distance metrics:

4.3. Sampling methods
(i) sphere dispersion uses the 2-norm:
dist(x, p) = ∥x − p∥2 = (x1 − p1)2 + · · · + (xd − pd)2,
(ii) square dispersion uses the ∞-norm: dist(x, p) = ∥x − p∥∞ = max(|x1 − p1|, . . . , |xd − pd|),
where x = (x1, . . . , xd) and p = (p1, . . . , pd) are the coordinates of the points x and p.
Note: The sampling methods discussed in this chapter look only at sampling in a d-dimensional cube. These methods can be extended to sampling methods for general configuration spaces such as the sphere and the set of rotations.
Uniform grids There are two ways of defining uniform grids in the unit cube X = [0, 1]d as shown in Figure 4.14 for d = 2. We call them the center grid and the corner grid. Both grids with n points can be defined if n = kd for some number k. For n = kd for some k, the center grid is defined in two steps: (1) along each of the d dimensions, divide the [0, 1] interval into k subintervals of equal length and therefore compute kd sub-cubes of X, (2) place one grid point at the center of each sub-cube; see the left image in Figure 4.14. This center uniform grid is sometimes

Figure 4.14: Uniform grids with n = 36 points in the 2-dimensional cube. Left figure: the center grid, also called the Sukharev grid. Right figure: the corner grid.

called the Sukharev grid and has minimal square-dispersion (Sukharev, 1971) equal

to

dispersionsquare(Pcenter grid(n, d))

=

√1 . 2dn

The sphere-dispersion of the center grid is 1/2 the length of th√e longest diagonal of a sub-cube. In d dimensions the unit cube has diagon√al of length d. For example, with d = 2 the unit squar√e has a√diagonal with length 2. Hence, the sphere-dispersion of the center grid is d/(2 d n).

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection
The corner grid is defined as follows: (1) divide the [0, 1] interval into (k − 1) subintervals of equal length and therefore compute (k −1)d sub-cubes of X, (2) place one grid point at each vertex of each sub-cube; see the right image in Figure 4.14.
No√te: There is no uniform grid if n is not equal to kd for some k: one can set k := ⌊ d n⌋, place the k points as Figure 4.14 and the other points arbitrarily.
Note: It is possible to design multi-resolution versions of the uniform center grid, i.e., compute a uniform grid with some number of points and then add additional points while keeping the ones from the previous resolution level. This process is illustrated in Figure 4.15. The growth in number of points in multi-resolution uniform grids is exponential: one can see that a step increase in resolution correspond to a jump in number of samples from n to n3d.
Figure 4.15: Growth in number of points when increasing resolution of uniform grid
Random and pseudo-random sampling Adopting a random number generator is usually a very simple approach to (uniformly or possibly non-uniformly) sample the cube X = [0, 1]d. An example set of 100 randomly generated points is shown in Figure 4.16.
Note: Let P be a set of n points generated independently and uniformly over X. As n → ∞, the set P has square-dispersion of order O (ln(n)/n)1/d (Deheuvels, 1983). Therefore, randomly-sampled points have asymptotically worse dispersion than center grids.
Programming Note: In Matlab the command rand(n,d) returns a vector with n rows and d columns: each row i gives a uniform sample qi in [0, 1]d. In Python, uniform samples can be generated using the random module or the numpy module:
(i) Import the random module using the command import random. A random number between 0 and 1 is generated with random.random(). A For-loop can then be used to generate n samples, in [0, 1]d. Or,
(ii) Import the numpy module using the command import numpy. An ar-

4.3. Sampling methods

ray containing n random numbers between 0 and 1 is generated using numpy.random.sample(n). Running this d times, d-dimensional coordinates for each sample are generated.

Deterministic sampling sequences Halton sequences (Halton, 1960) are an elegant way of sampling an interval with good uniformity (better than a pseudorandom sequence, though not as good as the optimal center grid) and with the incremental property (which the center grid does not possess). Each scalar Halton sequence is generated by a prime number. In what follows we provide (1) two examples, (2) the exact definition, and (3) a simple algorithm.
First, we provide two examples. The Halton sequence generated by the prime number 2 is given by
1 13 1537 1 9 , , , , , , , , , ....
2 4 4 8 8 8 8 16 16 The horizontal spacing illustrates a shift in accuracy of the sequence. The prime number 3 instead generates:
12 147258 1 , , , , , , , , , ....
3 3 9 9 9 9 9 9 27 Next, to understand the Halton sequence we require a formal definition (you might want to review the notion of Wikipedia:Numeral system). Given a number p, one can write any number i in base p as
i = ejpj + · · · + e1p + e0, where ej, . . . , e0 ∈ {0, 1, . . . , p − 1}. The digits of i in base p are then ejej−1 · · · e0. For example, the number 6 is written in p = 2 (i.e., binary) as 110.
Then, the method for attaining the 6th number in the Halton sequence, using p = 2, is as follows:
(i) Write the number i in base p, where p is a prime number:
6 in base 2 is 110,

(ii) add a decimal place and then reverse the digits, including the decimal: 110.0 becomes 0.011,

(iii) convert this binary number back to base 10 and output this as the ith number

in the Halton sequence:

0.011

=

0·

1

+1

·

1

+1

·

1

=

3 .

2

4

88

Chapter 4. Free Configuration Spaces via Sampling and Collision Detection

We can write a formula for the ith number base p as

“ith

sample

of

Halton

sequence

in

base

p"

=

e0 p

+

e1 p2

+

···

+

ej . pj+1

Finally, we write this procedure as an algorithm to compute a Halton sequence of length N generated by any prime number. Repeating our previous example, let us

Halton sequence algorithm

Input: length of the sequence N ∈ N and prime number p ∈ N

Output: an array S with the first N samples of the Halton sequence generated by p

1: initialize: S to be an array of N zeros (i.e., S(i) := 0 for each i from 1 to N )

2: for each i from 1 to N :

3:

initialize: itmp := i, and f := 1/p

4:

while itmp > 0 :

5:

compute the quotient q and the remainder r of the division itmp/p

6:

S(i) := S(i) + f · r

7:

itmp := q

8:

f := f /p

9: return S

compute the 6th sample of the Halton sequence in base 2, using the algorithm:
(i) First we initialize itmp = 6, S(6) = 0, f = 1/2, (ii) 6 divided by 2 gives a quotient q = 3 and remainder r = 0. We set S(6) = 0,
itmp = 3, f = 1/4, (iii) 3 divided by 2 gives a quotient q = 1 and remainder r = 1. We set S(6) = 1/4,
itmp = 1, f = 1/8, (iv) 1 divided by 2 gives a quotient q = 0 and remainder r = 1. We set S(6) =
1/4 + 1/8, itmp = 0, f = 1/16.
For Halton sequences in higher dimensions, select a prime number for each dimension of the problem: usually, the number 2 for the first dimension, the number 3 for the second dimension, and so forth. The ith Halton sample in d-dimension is a point in [0, 1]d whose components are the ith samples of the d sequences computed with d different prime numbers. For example, in [0, 1]2, using the primes 2 and 3, one has
11 12 31 14 57 32 75 1 8 9 1 , , , , , , , , , , , , , , , , , , ....
2 3 4 3 4 9 8 9 8 9 8 9 8 9 16 9 16 27
Figure 4.16 shows the first 100 samples points of the Halton sequence in 2-dimension generated by the prime numbers 2 and 3.

