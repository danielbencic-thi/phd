IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Loading [MathJax]/extensions/MathZoom.js

Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

    Cart 
    Create Account
    Personal Sign In

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
ADVANCED SEARCH
Conferences > 2021 IEEE/RSJ International C...
Accelerating Kinodynamic RRT Through Dimensionality Reduction
Publisher: IEEE
Cite This
PDF
Dongliang Zheng ; Panagiotis Tsiotras
All Authors
106
Full
Text Views

    Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Related Works
    III.
    Problem formulation
    IV.
    Partial-Final-State-Free Optimal Controller
    V.
    The Kino-RRT* Algorithm

Show Full Outline
Authors
Figures
References
Keywords
Metrics
Footnotes
Abstract:
Sampling-based motion planning algorithms such as RRT* are well-known for their ability to quickly find an initial solution and then converge to the optimal solution asymptotically as the number of samples tends to infinity. However, the convergence rate can be slow for high-dimensional planning problems, particularly for dynamical systems where the sampling space is not just the configuration space but the full state space. In this paper, we introduce the idea of using a partial-final-state-free (PFF) optimal controller in kinodynamic RRT* [1] to reduce the dimensionality of the sampling space. Instead of sampling the full state space, the proposed accelerated kinodynamic RRT*, called Kino-RRT*, only samples part of the state space, while the rest of the states are selected by the PFF optimal controller. We also propose a delayed and intermittent update of the optimal arrival time of all the edges in the RRT* tree to decrease the computation complexity. We tested the proposed algorithm using 4-D and 10-D state-space linear systems and showed that Kino-RRT* converges much faster than the kinodynamic RRT* algorithm.
Published in: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Date of Conference: 27 Sept.-1 Oct. 2021
Date Added to IEEE Xplore : 16 December 2021
ISBN Information:
ISSN Information:
INSPEC Accession Number: 21503982
DOI: 10.1109/IROS51168.2021.9636754
Publisher: IEEE
Conference Location: Prague, Czech Republic
SECTION I.
Introduction

Robotic motion planning with the goal of finding a dynamically feasible and optimal trajectory for the robot through an environment with obstacles has gained much progress over the past decades. As a fundamental problem in robotics applications, it is still a challenging problem to solve when the environment is complex with irregular obstacles and the dynamics of the robot are to be considered.

Sampling-based motion planning algorithms, such as rapidly exploring randomized trees (RRTs) [2] , have been developed to solve planning problems in high-dimensional continuous state spaces by incrementally building a tree through the search space. The asymptotic optimal variant of RRT, namely RRT* [3] , almost surely converges asymptotically to the optimal solution. RRT* is well-suited for planning in high-dimensional spaces and obstacle-rich environments. Many applications of RRT* have been studied in recent years [4] , [5] .

One limitation of RRT* is that it requires any two points sampled in the planning space to be connected with an optimal trajectory. Thus, many works on RRT* consider robots with simple dynamics [4] , [6] or assume a holonomic model and connect sampled points with straight lines [7] . For robots with differential constraints, the optimal trajectory be- tween two states is obtained by solving a two-point boundary value problem (TPBVP), which is a non-trivial undertaking for complex nonlinear systems. The solution to this local TPBVP is also referred to as the steering function. A version of the RRT* algorithm that explicitly considers differential dynamics is the kinodynamic RRT* [1] , [6] .

Solving TPBVPs is the computationally dominant component of kinodynamic RRT*, and thus researchers have looked into more efficient ways to solve these TPBVPs. A steering function based on LQR is used in [8] . A fixed-final-state free-final-time controller that optimally connects any pair of states is used in [1] . Learning-based RRT* algorithms are introduced in [9] , [10] , [11] , where the TPBVP is solved using supervised learning [9] , [10] and reinforcement learning [11] .

Another challenge of RRT* is the slow convergence rate of the solution to the optimal one, which is especially evident for the kinodynamic case where the sampling space is not just the configuration space but the full state space. Heuristic and informed sampling methods have been developed to improve the convergence rate [7] , [12] . However, these methods only consider the geometric planning problem and the dynamics of the robot is not considered. Good heuristics for improving the convergence of kinodynamic RRT* is still an open research problem [13] .
Fig. 1: - Motivation of the partial-final-state-free (PFF) optimal controller. (a) Existing kinodynamic RRT* algorithms sample the full state space, which results in inefficient trajectories. (b) Kino-RRT* with a PFF controller samples the reduced state-space to improve convergence performance.
Fig. 1:

Motivation of the partial-final-state-free (PFF) optimal controller. (a) Existing kinodynamic RRT* algorithms sample the full state space, which results in inefficient trajectories. (b) Kino-RRT* with a PFF controller samples the reduced state-space to improve convergence performance.

Show All

In this paper, we build on previous work on the kinodynamic RRT* [1] and propose a new algorithm, called Kino-RRT*, which shows faster convergence. We propose the idea of using a partial-final-state-free (PFF) optimal controller to reduce the sampling dimension of the state space. The motivation is illustrated in Figure 1 . Instead of randomly uniformly sampling the full state space, the proposed Kino- RRT* only samples part of the state space. The rest of the states are selected by the PFF optimal controller. Because part of the final state is computed by the PFF optimal controller to optimize the cost function, Kino-RRT* samples in the state space with reduced dimension. The method can also be interpreted as a heuristic for state-space sampling. Choosing the partial-free final states by the PFF optimal controller is more efficient than uniformly random sampling, and thus the resulting algorithm achieves faster convergence. We derive an analytical solution of the PFF optimal controller for the case of linear systems. Note, however, that the idea of using PFF controller in kinodynamic RRT* is not limited to linear systems. It can be adopted in combination with [14] , [9] , [10] to deal with nonlinear dynamics as well.

Finding the optimal arrival time for the TPBVP in the kinodynamic RRT* requires solving a root-finding problem of a high-order polynomial. Because the TPBVP is required to be solved repeatedly, the root-finding procedure can be computationally expensive. We therefore also propose a delayed and intermittent update of the optimal arrival time to reduce the computation complexity.
SECTION II.
Related Works

Incremental sampling-based motion planning algorithms find an initial solution in high dimensional planning spaces quickly and then incrementally improve the solution. For motion planning of robot systems, considering the differential constraints is necessary for generating feasible trajectories. The extension of RRT* to dynamic systems is studied in [6] , where sufficient conditions ensuring asymptotic optimality of the RRT* for dynamic systems were established. Every local steering and distance function in kinodynamic RRT* requires the solution of a TPBVP [6] . Assuming a solver of the TPBVP is available, references [15] , [16] study the radius of the neighbor nodes in kinodynamic RRT* to guarantee asymptotic optimality.

Solving the TPBVPs is the computationally expensive component of the kinodynamic RRT* algorithm. Infinite- horizon and finite-horizon LQR controllers were used as the steering function in kinodynamic RRT* for linear or linearized systems in [8] and [17] , respectively. However, these methods cannot achieve the exact connection of two states, which is required in the kinodynamic RRT* algorithm. A fixed-final-state free-final-time controller is used in [1] to achieve the exact connection of any pair of states for linear or linearized systems. The optimal arrival time is computed by solving a root-finding problem. To deal with nonlinear dynamics, [14] directly uses a numerical solver to solve the TPBVP online, and [18] uses discrete motion primitives. Learning-based methods have also been studied to solve the TPBVP in kinodynamic RRT*. References [9] and [10] use offline generated optimal trajectories and supervised learning to train neural networks to solve the TPBVP. In [11] , the steering function is realized by a local policy trained using Deep Reinforcement Learning.

Other works solve the kinodynamic motion planning problem without relying on TPBVP solvers [19] , [20] . These methods extended RRT-style shooting methods to kinodynamic planning by randomly sampling piece-wise constant control inputs of the system. The convergence to high-quality trajectories in practice can be slow by the use of random controls as mentioned in [14] , [21] . Our method improves algorithms that are based on steering functions. Comparison with shooting-based methods [20] , [22] is left for future investigation.
SECTION III.
Problem formulation

The optimal kinodynamic motion planning problem is defined as finding a dynamically feasible trajectory for the robot to reach the goal state starting from an initial state, while satisfying the state and control constraints and minimizing a cost function [1] , [6] . Specifically, given the planning domain X , free space X free , goal region X goal , initial state x 0 , consider the dynamics of the robot
x ˙ = A x + B u + c , (1)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\dot x = Ax + Bu + c,\tag{1}\end{equation*} and the cost function,
J ( u ) = ∫ T 0 ( 1 + u ⊤ R u ) d τ , (2)
View Source Right-click on figure for MathML and additional features. \begin{equation*}J(u) = \int_0^T {\left( {1 + {u^ \top }Ru} \right)} {\text{d}}\tau ,\tag{2}\end{equation*} the goal of the motion planning problem is to find a control u ( t ), t ∈ [0, T ], such that the solution x ( t ) to (1) is obstacle- free, i.e. x ( t ) ∈ X free , t ∈ [0, T ], reaches the goal region, i.e. x ( T ) ∈ X goal , and minimizes the cost functional (2) . A , B , and c are constant and given. (1) represents the dynamics of a linear or linearized system. R is a weighting matrix.

RRT*-type algorithms try to solve this problem by growing a tree, which involves sampling intermediate states (nodes) and making optimal connections between states (edges). This results in convergence to the optimal solution asymptotically. In kinodynamic RRT*, every edge between two states is the solution of a TPBVP given by
u ∗ = arg min u J ( u ) , s .t .  x ˙ = A x + B u + c , x ( 0 ) = x a , x ( t f ) = x b , (3)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\begin{array}{l} {u^{\ast}} = \mathop {\arg \min }\limits_u J(u), \\ {\text{s}}{\text{.t}}{\text{. }}\quad \dot x = Ax + Bu + c,\quad \\ \,\,\,\,\,\,x(0) = {x_a},x\left( {{t_{\text{f}}}} \right) = {x_b}, \\ \end{array} \tag{3}\end{equation*} where J is the same as in (2) but over the time interval [0, t f ], and x a and x b are the sampled initial state and final state of this edge, respectively. The solution of (3) with free-final-time t f is given in [1] . Besides this fixed-final-state free-final-time controller, next, we will present a partial-final-state-free controller, which is the key ingredient of the proposed Kino-RRT* algorithm.

SECTION IV.
Partial-Final-State-Free Optimal Controller

Rewrite the state x ∈ R n as the concatenation of two vectors x = [ x ⊤ 1 x ⊤ 2 ] ⊤ , where x 1 ∈ R n 1 and x 2 ∈ R n 2 with n 1 + n 2 = n. The partial-final-state-free (PFF) optimal control problem is given by
u ∗ = s .t . arg min u J ( u ) , x ˙ = A x + B u + c , x ( 0 ) = x a , x 1 ( t f ) = x c . (4)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\begin{array}{ll} {{u^{\ast}} = }&{\mathop {\arg \min }\limits_u J(u),} \\ {{\text{s}}{\text{.t}}{\text{.}}}&{\dot x = Ax + Bu + c,} \\ {}&{x(0) = {x_a},{x_1}\left( {{t_{\text{f}}}} \right) = {x_c}.} \end{array}\tag{4}\end{equation*}

First, we consider the case where the arrival time t f is given. Instead of fixing the states x (0) and x ( t f ) as in (3) , only x (0) and x 1 ( t f ) are fixed, and x 2 ( t f ) is free in (4) .
A. The PFF Optimal Controller

We solve this PFF optimal control problem using Pontryagin’s Maximum Principle [23] . The Hamiltonian of the system is given by
H ( x , u , t , λ ) = 1 + u ⊤ R u + λ ⊤ ( A x + B u + c ) . (5)
View Source Right-click on figure for MathML and additional features. \begin{equation*}H(x,u,t,\lambda ) = 1 + {u^ \top }Ru + {\lambda ^ \top }(Ax + Bu + c).\tag{5}\end{equation*}

The necessary conditions for optimality are
x ˙ = A x + B u + c , λ ˙ = − ∂ H ∂ x = − A ⊤ λ , 0 = ∂ H ∂ u = 2 R u + B ⊤ λ , 0 = λ 2 ( t f ) , (6) (7) (8) (9)
View Source Right-click on figure for MathML and additional features. \begin{align*} & \dot x = Ax + Bu + c,\tag{6} \\ & \dot \lambda = - \frac{{\partial H}}{{\partial x}} = - {A^ \top }\lambda ,\tag{7} \\ & 0 = \frac{{\partial H}}{{\partial u}} = 2Ru + {B^ \top }\lambda ,\tag{8} \\ & 0 = {\lambda _2}\left( {{t_{\text{f}}}} \right),\tag{9}\end{align*} where λ = [ λ ⊤ 1 λ ⊤ 2 ] ⊤ , λ 1 ∈ R n 1 is the costate of x 1 , and λ 2 ∈ R n 2 is the costate of x 2 . Solving for u using (8) , we get
u = − 1 2 R − 1 B ⊤ λ . (10)
View Source Right-click on figure for MathML and additional features. \begin{equation*}u = - \frac{1}{2}{R^{ - 1}}{B^ \top }\lambda .\tag{10}\end{equation*}

Substituting (10) into (6) , yields
x ˙ = A x − 1 2 B R − 1 B ⊤ λ + c . (11)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\dot x = Ax - \frac{1}{2}B{R^{ - 1}}{B^ \top }\lambda + c.\tag{11}\end{equation*}

The analytical solutions for the differential equations (7) and (11) are available and are given by
λ ( t ) = e A ⊤ ( t f − t ) λ ( t f ) , x ( t ) = e A t x ( 0 ) − 1 2 G ( t ) λ ( t f ) + ∫ t 0 e A ( t − τ ) c d τ , (12) (13)
View Source Right-click on figure for MathML and additional features. \begin{align*} & \lambda (t) = {e^{{A^ \top }\left( {{t_{\text{f}}} - t} \right)}}\lambda \left( {{t_{\text{f}}}} \right),\tag{12} \\ & x(t) = {e^{At}}x(0) - \frac{1}{2}G(t)\lambda \left( {{t_{\text{f}}}} \right) + \int_0^t {{e^{A(t - \tau )}}} c{\text{d}}\tau ,\tag{13}\end{align*} where G ( t ) = ∫ t 0 e A ( t − τ ) B R − 1 B ⊤ e A ⊤ ( t f − τ ) d τ .

x ( t f ) = x ¯ ( t f ) − 1 2 G ( t f ) λ ( t f ) , (14)
View Source Right-click on figure for MathML and additional features. \begin{equation*}x\left( {{t_{\text{f}}}} \right) = \bar x\left( {{t_{\text{f}}}} \right) - \frac{1}{2}G\left( {{t_{\text{f}}}} \right)\lambda \left( {{t_{\text{f}}}} \right),\tag{14}\end{equation*}

where
x ¯ ( t f ) ≜ e A t f x ( 0 ) + ∫ t f 0 e A ( t f − τ ) c d τ . (15)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\bar x\left( {{t_{\text{f}}}} \right) \triangleq {e^{A{t_{\text{f}}}}}x(0) + \int_0^{{t_{\text{f}}}} {{e^{A\left( {{t_{\text{f}}} - \tau } \right)}}} c{\text{d}}\tau .\tag{15}\end{equation*}

We may obtain x 2 ( t f ) and λ 1 ( t f ) by solving the linear equations (14) . Using (9) , rewrite (14) as
[ x ¯ 1 ( t f ) − x 1 ( t f ) x ¯ 2 ( t f ) − x 2 ( t f ) ] = 1 2 [ G 11 ( t f ) G 21 ( t f ) G 12 ( t f ) G 22 ( t f ) ] [ λ 1 ( t f ) 0 ] , (16)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\left[ {\begin{array}{c} {{{\bar x}_1}\left( {{t_{\text{f}}}} \right) - {x_1}\left( {{t_{\text{f}}}} \right)} \\ {{{\bar x}_2}\left( {{t_{\text{f}}}} \right) - {x_2}\left( {{t_{\text{f}}}} \right)} \end{array}} \right] = \frac{1}{2}\left[ {\begin{array}{ll} {{G_{11}}\left( {{t_{\text{f}}}} \right)}&{{G_{12}}\left( {{t_{\text{f}}}} \right)} \\ {{G_{21}}\left( {{t_{\text{f}}}} \right)}&{{G_{22}}\left( {{t_{\text{f}}}} \right)} \end{array}} \right]\left[ {\begin{array}{c} {{\lambda _1}\left( {{t_{\text{f}}}} \right)} \\ 0 \end{array}} \right],\tag{16}\end{equation*} where x ¯ ( t f ) = [ x ¯ ⊤ 1 ( t f ) x ⊤ 2 ( t f ) ] ⊤ . Note that x ¯ 1 ( t f ) − x 1 ( t f ) is known and x ¯ 2 ( t f ) − x 2 ( t f ) is unknown. Then, (16) becomes
2 ( x ¯ 1 ( t f ) − x 1 ( t f ) ) = G 11 ( t f ) λ 1 ( t f ) , 2 ( x ¯ 2 ( t f ) − x 2 ( t f ) ) = G 21 ( t f ) λ 1 ( t f ) . (17) (18)
View Source Right-click on figure for MathML and additional features. \begin{align*} & 2\left( {{{\bar x}_1}\left( {{t_{\text{f}}}} \right) - {x_1}\left( {{t_{\text{f}}}} \right)} \right) = {G_{11}}\left( {{t_{\text{f}}}} \right){\lambda _1}\left( {{t_{\text{f}}}} \right),\tag{17} \\ & 2\left( {{{\bar x}_2}\left( {{t_{\text{f}}}} \right) - {x_2}\left( {{t_{\text{f}}}} \right)} \right) = {G_{21}}\left( {{t_{\text{f}}}} \right){\lambda _1}\left( {{t_{\text{f}}}} \right).\tag{18}\end{align*}

Assuming ( A , B ) is controllable, it follows that G ( t f ) is invertible and hence G 11 ( t f ) is invertible. From (17) , we can solve for λ 1 ( t f ) as follows
λ 1 ( t f ) = 2 G − 1 11 ( t f ) ( x ¯ 1 ( t f ) − x 1 ( t f ) ) . (19)
View Source Right-click on figure for MathML and additional features. \begin{equation*}{\lambda _1}\left( {{t_{\text{f}}}} \right) = 2G_{11}^{ - 1}\left( {{t_{\text{f}}}} \right)\left( {{{\bar x}_1}\left( {{t_{\text{f}}}} \right) - {x_1}\left( {{t_{\text{f}}}} \right)} \right).\tag{19}\end{equation*}

x 2 ( t f ) can be computed from (18) . Finally, from (10) and (12) , the open-loop optimal control is given by
u ( t ) = − 1 2 R − 1 B ⊤ e A ⊤ ( t f − t ) λ ( t f ) . (20)
View Source Right-click on figure for MathML and additional features. \begin{equation*}u(t) = - \frac{1}{2}{R^{ - 1}}{B^ \top }{e^{{A^ \top }\left( {{t_{\text{f}}} - t} \right)}}\lambda \left( {{t_{\text{f}}}} \right).\tag{20}\end{equation*}

Substituting (20) into (2) , the optimal cost is
J ( u ∗ ) = t f + 1 4 λ ( t f ) ⊤ G ( t f ) λ ( t f ) . (21)
View Source Right-click on figure for MathML and additional features. \begin{equation*}J\left( {{u^{\ast}}} \right) = {t_{\text{f}}} + \frac{1}{4}\lambda {\left( {{t_{\text{f}}}} \right)^ \top }G\left( {{t_{\text{f}}}} \right)\lambda \left( {{t_{\text{f}}}} \right).\tag{21}\end{equation*}

B. The Optimal Arrival Time

Next, consider the case when t f is free. In this case, we have the transversality condition [23]
H ( t f ) = 0. (22)
View Source Right-click on figure for MathML and additional features. \begin{equation*}H\left( {{t_{\text{f}}}} \right) = 0.\tag{22}\end{equation*}

Substituting (10) into (5) and evaluating (5) at t f , then (22) becomes
H ( t f ) = 1 + λ ( t f ) ⊤ ( A x ( t f ) + c ) − 1 4 λ ( t f ) ⊤ B R − 1 B ⊤ λ ( t f ) = 0. (23)
View Source Right-click on figure for MathML and additional features. \begin{equation*}H\left( {{t_{\text{f}}}} \right) = 1 + \lambda {\left( {{t_{\text{f}}}} \right)^ \top }\left( {Ax\left( {{t_{\text{f}}}} \right) + c} \right) - \frac{1}{4}\lambda {\left( {{t_{\text{f}}}} \right)^ \top }B{R^{ - 1}}{B^ \top }\lambda \left( {{t_{\text{f}}}} \right) = 0.\tag{23}\end{equation*}

We find the optimal arrival time t f by solving (23) , which requires finding the roots of a polynomial [1] .
C. PFF with Quadratic Terminal Penalty

In some cases, it may be desired to add implicit constraints on the free-final-state. Here, we extend the PFF optimal controller by adding a quadratic penalty on the free-final- state to the cost function. Consider the PFF optimal control problem with the cost function,
J ( u ) = 1 2 x 2 ( t f ) ⊤ S x 2 ( t f ) + ∫ t f 0 ( 1 + u ⊤ R u ) d τ . (24)
View Source Right-click on figure for MathML and additional features. \begin{equation*}J(u) = \frac{1}{2}{x_2}{\left( {{t_{\text{f}}}} \right)^ \top }S{x_2}\left( {{t_{\text{f}}}} \right) + \int_0^{{t_{\text{f}}}} {\left( {1 + {u^ \top }Ru} \right)} {\text{d}}\tau .\tag{24}\end{equation*}

The necessary conditions for optimality for the PFF control problem (4) with this new cost function are still given by (6) - (8) , except that (9) is now replaced by
λ 2 ( t f ) = ϕ ⊤ x ( x ( t f ) ) = S x 2 ( t f ) , (25)
View Source Right-click on figure for MathML and additional features. \begin{equation*}{\lambda _2}\left( {{t_{\text{f}}}} \right) = \phi _x^ \top \left( {x\left( {{t_{\text{f}}}} \right)} \right) = S{x_2}\left( {{t_{\text{f}}}} \right),\tag{25}\end{equation*} where ϕ ( x ( t f ) ) = 1 2 x 2 ( t f ) ⊤ S x 2 ( t f ) .

Following the same derivation as before, we get the same expression given by (14) . The problem remains to solve for λ ( t f ). Substituting (25) into (14) , we get
x ¯ ( t f ) − x ( t f ) = 1 2 G ( t f ) [ λ 1 ( t f ) S x 2 ( t f ) ] , (26)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\bar x\left( {{t_{\text{f}}}} \right) - x\left( {{t_{\text{f}}}} \right) = \frac{1}{2}G\left( {{t_{\text{f}}}} \right)\left[ {\begin{array}{c} {{\lambda _1}\left( {{t_{\text{f}}}} \right)} \\ {S{x_2}\left( {{t_{\text{f}}}} \right)} \end{array}} \right],\tag{26}\end{equation*} which is equivalent to
x ¯ ( t f ) − x ( t f ) = 1 2 G ( t f ) [ λ 1 ( t f ) S x 2 ( t f ) ] , (27)
View Source Right-click on figure for MathML and additional features. \begin{equation*}\bar x\left( {{t_{\text{f}}}} \right) - x\left( {{t_{\text{f}}}} \right) = \frac{1}{2}G\left( {{t_{\text{f}}}} \right)\left[ {\begin{array}{c} {{\lambda _1}\left( {{t_{\text{f}}}} \right)} \\ {S{x_2}\left( {{t_{\text{f}}}} \right)} \end{array}} \right],\tag{27}\end{equation*} where
M = ( 1 2 G ( t f ) [ I 0 0 S ] + [ 0 0 0 I ] ) . (28)
View Source Right-click on figure for MathML and additional features. \begin{equation*}M = \left( {\frac{1}{2}G\left( {{t_{\text{f}}}} \right)\left[ {\begin{array}{ll} I&0 \\ 0&S \end{array}} \right] + \left[ {\begin{array}{ll} 0&0 \\ 0&I \end{array}} \right]} \right).\tag{28}\end{equation*}

Note that M is invertible. Thus, we can calculate λ 1 ( t f ) and x 2 ( t f ) from (27) . Along with (25) , we obtain λ ( t f ).
SECTION V.
The Kino-RRT* Algorithm

In this section, we present the details of the Kino-RRT* algorithm, which is built on both the PFF controller and the fixed-final-state free-final-time controller. We summarize some primitive procedures. Some of them follow [3] .

Sampling: The sampling procedure SamplePFF returns a partial state that is randomly sampled in a reduced state space and is collision-free in the corresponding reduced state space. For example, for a robot whose state space includes the position space and the velocity space, SamplePFF may sample a position of the robot that is collision-free.

Nearest Neighbor: Given a tree G = ( V , E ), where V is the node set and E is the edge set, the procedure Nearest ( V , x ) returns the node in V that is closest to the state x.

Near Nodes: The function Near ( V , x , r ) returns all the nodes in V that are contained in a ball of radius r centered at x.

Collision Checking: The function CollisionFree ( π ) takes a trajectory π (an edge segment) as an input and returns true if and only if π lies entirely in the collision-free space. The function CollisionPoint ( x ) returns true if and only if the point x is collision-free.

Cost: The procedure Cost ( x ) returns the cost-to-come from the root node to x. The procedure SegCost ( x i , x j ) returns the cost from x i to x j . Depending on x j , this cost is obtained by either solving the PFF control problem or the fixed-final- state free-final-time control problem.

Shrink: The procedure Shrink ( x i , x j ) returns x j if the distance between x i and x j is less than or equal to ℓ. Otherwise, it returns a new state x new that lies on the line formed by x i and x j and is at a distance ℓ away from x i towards x j . The Shrink procedure is consistent with the RRT* algorithm and dictates that segments should have a maximum length ℓ. If one tries to connect two points that are far away, this connecting segment will collide with obstacles with a high probability.

Steering: The procedure SteerPFF ( x i , x j ) solves the TP-BVP using the PFF optimal controller, and it returns a trajectory π that starts from x i and ends at x j . The procedure Steer ( x i , x j ) solves the TPBVP using the fixed-final-state free-final-time controller, and it returns a trajectory π that starts from x i and ends at x j . Note that x j in Steer ( x i , x j ) is a point in the full state space, while x j in SteerPFF ( x i , x j ) is a point in the reduced sampling space.

FreeState: The function FreeSate takes the trajectory π returned by SteerPFF ( x i , x j ) as input and returns the rest of the state x free at the endpoint of the trajectory that is not specified by x j .

The complete algorithm is given by Algorithm 1 , 2 , and 3 . We use z to denote a point in the reduced sampling space. The rest of the state (free-state) x free , which comes from the endpoint of the edge segment (state trajectory), is decided by the PFF optimal controller. After the ChooseParent step (line 11, Algorithm 1 ), the free-state is found and is combined with the sampled state to form a point in the full state space (line 12, Algorithm 1 ). Then, this point is added to the tree as a node (line 13, Algorithm 1 ).
Algorithm 1: Kino-RRT*
Table 1:- Kino-RRT*
Algorithm 2: ChooseParent
Table 2:- ChooseParent
Algorithm 3: Rewire
Table 3:- Rewire
A. Delayed and Intermittent Update of the Arrival Time

For both the PFF controller and the fixed-final-state controller, finding the optimal arrival time of the TPBVP requires solving a root-finding problem of a high-order polynomial (see (23) ). This root-finding procedure will slow down the kinodynamic RRT* algorithm, as the TPBVP is required to be solved repeatedly. Here we propose a delayed and intermittent update of the optimal arrival time, which is shown in Figure 2 . The planning algorithm first grows a tree using a heuristic of the arrival time (for example, by setting a desired average speed) without solving the root-finding problem ( Figure 2(a) ). Then, we intermittently update all the edges in the tree using the optimal arrival time ( Figure 2(b) ). If the updated edge is in-collision, we will use the original edge. We call this method KinoD-RRT*.
Fig. 2: - Delayed and intermittent update of the arrival time. (a) Grow a tree using a heuristic of the arrival time (blue lines). (b) Update the optimal arrival time of all edges (red lines). If the updated edge is in-collision (red dash lines), the original edge is used (blue lines).
Fig. 2:

Delayed and intermittent update of the arrival time. (a) Grow a tree using a heuristic of the arrival time (blue lines). (b) Update the optimal arrival time of all edges (red lines). If the updated edge is in-collision (red dash lines), the original edge is used (blue lines).

Show All
SECTION VI.
Experimental Results

We tested the Kino-RRT* algorithm on two kinodynamic systems: a 2D double integrator robot operating in a plane environment and a linearized quadrotor robot with a 10-dimensional state-space. We compared the Kino-RRT* algorithm with a variant of the kinodynamic RRT* algorithm. The only difference between the Kino-RRT* and the compared algorithm (a variant of kinodynamic RRT*) is the utilization of the PFF controller in Kino-RRT*. The compared kino-dynamic RRT* algorithm samples the full state space and uses the fixed-final-state free-final-time controller to solve the TPBVPs. The gain of performance is solely due to the PFF controller. Thus, this comparison is informative.
A. Implementation Details

In kinodynamic RRT*, the near nodes are found by using the forward-reachable set or the backward-reachable set [1] , [16] . Specifically, in line 12, Algorithm 1 , Near ( V , x , r ) returns all nodes in V such that the cost J to go from these nodes to x is less than r (backward-reachable set). Checking membership in the forward/backward reachable set for a set of nodes can be computationally expensive.

We use Euclidean distance to find the near nodes and the nearest node. This essentially means that we do not use the true distance. In this case, the forward-reachable set and the backward-reachable set are the same. For kinodynamic motion planning, the true distance between two states is the minimum cost J from the solution of the TPBVP [6] . Using the true distance, the forward (or backward) reachable set defines an ε -radius sub-Riemannian ball centered at x. It is showed in [20] that there always exists a certain size Euclidean hyper-ball inside such sub-Riemannian ball under mild conditions, which justifies the use of Euclidean norms. Euclidean distance is also used in [20] . After the nearest node and the near nodes are selected, the true distance is used in the ChooseParent and Rewire algorithms. The Euclidean distance is used only to pre-select relevant nodes and to help with the computations.

We also used a constant radius for the Euclidean hyper- ball for the near nodes, which implies a constant radius of the sub-Riemannian ball with respect to the true distance. Note that the kinodynamic RRT* is asymptotically optimal with a constant neighbor radius. The implementation is the same for the Kino-RRT* and the compared algorithm for an informative comparison.
B. 2D Double Integrator

The state of the 2D double integrator is given by x = [ p ⊤ v ⊤ ] ⊤ , where   p = [ x 1 x 2 ] ⊤ is the position and v = [ x 3 x 4 ] ⊤ is the velocity. The control input is the acceleration. The weighting matrix in the cost function is set to R = I 2 .

For both Kino-RRT* and kinodynamic RRT* the position is uniformly sampled within the boundary of the environment, that is, p ∈ [0,20] 2 m. The free-final-state of the PFF controller is the velocity. Thus, the Kino-RRT* algorithm does not sample the velocity space. For the kinodynamic RRT* algorithm, the velocity is uniformly sampled in v ∈ [−2,2] 2 m / s 2 . Note that a larger interval for the velocity essentially requires searching in a larger state space, which will result in slower convergence. However, if the sampling velocity interval is too small, the search is confined to a small state space that may not contain the optimal solution. Here, the velocity interval is chosen to be small while containing the optimal solution.

The results of the kinodynamic RRT* algorithm and the Kino-RRT* algorithm are given in Figure 3 and Figure 4 , respectively. The comparison of the Kino-RRT* and the kinodynamic RRT* is shown in Figure 5 . In Figure 5 , we can see that our algorithm finds a better trajectory from the beginning (the first solution). In fact, the solution found by Kino-RRT* within 0.14 sec is comparable to the solution found by kinodynamic RRT* that took 8 sec after expanding 4000 nodes. After the Kino-RRT* finds the first solution, the cost enters a sharp decrease phase. For the kinodynamic RRT* algorithm, the cost curve is close to flat after 8 sec, and the probability of sampling good states to decrease the cost is low. Kino-RRT* is more than 50 times faster than the kinodynamic RRT* to find a trajectory with the same cost. By sampling in a reduced state-space, the solution returned by Kino-RRT* is close to the optimal solution after a few seconds of computation. However, for the kinodynamic RRT* algorithm, it is difficult to sample good velocities that are comparable to the ones chosen by the PFF optimal controller, which leads to slow convergence.
Fig. 3: - Kinodynamic RRT* results of the double integrator.
Fig. 3:

Kinodynamic RRT* results of the double integrator.

Show All
Fig. 4: - Kino-RRT* results of the 2D double integrator.
Fig. 4:

Kino-RRT* results of the 2D double integrator.

Show All

Figure 6 shows the results of the delayed and intermittent update of the optimal arrival time. The Kinodynamic RRT* combined with the delayed and intermittent update of the optimal arrival time is called Kinodynamic RRT* with delay. Four methods, Kinodynamic RRT*, Kinodynamic RRT* with delay, Kino-RRT*, and KinoD-RRT*, are compared. Kinodynamic RRT* with delay is 3 times faster than Kino- dynamic RRT* when expanding the same number of nodes. The planned trajectories have a similar cost for expanding the same number of nodes.

Kino-RRT* with delay is also 3 times faster than Kino- RRT* when expanding the same number of nodes. We can see in Figure 6(b) that KinoD-RRT* (blue dash line) finds a better trajectory in the beginning as it expands more nodes in a given interval of time. However, Kino-RRT* outperforms KinoD-RRT* after some point. This is because the velocities (free-final-state) chosen by KinoD-RRT* are not as optimized as the velocities chosen by Kino-RRT*. The velocity chosen by the PFF controller is affected by the arrival time. Non-optimal arrival times (which is the case with KinoD-RRT*) will result in a sub-optimal final velocity. Thus, the performance of delayed update depends on the heuristic for the arrival time.
Fig. 5: - Comparison of Kino-RRT* and kinodynamic RRT* for the 2D double integrator case.
Fig. 5:

Comparison of Kino-RRT* and kinodynamic RRT* for the 2D double integrator case.

Show All
Fig. 6: - Delayed and intermittent updates of the optimal arrival time of the 2D double integrator. The arrival time is updated whenever another 500 nodes are added to the tree.
Fig. 6:

Delayed and intermittent updates of the optimal arrival time of the 2D double integrator. The arrival time is updated whenever another 500 nodes are added to the tree.

Show All
C. Linearized Quadrotor

A linearized quadrotor model adopted from [1] is used in this example. The 10-dimensional state is given by x = [ p ⊤ v ⊤ r ⊤ w ⊤ ] ⊤ , which consists of the three-dimensional position p and velocity v , and the two-dimensional orientation r and angular velocity w. The yaw rotation, which is a redundant degree of freedom, is not considered in the model.

The free-final-state of the PFF controller is v , r , and w. Thus the Kino-RRT* algorithm only samples the position space. Since the quadrotor is linearized at the hovering state and the dynamics is sensitive to the roll and pitch angles, we will use the PPF controller with quadratic terminal penalty introduced in Section IV-C . The terminal penalty matrix is S = diag(0,0,0,20,20,0,0). The weighting matrix of the control is R = diag(15,30,30). For both Kino-RRT* and kinodynamic RRT* the position is uniformly sampled within the boundary of the 3D environment. The sampling intervals of v , r , and w for the kinodynamic RRT* are v ∈ [−2,2] 3 m / s, r ∈ [−1,1] 2 rad, and w ∈ [−4,4] 2 rad / s respectively.

One solution from Kino-RRT* is shown in Figure 7(a) . The comparison of Kino-RRT* and kinodynamic RRT* is shown in Figure 7(b) . The solution of the PPF controller with quadratic terminal penalty is more complex than the fixed- final-state free-final-time controller. Thus, the Kino-RRT* algorithm takes more time to expand the same number of nodes compared to the kinodynamic RRT*. Because each node in Kino-RRT* is more optimized, it still converges faster than kinodynamic RRT*. The detailed simulation results can be found in the extend version of the paper [24] .
Fig. 7: - (a) Planning result of Kino-RRT*; (b) Comparison of Kino-RRT* and kinodynamic RRT* for the quadrotor case.
Fig. 7:

(a) Planning result of Kino-RRT*; (b) Comparison of Kino-RRT* and kinodynamic RRT* for the quadrotor case.

Show All
Fig. 8: - Delayed and intermittent update of the optimal arrival time for the linearized quadrotor example.
Fig. 8:

Delayed and intermittent update of the optimal arrival time for the linearized quadrotor example.

Show All

Figure 8 shows the results of the delayed and intermit- tent update of the optimal arrival time. For the linearized quadrotor example, the kinodynamic RRT* with delay is 2 times faster than the kinodynamic RRT* when expanding the same number of nodes, and is also 2 times faster for finding a trajectory with a similar cost. Similar performance improvement is observed for the KinoD-RRT* compared to Kino-RRT*. This performance improvement depends on the heuristic of the arrival time for the KinoD-RRT* algorithm.
SECTION VII.
Conclusion

In this paper, we developed the Kino-RRT* algorithm, which utilizes a partial-final-state-free (PFF) optimal controller to improve the convergence performance of sampling-based motion planning of kinodynamic systems. Instead of sampling the full state of the robot, Kino-RRT* only samples part of the state-space and the rest of the states are optimized by the PFF optimal controller. We tested the algorithm on robot systems with 4-D and 10-D state-spaces. In both cases, Kino-RRT* showed better convergence compared to the standard kinodynamic RRT*, achieving trajectories with better cost using much less time to compute. The proposed Kino- RRT* algorithm shows potential for real-time kinodynamic motion planning for high-dimensional dynamical systems.

Authors
Figures
References
Keywords
Metrics
Footnotes
   Back to Results   
More Like This
Mobile robots path planning using ant colony optimization and Fuzzy Logic algorithms in unknown dynamic environments

2013 International Conference on Control, Automation, Robotics and Embedded Systems (CARE)

Published: 2013
Path Planning for Mobile Robots in Dynamic Environments Using Particle Swarm Optimization

2009 International Conference on Advances in Recent Technologies in Communication and Computing

Published: 2009
Show More
References
1. D. J. Webb and J. Van Den Berg, "Kinodynamic RRT*: Asymptotically optimal motion planning for robots with linear dynamics", IEEE International Conference on Robotics and Automation , pp. 5054-5061, May 2013.
Show in Context View Article Full Text: PDF (479) Google Scholar
2. S. M. LaValle and J. J. Kuffner, "Randomized kinodynamic planning", The International Journal of Robotics Research , vol. 20, no. 5, pp. 378-400, 2001.
Show in Context CrossRef Google Scholar
3. S. Karaman and E. Frazzoli, "Sampling-based algorithms for optimal motion planning", The International Journal of Robotics Research , vol. 30, pp. 846-894, June 2011.
Show in Context CrossRef Google Scholar
4. S. Karaman, M. R. Walter, A. Perez, E. Frazzoli and S. Teller, "Anytime motion planning using the RRT*", IEEE International Conference on Robotics and Automation , pp. 1478-1483, May 2011.
Show in Context View Article Full Text: PDF (1406) Google Scholar
5. J. D. Gammell and M. P. Strub, "Asymptotically optimal sampling- based motion planning methods", Annual Review of Control Robotics and Autonomous Systems , vol. 4, pp. 1-25, 2021.
Show in Context CrossRef Google Scholar
6. S. Karaman and E. Frazzoli, "Optimal kinodynamic motion planning using incremental sampling-based methods", 49th IEEE Conference on Decision and Control , pp. 7681-7687, December 2010.
Show in Context View Article Full Text: PDF (2853) Google Scholar
7. J. D. Gammell, S. S. Srinivasa and T. D. Barfoot, "Informed RRT*: Optimal sampling-based path planning focused via direct sampling of an admissible ellipsoidal heuristic", IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 2997-3004, 2014.
Show in Context View Article Full Text: PDF (2004) Google Scholar
8. A. Perez, R. Platt, G. Konidaris, L. Kaelbling and T. Lozano-Perez, "LQR-RRT*: Optimal sampling-based motion planning with automatically derived extension heuristics", IEEE International Conference on Robotics and Automation , pp. 2537-2542, May 2012.
Show in Context View Article Full Text: PDF (1286) Google Scholar
9. W. J. Wolfslag, M. Bharatheesha, T. M. Moerland and M. Wisse, "RRT-CoLearn: Towards kinodynamic planning without numerical trajectory optimization", IEEE Robotics and Automation Letters , vol. 3, no. 3, pp. 1655-1662, 2018.
Show in Context View Article Full Text: PDF (586) Google Scholar
10. D. Zheng and P. Tsiotras, "Sampling-based kinodynamic motion planning using a neural network controller", AIAA Scitech 2021 Forum , pp. 1754, 2021.
Show in Context CrossRef Google Scholar
11. H. T. L. Chiang, J. Hsu, M. Fiser, L. Tapia and A. Faust, "RL-RRT: Kinodynamic motion planning via learning reachability estimators from RL policies", IEEE Robotics and Automation Letters , vol. 4, no. 4, pp. 4298-4305, 2019.
Show in Context View Article Full Text: PDF (2904) Google Scholar
12. L. Janson, E. Schmerling, A. Clark and M. Pavone, "Fast marching tree: A fast marching sampling-based method for optimal motion planning in many dimensions", The International Journal of Robotics Research , vol. 34, no. 7, pp. 883-921, 2015.
Show in Context CrossRef Google Scholar
13. B. Paden, V. Varricchio and E. Frazzoli, "Verification and synthesis of admissible heuristics for kinodynamic motion planning", IEEE Robotics and Automation Letters , vol. 2, no. 2, pp. 648-655, 2017.
Show in Context View Article Full Text: PDF (479) Google Scholar
14. C. Xie, J. van den Berg, S. Patil and P. Abbeel, "Toward asymptotically optimal motion planning for kinodynamic systems using a two-point boundary value problem solver", IEEE International Conference on Robotics and Automation , pp. 4187-4194, May 2015.
Show in Context View Article Full Text: PDF (2193) Google Scholar
15. S. Karaman and E. Frazzoli, "Sampling-based optimal motion planning for non-holonomic dynamical systems", IEEE International Conference on Robotics and Automation , pp. 5041-5047, 2013.
Show in Context View Article Full Text: PDF (702) Google Scholar
16. E. Schmerling, L. Janson and M. Pavone, "Optimal sampling-based motion planning under differential constraints: the drift case with linear affine dynamics", 54th IEEE Conference on Decision and Control , pp. 2574-2581, 2015.
Show in Context View Article Full Text: PDF (634) Google Scholar
17. G. Goretkin, A. Perez, R. Platt and G. Konidaris, "Optimal sampling-based planning for linear-quadratic kinodynamic systems", 2013 IEEE International Conference on Robotics and Automation , pp. 2429-2436, 2013.
Show in Context View Article Full Text: PDF (2445) Google Scholar
18. B. Sakcak, L. Bascetta, G. Ferretti and M. Prandini, "Sampling-based optimal kinodynamic planning with motion primitives", Autonomous Robots , vol. 43, no. 7, pp. 1715-1732, 2019.
Show in Context CrossRef Google Scholar
19. K. Hauser and Y. Zhou, "Asymptotically optimal planning by feasible kinodynamic planning in a state–cost space", IEEE Transactions on Robotics , vol. 32, no. 6, pp. 1431-1443, 2016.
Show in Context View Article Full Text: PDF (1175) Google Scholar
20. Y. Li, Z. Littlefield and K. E. Bekris, "Asymptotically optimal sampling-based kinodynamic planning", The International Journal of Robotics Research , vol. 35, no. 5, pp. 528-564, 2016.
Show in Context CrossRef Google Scholar
21. A. Sivaramakrishnan, Z. Littlefield and K. E. Bekris, "Towards learning efficient maneuver sets for kinodynamic motion planning", 2019.
Show in Context Google Scholar
22. Z. Littlefield and K. E. Bekris, "Efficient and asymptotically optimal kinodynamic motion planning via dominance-informed regions", IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 7410-7415, 2018.
Show in Context View Article Full Text: PDF (5492) Google Scholar
23. F. L. Lewis, D. Vrabie and V. L. Syrmos, Optimal Control, John Wiley & Sons, 2012.
Show in Context CrossRef Google Scholar
24. D. Zheng and P. Tsiotras, "Accelerating kinodynamic RRT* through dimensionality reduction (extended version)", 2021.
Show in Context Google Scholar
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
