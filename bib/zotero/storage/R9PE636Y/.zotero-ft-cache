2021 International Conference on Unmanned Aircraft Systems (ICUAS) Athens, Greece. June 15-18, 2021
3D Trajectory Planning for UAV-based Search Missions: An Integrated Assessment and Search Planning Approach
Savvas Papaioannou, Panayiotis Kolios, Theocharis Theocharides, Christos G. Panayiotou and Marios M. Polycarpou

2021 International Conference on Unmanned Aircraft Systems (ICUAS) | 978-1-6654-1535-4/21/$31.00 ©2021 IEEE | DOI: 10.1109/ICUAS51884.2021.9476869 z

Abstract— The ability to efﬁciently plan and execute search missions in challenging and complex environments during natural and man-made disasters is imperative. In many emergency situations, precise navigation between obstacles and timeefﬁcient searching around 3D structures is essential for ﬁnding survivors. In this work we propose an integrated assessment and search planning approach which allows an autonomous UAV (unmanned aerial vehicle) agent to plan and execute collisionfree search trajectories in 3D environments. More speciﬁcally, the proposed search-planning framework aims to integrate and automate the ﬁrst two phases (i.e., the assessment phase and the search phase) of a traditional search-and-rescue (SAR) mission. In the ﬁrst stage, termed assessment-planning we aim to ﬁnd a high-level assessment plan which the UAV agent can execute in order to visit a set of points of interest. The generated plan of this stage guides the UAV to ﬂy over the objects of interest thus providing a ﬁrst assessment of the situation at hand. In the second stage, termed search-planning, the UAV trajectory is further ﬁne-tuned to allow the UAV to search in 3D (i.e., across all faces) the objects of interest for survivors. The performance of the proposed approach is demonstrated through extensive simulation analysis.
I. INTRODUCTION
Over the last several years we have witnessed an unprecedented interest in unmanned aerial systems. Indeed, the miniaturization and cost reduction of electronic components and the recent technological advancements in avionics, robotic systems and artiﬁcial intelligence has led to the rapid growth of unmanned aerial vehicles (UAVs). This has enabled the utilization of UAVs in search-and-rescue (SAR) missions [1]–[4] i.e., during natural or man-made disasters and in emergency response situations. UAVs are currently being used by ﬁrst responders mainly to provide a birds-eye view of the incident and for conducting rapid spot searches over inaccessible areas to locate missing people and for damage assessment. However, in many situations searching the affected area for survivors with a birds-eye view in not sufﬁcient, especially in challenging and complex environments with obstacles and occlusions, as illustrated in Fig. 1. In such emergency situations, precise navigation between obstacles and efﬁcient searching around 3D structures is essential for ﬁnding survivors.
UAV-based SAR missions are quite challenging by nature, with complex objectives and tight constraints. Take for instance the real-world scenario of a missing person in the woods depicted in Fig. 1(b). Speciﬁcally, the ﬁgure shows a birds-eye-view of the scene from a real-world
The authors are with the KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, 1678, Cyprus. {papaioannou.savvas, pkolios, ttheocharides, christosp, mpolycar}@ucy.ac.cy

1

FoV

0.5

Vegetation Vehicles Buildings

0 1
0.8 0.6 0.4 0.2
y

00
(a)

1 0.8 0.6 0.4 0.2
x

(b)

Fig. 1. (a) In many emergency situations, precise navigation between obstacles and efﬁcient searching around 3D structures is essential for ﬁnding survivors, (b) Aerial view of a rural area taken during a SAR missing person incident from a UAV equipped with a thermal camera.

deployment of a UAV in a SAR mission that the authors participated to assist civil protection ofﬁcers in a missing person incident. The scene depicts the ﬁrst responders and their vehicles after the UAV took off and the surrounding rural scenery composed of various forms of vegetation. In the depicted thermal image, lighter color represents higher temperatures. Evidently, trees and high foliage block any thermal dissipation from being detected and thus make it impossible to search for the missing person with this topdown view. Additionally, missing people tend to ﬁnd cover under tall trees to safeguard themselves from the elements of bad weather which makes detection from above impractical. Although, the use of the UAV in this scenario can provide a ﬁrst assessment of the situation at hand, the chances of ﬁnding the missing person using this tactic are very limited.
Motivated by the challenges described above, in this work we proposed a UAV-based 3D search-planning framework which can be utilized by ﬁrst responders during search and rescue missions. More speciﬁcally our contributions are the following:
• We propose an integrated assessment and search planning approach which can be used to aid search-andrescue missions with an autonomous UAV agent. In the assessment planning stage, a high-level plan is produced which guides the UAV to ﬂy over the area of interest and gather mission critical information. Then in the second stage, i.e., the search planning stage, the generated search plan is further ﬁne-tuned to allow the UAV agent to search the objects of interest in 3D (i.e., across all faces).
• In order to accomplish the 3D search task a number of artiﬁcial rectangular cuboids are generated and placed around the objects of interest that need to be searched. Then, a model predictive control (MPC) algorithm with linear and binary constraints is proposed, for guiding

978-0-7381-3115-3/21/$31.00 ©2021 IEEE

517

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

the UAV agent through the generated cuboids. The proposed formulation allows the problem to be solved exactly and efﬁciently using off-the-shelf solvers. • We demonstrate the capabilities and performance of the proposed approach through extensive simulated search scenarios.
The rest of the paper is structured as follows. Section II presents an overview of the related work on UAV-based trajectory planning for SAR missions. Section III presents the proposed system architecture and Section IV develops the system model. Section V discusses the details of the assessment planning phase and Section VI presents the proposed 3D search planning phase. Finally, Section VII evaluates the proposed system and Section VIII concludes the paper.
II. RELATED WORK
Autonomous planning and control are perhaps the two most desired capabilities in mobile robotics. Over the last years a plethora of methods have been proposed from academic and industrial research labs especially for the problem of planning and control of ground robots operating in 2D environments. Although the proposed approaches have reached a signiﬁcant level of maturity, there are still challenges to be tackled when more complex scenarios are considered i.e., planning and control in 3D with UAVs during search and rescue (SAR) missions. In such scenarios the task of planning and control is considerably more challenging mainly due to the more demanding mission objectives (e.g., searching with a UAV for survivors during natural disasters in threedimensional environments, scanning around buildings for people in need, etc.).
UAV-based 3D trajectory planning was investigated in [5]–[8], with the main objective being the search for a collision-free trajectory to the goal region. More speciﬁcally, [5] proposes a two-step trajectory planning approach using Voronoi graph search and artiﬁcial forces. In [6], the authors investigate the problem of UAV trajectory planning in GPS-denied environments. To handle the inherited uncertainty in these situations the authors extend the Belief Roadmap [9] (BRM) planning algorithm with accurate stateestimation based on stochastic-ﬁltering techniques. The trajectory planning problem studied in this work however, is purely kinematic and ignores the UAV dynamics. In [7], a receding horizon trajectory planning approach is proposed for UAVs and solved using gradient-based methods whereas in [8] the authors use rapidly-exploring random trees (RTTs) to generate collision-free waypoints in a computationally efﬁcient way. At a second stage the generated waypoints are connected with straight line segments and the resulting path is smoothed out using cubic Bezier curves to create a continuous curvature path which the UAV can execute. Because of the complex and not ﬂat terrain, the authors in [10] develop a 3D path planning and execution method based on D∗-Lite for search-and-rescue ground robots. In order to reduce the computational complexity of the task, the authors propose to decouple the problem into positioning and orientation planning.
The work in [11] proposes a multi-agent path-planner for detecting a static target with unknown location during search

and rescue missions. The proposed technique is exact and is solved using mixed-integer linear programming (MILP). However, it is based on a 2D discrete representation of the world and it does not considers the system dynamics.
The authors in [12] investigate various discrete pathplanning techniques for searching survivors with UAVs during disasters, including artiﬁcial potential ﬁelds (APF), fuzzy logic and genetic algorithms (GA). The works in [13]– [16] develop searching-and-tracking (SAT) approaches for searching an area of interest with multiple UAV agents and tracking multiple targets of interest. These works however are myopic and are based on a 2D representation of the world.
More recently the work in [17] investigated the problem of search planning during SAR missions using UAVs. The authors formulate the trajectory planning problem as a model predictive control (MPC) problem and they solve it using particle swarm optimization (PSO). This technique used a 2D coordinated kinematic model for the UAVs and the search planning was conducted in two-dimensions. Detailed surveys discussing the various trajectory/path planning methods in the literature and their applications can be found in [18]– [21].
Compared to the related work the most notable differentiating factors of this work are a) the proposed two-stage search planning architecture which captures the increasing level of complexity of the various phases of a SAR mission and b) the necessity to search in 3D the objects of interest from all views in order to search for survivors.
III. SYSTEM ARCHITECTURE
SAR missions typically consist of three phases [22], [23] namely a) assessment, b) search and c) rescue. The goal of the assessment phase is the determination of the course of action. This is a critical phase in which the rescue team assesses the damages and the hazards in the vicinity of the affected area in order to prepare and organize the search and rescue mission. On the other hand the goal of the search phase is to conduct efﬁcient, organized and thorough searches in the affected area in order to located survivors as efﬁciently as possible. Search operations when possible follow optimized search patterns which have been planned ahead in order to increase the efﬁciency of the search. In addition, the search team is often required to search around and along large structures/buildings, below bridges and under high foliage in order to locate people in need. Finally, during the last phase, people are given medical aid and are transported to safety.
The proposed approach aims to integrate and automate the ﬁrst two phases (i.e., the assessment and the search phases) of a traditional SAR mission with a single UAV agent. The proposed approach is illustrated in Fig. 2. In the ﬁrst phase the human operator speciﬁes the critical areas (as waypoints) to be visited in order for the rescue team to assess the incident at hand. In the second phase a more detailed speciﬁcation is given regarding the mission which allows the UAV agent to search the objects of interest across all faces in 3D.
In this paper we assume that a controllable ﬂying agent or a UAV, operates inside a bounded 3D environment which contains a) objects of interest which need to be searched (i.e.,

518

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

Phase 1: Assessment

Waypoint Generation

Agent dynamics

+ Assessment Planning

Phase 2: Search

Agent dynamics

Sensing model

Objects of interest

Obstacles

Cuboid Generation

Search Planning

High-level automated assessment planning

Collision free, ﬁne-tuned automated search planning

z

Automated UAV-based Search Planning

1

0.5

0 1
0.8 0.6 0.4 0.2
y

00

1 0.8 0.6 0.4 0.2
x

Fig. 2. Overview of the proposed search planning system architecture. The proposed framework aims to automate the ﬁrst two phases (i.e., the assessment phase and the search phase) of a traditional SAR mission with a UAV agent.

searched across all faces) and b) obstacles that need to be avoided.
Let the set of all objects of interest inside the surveillance region that need to be searched be denoted by J = {j1, j2, · · · , j|J|}, with the set cardinality |J| denoting their total count. Similarly, we denote the set of all obstacles in the environment by Ξ = {ξ1, ξ2, · · · , ξ|Ξ|}. We assume that the UAV agent is controllable and evolves in time according to a discrete-time dynamical model. Additionally, we assume that the agent is equipped with a camera system, with ﬁnite ﬁeldof-view (FoV), which uses for perceiving its surroundings.
In the ﬁrst stage, termed Assessment planning, we aim to derive a high-level 3D search plan in order to acquire more information about the objects of interest in the set J. This plan is generated in accordance to the agent dynamics and optimizes a simpliﬁed mission objective (i.e., minimizing the proximity of the agent with a set of waypoints). In this stage, the 3D objects of interest are approximated by waypoints in 3D, produced in a pre-processing step (i.e., during the waypoint generation step). The generated trajectory of this stage will guide the UAV to ﬂy over the objects of interest by visiting their waypoint approximation, gathering information about the mission such as the dimensions of the objects of interest and the location of the obstacles in the environment. Essentially, the generated UAV trajectory of this phase is used to build a 3D map of the environment [24]–[27], which in turn is utilized to reconstruct the objects of interest J and obstacles Ξ in the environment as rectangular cuboids for the Search Planning stage.
In the second stage, termed Search Planning, all objects of interest and obstacles are represented as rectangular cuboids based on the information acquired in the ﬁrst stage. In this stage, the planning takes place over a smaller area of the surveillance region and produces accurate and ﬁne-tuned plans which take into account the agent dynamics, the environmental constraints (i.e., obstacles), and the agent sensing model (i.e., the speciﬁcations of the UAV onboard camera system) and allows the agent to search in 3D all objects of interest while avoiding collisions with the obstacles in the environment. In essence, during this stage we ﬁnd the optimal UAV control inputs which allow the UAV to search an object of interest across all faces.

IV. SYSTEM MODEL

A. Agent Dynamical Model

In this work we assume that the UAV agent evolves in

3D space according to the following discrete-time dynamical

model:

xt = Φxt−1 + Γut−1

(1)

where xt = [x, x˙ ]t ∈ R6 denotes the agent’s state at time t which consists of position xt = [px, py, pz]t ∈ R3 and velocity x˙ t = [νx, νy, νz]t ∈ R3 components in
3D cartesian coordinates. The agent can be controlled by applying an amount of force u ∈ R3 in each dimension,
thus ut = [fx, fy, fz]t denotes the applied force vector at t. The matrices Φ and Γ are given by:

Φ=

I3 03

∆T · I3 φ · I3

, Γ=

03 γ · I3

(2)

where ∆T is the sampling interval, I3 is the identity matrix of dimension 3×3 and 03 is the zero matrix of dimension 3×3. The parameters φ and γ are further given by φ = (1−η) and γ = m−1∆T , where η is used to model the air resistance
and m is the agent mass.

B. Agent Sensing Model

The agent is equipped with an onboard camera taking snapshots of the objects of interest in order to search for survivors or people in need. Without loss of generality, we assume in this work that the camera ﬁeld of view (FoV) angles in the horizontal and vertical axis are equal [28] and thus the projected FoV footprint on a planar surface is square with side length r and given by:

ϕ

r(d) = 2d tan

(3)

2

where d denotes the distance in meters between the location of agent and the surface of the object that needs to be searched and ϕ is the angle opening of the FoV according to the camera speciﬁcations. Thus the area of the FoV footprint at a distance d is r(d)2 meters. Before taking a snapshot of the object of interest the agent ﬁrst aligns its camera with respect to the surface in such a way so that the optical axis of the camera (i.e., the viewing direction) is parallel to the normal vector (α) of the surface, as illustrated in Fig. 3.
In order to search an object of interest the agent needs to take multiple snapshots (according to the size of the FoV as

519

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

d r

φ

r

α

Fig. 3. The ﬁgure illustrates the agent sensing model i.e., a square region with dimensions r × r. The angle ϕ determines the FoV opening and α is the normal vector to the face of the object.
given by Eqn. (3)) such that the surface area of each face of the object is completely included in the acquired images.
C. Object Representation
The objects of interest that need to be searched in 3D and the obstacles inside the surveillance area that need to be avoided are represented in this work as rectangular cuboids of various sizes (referred to as cuboids hereafter). A rectangular cuboid is a convex hexahedron in three dimensional space which exhibits six rectangular faces (i.e., where each pair of adjacent faces meets in a right angle). A point x = [x, y, z] ∈ R3 that belongs to the cuboid C or resides inside the cuboid satisﬁes the following system of linear inequalities:
a11x + a12y + a13z ≤ b1 a21x + a22y + a23z ≤ b2
...
an1x + an2y + an3z ≤ bn
where n = 6 is the total number of faces which compose the cuboid C, αi = [ai1, ai2, ai3] is the outward normal vector to the ith face of the cuboid and bi is a constant. In more compact form the expression above can be written as Ax ≤ B where A is a n×3 matrix, x is a 3×1 column vector and B is a n × 1 column vector. For the rest of the paper, we will denote a rectangular cuboid C by the matrices A and B. That said, in this work we assume that the surveillance region has been 3D mapped [24], [25] during the assessment phase and subsequently the objects of interest and obstacles in the environment have been represented as cuboids, as discussed above. Moreover, we should note here that the proposed technique can be applied to any type of object as long as it can be represented as a convex polyhedron.
V. ASSESSMENT PLANNING
In the assessment planning phase the objective is to compute the UAV control inputs which guide the agent to ﬂy over the objects of interest with the ultimate purpose of collecting critical information regarding the mission. We assume that this information includes the dimensions of the objects of interest and obstacles and the faces of the objects of interest that need to be searched. This information is passed to the second stage which is responsible for guiding

the UAV agent to search the objects of interest in 3D while avoiding collisions with obstacles in the environment.
In this stage, the objects of interest are approximated by single 3D waypoints and by taking into account the agent dynamics a high-level plan is generated which minimizes the proximity of the agent with the waypoints. Thus the waypoint generation pre-processing step is applied ﬁrst in which each object of interest j ∈ J is approximated by a single location in 3D space (i.e., the waypoint wj) and a mixed integer linear program (P 1) is derived below to compute the plan which guides the UAV as close as possible to the waypoints.

Problem Assessment Planning :

T |J|

(P1) min

ζt,j

u0:T −1

t=1 j=1

(4a)

subject to t ∈ {1, . . . , T }:

t−1
xt = Φtx0 + Φτ Γut−τ−1
τ =0
xwt+,j − xwt−,j = d(Hxt, wj )
T
bt,j = 1
t=1
ζt,j ≤ M bt,j ζt,j ≤ xwt+,j + xwt−,j ζt,j ≥ xwt+,j + xwt−,j − M (1 − bt,j ) {xwt+,j , xwt−,j , ζt,j } ≥ 0 bt,j ∈ {0, 1}

(4b)
∀t, j (4c)
∀j (4d)
∀t, j (4e) ∀t, j (4f) ∀t, j (4g) ∀t, j (4h) ∀t, j (4i)

The program in (P 1) ﬁnds the optimal control inputs u0:T −1 over the planning horizon T which minimizes the L1-norm between the computed UAV 3D trajectory and the waypoints
according to the agent dynamics deﬁned in Eqn. (4b). First, we linearize the L1-norm between the position of the agent Hxt at a speciﬁc time instance and the position of waypoint wj of object j i.e., |Hxt − wj|, where H is a matrix which extracts the position coordinates from the agent state xt.
To do that we deﬁne d(Hxt, wj) = Hxt − wj, which according to the constraint in Eqn. (4c), is assigned to the variable xwt+,j if it is positive and to the variable xwt−,j if it is negative. Because, xwt+,j and xwt−,j are tied to the decision variable ζt,j which is minimized and since xwt+,j, xwt−j and ζt,j are all deﬁned to take positive values (i.e., Eqn. (4h)), the optimizer assigns the value of |Hxt − wj| to ζt,j via the constraints in Eqn. (4e) - Eqn. (4g) when the binary variable bt,j is activated.
More speciﬁcally, the binary variable bt,j indicates the time instance that waypoint wj is visited by the agent. Thus the decision variable ζt,j is assigned with distance values at the time-steps which speciﬁc waypoints are visited. The constraint in Eqn. (4c) computes the L1-norm between the
UAV trajectory and the waypoints for all possible UAV
positions in the planning horizon. The constraint in Eqn. (4d)
ensures that the number of binary variables that are activated
are equal to the total number of waypoints i.e., each waypoint

520

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

rr

d

r

y

r

d

d

x

(a)

(b)

Fig. 4. The ﬁgure illustrates the cuboid-generation pre-processing step which allows the agent to search all faces of an object of interest by passing through the generated cuboids.

is visited exactly once during the planning horizon. Finally, the set of constraints (4e)-(4g) assign the distance between waypoint j and the UAV position Hxt at time t to ζt,j, if bt,j = 1. Observe, that when bt,j = 0 the value of ζt,j is driven to zero. Thus, the minimization of Eqn. (4a) forces the UAV agent to approach as close as possible to the waypoints, one waypoint at a time, while enforcing the constraint of its dynamical model.
The produced 3D trajectory guides the agent to pass from all waypoints thus acquiring information regarding the objects of interest i.e., their dimensions and other critical information about the mission such as the location of obstacles which are used in stage two below.
VI. SEARCH PLANNING
In the second phase, termed Search Planning, the framework can be used to compute ﬁne-tuned and collision-free search plans inside a smaller area of the surveillance region. In particular in this stage the generated search plans allow the agent to search the objects of interest in 3D (i.e., for each object of interest all their faces are searched for survivors according to the camera speciﬁcations). We assume that the information collected during the ﬁrst stage allows us to represent each object of interest j that needs to be searched and the obstacles in the environment as rectangular cuboids i.e., Sec. IV-C. Thus for this phase we assume that the UAV has obtained a map of the environment which contains the locations of the objects of interest as well as the locations of the obstacles in the environment. In this map all objects of interest and obstacles have been represented as rectangular cuboids of appropriate dimensions.
Before discussing the details of the proposed search planning technique we ﬁrst describe the pre-processing step (i.e., the cuboid generation step) which takes place before the main trajectory planning process.
A. Cuboid Generation
The main idea here is to generate artiﬁcial cuboids all around the object of interest and then guide the UAV agent through these cuboids in order to search the object in 3D from all faces, i.e., scan the total surface area of the object with the UAV’s camera system. The generated cuboids are placed at speciﬁc distances from the object of interest according to the speciﬁcations of the UAV camera system Eqn. (3). More speciﬁcally, we assume that we know apriori the distance d that the UAV must maintain with a

particular object of interest during searching. Given d and the camera FoV angle ϕ, the size of the UAV FoV footprint can be determined by Eqn. (3) as a square with length r. Subsequently, the area of each face of the object of interest that needs to be searched is decomposed into several r × r cells and for each of those cells a cuboid is generated at distance d, so that when the agent passes from within a cuboid the corresponding area of the face is searched. That said, in the cuboid generation preprocessing step, for each face fi, i ∈ [1, . . . , 6] of the object of interest j we generate artiﬁcial cuboids Cij,n, n ∈ [1, . . . , Nij] at distance d where Nij is the total number of cuboids that are necessary to cover the whole area of face fi of object of interest j.
This is illustrated in Fig. 4, where 4 faces of the object of interest need to be searched and thus each of the 4 faces has been decomposed into several cells marked with light blue color. For each cell a cuboid shown in black color is generated to allow the agent to pass through it and search the corresponding part (area) of the face. More speciﬁcally, in Fig. 4, the object of interest (with brown color) is represented by a rectangular cuboid with dimensions width=60m, length=60m and height=60m. We assume that this information was acquired during the Assessment planning phase. The UAV agent must maintain a distance of d = 27m from each of the object’s faces, and the FoV angle is ϕ = 60deg. The camera FoV area in this case is approximately 30 × 30 m2 according to Eqn. (3). That said, each of the objects’s faces is decomposed into cells of size 30 × 30 m2 creating a grid of 4 cells. This is depicted in Fig. 4 with the light blue 3D boxes in front of each face. Then for each cell a cuboid is generated at distance d from the object, shown in black color in Fig. 4. When the agent resides within a cuboid their FoV projection captures an area of size 30 × 30 m2 on the face of the object. By guiding the agent through all 4 cuboids we allow the agent to cover the total surface area of a face with its camera system. Consequently, we are interested in guiding the agent via all the generated cuboids in order to search the object of interest across all faces.
B. 3D Search Planning
Once the cuboid generation pre-processing step is completed, we formulate the problem of searching the object of interest in 3D, as a rolling-horizon model predictive control (MPC) problem with linear and binary constraints and we solve it using off-the-shelf mixed-integer programming (MIP) solvers. Speciﬁcally, in the proposed approach at each sampling time t the UAV control actions ut|t, . . . , ut+T −1|t are obtained over a rolling-horizon of length T time-steps by solving a ﬁnite horizon open-loop optimal control problem using the current state of the UAV xt|t as the initial state. The ﬁrst control action ut|t in the sequence is then applied to the UAV and the optimization is repeated for the next sampling time. In this problem we consider 2 different types of constraints: a) linear constraints which govern the UAV dynamical model and b) binary constraints for the search task, obstacle avoidance and duplication of effort. Let us assume, that the cuboid generation pre-processing step has created a total of N cuboids Cn, n ∈ [1, . . . , N ] (across all faces) around a single object of interest j. For notational

521

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

clarity we assume that for every face i of the object of interest we generate the same number of cuboids and we drop the index j of the object of interest, thus Cij,n becomes Cn for a single object of interest.
We associate each cuboid Cn that needs to be visited with a binary variable yn which indicates whether this cuboid has been marked to be visited at some future time step (t + τ + 1|t), τ ∈ {0, . . . , T − 1} i.e., yn = 1, iff Hxt+τ+1|t ∈ Cn. Here H is a matrix which extracts the position coordinates from the agent’s state. That said, the 3D search task objective becomes the maximization of the cuboids to be visited over the planning horizon i.e.,

max yn

(5)

n

For inﬁnite planning horizon problems Eqn. (5) can be used to devise a search plan that will visit all the unvisited cuboids. However, to apply Eqn. (5) in a rolling ﬁnite horizon fashion we need to keep track of the visited cuboids in order to avoid visiting the same cuboids over and over. To achieve this, the UAV agent maintains a map V which is used to keep track of all visited cuboids as shown below:

V (n) = 1 , if Hx0:t ∈ Cn

(6)

0 , o.w

2) Mission Constraints: We can now describe the mission
constraints which lead to the desired 3D search planning
behavior. The constraints in Eqn. (8b) - (8c) are due to
the agent dynamical model as described in Section IV, assuming a known initial state x1|1 = x0. As we have already mentioned, the cuboid generation pre-processing step has created a total of N cuboids Ci, i ∈ [1, . . . , N ] for the object of interest j.
The constraints in Eqn. (8d)-(8g) are due to the 3D search task. Speciﬁcally, the constraint in (8d) uses τ ×N ×L binary variables bτ,n,l, for τ ∈ {0, . . . , T − 1}, n ∈ {1, . . . , N } and l ∈ {1, . . . , L} to determine whether the agent position Hxt+τ+1|t resides inside the negative or positive half-space deﬁned by the plane which contains the lth face of the nth cuboid. The matrix An of size (L × 3) and the vector Bn of size (L×1) represent the linear system of inequalities Anx ≤ Bn for which a 3D point x must satisfy in order to reside inside the cuboid Cn i.e., Sec. IV-C. Thus, the inequality An,lHxt+τ+1|t ≤ Bn,l becomes true when the UAV location resides inside the negative half-space created by the plane containing the lth face of the nth cuboid. When this happens the corresponding binary variable bτ,n,l becomes 1 to satisfy the constraint. Otherwise bτ,n,l = 0 and the constraint in Eqn. (8d) is valid with the addition of a large positive constant (i.e., big-M) M as shown.

where Hx0:t denotes the agent’s locations up to time t. That said, the complete mathematical formulation of the 3D search planning problem tackled in this work is shown in (P2) below:
1) Mission Objective: In (P2) we are interested in ﬁnding the optimal UAV control actions ut|t, . . . , ut+T −1|t over the rolling horizon of length T that minimizes the mission objective h(x, u, y) shown in Eqn. (7). The mission objective is a function of the agent’s future state x, control inputs u and the binary variables y which indicate whether a cuboid has been planned to be visited in the future. More speciﬁcally, the mission objective is given by:

h(x, u, y) = a Hxt+τ +1|t − x

2 2

+

(7)

T −1

N

b

ut+τ |t − ut+τ −1|t

2 2

−

c

yn

τ =1

n=1

where τ ∈ {0, . . . , T − 1}, x is the centroid of the

nearest (with respect to the agent’s current location) un-

visited cuboid and (a, b, c) are weights associated with the

different mission objectives. In particular, the ﬁrst term i.e.,

H xt+τ +1|t

−x

2 2

guides

the

UAV

agent

towards

the

nearest unvisited cuboid by minimizing the squared euclidian

distance of the future agent location Hxt+τ +1|t with the

centroid of the nearest unvisited cuboid x . Moreover, the

second term i.e.,

T −1 τ =0

ut+τ +1|t

− ut+τ |t

2 2

is used to

minimize the deviations between consecutive control inputs,

thus leading to smoother UAV trajectories. Finally, the last

term in Eqn. (7) is used for maximizing the number of

cuboids to be visited over the planning horizon, as discussed

previously.

Problem Search Planning :

(P2)

min h(x, u, y)

ut|t,...,ut+T −1|t

subject to τ ∈ {0, . . . , T − 1}:

xt+τ +1|t = Φxt+τ |t + Γut+τ |t xt|t = xt|t−1 An,lHxt+τ+1|t + (M − Bn,l)bτ,n,l ≤ M
L
L˜bτ,n − bτ,n,l ≤ 0
l=1
ˆbn ≤ ˜bτ,n
τ
yn ≤ ˆbn + V (n) Aψ,lH xt+τ +1|t > Bψ,l − M zτ,ψ,l
L
zτ,ψ,l ≤ L − 1
l=1
bτ,n,l, ˜bτ,n, ˆbn, yn, zτ,ψ,l ∈ {0, 1} |x˙ t+τ+1|t| ≤ vmax |ut+τ +1|t| ≤ umax

(8a)
∀τ (8b) (8c)
∀τ, n, l (8d)
∀τ, n (8e)
∀n (8f)
∀τ, n (8g) ∀τ, ψ, l (8h)
∀τ, ψ (8i)
∀τ, n, ψ, l (8j) ∀τ (8k) ∀τ (8l)

Subsequently, the binary variable ˜bτ,n in Eqn. (8e) is activated when the system of linear inequalities is satisﬁed i.e., An,lHxt+τ+1|t ≤ Bn,l, ∀l which indicates that the agent location Hxt+τ+1|t resides inside the cuboid n at time t + τ + 1. The constraint in Eqn. (8f) makes sure that the agent is not rewarded by planning trajectories which visit the same cuboid more than once in the future.
Finally, the constraint in Eqn. (8g) makes sure that the

522

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

Runtime (s) Nodes Explored Objective value (m)

X (m)

500 0 0
200 0 0
50 0 0

(a)
10 20 30 40 50 60 time (s)
10 20 30 40 50 60 time (s)
10 20 30 40 50 60 time (s)
(c)

Uz (N)

Uy (N)

Ux (N)

Error distance (m)

1.5
1
0.5
0
20 0
-20 0
20 0
-20 0
20 0
-20 0

1234567 Waypoint #
(b)

20

40

60

time (s)

20

40

60

time (s)

20

40

60

time (s)

(d)

Fig. 5. An illustrative example of the Assessment Planning phase

Y (m)

Z (m)

agent is not rewarded for visiting cuboids that have been visited in the past.
Lastly, the constraints (8h) - (8i) are the collision avoidance constraints with the object of interest and with obstacles in the environment. The UAV agent avoids a collision with an object when:
Hxt+τ+1|t ∈/ Cψ, ∀ψ ∈ Ψ, τ ∈ {0, . . . , T − 1} (9)
where Cψ denotes the obstacle ψ ∈ Ψ to be avoided which is represented as a convex polyhedron e.g., a rectangular cuboid. Suppose that all objects ψ to be avoided contain L faces, then a collision is avoided at time τ with object ψ if ∃l ∈ {1, . . . , L} : Aψ,lHxt+τ+1|t > Bψ,l.
The constraint in Eqn. (8h) uses T × |Ψ| × L binary variables zt,ψ,l to check if the constraint Aψ,lHxt+τ+1|t > Bψ,l is violated where M is a big positive constant. Then, constraint (8i) counts the number of times zt,ψ,l is activated and makes sure that this number is less or equal than L − 1. Equivalently, agent controls are chosen so that the linear system of inequalities AψHxt+τ+1|t < Bψ is not satisﬁed. The constraint in Eqn. (8j) declares the binary variables of the problem and ﬁnally the constraints in Eqn. (8k) and Eqn. (8l) deﬁne the agent’s maximum speed and maximum control input respectively.
Finally, we should mention that the above search planning formulation can be easily extended for multiple objects of interest. This can be achieved by expanding the binary variables by one dimension in order to distinguish the cuboids of different objects of interest. For instance for objects of interest j ∈ J the binary variable bτ,n,l in Eqn. (8d) becomes bjτ,n,l, the binary variable ˜bτ,n in Eqn. (8e) becomes ˜bjτ,n and so forth.
VII. EVALUATION
A. Experimental Setup
To evaluate the performance of the proposed two-stage search planning approach we have conducted several synthetic experiments and simulations with varying number of waypoints, obstacles and objects of interest. In each test

150

15000

100

10000

50

5000

0

0

3 5 8 11 14 17

# Waypoints

(a)

20
10
0 3 5 8 11 14 17 # Waypoints (b)

Fig. 6. The ﬁgure illustrates how the number of waypoints affects the performance of the proposed technique.

we evaluate the proposed approach either qualitatively or quantitatively and we discuss its strengths and weaknesses. The experimental evaluation is divided into two parts. First, we investigate the performance of the Assessment Planning phase as discussed in Sec. V and then we conduct the experimental evaluation of the Search Planning phase i.e., Sec. VI.
The experimental setup used for the evaluation of the proposed system is as follows: The agent dynamics are expressed by Eqn. (1) with ∆T = 1s, agent mass m = 3.35kg and η = 0.2. The maximum applied control input umax is 20N or (kg.m/s2), the maximum agent velocity vmax is 15m/s and the agent acceleration can reach 6m/s2. Moreover, we assume that the agent FoV angle φ is 60deg.
B. Results
1) Assessment Planning: We begin our evaluation with a 3D simulated scenario for the assessment planning phase. In this scenario we deploy 7 objects of interest of various sizes throughout the surveillance area of dimension 600m × 300m × 70m. The objects of interest are approximated in this step as 3D waypoints shown as green circles in Fig. 5a. The planning horizon T is set to 55 time-steps and the mixed-integer linear program in (P1) is applied to obtain the results shown in Fig. 5. The objective here is to devise a plan that will guide the UAV agent to visit all waypoints within the speciﬁed time horizon while satisfying the agent dynamical constraints. The agent start position is marked with a green asterisk and the agent ﬁnal position is marked with a red asterisk as shown in the ﬁgure. Figure. 5a shows the generated UAV trajectory that visits all the speciﬁed waypoints. Figure 5b shows the L1-distance of the planned trajectory with each of the 7 waypoints and ﬁnally Fig. 5c and Fig. 5d show in more detail the (x, y, z) coordinates of obtained trajectory and the applied control inputs respectively.
The next experiment aims to investigate how the number of waypoints affect the performance of the proposed assessment planning technique. For this experiment we have conducted 20 Monte Carlo trials where we uniformly generate random waypoints inside a surveillance area of dimensions 200m × 200m × 50m and will let our system to run with a ﬁxed time-horizon of 50 time-steps, measuring the runtime, the number of explored nodes during the MIP branch-andbound optimization and the value of the objective function at the end of the optimization. Figure 6a shows the average runtime and the average number of explored nodes as a function of the number of waypoints. As we can observe the average runtime increases as the number of waypoints

523

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

Executed trajectory :

Predicted Trajectory :

Fig. 7. Simulated scenario demonstrating the Search planning phase for one object of interest as discussed in Sec. VI.

increases. Additionally, we can observe that the complexity of the problem increases with the number of waypoints. This is also shown by the number of nodes that have been explored until a solution is found. As the number of binary variables
increases itnima emsix: e1d,-i6nt,eg1e3r, p3r8og,r5am0, t5he3,p6ro3duced search
tree that is needed to be explored during the branch-andbound optimization procedure also increases in size and as a result more nodes are needed to be explored until a solution is found. Finally, Fig. 6b shows the value of the objective function at the end of the optimization. Essentially, we would like to drive this value close to zero, as we would like to bring the generated search plan as close as possible to the waypoints. However, this is not always possible especially as the number of waypoints increases. This is attributed to the overall complexity of the problem i.e., agent dynamics, the placement of the waypoints, the length of time horizon, etc.
2) Search Planning: The next set of experiments aims to demonstrate the performance of the proposed search planning technique as discussed in Sec. VI. The objective here is to produce ﬁne-tuned and accurate search plans which search the object of interest in 3D across all faces while avoiding collisions with the surrounding obstacles.
The ﬁrst experiment aims to demonstrate the 3D search task for an object of interest which is represented by a cuboid with size 60m × 60m × 60m. In this experiment, the agent is tasked to conduct search planning around the object (i.e., covering four of its faces) at a distance of no less than d =27m from the object of interest. At this distance the camera FoV footprint has size 30m × 30m and thus for each of the object’s faces 4 cuboids are generated to capture the total surface area of the face. In total 16 cuboids are generated around the object of interest as illustrated in Fig. 7(a). The agent’s initial state is X0 = [60, 230, 10, 0, 0, 0] , indicated by the green square in Fig. 7(a), and the weights of the objective function in Eqn. (7) are set to (a, b, c) = (0.3, 0.001, 1.5). The planning horizon for this experiment is set to 10 time-steps.

In Fig. 7(a), the object of interest to be searched is colored orange and the generated cuboids that need to be visited by the agent are marked in black. Finally, the executed UAV trajectory is marked with green diamonds and the future UAV trajectory over the planning horizon is marked with red circles.
As shown, in Fig. 7 the agent passes from all 16 cuboids and thus manages to search all 4 faces of this object. More speciﬁcally, Fig. 7(b) - Fig. 7(h) show the agent executed and planned trajectory at time-steps 1, 6, 13, 38, 50, 57 and 63 respectively. As we can observe in each planning horizon the agent tries to maximize the number of cuboids that are visited while at the same time minimizes its distance to the nearest unvisited cuboid according to the mission objective in Eqn. (7). For this scenario, the search planning problem in (P2) requires 10×16×6 binary variables for bτ,n,l, 10×16 binary variables for ˜bτ,n, 16 binary variables for ˆbn and ﬁnally 16 binary variables for yn. Thus, in total we need 1152 binary variables to model the functionality of this problem in an obstacle free environment.
In particular, the main factor that drives the computational complexity is the number of binary variables which are required by (P2). As the number of binary variables increases the search-space that is needed to be explored during the optimization process increases in size and as a result more nodes are needed to be explored until a feasible solution is found. For a problem with |J| objects of interest, N cuboids per object of interest, |Ψ| obstacles and planning horizon of length T , the number of binary variables needed by (P2) is equal to 2N |J| + T [N |J|(L + 1) + |Ψ|L] (assuming each polyhedron in the environment has L faces) which drives the main computational complexity.
Finally, Fig. 8 shows the proposed 3D search planning approach for multiple objects of interest in the presence of obstacles. In this scenario, two objects of interest of size 60m × 60m × 60m each are placed inside the surveillance area. The UAV agent is instructed to search the ﬁrst object from a distance of d1 = 53m and the second object from a distance

524

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

Stop

Start

(a)

(b)

Fig. 8. Search Planning for multiple objects of interest in the presence of obstacles.

of d2 = 27m. This results in FoV sizes of 60m × 60m and 30m × 30m for d1 and d2 respectively. Additionally, the two objects of interest are separated by an obstacle of dimensions 30m × 380m × 63m as shown in Fig. 8. The UAV initial state is X0 = [460, 140, 10, 0, 0, 0] , the planning horizon T is 12 time-steps and and the weights of the objective function in Eqn. (7) are set to (a, b, c) = (0.3, 0.001, 0.001). According to the agent FoV size for this scenario each face of the ﬁrst object was decomposed into one cell (illustrated by the light blue 3d boxes) whereas each face of the second object was decomposed into 4 cells. The cuboid generation pre-processing step generates 4 cuboids (1 cuboid per face) for the ﬁrst object and 16 cuboids (4 cuboids per face) for the second object. As we can observe, the proposed approach guides the UAV agent to search both objects starting from the ﬁrst object of interest and moving to the second while avoiding the obstacle in its path. The ﬁnal agent location is shown in Fig. 8(b) with a red diamond. Finally we should mention that, in the examples above we have shown the search planning task on the lateral faces of the objects of interest. This is done purely for presentation purposes and for visual clarity. The orientation of the face in 3D space is irrelevant in the proposed approach i.e., a face on the horizontal plane (e.g., the face on the top of the object of interest) can be handled the same way.

VIII. CONCLUSION
In this work we have proposed a novel approach, for integrating and automating the ﬁrst two phases of a traditional search and rescue mission, with an autonomous UAV agent. In the ﬁrst stage, namely assessment planning a high-level plan is produced which allows the UAV to ﬂy over the area of interest and gather mission critical information. Then in the second stage i.e., search planning, the generated plan is further ﬁne-tuned to allow the UAV agent to search the objects of interest in 3D (i.e., across all faces) while avoiding collisions with the obstacles in its path. The performance of the proposed approach has been demonstrated through extensive simulation analysis. Future work, will investigate the real-world implementation of the proposed system, and its integration into our existing multi-drone tasking platform. Additional future directions include the extension of this work to multiple UAV agents, and the investigation of search planning techniques in noisy and uncertain environments.

ACKNOWLEDGMENTS
This work is supported by the European Union’s Hori-
zon 2020 research and innovation programme under grant
agreement No 739551 (KIOS CoE), by the European Union
Civil Protection Call for proposals UCPM-2019-PP-AG grant
agreement No 873240 (AIDERS) and from the Republic
of Cyprus through the Directorate General for European
Programmes, Coordination and Development.
REFERENCES
[1] M. A. Goodrich, B. S. Morse, D. Gerhardt, J. L. Cooper, M. Quigley, J. A. Adams, and C. Humphrey, “Supporting Wilderness Search and Rescue using a Camera-equipped mini UAV,” Journal of Field Robotics, vol. 25, no. 1-2, pp. 89–110, 2008.
[2] E. Bitton and K. Goldberg, “Hydra: A Framework and Algorithms for Mixed-initiative UAV-assisted Search and Rescue,” in 2008 IEEE International Conference on Automation Science and Engineering. IEEE, 2008, pp. 61–66.
[3] S. Hayat, E. Yanmaz, T. X. Brown, and C. Bettstetter, “Multi-objective uav path planning for search and rescue,” in 2017 IEEE International Conference on Robotics and Automation (ICRA), 2017, pp. 5569– 5574.
[4] M. Bernard, K. Kondak, I. Maza, and A. Ollero, “Autonomous transportation and deployment with aerial robots for search and rescue missions,” Journal of Field Robotics, vol. 28, no. 6, pp. 914–931, 2011.
[5] S. A. Bortoff, “Path Planning for UAVs,” in Proceedings of the 2000 American Control Conference (ACC) , vol. 1, no. 6. IEEE, 2000, pp. 364–368.
[6] Ruijie He, S. Prentice, and N. Roy, “Planning in Information Space for a Quadrotor Helicopter in a GPS-denied environment,” in 2008 IEEE International Conference on Robotics and Automation, 2008, pp. 1814–1820.
[7] J. Tisdale, Z. Kim, and J. K. Hedrick, “Autonomous UAV Path Planning and Estimation,” IEEE Robotics Automation Magazine, vol. 16, no. 2, pp. 35–42, 2009.
[8] Kwangjin Yang and S. Sukkarieh, “3D Smooth Path Planning for a UAV in Cluttered Natural Environments,” in 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2008, pp. 794– 800.
[9] S. Prentice and N. Roy, “The Belief Roadmap: Efﬁcient Planning in Belief Space by Factoring the Covariance,” The International Journal of Robotics Research, vol. 28, no. 11-12, pp. 1448–1465, 2009.
[10] F. Colas, S. Mahesh, F. Pomerleau, M. Liu, and R. Siegwart, “3D Path Planning and Execution for Search and Rescue Ground Robots,” in 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2013, pp. 722–727.
[11] J. Berger and N. Lo, “An Innovative Multi-agent Search-and-rescue Path Planning Approach,” Computers & Operations Research, vol. 53, pp. 24 – 31, 2015.
[12] V. San Juan, M. Santos, and J. M. Andu´jar, “Intelligent UAV Map Generation and Discrete Path Planning for Search and Rescue Operations,” Complexity, vol. 2018, 2018.
[13] S. Papaioannou, P. Kolios, T. Theocharides, C. G. Panayiotou, and M. M. Polycarpou, “Probabilistic search and track with multiple mobile agents,” in 2019 International Conference on Unmanned Aircraft Systems (ICUAS), 2019, pp. 253–262.
[14] ——, “Jointly-optimized searching and tracking with random ﬁnite sets,” IEEE Transactions on Mobile Computing, vol. 19, no. 10, pp. 2374–2391, 2020.
[15] ——, “Decentralized search and track with multiple autonomous agents,” in 2019 IEEE 58th Conference on Decision and Control (CDC), 2019, pp. 909–915.
[16] ——, “A cooperative multi-agent probabilistic framework for search and track missions,” IEEE Transactions on Control of Network Systems, pp. 1–1, 2020.
[17] F. A. de Alcantara Andrade, A. Reinier Hovenburg, L. Netto de Lima, C. Dahlin Rodin, T. A. Johansen, R. Storvold, C. A. Moraes Correia, and D. Barreto Haddad, “Autonomous Unmanned Aerial Vehicles in Search and Rescue Missions Using Real-Time Cooperative Model Predictive Control,” Sensors, vol. 19, no. 19, 2019.
[18] L. Yang, J. Qi, J. Xiao, and X. Yong, “A Literature Review of UAV 3D Path Planning,” in Proceeding of the 11th World Congress on Intelligent Control and Automation, 2014, pp. 2376–2381.
[19] M. Radmanesh, M. Kumar, P. H. Guentert, and M. Sarim, “Overview of Path-planning and Obstacle Avoidance Algorithms for UAVs: A Comparative Study,” Unmanned Systems.

525

Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

[20] L. Yang, J. Qi, D. Song, J. Xiao, J. Han, and Y. Xia, “Survey of Robot 3D Path Planning Algorithms,” Journal of Control Science and Engineering, vol. 2016, 2016.
[21] O. Souissi, R. Benatitallah, D. Duvivier, A. Artiba, N. Belanger, and P. Feyzeau, “Path Planning: A 2013 Survey,” in Proceedings of 2013 International Conference on Industrial Engineering and Systems Management (IESM), 2013, pp. 1–8.
[22] The Ofﬁce of the United Nations High Commissioner for Refugees, UNHCR’s Handbook for Emergencies, 2015.
[23] United Nations Ofﬁce for the Coordination of Humanitarian Affairs, International Search and Rescue Advisory Group, Guidelines and Methodology, 2012.
[24] A. Nuchter, K. Lingemann, and J. Hertzberg, “Mapping of rescue environments with Kurt3D,” in IEEE International Safety, Security and Rescue Rototics, Workshop, 2005. IEEE, 2005, pp. 158–163.
[25] K. Pathak, A. Birk, N. Vaskevicius, M. Pﬁngsthorn, S. Schwertfeger,

and J. Poppinga, “Online three-dimensional slam by registration of large planar surface segments and closed-form pose-graph relaxation,” Journal of Field Robotics, vol. 27, no. 1, pp. 52–84, 2010. [26] R. Dube´, A. Gawel, C. Cadena, R. Siegwart, L. Freda, and M. Gianni, “3d localization, mapping and path planning for search and rescue operations,” in 2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR). IEEE, 2016, pp. 272–273. [27] A. Gawel, R. Dube´, H. Surmann, J. Nieto, R. Siegwart, and C. Cadena, “3d registration of aerial and ground robots for disaster response: An evaluation of features, descriptors, and transformation estimation,” in 2017 IEEE international symposium on safety, security and rescue robotics (SSRR). IEEE, 2017, pp. 27–34. [28] P. Petrides, C. Kyrkou, P. Kolios, T. Theocharides, and C. Panayiotou, “Towards a holistic performance evaluation framework for drone-based object detection,” in 2017 International Conference on Unmanned Aircraft Systems (ICUAS), 2017, pp. 1785–1793.

526 Authorized licensed use limited to: Technische Hochschule Ingolstadt. Downloaded on April 21,2022 at 10:20:21 UTC from IEEE Xplore. Restrictions apply.

