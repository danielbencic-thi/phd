Incremental A
S. Koenig and M. Likhachev Georgia Institute of Technology
College of Computing Atlanta, GA 30312-0280
¡
skoenig, mlikhach @cc.gatech.edu ¢
Abstract
Incremental search techniques ﬁnd optimal solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. While researchers have developed incremental versions of uninformed search methods, we develop an incremental version of A*. The ﬁrst search of Lifelong Planning A* is the same as that of A* but all subsequent searches are much faster because it reuses those parts of the previous search tree that are identical to the new search tree. We then present experimental results that demonstrate the advantages of Lifelong Planning A* for simple route planning tasks.
1 Overview
Artiﬁcial intelligence has investigated knowledge-based search techniques that allow one to solve search tasks in large domains. Most of the research on these methods has studied how to solve one-shot search problems. However, search is often a repetitive process, where one needs to solve a series of similar search tasks, for example, because the actual situation turns out to be slightly different from the one initially assumed or because the situation changes over time. An example for route planning tasks are changing trafﬁc conditions. Thus, one needs to replan for the new situation, for example if one always wants to display the least time-consuming route from the airport to the conference center on a web page. In these situations, most search methods replan from scratch, that is, solve the search problems independently. Incremental search techniques share with case-based planning, plan adaptation, repair-based planning, and learning search-control knowledge the property that they ﬁnd solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. Incremental search techniques, however, differ from the other techniques in that the quality of their solutions is guaranteed to be as good as the quality of the solutions obtained by replanning from scratch.
Although incremental search methods are not widely known in artiﬁcial intelligence and control, different researchers have developed incremental search versions of uninformed search methods in the algorithms literature. An overview can be found in [FMSN00]. We, on the other hand, develop an incremental version of A*, thus combining ideas from the algorithms literature and the artiﬁcial intelligence literature. We call the algorithm Lifelong Planning A* (LPA*), in analogy to “lifelong learning” [Thr98], because it reuses
£
We thank Anthony Stentz for his support. The Intelligent Decision-Making Group is partly supported by NSF awards under contracts IIS9984827, IIS-0098807, and ITR/AP-0113881. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the ofﬁcial policies, either expressed or implied, of the sponsoring organizations and agencies or the U.S. government.

information from previous searches. LPA* uses heuristics to focus the search and always ﬁnds a shortest path for the current edge costs. The ﬁrst search of LPA* is the same as that of A* but all subsequent searches are much faster. LPA* produces at least the search tree that A* builds. However, it achieves a substantial speedup over A* because it reuses those parts of the previous search tree that are identical to the new search tree.

2 The Route Planning Task

Lifelong Planning A* (LPA*) solves the following search task: It applies to ﬁnite graph

search problems on known graphs whose edge costs can increase or decrease over time.

denotes the ﬁnite set of vertices of the graph. ¢¡¤£¥£§¦©¨ denotes the set of successors

o(0f)

vertex ¨ . £§¦$¨213¨%457698

Similarly, !"#¦$¨%&' denotes the set of denotes the cost of moving from vertex ¨

predecessors of vertex ¨ . to vertex ¨!4@AB¡C£¥£D¦©¨ . LPA*

always determines a shortest path from a given start vertex ¨DEGFIHQPRFST to a given goal

vertex ¨VU¥W HYX  , knowing both the topology of the graph and the current edge costs. We

use `baD¦©¨ to denote the start distance of vertex ¨cd , that is, the length of a shortest path

from ¨EGFIH¥PeF to ¨ .

To motivate and test LPA*, we use a special case of these search tasks that is easy to visualize. We apply LPA* to navigation problems in known eight-connected gridworlds with cells whose traversability can change over time. They are either traversable (with cost one) or untraversable. LPA* always determines a shortest path between two given cells of the gridworld, knowing both the topology of the gridworld and which cells are currently blocked. This is a special case of the graph search problems on eight-connected grids whose edge costs are either one or inﬁnity. As an approximation of the distance between two cells, we use the maximum of the absolute differences of their x and y coordinates. This results in consistent heuristics that are for eight-connected grids what Manhattan distances are for four-connected grids.

3 Reusing Information from Previous Searches
The graph search problems can be solved with traditional graph-search methods, such as breadth-ﬁrst search, if they update the shortest path every time some edge costs change. They typically do not take advantage of information from previous searches. The following example, however, shows that this can be advantageous.
Consider the gridworlds of size f (Sgihp shown in Figure 1. The original gridworld is
shown on top and the changed gridworld is shown at the bottom. The traversability of only a few cells has changed. In particular, three blocked cells became traversable (namely, B3, C5, and D2) and three traversable cells became blocked (namely, A1, A4, D3). Thus, two percent of the cells changed their status but the obstacle density remained the same. The ﬁgure shows the shortest paths in both cases, breaking ties towards the north. Note that we assume that one can squeeze through diagonal obstacles. (This is just an artifact of how we generated the underlying graphs from the mazes.) The shortest path changed since one cell on the original shortest path became blocked.
Once the start distances of all cells are known, one can easily trace back a shortest path from the start cell to the goal cell by always greedily decreasing the start distance, starting
at the goal cell. This is similar to how A* traces the shortest path back from ¨!U¥W HQX to ¨ EGFIHQPRF using the search tree it has constructed. Thus, we only need to determine the start
distances. The start distances are shown in each traversable cell of the original and changed gridworlds. Those cells whose start distances in the changed gridworld have changed from the corresponding ones in the original gridworld are shaded gray.
There are two different ways of decreasing the search effort for determining the start distances for the changed gridworld. First, some start distances have not changed and thus need not get recomputed. This is what DynamicSWSF-FP [RR96] does. (DynamicSWSF-

Original Eight-Connected Gridworld

1

23

45

7

77

11 11 11 11 12

16 16

7776

6

10 10

10 10

15

15 16

6

55

99999

13

14 14 15

54

4

8888

12

13 14 15 16

44

3

3

7

7

11 11 12

14 15 16

3

2

23

66

10

16

A3 2

11

3

5

789

11

16

2 1 sstart 1 2

45

10 11 12 sgoal 14 15 16

2

34

78

10

12 13

15 16

33

654

567

9 10 11

14 15

44

55

7 8 9 10 11 12

15

B

5

6

66

8 8 8 8 9 10 11 12

14 15 16

6667

7778

99

10

12 13 14 15

C7

77

88889

10

11

13 14 15 16

D8

8

8

9 9 9 10

12

14

14 15

Changed Eight-Connected Gridworld

7

77

11 11 11 11 12

19 19

7776

6

10 10

10 10

18

18 19

6

55

99999

16

17 17 18

54

4

8888

15

16 17 18 19

55

3

3

7

7

14 14 15

17 18 18

4

2

23

66

13

17

3

11

3

5

7

12

12

16

2 1 sstart 1 2

45

11 11 12 sgoal 14 15 16

2

34

78

10

12 13

15 16

33

654

567

9 10 11

14 15

44

55

7 8 9 10 11 12

15

5

6666

8 8 8 8 9 10 11 12

14 15 16

6667

7778

99

10

12 13 14 15

7

77

88889

10 10 11

13 14 15 16

8

88

9 9 9 10

11

14

14 15

Figure 1: Simple Gridworld

FP, as originally stated, searches from the goal vertex to the start vertex and thus maintains estimates of the goal distances rather than the start distances. It is a simple matter of restating it to search from the start vertex to the goal vertex. Furthermore, DynamicSWSFFP, as originally stated, recomputes all goal distances that have changed. To avoid biasing our experimental results in favor of LPA*, we changed the termination condition of DynamicSWSF-FP so that it stops immediately after it is sure that it has found a shortest path.) Second, heuristic knowledge, in form of approximations of the goal distances, can be used to focus the search and determine that some start distances need not get computed at all. This is what A* [Pea85] does. We demonstrate that the two ways of decreasing the search effort are orthogonal by developing LPA* that combines both of them and thus is able to replan faster than either DynamicSWSF-FP or A*.
Figure 2 shows in gray those cells whose start distances each of the four algorithms recomputes. (To be precise: it shows in gray the cells that each of the four algorithms expands.) During the search in the original gridworld, DynamicSWSF-FP computes the same start distances as breadth-ﬁrst search during the ﬁrst search and LPA* computes the same start distances as A*. During the search in the changed gridworld, however, both incremental search (DynamicSWSF-FP) and heuristic search (A*) individually decrease the number of start distances that need to get recomputed compared to breadth-ﬁrst search, and together (LPA*) decrease the number even more.

4 Lifelong Planning A*

Lifelong Planning A* (LPA*) is an incremental version of A* that uses heuristics ¦©¨ to

control its search. As for A*, the heuristics approximate
¨ . They need to be consistent, that is, satisfy ¦©¨ U¥W HQX©¢¡

(

the goal distances
and ¦$¨ 6i£§¦$¨D1Y¨

of the
4 ¤£¥

vertices
¦©¨ 4  for

all vertices ¨ S and ¨4 S¢¡C£ £§¦©¨ with ¨§¡'¦ ¨ U¥W HYX .

LPA* maintains an estimate ` ¦©¨ of the start distance `Ca!¦©¨ of each vertex ¨ . These values
directly correspond to the g-values of an A* search. They are carried forward from search to
search. LPA* also maintains a second kind of estimate of the start distances. The rhs-values are one-step lookahead values based on the g-values and thus potentially better informed

complete search

incremental search

Original Eight-Connected Gridworld

uninformed search

heuristic search

breadth-ﬁrst search

A*

sstart

sgoal

sstart

sgoal

DynamicSWSF-FP (with early termination)

sstart

sgoal

Lifelong Planning A*

sstart

sgoal

Changed Eight-Connected Gridworld

uninformed search

heuristic search

breadth-ﬁrst search

A*

sstart

sgoal

sstart

sgoal

DynamicSWSF-FP (with early termination)

sstart

sgoal

Lifelong Planning A*

sstart

sgoal

complete search

incremental search

Figure 2: Performance of Search Methods in the Simple Gridworld

than the g-values. They always satisfy the following relationship:

¢¡¤£¦¥§£©¨') (10 !243657$98A@©B1DC ¥FE7¥§£GH¨PIRQS¥§£%G§T&£©¨D¨

if ££!#"%$& otherwise.

(1)

A vertex is called locally consistent iff its g-value equals its rhs-value. This is similar to satisfying the Bellman equation for undiscounted deterministic sequential decision problems. Thus, this concept is important because the g-values of all vertices equal their start distances iff all vertices are locally consistent. However, LPA* does not make every vertex
locally consistent. Instead, it uses the heuristics ¦©¨ to focus the search and update only the g-values that are relevant for computing a shortest path from ¨DEGFIHQPRF to ¨ UQW HYX .
LPA* maintains a priority queue U that always contains exactly the locally inconsistent vertices. These are the vertices whose g-values LPA* potentially needs to update to make them locally consistent. The keys of the vertices in the priority queue correspond to the f-values used by A*, and LPA* always expands the vertex in the priority queue with the smallest key, similar to A* that always expands the vertex in the priority queue with the
¡
smallest f-value. By expanding a vertex, we mean executing 10-16 (numbers in brackets ¢
refer to line numbers in Figure 3). The key V ¦$¨ of vertex ¨ is a vector with two components:

¡ ¡ © ¢ £¥¤¦£¨§ ¡  ¡ ¡ B C

B C B C The pseudocode uses the following functions to manage the priority queue: U.TopKey returns the smallest priority of all vertices in priority queue

. (If is emB1p ty,%tChen U.TopKey  returns

.) U.Pop deletes the vertex with the sB1mDCallest priority in p riority queue and returns the

vertex. U.Insert

inserts vertex into priority queue with priority . Finally, U.Remove removes vertex from priority queue .

B DC
  !© #" %$&"  !© #" procedure CalculaB t©eKB1DeCy§$  B1!CFC ¢B1DC

B B DC 4$  B1DC#C

 ¢   ¤  § 01 return

BC

;

procedure Initialize

  ¡(' )¥0 21 #" )  ) 02

 ;3 $ ©&B1DC

  #" 436587#9@5 )¥A £ 03 f$ or alB1l !C

  36587#9B5 © " 3!5¦7C9B5 A 04

B1

¢; B1

B DC ; CC

 ¢ ED ¤ § 05 U.Insert

B SC

;

  DG)F 36587#9@5 " D )   3 IHQP 94R6S#TEUWV  %$YX ©D procedurB e UpdateVerteCx$  B ¢C

 D ¡ ED 06 if B 3 C

B SC

2

   ED `)F #" ED Da© ED 07 if B B SC U$ .R eBmSoCFvCe ; B

B ©B1 2 C B SCFC

B1 2 SCFC ;

08 if

U.InsB1eC rt CalculateKey ;

  cd b 4e4f 7g #" 4e4f 7#g `)F  Be4f 7g procedure CB omputeShoB CrtestPath B1 C $ ©&B1 C B1 C#C

D ) 09 while U.TopKeB yC CalculateKey

OR

   ED ih #" ED 10

B ©B US.CPop $ ; B SCFC

   ED ) #" ED 11 if B SC $  B SC

  21pDQX6X ED 12

3

B; SC

B1DC

 13

for all

UpdateVertex ;

   ED ) 14 else B SC

  2£ 1pDQX6X ED Qq  D 15

 3 ; B SC

B1DC

  16

for aB lCl

procedure MaiB nC

UpdateVertex ;

 17 Initialize ;

 18 forever

B1C

 19 ComputeShortestPath ;

  EDp©!r 20 Wait for changes in edB ge c%osC ts;

  X EDp©!r 21 for all directed edges B w%itCh changed edge costs

  r 22

Update the edgB %e Ccost

;

23

UpdateVertex ;

Figure 3: Lifelong Planning A*.

s ¥§£©¨ut siv ¥§£©¨w sax ¥§£©¨6y4T

(2)

where V§¦©¨ ¡8 ¦ ` ¦©¨¥1e #¨ ¦$¨%R £

¦©¨

and Vc

¦©¨

¡8

¦`

¦©¨¥1e

#¨

¦$¨%R

¡
1

. Keys are

¢

compared according to
or equal to a key V 4G¦©¨ ,

a lexicographic ordering. For example,
denoted by V@¦©¨6  V 4$¦©¨ , iff either V  ¦$¨%

)

a

key V@¦©¨
V 4 ¦©¨ or

is (V



smaller
¦$¨ ¡ V

than
4 ¦$¨

and V2¦©¨&6 V 4 ¦©¨ ). VD¦©¨ corresponds directly to the f-values ¢¦©¨ ¡'`Ca§¦$¨% £ ¦$¨ used

by A* because both the g-values and rhs-values of LPA* correspond to the g-values of
 A* and the h-values of LPA* correspond to the h-values of A*. V ¦$¨% corresponds to the  g-values of A*. LPA* expands vertices in the order of increasing k -values and vertices   with equal k -values in order of increasing k -values. This is similar to A* that expands

vertices in the order of increasing f-values (since the heuristics are consistent) and vertices

with equal f-values that are on the same branch of the search tree in order of increasing

g-values (since it grows the search tree).

A locally inconsistent vertex ¨ is called overconsistent iff ` ¦©¨  #¨ ¦©¨ . When LPA*
expands a locally overconsistent vertex ¡ 12-13 , then  C¨ ¦©¨ ¡ `CaD¦©¨ because vertex ¨ ¢
has the smallest key among all locally inconsistent vertices.  #¨ ¦$¨% ¡ `CaD¦©¨ implies that
V ¦$¨% ¡ ¢¦©¨e` a§¦©¨B and thus LPA* expands overconsistent vertices in the same order
as A*. During the expansion of vertex ¨ , LPA* sets the g-value of vertex ¨ to its rhs-

¡
value and thus its start distance 12 , which is the desired value and also makes the vertex ¢

locally consistent. inconsistent vertex

Its g-value
¨ is called

then no longer changes
underconsistent iff `¤¦$¨%

u) nti l#L¨ P¦$A¨% *.

terminates. A locally When LPA* expands

¡
a locally underconsistent vertex 15-16 , then it simply sets the g-value of the vertex to ¢

¡
inﬁnity 15 . This makes the vertex either locally consistent or locally overconsistent. If ¢

the expanded vertex was locally overconsistent, then the change of its g-value can affect

¡
the local consistency of its successors 13 . Similarly, if the expanded vertex was locally ¢

¡
underconsistent, then it and its successors can be affected 16 . LPA* therefore updates ¢

rhs-values of these vertices, checks their local consistency, and adds them to or removes

them from the priority queue accordingly.

LPA* expands vertices until ¨ UQW HYX is locally consistent and the key of the vertex to expand next is no smaller than the key of ¨ U¥W HYX . This is similar to A* that expands vertices until it expands ¨VU¥W HQX at which point in time the g-value of ¨UQW HYX equals its start distance and the f-value of the vertex to expand next is no smaller than the f-value of ¨!U¥W HYX . It turns out
that LPA* expands a vertex at most twice, namely at most once when it is underconsistent
and at most once when it is overconsistent. Thus, ComputeShortestPath¦$ returns after a
number of vertex expansions that is at most twice the number of vertices.
If ` ¦©¨VU¥W HYX  ¡ 8 after the search, then there is no ﬁnite-cost path from ¨ E FIHQPeF to ¨VU¥W HYX . Otherwise, one can trace back a shortest path from ¨§EGFIHQPRF to ¨ U¥W HYX by always moving from the current vertex ¨ , starting at ¨ U¥W HQX , to any predecessor ¨4 that minimizes ` ¦©¨45 £ £§¦$¨%4©1Y¨ until ¨ EGFIHQPRF is reached (ties can be broken arbitrarily), similar to what A* can do if it does
not use backpointers.
The resulting version of LPA* is shown in Figure 3. The main function Main() ﬁrst calls
¡
Initialize() to initialize the search problem 17 . Initialize() sets the initial g-values of ¢
¡
all vertices to inﬁnity and sets their rhs-values according to Equation 1 03-04 . Thus, ¢
initially ¨EGFIHQPRF is the only locally inconsistent vertex and is inserted into the otherwise
¡
empty priority queue with a key calculated according to Equation 2 05 . This initialization ¢
guarantees that the ﬁrst call to ComputeShortestPath() performs exactly an A* search, that is, expands exactly the same vertices as A* in exactly the same order, provided that A* breaks ties between vertices with the same f-values suitably. Notice that, in an actual implementation, Initialize() only needs to initialize a vertex when it encounters it during the search and thus does not need to initialize all vertices up front. This is important because the number of vertices can be large and only a few of them might be reached during the
¡
search. LPA* then waits for changes in edge costs 20 . If some edge costs have changed, ¢
¡
it calls UpdateVertex() 23 to update the rhs-values and keys of the vertices potentially ¢
affected by the changed edge costs as well as their membership in the priority queue if they
¡
become locally consistent or inconsistent, and ﬁnally recalculates a shortest path 19 . ¢

5 Optimizations of Lifelong Planning A*

There are several simple ways of optimizing LPA* without changing its overall operation.

The resulting version of LPA* is shown in Figure 4. First, a vertex sometimes gets removed

from the priority queue and then immediately reinserted with a different key. For example,

¡

¡

a vertex can get removed on line 07 and then be reentered on line 08 . In this case,

¢

¢

it is often more efﬁcient to leave the vertex in the priority queue, update its key, and only

change its position in the priority queue. Second, when UpdateVertex¦©

¡
on line 13

com-

¢

putes the rhs-value for a successor of an overconsistent vertex it is unnecessary to take the

minimum over all of its respective predecessors. It is sufﬁcient to compute the rhs-value

as the minimum of its old rhs-value and the sum of the new g-value of the overconsistent

vertex and the cost of moving from the overconsistent vertex to the successor. The reason

is that only the g-value of the overconsistent vertex has changed. Since it decreased, it can

only decrease the rhs-values of the successor.

Third, when UpdateVertex¦$

¡
on line 16

¢

computes the rhs-value for a successor of an underconsistent vertex, the only g-value that

has changed is the g-value of the underconsistent vertex. Since it increased, the rhs-value

of the successor can only get affected if its old rhs-value was based on the old g-value of

the underconsistent vertex. This can be used to decide whether the successor needs to get

¡
updated and its rhs-value needs to get recomputed 21’ . Fourth, the second and third op¢

timization concerned the computations of the rhs-values of the successors after the g-value

of a vertex has changed. Similar optimizations can be made for the computation of the

rhs-value of a vertex after the cost of one of its incoming edges has changed.

6 Analytical and Experimental Results
We can prove the correctness of ComputeShortestPath().

B1C

¡ ¡ ¡ B C B C The pseudocode uses the following functions to manage the priority queue: U.Top returns a vertex with the smallest priority of all vertices in

©! ¡  ©6 ¡ ¢ £ ¤I £¨§ priority qB1ueueC . U.TopKey  returns the smallest priority of all vertices in prioB r ity%qC ueue . (If  is empty, then U.TopKey returns

.)

 ¡ U.Insert

 inserts vertex into priority queue with priority . U.Update B1DC  changes the priority of vertex in priority queue to . (It

does nothing if the current priority of vertex already equals .) Finally, U.Remove removes vertex from priority queue .

B DC
  !© #" $&"  !© #" procedure CalculatB e©KB1eDyC §$  B1!CFC ¢B1DC

B B DC §$  B1DCFC

 ¢   ¤¦  § 01’ return

BC

;

procedure Initialize

  ¡ ' ) 0 21 #" )  ) 02’  ;3 $  B1!C ©B1DC

  " 365¦7C9B5 ) A £ 03’ f$ or alBl

C

;

  365¦7C9B5 © " 3!5¦7C9B5 A 04’

B1

¢;B1 C C

 E¢ D ¤ § 05’ U.Insert

B SC

  D `)F #" ED D ¡ EDp© D procedure UB ¢pdC ateV$ ertexB SC

3

   ED )F " D D ¡ EDa© ED 06’ if ( B ©B SC $  AB ¢NCD

   ED ) " D D ¡ ED 07’ else if B ©B SC $  B ¢C AND

;

C

B

B ¢CFC

3 3

¡

U.UC pdate B CalculateKey B S; CFC C U.Insert B ¢CC alculateKey ;

08’ else if

AB1NC D

  d b e4f 7g #" e4f 7g )F  e4f 7g procedure CoB mputeShoBrCtestPath

B

D ) 09’ while U.TopKeB yC CalculateKey

   ED h #" ED 10’

B ©B US.CTop $ ; B SCFC

   ED ) " D 11’ if ©B SC $  B ¢C

  ED 12’

B SC ;

  1aDWX@X ED 13’

U.Remov3e ; &B SC

  )F 365¦7C9B5 #" ) #" ©I D %$GX EDp© 14’

for allB1 

C $  B1DC

U.Remove ;
C $  B1 C ©B1 CFC OR
B1$  B1DC B ¢C &B 4DCFC

    15’

if

B1DC

;

 16’

UpdateVertex ;

  #f g S )  ED 17’ else

©B ¢C

   ED ) 18’

©B SC

;

  £ 1aDWX@X ED %q  D 19’

3 ; &B SC

  #" ) #f g S $¨X  20’   EDp© ) D 21’   )F 3!5¦7C9B5 #" )   3 HQP 9BR@S#T 36V  $¨X © 22’

for allB1$ ©&B1DC

B 4DC  ¢C

if B  if

 C©$  B1DC OR 2 B1DC

B ©B1 2 C &B1 2 §DCFC ;

23’

B UC pdateVertex ;

procedure MainB1C

 24’ Initialize ;

 25’ forever

B1C

 26’ ComputeShortestPath ;

  EDp©r 27’ Wait for changes in edB ge c%osC ts;

  X f g S ) X EDp©r 28’ for all directe&dBedge%sC

with changed edge costs

  X EDa©Ir 29’

; &B %C

  XBf g S h X EDa©Ir 30’

Update the ed&gB e co%stC

;

  Er2)F 36587#9B5 #" Er ) #" Er !©¦ ED $¨X EDa©Ir 31’

if ( B 

C) $  B C

B1$ ©&B %C B SC &B %CFC

  #" Er )  ED $YX4f g S   32’  33’   Er2)F E36r 587#9B5 #" Er )   3 IHQP 94R6ST #V  $YX ©Ir 34’

if B1$  B %C ©B SC

C

else ifB



C $  B C

if

BC

2

;

£¢ B ©B1 2 C

&B1 2 %CFC ;

35’

UpdateVertex ;

Figure 4: Lifelong Planning A* (optimized version)

  Tt£h!ha#"et o$9mrietnomim£ 1¥iz¤9e"§Cs¦ oE7bmy¥§£paGu¨PltweIRSahyQSos¥§r£ mtG eT&os£©vt¨Pinaugtnhtf(irl)o£mte!#rt"%mh$&einciasuterrerseanactnhdevdeor(tnteiexesc£ ac,nasnttahbreetinnbgrtroaaktceen£

¥b¤9a"§c¦ ,k

a to

ashnoyrptersetdepcaetshsofrrom£ G

arbitrarily).

(The proofs can be found in [LK01].) We now compare breadth-ﬁrst search, A*, DynamicSWSF-FP, and the optimized version of LPA* experimentally. (We use DynamicSWSF-FP with the same optimizations that we developed for LPA*, to avoid biasing our experimental results in favor of LPA*.) The priority queues of all four algorithms were implemented as binary heaps. Since all algorithms determine the same paths (if they break ties suitably), we need to compare their total search time until a shortest path has been found. Since the actual runtimes are implementation-dependent, we instead use three measures that all correspond to common operations performed by the algorithms and thus heavily inﬂuence their runtimes: the total number of vertex expansions ¨ (that is, updates of the g-values, similar to backup operations of dynamic programming for sequential decision problems), the total number of vertex accesses ¨© (for example, to read or change their values), and the total number of heap percolates  (exchanges of a parent and child in the heap). Note that we count two vertex expansions, not just one vertex expansion, if LPA* expands the same vertex twice, to avoid biasing our experimental results in favor of LPA*.
(0g (
All of our experiments use ﬁfty eight-connected gridworlds that have size   and an

obstacle density of 40 percent. The start cell is at coordinates (34, 20) and the goal cell is at coordinates (5, 20), where the upper leftmost cell is at coordinates (0, 0). For each gridworld, the initial obstacle conﬁguration was generated randomly. Then, it was changed 500 times in a row, each time by making eight randomly chosen blocked cells traversable and eight randomly chosen traversable cells blocked. Thus, each time one percent of the cells changed their status but the obstacle density remained the same. After each of the 500 changes, the algorithms recomputed a shortest path from the start cell to the goal cell. For each of the four algorithms and each of the three performance measures, the following table reports the mean of the performance measure for the 500 changes: both its average over the ﬁfty mazes and its 95-percent conﬁdence interval over the ﬁfty mazes (assuming a normal distribution with unknown variance). The table conﬁrms the observations made in Section 3: LPA* outperforms the other three search methods according to all three performance measures.

complete search incremental search

uninformed search

breadth-ﬁrst search

ve = 1331.7

4.4

va = 26207.2

84.0

hp = 5985.3

19.7

DynamicSWSF-FP

ve = 173.0

4.9

va = 5697.4

167.0

hp = 956.2

26.6

heuristic search

A*

ve = 284.0

5.9

va = 6177.3

129.3

hp = 1697.3

39.9

Lifelong Planning A*

ve = 25.6

2.0

va = 1235.9

75.0

hp = 240.1

16.9

We have also applied LPA* successfully to more complex planning tasks, including the kind of route planning tasks that Focussed Dynamic A* [Ste95] applies to. The results will be reported separately.

References

[FMSN00] D. Frigioni, A. Marchetti-Spaccamela, and U. Nanni. Fully dynamic algorithms for maintaining shortest paths trees. Journal of Algorithms, 34(2):251– 281, 2000.

[LK01]

M. Likhachev and S. Koenig. Lifelong Planning A* and Dynamic A* Lite: The proofs. Technical report, College of Computing, Georgia Institute of Technology, Atlanta (Georgia), 2001.

[Pea85] J. Pearl. Heuristics: Intelligent Search Strategies for Computer Problem Solving. Addison-Wesley, 1985.

[RR96] G. Ramalingam and T. Reps. An incremental algorithm for a generalization of the shortest-path problem. Journal of Algorithms, 21:267–305, 1996.

[Ste95]

A. Stentz. The focussed D* algorithm for real-time replanning. In Proceedings of the International Joint Conference on Artiﬁcial Intelligence, pages 1652– 1659, 1995.

[Thr98] Sebastian Thrun. Lifelong learning algorithms. In S. Thrun and L. Pratt, editors, Learning To Learn. Kluwer Academic Publishers, 1998.

