IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Loading [MathJax]/extensions/MathMenu.js

Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

    Cart 
    Create Account
    Personal Sign In

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Access provided by:
Technische Hochschule Ingolstadt
Sign Out
IEEE logo - Link to IEEE main site homepage
ADVANCED SEARCH
Conferences > 2021 IEEE/RSJ International C...
Connecting Deep-Reinforcement-Learning-based Obstacle Avoidance with Conventional Global Planners using Waypoint Generators
Publisher: IEEE
Cite This
PDF
Linh Kästner ; Xinlin Zhao ; Teham Buiyan ; Junhui Li ; Zhengcheng Shen ; Jens Lambrecht ; Cornelius Marx
All Authors
128
Full
Text Views

    Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Related Works
    III.
    Methodology
    IV.
    Results and Evaluation
    V.
    Conclusion

Show Full Outline
Authors
Figures
References
Keywords
Metrics
Media
Abstract:
Deep Reinforcement Learning has emerged as an efficient dynamic obstacle avoidance method in highly dynamic environments. It has the potential to replace overly conservative or inefficient navigation approaches. However, integrating Deep Reinforcement Learning into existing navigation systems is still an open frontier due to the myopic nature of Deep-Reinforcement-Learning-based navigation, which hinders its widespread integration into current navigation systems. In this paper, we propose the concept of an intermediate planner to interconnect novel Deep-Reinforcement-Learning-based obstacle avoidance with conventional global planning methods using waypoint generation. Therefore, we integrate different waypoint generators into existing navigation systems and compare the joint system against traditional ones. We found an increased performance in terms of safety, efficiency and path smoothness, especially in highly dynamic environments.
Published in: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Date of Conference: 27 Sept.-1 Oct. 2021
Date Added to IEEE Xplore : 16 December 2021
ISBN Information:
ISSN Information:
INSPEC Accession Number: 21487421
DOI: 10.1109/IROS51168.2021.9636039
Publisher: IEEE
Conference Location: Prague, Czech Republic
SECTION I.
Introduction

Recently, mobile robots have become important tools in the industry, especially in logistics [1] , [2] . Typically, robotic navigation systems employ hierarchical planners consisting of a global planner, which calculates the optimal path using search-based approaches like A-star or Random Rapid Tree (RRT) search, and a local planner, which executes it considering local observations and unknown obstacles. While current systems can cope well with static environments, dynamic ones employing various dynamic obstacles still pose a great challenge. Deep Reinforcement Learning (DRL) has emerged as an end-to-end planning method to replace overly conservative planners in highly dynamic environments due to its ability to achieve efficient navigation and obstacle avoidance from raw sensor input. However, the integration of DRL into conventional planners and usage in industries is limited due to its myopic nature and tedious training. Furthermore, due to the lack of a long term memory, DRL-based methods are very sensitive to local minima and thus can easily be trapped in complex situations like long corridors, corners, or dead ends. Efforts to increase the capabilities of DRL-based systems to achieve long-range-navigation are complex and intensify the already tedious training procedures [3] , [4] .

In this work, we propose an interconnection entity called the intermediate planner to combine traditional global planning methods with a DRL-based local planner by using waypoints. Contrarily to existing works, the intermediate planner should generate waypoints more dynamically and flexibly along a given path while considering global as well as local information. This not only provides a shorter goal horizon but also adds an additional security layer in preparation for the local planner, which only has access to local sensor data. In particular, we propose two different waypoint generators that we compare against each other and against conventional navigation systems in terms of safety, robustness and efficiency. The main contributions of this work are the following:
Fig. 1: - Our proposed hierarchical navigation system includes an intermediate planner which interconnects a traditional global planner and a DRL-based local planner. We propose three different waypoint generators based on: subsampling (SUB-WP), a spatial-time-horizon (STH-WP), and on landmarks (LM-WP).
Fig. 1:

Our proposed hierarchical navigation system includes an intermediate planner which interconnects a traditional global planner and a DRL-based local planner. We propose three different waypoint generators based on: subsampling (SUB-WP), a spatial-time-horizon (STH-WP), and on landmarks (LM-WP).

Show All

    Proposal of two different waypoint generators to interconnect DRL-based local navigation with global methods and make DRL feasible for integration long-range-navigation.

    Integration of our approaches into the robot operating system (ROS) for a combination with conventional planners and to make deployment towards a real robot feasible.

    Extensive evaluation of the waypoint generators against one another as well as against conventional planning systems.

The paper is structured as follows. Sec. II begins with related works. Subsequently, the methodology is presented in Sec. III . Sec. IV presents the results and discussion. Finally, Sec. V will give a conclusion and outlook. We made the code publicly available under https://github.com/ignc-research/arena-rosnav .
SECTION II.
Related Works

DRL has been extensively studied in various publications ranging from simulation, gaming, to navigation and achieved remarkable results in these areas. Mnih et al. [5] first introduced the combination of Reinforcement Learning with deep neural networks and trained an agent to navigate in unknown environments based solely on sensor observations. In recent years, the usage of DRL for the path planning and obstacle avoidance problem has intensified [3] [4] [5] - [6] . Chen et al. [7] , [8] proposed a DRL-based navigation for crowded environments and successfully transferred the approach to a real robot. The agent could contemplate to social behaviors and navigate robustly in cluttered environments. Everett et al. [9] extended the approach with a Long-Short-Term-Memory (LSTM) architecture [10] and made it feasible for a dynamic number of obstacles. In [6] , Dugas et al. propose a platform consisting of a 2D simulation environment to train and test different DRL algorithms. The researchers integrate a variety of different DRL-based navigation approaches into their platform and compare them against one another. Faust et al. [3] combines a DRL-based local planner with sampling-based traditional planners. Global maps are generated by a DRL agent and, subsequently, the same DRL agent is utilized to execute the navigation. The researchers achieved long-range navigation in large scale office maps. However, the training is tedious, requires a high amount of parameters, and a not intuitive pre-setup. Chen et al. [11] , [12] utilizes DRL to generate waypoints by considering audio visual clues and an acoustic memory. The researchers trained the DRL agent to learn optimal waypoint generation in an end-to-end manner and validated their approach in 3D maps of typical residencies. Bansal et al. [13] trained a learning-based perception module to set waypoints in unknown environments for a collision-free path. The model is trained using visual representations and is combined with conventional model-based control for navigation. In this work, we follow a similar hierarchical approach, but focus on employing a DRL-based local planner for the obstacle avoidance problem. Gundelring et al. [14] first integrated a DRL-based local planner with a conventional global planner from the ubiquitously used robot operating system (ROS) and demonstrated promising results. The researchers employs a subsampling of the global path to create waypoints for the DRL-local planner. Similarly, Regler et al. [15] proposes a hand-designed sub-sampling to deploy a DRL-based local planner with conventional navigation stacks. A limitation of these works is that the a simple sub-sampling of the global path is inflexible and could lead to hindrance in complex situations, e.g. when multiple humans are blocking the way. In this work, we introduce an intermediate planner to spawn way-points more flexibly by considering local as well as global map information for optimal waypoint generation and replanning functionality. This should result in smoother trajectories, increased efficiency, and less collisions.
SECTION III.
Methodology

In this chapter, we present the methodology of our proposed framework. In order to accomplish long-range navigation while utilizing a DRL-based local planner, our work proposes a combination with traditional global planners. The system design is described in Fig. 1 . We propose an interconnection entity called the intermediate planner, which connects the two planners and present two different approaches to generate waypoints. As a baseline approach, we also provide a simple subsampling of waypoints along the path as proposed by [14] and [15] . This approach is denoted as SUB-WP.
A. Spatial Horizon Waypoint Generator

Our second waypoint generator calculates the waypoint using a look-ahead distance and the robot’s spatial position. Given the global path π g as an array Y consisting of N t poses, we sample a subset Y s u b g o a l s i ⊂ X p o s e s = { x i , … , x N t } of local goals based on the robot’s position p r and a look-ahead distance d ahead . The concept is illustrated in Fig. 2 . The algorithm of the S-WP is described in Alg. 3 .
Fig. 2: - Subgoal selection. Given a global path, our intermediate planner will calculate a subgoal based on the spatial horizon distahead.
Fig. 2:

Subgoal selection. Given a global path, our intermediate planner will calculate a subgoal based on the spatial horizon dist ahead .

Show All
Algorithm 1: Subgoal calculation
Table 1:- Subgoal calculation

This subset of goals can be observed as local sub-goals x i = p g and given as input for the DRL-based local planner. Additionally, we integrate a replanning mechanism to rework the global path when the robot is off-course for a certain distance from the global path, or if a time limit t lim is reached without movement, e.g. when the robot is stuck. In that case, a global replanning will be triggered and a new sub-goal will be calculated based on the new global plan and current robot position. This approach is denoted as spatial-time-horizon waypoint generator (STH-WP).
B. Landmark-based Waypoint Generator

Utilizing a simple subsampling approach can result in inefficient trajectories especially in highly dynamic environments, because the initially planned trajectory of the robot is constantly being changed when avoiding unknown obstacles. This may cause the robot to ignore more suitable paths in order to reach the static preset waypoints which might cause the trajectory to be less smooth and efficient. For our final waypoint generator, we postulate the assumption that not all points on the global path π g are equally important and that only critical waypoints have to be visited by the robot. These points are called landmarks L in this paper. Our waypoint generator utilizes these speci c landmarks to calculate optimal waypoint positions for the DRL local planner. This enables smoother trajectories and results in more efficient navigation. In the following, the landmark selection is described.
Fig. 3: - Landmark on different test maps.
Fig. 3:

Landmark on different test maps.

Show All
1) Landmark Selection

In a map, landmarks are recog-nized by humans as turning points. In order to navigate across these points, a turning action is performed by the robot. In return, we formulate the landmark as a point where the robot’s steering angle is bigger than a threshold value:
ψ p > ψ t h r e s h , p ∈ m a p (1)
View Source Right-click on figure for MathML and additional features. \begin{equation*} {\psi _p} > {\psi _{thresh}}\quad ,p \in map\tag{1}\end{equation*}

In order to calculate a reasonable steering angle value at a certain point on the map, the initial global path and its corresponding interpolated b-spline trajectory are used. We use a kinodynamic A-star search global path planner method proposed by Zhou et al. [16] , which provides b-spline properties to calculate reasonable steering angles for certain positions on the map.

Once the global b-spline trajectory is parameterized, the position, velocity, and acceleration at each time t ∈ [ t q , t M−q ] is be calculated. To evaluate the position at time t , we employ De Boor’s algorithm [17] . Finally, the derivatives of a point on the b-spline trajectory are calculated with [16]
Algorithm 2: Landmark selection
Table 2:- Landmark selection
Fig. 4: - Subgoal calculation for the LM-WP approach.
Fig. 4:

Subgoal calculation for the LM-WP approach.

Show All
v i = 1 t ( p i + 1 − p i ) a i = 1 t ( v i + 1 − v i ) (2)
View Source Right-click on figure for MathML and additional features. \begin{equation*}{{\mathbf{v}}_i} = \frac{1}{t}\left( {{{\mathbf{p}}_{i + 1}} - {{\mathbf{p}}_i}} \right)\quad {{\mathbf{a}}_i} = \frac{1}{t}\left( {{{\mathbf{v}}_{i + 1}} - {{\mathbf{v}}_i}} \right)\tag{2}\end{equation*}

The steering angle is calculated using the kinematic equations in Eq.3-5
a n o r m = v × a ∥ v ∥ ω = ∥ a n o r m ∥ ∥ v ∥ ψ = ∫ ω d t (3) (4) (5)
View Source Right-click on figure for MathML and additional features. \begin{align*} & {{\mathbf{a}}_{norm}} = \frac{{{\mathbf{v}} \times {\mathbf{a}}}}{{\left\| {\mathbf{v}} \right\|}}\tag{3} \\ & \omega = \frac{{\left\| {{{\mathbf{a}}_{norm}}} \right\|}}{{\left\| {\mathbf{v}} \right\|}}\tag{4} \\ & \psi = \int \omega dt\tag{5}\end{align*}

Fig. 3 illustrates landmarks on different maps using aforementioned calculations.
2) Subgoal Calculation

Once landmarks are selected from the global path, the waypoints will be calculated according to the robot’s current location, the current approaching landmark location, and the obstacles’ locations in the occupancy grid-map. Hence, the calculated sub-goal is not only calculated with respect to the landmark but also takes obstacles within sensor range into consideration. To ensure a collision-free path, we optimize the b-spline trajectory using the ESDF-free gradient-based optimization method introduced by Zhou et al. [18] . This method has the advantage of fast calculation times, which makes online deployment feasible. After the local trajectory optimization is finished, the sub-goal is calculated by evaluating a point on the optimized b-spline trajectory in time t eval with help of De Boor’s algorithm. The algorithm is described in Alg. 3 . We denote this waypoint landmark-based generator as LM-WP.
Fig. 5: - Trajectories and waypoints of all planners on the test scenario with 20 obstacles and a obstacle velocity of vobs = 0:3m=s. Upper row: plain test area, lower row: office map. (a) SUB-WP on the empty map (b) STH-WP on the empty map (c) LM-WP on the empty map (d) SUB-WP on the office map (e) STH-WP on the office map (f) LM-WP on the office map
Fig. 5:

Trajectories and waypoints of all planners on the test scenario with 20 obstacles and a obstacle velocity of v obs = 0 : 3 m=s. Upper row: plain test area, lower row: office map. (a) SUB-WP on the empty map (b) STH-WP on the empty map (c) LM-WP on the empty map (d) SUB-WP on the office map (e) STH-WP on the office map (f) LM-WP on the office map

Show All
Algorithm 3: Subgoal calculation
Table 3:- Subgoal calculation
C. The Joint System

The three proposed waypoint generators act as an interconnection entity for the traditional global planner and a DRL-based local planner of our previous work [19] . This planner was trained within the arena-rosnav environment, which provides a 2D platform to train and test agents based solely on 2D laser scan data. For our experiments, we denote the combination of traditional global planner, intermediate waypoint generator and local DRL-based planner as the joint system. The resulting systems are compared against traditional navigation systems, which only consists of a global plan and a model-based local planner such as MPC or TEB.
SECTION IV.
Results and Evaluation

We conducted experiments on two different maps in which we created a total of six different test scenarios of increasing dif culty with ve, 10 and 20 obstacles. In each scenario, the obstacle velocities are set to 0.3 m/s. More extensive evaluations of the obstacle velocities’ impacts are presented in the quantitative evaluations. As a global planner, the opti-mized b-spline kino A-star planner is used for all approaches. Localization is assumed to be perfectly known. For each planner, we conduct 30 test runs on each scenario. Finally, we compare our joint systems against conventional ones-TEB [20] and MPC [21] - in terms of safety, robustness and efficiency. For STH-WP, the time and spatial horizon is set to t lim = 4 s and d ahead = 1 : 55 m respectively. The lookahead distance of the SUB-WP approach is set to be 1 m.
A. Evaluation of Waypoint Generators

First, we evaluate the overall performance of our way-point generators against one another. Figure 5 illustrates the qualitative trajectories and waypoints of each planner. The opacity of the waypoints indicates their order of generation. It is observed that the trajectories of the SUB-WP contain more circular movements and are less efficient compared to the other two approaches. Due to the preset waypoints of the SUB-WP approach, the agent has to strictly reach each waypoint regardless of a potentially more efficient trajectory. This happens once the agent is off of the path when avoiding obstacles, which makes the approach inflexible and results in less efficient trajectories. As expected, the paths of LM-WP have the most variance due to the constant replanning as obstacles are being observed. Most of the waypoints are placed on the global path. However, in situations where obstacles are interfering, the waypoints are adjusted dynamically as can be observed in Fig. 5 (b), (e) . This results in a more compact path with less collisions. It is notable that whereas the LM-WP achieves robust navigation with efficient paths on the office map, in the empty map, it is less efficient and performs more roundabout paths. This is caused by the lack of landmarks as reference points for the intermediate planner to calculate optimal waypoints, which indicates that our approach works better in structured environments. Contrarily, the STH-WP achieves robust and strict trajectories towards the goal on the empty map. Whereas in the office map, the more roundabout paths are observed. Nevertheless, in all scenarios, the paths are still more efficient compared to the SUB-WP- which has increased circular movements. This is more evident in the office map ( Fig. 5 (d) ). In Fig. 6 , the trajectories of one test run in a scenario with ve obstacles were plotted over time. Once again, it is evident that the SUB-WP method results in a more inefficient trajectory because the robot has to follow the preset waypoint while dismissing potentially more suitable trajectories. The dynamic adjustment of the LM-WP generator results in a shorter and smoother path. Similarly, the STH-WP approach results in smoother trajectory because the waypoint adapts to the robots position. Live demonstrations of the approaches can be viewed in the supplementary video material.
Fig. 6: - Comparison of different waypoint generators. The trajectories are plotted over time. It is observable that LM-WP dynamically generates waypoints based on the obstacle position and results in a shorter, smoother trajectory (s. (a) (vii)). The path for SUB-WP is the most inefficient and includes roundabouts circles around obstacle areas. STH-WP achieves an efficient navigation as well without replanning and can follow the global path in a more robust manner. The sequences and other situations can be observed in action in the supplementary video material.
Fig. 6:

Comparison of different waypoint generators. The trajectories are plotted over time. It is observable that LM-WP dynamically generates waypoints based on the obstacle position and results in a shorter, smoother trajectory (s. (a) (vii)). The path for SUB-WP is the most inefficient and includes roundabouts circles around obstacle areas. STH-WP achieves an efficient navigation as well without replanning and can follow the global path in a more robust manner. The sequences and other situations can be observed in action in the supplementary video material.

Show All
B. Comparison with Conventional Navigation Systems

After evaluating our approaches against one another, we compare the navigation behavior of our joint navigation systems against model-based navigation systems MPC [21] and TEB [20] . Our joint systems includes the following: our proposed waypoint generators as intermediate planner, the kino A-star global planner, and a DRL-based local planner of our previous work [19] against the model-based navigation systems MPC [21] and TEB [20] . Throughout this paper, the notion previously used to denote the waypoint generators are used to denote the joint systems. The traditional navigation systems, consisting of the same kino A-star global planner and the model-based local planners MPC and TEB, are denoted as MPC and TEB respectively. The qualitative trajectories of all systems for an obstacle velocity of 0.3 m/s on all scenarios are illustrated in Fig. 7 . The intensity of the trajectories indicates their frequency. Results for all test runs are stated in Table I . Additionally, we plotted collision circles, which radius’ indicates the number of collisions.
Fig. 7: - Trajectories of all planners on different test scenarios with obstacle velocity vobs = 0:3m=s and 20 obstacles. Upper row: empty map, lower row: office map. (a) SUB-WP on the empty map (b) STH-WP on the empty map (c) LM-WP on the empty map (d) SUB-WP on the office map (e) STH-WP on the office map (f) LM-WP on the office map. The obstacles trajectories are visualized in black. Collisions are visualized as dots in the respective colors. The circle radius’ denotes the number of collisions (a larger radius means more collisions).
Fig. 7:

Trajectories of all planners on different test scenarios with obstacle velocity v obs = 0 : 3 m=s and 20 obstacles. Upper row: empty map, lower row: office map. (a) SUB-WP on the empty map (b) STH-WP on the empty map (c) LM-WP on the empty map (d) SUB-WP on the office map (e) STH-WP on the office map (f) LM-WP on the office map. The obstacles trajectories are visualized in black. Collisions are visualized as dots in the respective colors. The circle radius’ denotes the number of collisions (a larger radius means more collisions).

Show All
1) Safety and Robustness

It is observed that all navigation systems manage a robust collision avoidance and efficient navigation towards the goal for the scenarios with ve obstacles. With increasing number of obstacles, collisions increase which is evident in larger circles. Less collisions and thus smaller circles are observed for systems with our proposed LM-WP and STH-WP generators compared to TEB. Furthermore, the paths of our joint systems are more efficient compared to the TEB planner, which performs more roundabout paths. The model-based MPC planner accomplishes a similar performance in terms of path length and navigation efficiency. However, with more obstacles, the collisions increased (s. Fig. 7 (e) ). While SUB-WP manages to keep a competitive performance in maps with 5 obstacles, increased collisions occur in maps with 10 and 20 obstacles (s. 7 (e),(f)). In terms of collision rates and robustness, the LM-WP approach was best performing due to its replaning capability and long sight, which calculates the next waypoints online. This way, even in stuck situations the planner manages to nd a way out. In contrast, the SUB-WP method was stuck in hard situations when obstacles were constantly blocking the way. The STH-WP approach was limited in such situations as well. The quantitative results are listed in Table I and plotted in Fig. 8c. We evaluated the time to reach the goal, the path length, the number of collisions and the success rate for all navigation systems. Thereby, runs with less than three collisions are regarded as successful. Our LM-WP approach achieves the best overall performance in terms of collision and success rate accomplishing an average of 95.94%. This holds true for scenarios with increased obstacle count and velocities. Notably, the SUB-WP approach accomplishes a similar performance in maps with ve obstacles but experiencing a rapid decline in maps with 10 and 20 obstacles and v obs = 0 : 2 and 0 : 3 m=s accomplishing only 40.5 and 16.5% respectively. This decline in performance for scenarios with 10 and 20 obstacles is also evident for MPC and TEB achieving only over 68% success compared to 72.5% by our LM-WP.
2) Efficiency

In terms of efficiency, LM-WP achieves an overall average of 112.4 s as opposed to more then 142.74 s by the other approaches. The MPC system requires a smaller path of 28.44 m while requiring more time (avg. of 153.50 s). Similar to the success and collision rates, a decline in efficiency for all model-based planners can be noticed for scenarios with increased obstacle numbers and velocities. As stated in Table I , TEB and MPC require an average of 188.44 and 153.5 s respectively with an average path length of 30.12 and 28.44 meters respectively, whereas LM-WP, SUB-WP require 112.4 s and 142.74 s, while the average path length is 29.92 and 35.03 meters respectively. It is notable that although the TEB system accomplishes a short average path length, it took the longest time to reach the goal. This is because TEB tends to stop and wait once obstacles are approaching. Overall, our proposed joint systems using LM-WP and STH-WP achieve shorter trajectories and less collisions in scenarios with more than 10 obstacles and velocities higher than 0.2 m/s. Due to the DRL local planner of our approaches, obstacles can be avoided more efficiently.
TABLE I: Quantitative evaluations
Table I:- Quantitative evaluations
SECTION V.
Conclusion

In this paper, we proposed waypoint generators to connect DRL-based local planners with conventional global planners for long-range-navigation. Therefore, we propose two different methods: a spatial and time horizon based waypoint generator which calculates the waypoint based on the robots state and a build in replanning mechanism, and a landmark based waypoint generator, which generates waypoints while taking obstacle and robot positions and global information into consideration. We integrated our approaches into the ubiquitously used ROS navigation stack and combined traditional global planner with a DRL-based local planner from our previous work. We demonstrated the feasibility of our approach and compared it against model-based navigation systems. Results showed that our joint navigation systems outperform conventional systems in terms of safety and efficiency. Our ongoing work focuses on extensive evaluations in more complex maps like mazes or office buildings. Furthermore, we aspire to deploy a DRL-based waypoint generator which learns to spawn optimal waypoints using sensor observations.
- (c) Results from test-runs on (a) the empty map and (b) office map. (i) Collisions over number of obstacles and vobs, (ii) average time to reach goal over number of obstacles and vobs, (iii) Average path length over number of obstacles and vobs. (iv) Success over number of obstacles and vobs. With vobs = (0.1,0.2,0.3)m=s, while a high opacity indicates a lower velocity. (v) Collisions over obstacle velocities, (vi) average time to reach goal over obstacle velocities (lower is better), (vii) Path length over obstacle velocity. (viii) Success rate over obstacle velocity

(c) Results from test-runs on (a) the empty map and (b) office map. (i) Collisions over number of obstacles and v obs , (ii) average time to reach goal over number of obstacles and v obs , (iii) Average path length over number of obstacles and v obs . (iv) Success over number of obstacles and v obs . With v obs = (0.1,0.2,0.3) m=s , while a high opacity indicates a lower velocity. (v) Collisions over obstacle velocities, (vi) average time to reach goal over obstacle velocities (lower is better), (vii) Path length over obstacle velocity. (viii) Success rate over obstacle velocity

Show All
Appendix

The code is publicly available at https://github.com/ignc-research/arena-rosnav .

Authors
Figures
References
Keywords
Metrics
Media
   Back to Results   
More Like This
Deep reinforcement learning based mobile robot navigation: A review

Tsinghua Science and Technology

Published: 2021
Development of the Neural-Based Navigation System for a Ground-Based Mobile Robot

2021 7th International Conference on Mechatronics and Robotics Engineering (ICMRE)

Published: 2021
Show More
References
1. G. Fragapane, D. Ivanov, M. Peron, F. Sgarbossa and J. O. Strandhagen, "Increasing exibility and productivity in industry 4.0 production networks with autonomous mobile robots and smart intralogistics", Annals of operations research , pp. 1-19, 2020.
Show in Context CrossRef Google Scholar
2. M. B. Alatise and G. P. Hancke, "A review on challenges of autonomous mobile robot and sensor fusion methods", IEEE Access , vol. 8, pp. 39 830-39 846, 2020.
Show in Context View Article Full Text: PDF (5811) Google Scholar
3. A. Faust, K. Oslund, O. Ramirez, A. Francis, L. Tapia, M. Fiser, et al., "Prm-rl: Long-range robotic navigation tasks by combining reinforcement learning and sampling-based planning", 2018 IEEE International Conference on Robotics and Automation (ICRA) , pp. 5113-5120, 2018.
Show in Context View Article Full Text: PDF (1687) Google Scholar
4. H.-T. L. Chiang, A. Faust, M. Fiser and A. Francis, "Learning navigation behaviors end-to-end with autorl", IEEE Robotics and Automation Letters , vol. 4, no. 2, pp. 2007-2014, 2019.
Show in Context View Article Full Text: PDF (3311) Google Scholar
5. V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski et al., "Human-level control through deep reinforcement learning", nature , vol. 518, no. 7540, pp. 529-533, 2015.
Show in Context CrossRef Google Scholar
6. D. Dugas, J. Nieto, R. Siegwart and J. J. Chung, "Navrep: Unsupervised representations for reinforcement learning of robot navigation in dynamic human environments", arXiv preprint arXiv:2012.04406 , 2020.
Show in Context Google Scholar
7. Y. F. Chen, M. Liu, M. Everett and J. P. How, "Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning", 2017 IEEE international conference on robotics and automation (ICRA) , pp. 285-292, 2017.
Show in Context View Article Full Text: PDF (1111) Google Scholar
8. Y. F. Chen, M. Everett, M. Liu and J. P. How, "Socially aware motion planning with deep reinforcement learning", 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , pp. 1343-1350, 2017.
Show in Context View Article Full Text: PDF (3693) Google Scholar
9. M. Everett, Y. F. Chen and J. P. How, "Motion planning among dynamic decision-making agents with deep reinforcement learning", 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , pp. 3052-3059, 2018.
Show in Context View Article Full Text: PDF (2557) Google Scholar
10. S. Hochreiter and J. Schmidhuber, "Long short-term memory", Neural computation , vol. 9, no. 8, pp. 1735-1780, 1997.
Show in Context View Article Full Text: PDF (237) Google Scholar
11. C. Chen, S. Majumder, Z. Al-Halah, R. Gao, S. K. Ramakrishnan and K. Grauman, "Learning to set waypoints for audio-visual navigation", arXiv preprint arXiv:2008.09622 , vol. 1, no. 2, pp. 6, 2020.
Show in Context Google Scholar
12. C. Chen, U. Jain, C. Schissler, S. V. A. Gari, Z. Al-Halah, V. K. Ithapu, et al., "Soundspaces: Audio-visual navigation in 3d environments", Proceedings of the European Conference on Computer Vision (ECCV) , 2020.
Show in Context Google Scholar
13. S. Bansal, V. Tolani, S. Gupta, J. Malik and C. Tomlin, "Combining optimal control and learning for visual navigation in novel environments", Conference on Robot Learning , pp. 420-429, 2020.
Show in Context Google Scholar
14. R. Güldenring, M. Görner, N. Hendrich, N. J. Jacobsen and J. Zhang, "Learning local planners for human-aware navigation in indoor environments".
Show in Context View Article Full Text: PDF (4462) Google Scholar
15. P. Regier, L. Gesing and M. Bennewitz, "Deep reinforcement learning for navigation in cluttered environments", 2020.
Show in Context CrossRef Google Scholar
16. B. Zhou, F. Gao, L. Wang, C. Liu and S. Shen, "Robust and efficient quadrotor trajectory generation for fast autonomous ight", IEEE Robotics and Automation Letters , vol. 4, no. 4, pp. 3529-3536, 2019.
Show in Context View Article Full Text: PDF (3656) Google Scholar
17. K. Qin, "General matrix representations for b-splines", The Visual Computer , vol. 16, no. 3-4, pp. 177-186, 2000.
Show in Context Google Scholar
18. X. Zhou, Z. Wang, H. Ye, C. Xu and F. Gao, "Ego-planner: An esdf-free gradient-based local planner for quadrotors", IEEE Robotics and Automation Letters , 2020.
Show in Context Google Scholar
19. L. Kästner, C. Marx and J. Lambrecht, "Deep-reinforcement-learning-based semantic navigation of mobile robots in dynamic environments", 2020 IEEE 16th International Conference on Automation Science and Engineering (CASE) , pp. 1110-1115, 2020.
Show in Context View Article Full Text: PDF (1471) Google Scholar
20. C. Räsmann, F. Hoffmann and T. Bertram, "Timed-elastic-bands for time-optimal point-to-point nonlinear model predictive control", 2015 european control conference (ECC) , pp. 3352-3357, 2015.
Show in Context View Article Full Text: PDF (355) Google Scholar
21. C. Räsmann, "Time-optimal nonlinear model predictive control", Ph.D. dissertation Dissertation , 2019.
Show in Context Google Scholar
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | Privacy & Opting Out of Cookies

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

© Copyright 2022 IEEE - All rights reserved.
