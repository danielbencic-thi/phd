JavaScript needs to be enabled for this application to run correctly
This is the Enhanced Reader view. For maximum accessibility screen reader users should use the HTML format which is available on the article page for most content.

    Outline
    Cited by
    Figures (9)

1 / 21
Previous  PDF Next  PDF
Article start
International Journal of Applied Earth Observations and Geoinformation 102 (2021) 102456
Available online 27 July 2021
0303-2434/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license
(http://creativecommons.org/licenses/by-nc-nd/4.0/). A review on deep learning in UAV remote sensing
Lucas Prado Osco a , * , Jos ́ e Marcato Junior b , Ana Paula Marques Ramos c , d ,
Lúcio Andr ́ e de Castro Jorge e , Sarah Narges Fatholahi f , Jonathan de Andrade Silva g ,
Edson Takashi Matsubara g , Hemerson Pistori g , h , Wesley Nunes Gonçalves b , g , Jonathan Li f
a Faculty of Engineering and Architecture and Urbanism, University of Western S ̃ ao Paulo, Rod. Raposo Tavares, km 572 - Limoeiro, Pres. Prudente 19067-175, SP,
Brazil
b Faculty of Engineering, Architecture, and Urbanism and Geography, Federal University of Mato Grosso do Sul, Av. Costa e Silva, Campo Grande 79070-900, MS, Brazil
c Environment and Regional Development Program, University of Western S ̃ ao Paulo, Rod. Raposo Tavares, km 572 - Limoeiro, Pres. Prudente 19067-175, SP, Brazil
d Agronomy Program, University of Western S ̃ ao Paulo, Rod. Raposo Tavares, km 572 - Limoeiro, Pres. Prudente 19067-175, SP, Brazil
e National Research Center of Development of Agricultural Instrumentation, Brazilian Agricultural Research Agency, R. XV de Novembro, 1452, S ̃ ao Carlos 13560-970,
SP, Brazil
f Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada
g Faculty of Computing, Federal University of Mato Grosso do Sul, Av. Costa e Silva, Campo Grande 79070-900, MS, Brazil
h Inovis ̃ ao, Dom Bosco Catholic University, Av. Tamandar ́ e, 6000, Campo Grande 79117-900, MS, Brazil
A R T I C L E I N F O
Keywords:
Convolutional neural networks
Remote sensing imagery
Unmanned aerial vehicles
A B S T R A C T
Deep Neural Networks (DNNs) learn representation from data with an impressive capability, and brought
important breakthroughs for processing images, time-series, natural language, audio, video, and many others. In
the remote sensing field, surveys and literature revisions specifically involving DNNs algorithms ’ applications
have been conducted in an attempt to summarize the amount of information produced in its subfields. Recently,
Unmanned Aerial Vehicle (UAV)-based applications have dominated aerial sensing research. However, a liter -
ature revision that combines both “ deep learning ” and “ UAV remote sensing ” thematics has not yet been con -
ducted. The motivation for our work was to present a comprehensive review of the fundamentals of Deep
Learning (DL) applied in UAV-based imagery. We focused mainly on describing the classification and regression
techniques used in recent applications with UAV-acquired data. For that, a total of 232 papers published in
international scientific journal databases was examined. We gathered the published materials and evaluated their
characteristics regarding the application, sensor, and technique used. We discuss how DL presents promising
results and has the potential for processing tasks associated with UAV-based image data. Lastly, we project future
perspectives, commentating on prominent DL paths to be explored in the UAV remote sensing field. This revision
consisting of an approach to introduce, commentate, and summarize the state-of-the-art in UAV-based image
applications with DNNs algorithms in diverse subfields of remote sensing, grouping it in the environmental,
urban, and agricultural contexts.
Abbreviations: AdaGrad, Adaptive Gradient Algorithm; AI, Artificial Intelligence; ANN, Artificial Neural Network; CEM, Context Enhanced Module; CNN, Con -
volutional Neural Network; DCGAN, Deep Convolutional Generative Adversarial network; DDCN, Deep Dual-domain Convolutional neural Network; DL, Deep
Learning; DNN, Deep Neural Network; DEM, Digital Elevation Model; DSM, Digital Surface Model; FPS, Frames per Second; GAN, Generative Adversarial Network;
GPU, Graphics Processing Unit; KL, Kullback-Leibler; LSTM, Long Short-Term Memory; IoU, Intersection over Union; ML, Machine Learning; MAE, Mean Absolute
Error; MAPE, Mean Absolute Percentage Error; MRE, Mean Relative Error; MSE, Mean Squared Error; MSLE, Mean Squared Logarithmic Error; MSM, Multi-Stage
Module; MVS, Multiview Stereo; NAS, Network Architecture Search; PCA, Principal Component Analysis; PPM, Pyramid Pooling Module; r, Correlation Coefficient;
RMSE, Root Mean Squared Error; RNN, Recurrent Neural Network; ROC, Receiver Operating Characteristics; RPA, Remotely Piloted Aircraft; SAM, Spatial Attention
Module; SGD, Stochastic Gradient Descent; SfM, Structure from Motion; UAV, Unmanned Aerial Vehicle; WOS, Web of Science.
* Corresponding author.
E-mail addresses: lucasosco@unoeste.br (L.P. Osco), jose.marcato@ufms.br (J. Marcato Junior), anaramos@unoeste.br (A.P. Marques Ramos), lucio.jorge@
embrapa.br (L.A. de Castro Jorge), nfatholahi@uwaterloo.ca (S.N. Fatholahi), jonathan.andrade@ufms.br (J. de Andrade Silva), edsontm@facom.ufms.br
(E.T. Matsubara), pistori@ucdb.br (H. Pistori), wesley.goncalves@ufms.br (W.N. Gonçalves), junli@uwaterloo.ca (J. Li).
Contents lists available at ScienceDirect
International Journal of Applied Earth
Observations and Geoinformation
journal homepage: www.elsevier.com/locate/jag
https://doi.org/10.1016/j.jag.2021.102456
Received 22 January 2021; Received in revised form 30 June 2021; Accepted 17 July 2021
Lucas Prado Osco
Jos
e Marcato Junior
Ana Paula Marques Ramos
Lúcio Andr
e de Castro Jorge
Sarah Narges Fatholahi
Jonathan de Andrade Silva
Edson Takashi Matsubara
Hemerson Pistori
Wesley Nunes Gonçalves
Jonathan Li
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
2 1. Introduction
For investigations using remote sensing image data, multiple pro -
cessing tasks depend on computer vision algorithms. In the past decade,
applications conducted with statistical and Machine Learning (ML) al -
gorithms were mainly used in classification/regression tasks. The in -
crease of remote sensing systems allowed a wide collection of data from
any target on the Earth ’ s surface. Aerial imaging has become a common
approach to acquiring data with the advent of Unnamed Aerial Vehicles
(UAV). These are also known as Remotely Piloted Aircrafts (RPA), or, as
a commonly adopted term, drones (multi-rotor, fixed wings, hybrid,
etc). These devices have grown in market availability for their relatively
low cost and high operational capability to capture images quickly and
in an easy manner. The high-spatial-resolution of UAV-based imagery
and its capacity for multiple visits allowed the creation of large and
detailed amounts of datasets to be dealt with.
The surface mapping with UAV platforms presents some advantages
compared to orbital and other aerial sensing methods of acquisition. Less
atmospheric interference, the possibility to fly within lower altitudes,
and mainly, the low operational cost have made this acquisition system
popular in both commercial and scientific explorations. However, the
visual inspection of multiple objects can still be a time-consuming,
biased, and inaccurate operation. Currently, the real challenge in
remote sensing approaches is to obtain automatic, rapid, and accurate
information from this type of data. In recent years, the advent of Deep
Learning (DL) techniques has offered robust and intelligent methods to
improve the mapping of the Earth ’ s surface.
DL is an Artificial Neural Network (ANN) method with multiple
hidden layers and deeper combinations, which is responsible for opti -
mizing and returning better learning patterns than a common ANN.
There is an impressive amount of revision material in the scientific
journals explaining DL-based techniques, its historical evolution, gen -
eral usage, as well as detailing networks and functions. Highly detailed
publications, such as Lecun (Lecun et al., 2015) and Goodfellow
(Goodfellow et al., 2016) are both considered important material in this
are. As computer processing and labeled examples (i.e. samples) became
more available in recent years, the performance of Deep Neural Net -
works (DNNs) increased in the image-processing applications. DNN has
been successfully applied in data-driven methods. However, much needs
to be covered to truly understand its potential, as well as its limitations.
In this regard, several surveys on the application of DL in remote sensing
were developed in both general and specific contexts to better explain its
importance.
The context in which remote sensing literature surveys are presented
is variated. Zhang et al. (2016) organized a revision material which
explains how DL methods were being applied, at the time, to image
classification tasks. Later, Cheng and Han (2016) investigated object
detection in optical images, but focused more on the traditional ANN
and ML. A complete and systematic review was presented by Ball et al.
(2017) in a survey describing DL theories, tools, and its challenges in
dealing with remote sensing data. Cheng et al. (2017) produced a
revision on image classification with examples produced at their ex -
periments. Also, focusing on classification, Zhu et al. (2017) summa -
rized most of the current information to understand the DL methods
used for this task. Additionally, a survey performed by Li et al. (2018)
helped to understand some DL applications regarding the overall per -
formance of DNNs in publicly available datasets for image classification
task. Yao et al. (2018) stated in their survey that DL will become the
dominant method of image classification in remote sensing community.
Although DL does provide promising results, many observations and
examinations are still required. Interestingly enough, multiple remote
sensing applications using hyperspectral imagery (HSI) data were in the
process, which gained attention. In Petersson et al. (2017), probably one
of the first surveys on hyperspectral data was performed. In (Signoroni
et al., 2019), is presented a multidisciplinary review about how DL
models have been widely used in the field of HSI dataset processing.
These authors highlighted that, among the distinct areas of applications,
remote sensing approaches are one of the most emerging. Regarding the
use of DL models to process highly detailed remotely sensed HSI data,
Signoroni et al. (2019) summarized usage into classification tasks, object
detection, semantic segmentation, and data enhancement, such as
denoising, spatial super-resolution, and fusion. Ado et al. (2020) present
a recent review on hyperspectral imaging acquired by UAV-based sen -
sors for agriculture and forestry applications, and show that there are
manifold DL approaches to deal with HSI dataset complexity.
A more recent survey is presented by Jia et al. (2021) regarding DL
for hyperspectral image classification considering few labeled samples.
They commentate how there is a notable gap between deep learning
models and HSI datasets because DL models usually need sufficient
labeled samples, but it is generally difficult to acquire many samples in
HSI dataset due to the difficulty and time-consuming nature of manual
labeling. However, the issues of small-sample sets may be well defined
by the fusion of deep learning methods and related techniques, such as
transfer learning and a lightweight model. Deep learning is also a new
approach for the domain of infrared thermal imagery processing to
attend different domains, especially in satellite-provided data. Some of
these applications are the usage of convolutional layers to detect pot -
holes on roads with terrestrial imagery (Aparna et al., 2019), detection
of land surface temperatures from combined multispectral and micro -
wave observations from orbital platforms (Wang et al., 2020b), or
determining sea surface temperature patterns to identify ocean tem -
peratures extremes (Xavier Prochaska et al., 2021) from orbital imagery.
Yet in the literature revision theme, a comparative review by
Audebert et al. (2019) was conducted by examining various families of
networks ’ architectures while providing a toolbox to perform such
methods to be publicly available. In this regard, another paper written
by Paoletti et al. (2019) organized the source code of DNNs to be easily
reproduced. Similar to Cheng et al. (2017), Li et al. (2019a) conducted a
literature revision while presenting an experimental analysis with
DNNs ’ methods. As of recently, literature revision focused on more
specific approaches within this theme. Some of which included DL
methods for enhancement of remote sensing observations, as super-
resolution, denoising, restoration, pan-sharpening, and image fusion
techniques, as demonstrated by Tsagkatakis et al. (2019) and Signoroni
et al. (2019). Also, a meta-analysis by Ma et al. (2019) was performed
concerning the usage of DL algorithms in seven subfields of remote
sensing: image fusion and image registration, scene classification, object
detection, land use and land cover classification, semantic segmenta -
tion, and object-based image analysis (OBIA).
Although, from these recent reviews, various remote sensing appli -
cations using DL can be verified, it should be noted that the authors did
not focus on specific surveying in the context of DL algorithms applied to
UAV-image sets, which is something that, at the time of writing, has
gained the attention of remote sensing investigations. We verified in the
literature that, in general, similar DL methods are used for imagery ac -
quired at different levels, resolutions and domains, such as the ones from
orbital, aerial, terrestrial and proximal sensing platforms. However, as
of recently, some of the proposed deep neural networks are maintaining
high resolution images into deeper layers (Kannojia and Jaiswal, 2018).
This type of deep networks may benefit from UAV-based data, taking
advantage of its resolutions. Indeed, there are orbital images with high
spatial resolutions, but these are not as commonly available to the
general public as UAV-based images. Because of that, these kinds of
architectures associated with UAV-based data may be a surging trend in
remote sensing applications.
Another interesting take on DL-based methods was related to image
segmentation in a survey by Hossain and Chen (2019), which its theme
was expanded by Yuan et al. (2021) and included state-of-the-art algo -
rithms. A summarized analysis by Zheng et al. (2020) focused on remote
sensing images with object detection approaches, indicating some of the
challenges related to the detection with few labeled samples, multi-scale
issues, network structure problems, and cross-domain detection
L.P. Osco et al.
Lecun
et
al.,
2015
Goodfellow et al., 2016
Zhang et al. (2016)
Cheng and Han (2016)
Ball et al.
(2017)
Cheng et al. (2017)
Zhu et al. (2017)
Li et al. (2018)
Yao et al. (2018)
Petersson et al. (2017)
Signoroni
et al., 2019
Signoroni et al. (2019)
Ado et al. (2020)
Jia et al. (2021)
Aparna et al., 2019
Wang et al., 2020b
Xavier Prochaska et al., 2021
Audebert et al. (2019)
Paoletti et al. (2019)
Cheng et al. (2017), Li et al. (2019a)
Tsagkatakis et al. (2019)
Signoroni
et al. (2019)
Ma et al. (2019)
Kannojia and Jaiswal, 2018
Hossain and Chen (2019)
Yuan et al. (2021)
Zheng et al. (2020)
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
3 difficulties. In more of a “ niche ” type of research, environmental ap -
plications and land surface change detection were investigated in liter -
ature revision papers by Yuan et al. (2020) and Khelifi and Mignotte
(2020), respectively.
The aforementioned studies were evaluated with a text processing
method that returned a word cloud in which the word size denotes the
frequency of the word within these papers (Fig. 1). An interesting
observation regarding this world-cloud is that the term “ UAV ” is under
or not represented at all. This revision gap is a problem since UAV image
data is daily produced in large amounts, and no scientific investigation
appears to offer a comprehensive literature revision to assist new
research on this matter. In the UAV context, there are some revision
papers published in important scientific journals from the remote
sensing community. As of recently, a revision-survey (Bithas et al.,
2019) focused on the implications of ML methods being applied to UAV
image processing, but no investigation was conducted on DL algorithms
for this particular issue. This is an important theme, especially since
UAV platforms are more easily available to the public and DL-based
methods are being tested to provide accurate mapping in highly
detailed imagery.
As mentioned, UAVs offer flexibility in data collection, as flights are
programmed under users ’ demand; they are low-cost when compared to
other platforms that offer similar spatial-resolution images; produce
high-level of detail in its data collection; presents dynamic data char -
acteristics since it is possible to embed RGB, multispectral, hyper -
spectral, thermal and, LiDAR sensors on it; and are capable of gathering
data from difficult to access places. Aside from that, sensors embedded
in UAVs are known to generate data at different altitudes and point-of-
views. These characteristics, alongside others, are known to produce a
higher dynamic range of images than common sensing systems. This
ensures that the same object is viewed from different angles, where not
only their spatial and spectral information is affected, as well as form,
texture, pattern, geometry, illumination, etc. This becomes a challenge
for multidomain detection. As such, studies indicate that DL is the most
prominent solution for dealing with these disadvantages. These studies,
which most are presented in this revision paper, were conducted within
a series of data criteria and evaluated DL architectures in classifying,
detecting, and segmenting various objects from UAV scenes.
To the best of our knowledge, there is a literature gap related to
review articles combining both “ deep learning ” and “ UAV remote
sensing ” thematics. This survey is important to summarize the direction
of DL applications in the remote sensing community, particularly related
to UAV-imagery. The purpose of this study is to provide a brief review of
DL methods and their applications to solve classification, object detec -
tion, and semantic segmentation problems in the remote sensing field.
Herein, we discuss the fundamentals of DL architectures, including
recent proposals. There is no intention of summarizing existing litera -
ture, but to present an examination of DL models while offering the
necessary information to understand the state-of-the-art in which it
encounters. Our revision is conducted highlighting traits about the UAV-
based image data, their applications, sensor types, and techniques used
in recent approaches in the remote sensing field. Additionally, we relate
how DL models present promising results and project future perspectives
of prominent paths to be explored. In short, this paper brings the
following contributions:
1. A presentation of fundamental ideas behind the DL models, including
classification, object detection, and semantic segmentation ap -
proaches; as well as the application of these concepts to attend UAV-
image based mapping tasks;
2. The examination of published material in scientific sources regarding
sensors types and applications, categorized in environmental, urban,
and agricultural mapping contexts;
3. The organization of publicly available datasets from previous re -
searches, conducted with UAV-acquired data, also labeled for both
object detection and segmentation tasks;
4. A description of the challenges and future perspectives of DL-based
methods to be applied with UAV-based image data.
2. Deep neural networks overview
DNNs are based on neural networks which are composed of neurons
(or units) with certain activations and parameters that transform input
data (e.g., UAV remote sensing image) to outputs (e.g., land use and land
cover maps) while progressively learning higher-level features (Ma
et al., 2019; Schmidhuber, 2015). This progressive feature learning oc -
curs, among others, on layers between the input and the output, which
are referred to as hidden layers (Ma et al., 2019). DNNs are considered as
Fig. 1. Word-cloud of different literature-revision papers related to the “ remote sensing ” and “ deep learning ” themes.
L.P. Osco et al.
Yuan et al. (2020)
Khelifi and Mignotte
(2020)
Fig. 1
Bithas et al.,
2019
Ma
et al., 2019
Schmidhuber, 2015
Ma et al., 2019
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
4 a DL method in their most traditional form (i.e. with 2 or more hidden
layers). Their concept, based on an Artificial Intelligence (AI) modeled
after the biological neurons ’ connections, exists since the 1950s. But
only later, with advances in computer hardware and the availability of a
high number of labeled examples, its interest has resurged in major
scientific fields. In the remote sensing community, the interest in DL
algorithms has been gaining attention since mid 2010s decade, specif -
ically because these algorithms achieved significant success at digital
image processing tasks (Ma et al., 2019; Khan et al., 2020).
A DNN works similarly to an ANN, when as a supervised algorithm,
uses a given number of input features to be trained, and that these
feature observations are combined through multiple operations, where a
final layer is used to return the desired prediction. Still, this explanation
does not do much to highlight the differences between traditional ANNs
and DNNs. LeCun et. al. (Lecun et al., 2015), the paper amongst the most
cited articles in DL literature, defines DNN as follows: “ Deep-learning
methods are representation-learning methods with multiple levels of
representation ” . Representation-learning is a key concept in DL. It al -
lows the DL algorithm to be fed with raw data, usually unstructured data
such as images, texts, and videos, to automatically discover
representations.
The most common DNNs (Fig. 2) are generally composed of dense
layers, wherein activation functions are implemented in. Activation
functions compute the weighted sum of input and biases, which is used
to decide if a neuron can be activated or not (Nwankpa et al., 2018).
These functions constitute decision functions that help in learning
intrinsic patterns (Khan et al., 2020); i.e., they are one of the main as -
pects of how each neuron learns from its interaction with the other
neurons. Known as a piecewise linear function type, ReLu defines the
0 valor for all negative values of X. This function is, at the time of
writing, the most popular in current DNNs models. Regardless, another
potential activation function recently explored is Mish, a self regularized
non-monotonic activation function (Khan et al., 2020). Aside from the
activation function, another important information on how a DNN
works is related to its layers, such as dropout, batch-normalization,
convolution, deconvolution, max-pooling, encode-decode, memory
cells, and others. This layer is regularly used to solve issues with
covariance-shift within feature-maps (Khan et al., 2020). The organi -
zation in which the layers are composed, as well as its parameters, is one
of the main aspects of the architecture.
Multiple types of architectures were proposed in recent years to
improve and optimize DNNs by implementing different kinds of layers,
optimizers, loss functions, depth-level, etc. However, it is known that
one of the major reasons behind DNNs ’ popularity today is also related
to the high amount of available data to learn from it. A rule of thumb
conceived among data scientists indicates that at least 5,000 labeled
examples per category was recommended (Goodfellow et al., 2016). But,
as of today, DNNs ’ proposals focused on improving these network ’ s
capacities to predict features with fewer examples than that. Some ap -
plications which are specifically oriented may benefit from it, as it re -
duces the amount of labor required at sample collection by human
inspection. Even so, it should be noted that, although this pursuit is
being conducted, multiple takes are performed by the vision computer
communities and novel research includes methods for data-
augmentation, self-supervising, and unsupervised learning strategies,
as others. A detailed discussion of this manner is presented in (Khan
et al., 2020).
2.1. Convolutional and recurrent neural networks
A DNN can be formed by different architectures, and the complexity
of the model is related to how each layer and additional computational
method is implemented. Different DL architectures are proposed regu -
larly, Convolutional Neural Networks (CNN), Recurrent Neural Net -
works (RNN), and Deep Belief Networks (DBN) (Ball et al., 2017), and,
more recently yet, Generative Adversarial Networks (GAN) (Goodfellow
et al., 2016). However, the most common DNNs in the supervised net -
works categories are usually classified as CNNs (Fig. 3) and RNNs (Khan
et al., 2020).
As a different kind of DL network structure, RNNs refer to another
supervised learning model. The main idea behind implementing RNNs
regards their capability of improving their learning by repetitive ob -
servations of a given phenom or object, often associated with a time-
series collection. A type of RNN being currently implemented in multi -
ple tasks is the Long Short-Term Memory (LSTM)(Hochreiter and
Schmidhuber, 1997). In the remote sensing field, RNN models have been
applied to deal with time series tasks analysis, aiming to produce, for
example, land cover mapping (Ienco et al., 2017; Ho Tong Minh et al.,
Fig. 2. A DNN architecture. This is a simple example of how a DNN may be built. Here the initial layer (X input ) is composed of the collected data samples. Later this
data information can be extracted by hidden layers in a back-propagation manner, which is used by subsequent hidden layers to learn these features ’ characteristics.
In the end, another layer is used with an activation function related to the given problem (classification or regression, as an example), by returning a prediction
outcome (Y label ).
L.P. Osco et al.
Ma et al., 2019
Khan et al., 2020
Lecun et al., 2015
Fig. 2
Nwankpa et al., 2018
Khan et al., 2020
Khan et al., 2020
Khan et al., 2020
Goodfellow et al., 2016
Khan
et al., 2020
Ball et al., 2017
Goodfellow
et al., 2016
Fig. 3
Khan
et al., 2020
Hochreiter
and
Schmidhuber, 1997
Ienco et al., 2017
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
5 2018). For a pixel-based time series analysis aiming to discriminate
classes of winter vegetation coverage using SAR Sentinel-1 (Ho Tong
Minh et al., 2018), it was verified that RNN models outperformed clas -
sical ML approaches. A recent approach (Feng et al., 2020) for accurate
vegetation mapping combined multiscale CNN to extract spatial features
from UAV-RGB imagery and then fed an attention-based RNN to
establish the sequential dependency between multitemporal features.
The aggregated spatial-temporal features are used to predict the
vegetable category. Such examples with remote sensing data demon -
strate the potential in which RNNs are being used. Also, one prominent
type of architecture is the CNN-LSTM method (Fig. 4). This network uses
convolutional layers to extract important features from the given input
image and feed the LSTM. Although few studies implemented this type
of network, it should be noted that it serves specific purposes, and its
usage, for example, can be valued for multitemporal applications.
As aforementioned, other types of neural networks, aside from CNNs
Fig. 3. A CNN type of architecture with convolution and deconvolution layers. This example architecture is formed by convolutional layers, where a dropout layer is
added between each conv layer, and a max-pooling layer is adopted each time the convolution window-size is decreased. By the end of it, a deconvolutional layer is
used with the same size as the last convolutional, and then it uses information from the previous step to reconstruct the image with its original size. The final layer is
of a softmax, where it returns the models ’ predictions.
Fig. 4. An example of a neural network based on the CNN-LSTM type of architecture. The input image is processed with convolutional layers, and a max-pooling
layer is used to introduce the information to the LSTM. Each memory cell is updated with weights from the previous cell. After this process, one may use a flatten
layer to transform the data in an arrangement to be read by a dense (fully-connected) layer, returning a classification prediction, for instance.
L.P. Osco et al.
Ho Tong
Minh et al., 2018
Feng et al., 2020
Fig. 4
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
6 and RNNs, are currently being proposed to also deal with an image type
of data. GANs are amongst the most innovative unsupervised DL models.
GANs are composed of two networks: generative and discriminative,
that contest between themselves. The generative network is responsible
for extracting features from a particular data distribution of interest, like
images, while the discriminative network distinguishes between real
(reference or ground truth data) and those data generated by the
generative part of GANs (fake data) (Goodfellow et al., 2014; Ma et al.,
2019). Recently approaches in the image processing context like the
classification of remote sensing images (Lin et al., 2017a) and image-to-
image translation problems solution (Isola et al., 2018) adopted GANs as
DL model, obtaining successful results.
In short, several DNNs are constantly developed, in both scientific
and/or image competition platforms, to surpass existing methods.
However, as each year passes, some of these neural networks are often
mentioned, remembered, or even improved by novel approaches. A
summary of well-known DL methods built in recent years is presented in
Fig. 5. A detailed take on this, which we recommend to anyone inter -
ested, is found in Khan et al. (2020). Alongside the creations and de -
velopments of these and others, researchers observed that higher depth
channel exploration, and, as of recently proposed, attention-based
feature extraction neural networks, are regarded as some of the most
prominent approaches for DL. Initially, most of the proposed supervised
DNNs, like CNN and RNN, or CNN-LSTM models, were created to
perform and deal with specific issues. Often, these approaches can be
grouped into classification tasks, like scene-wise classification, object
Fig. 5. A DL time-series indicating some popular architectures implemented in image classification (yellowish color), object detection (greenish color), and seg -
mentation (bluish color). These networks often intertwine, and many adaptations have been proposed for them. Although it may appear that most of the DL methods
were developed during 2015 – 2017 annuals, it is important to note that, as some, novel deep networks use most of the already developed methods as backbones, or
accompanied from other types of architectures, mainly used as the feature extraction part of a much more complex structure.
L.P. Osco et al.
Goodfellow et al., 2014
Ma et al.,
2019
Lin et al., 2017a
Isola et al., 2018
Fig. 5
Khan et al. (2020)
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
7 detection, semantic and instance segmentation (pixel-wise), and
regression tasks.
2.2. Classification and regression approaches
When considering remote sensing data processed with DL-based al -
gorithms, the following tasks can be highlighted: scene-wise classifica -
tion, semantic and instance segmentation, and object detection. Scene-
wise classification involves assigning a class label to each image (or
patch), while the object detection task aims to draw bounding boxes
around objects in an image (or patch) and labeling each of them ac -
cording to the class label. Object detection can be considered a more
challenging task since it requires to locate the objects in the image and
then perform their classification. Another manner to detect objects in an
image, instead of drawing bounding boxes, is to draw regions or struc -
tures around the boundary of objects, i.e., distinguish the class of the
object at the pixel level. This task is known as semantic segmentation.
However, in semantic segmentation, it is not possible to distinguish
multiple objects of the same category, as each pixel receives one class
label (Wu et al., 2020b). To overcome this drawback, a task that com -
bines semantic segmentation and object detection named instance seg -
mentation was proposed to detect multiple objects in pixel-level masks
and labeling each mask with a class label (Thoma, 2016; Chen et al.,
2016). The instance segmentation, however, consists of a method that,
while classifying the image with this pixel-wise approach, is able to
individualize objects (Sharma and Mir, 2020).
To produce a deep regression approach, the model needs to be
adapted so that the last fully-connected layer of the architecture is
changed to deal with a regression problem instead of a common classi -
fication one. With this adaptation, continuous values are estimated,
differently from classification tasks. In comparison to classification, the
regression task using DL is not often used; however, recent publications
have shown its potential in remote sensing applications. One approach
(Lathuilire et al., 2020) performed a comprehensive analysis of deep
regression methods and pointed out that well-known fine-tuned net -
works, like VGG-16 (Simonyan and Zisserman, 2015) and ResNet-50 (He
et al., 2016), can provide interesting results. These methods, however,
are normally developed for specific applications, which is a drawback
for general-purpose solutions. Another important point is that depend -
ing on the application, not always deep regression succeeds. A strategy is
to discretize the output space and consider it as a classification solution.
For UAV remote sensing applications, the strategy of using well-known
networks is in general adopted. Not only VGG-16 and ResNet-50, as
investigated by (Lathuilire et al., 2020), but also other networks
including AlexNet (Krizhevsky et al., 2012) and VGG-11 have been used.
An important issue that could be investigated in future research,
depending on the application, is the optimizer. Algorithms with adap -
tive learning rates such as AdaGrad, RMSProp, AdaDelta (an extension
of AdaGrad), and Adam are among the commonly used.
2.2.1. Scene-wise classification, object detection, and segmentation
Scene-wise classification or scene recognition refers to methods that
associate a label/theme for one image (or patch) based on numerous
images, such as in agricultural scenes, beach scenes, urban scenes, and
others (Zou et al., 2015; Ma et al., 2019). Basic DNNs methods were
developed for this task, and they are among the most common networks
for traditional image recognition tasks. In remote sensing applications,
scene-wise classification is not usually applied. Instead, most applica -
tions benefit more from object detection and pixel-wise semantic seg -
mentation approaches. For scene-wise classification, the method needs
only the annotation of the class label of the image, while other tasks like
object detection method needs a drawn of a bounding box for all objects
in an image, which makes it more costly to build labeled datasets. For
instance or semantic segmentation, the specialist (i.e., the person who
performs the annotation or object labeling) needs to draw a mask
involving each pixel of the object, which needs more attention and
precision in the annotation task, reducing, even more, the availability of
datasets. Fig. 6 shows the examples of both annotation approaches
(object detection and instance segmentation).
Object detection methods can be described into two mainstream
categories: one-stage detectors (or regression-based methods) and two-
stage detectors (or region proposal-based methods) (Zhao et al., 2019;
Liu et al., 2019; Wu et al., 2020b). The usual two-stage object detection
pipeline is to generate region proposals (candidate rectangular bound -
ing boxes) on the feature map. It then classifies each one into an object
class label and refines the proposals with a bounding box regression. A
widely used strategy in the literature to generate proposals was pro -
posed with the Faster-RCNN algorithm with the Region Proposal
Network (RPN) (Zhao et al., 2019). Other state-of-the-art representa -
tives of such algorithms are Cascade-RCNN (Cai and Vasconcelos, 2018),
Trident-Net (Li et al., 2019), Grid-RCNN (Lu et al., 2019), Dynamic-
RCNN (Zhang et al., 2020b), DetectoRS (Qiao et al., 2020). As for one-
stage detectors, they directly make a classification and detect the loca -
tion of objects without a region proposal classification step. This reduced
component achieves a high detection speed for the models but tends to
reduce the accuracy of the results. These are known as region-free de -
tectors since they typically use cell grid strategies to divide the image
and predict the class label of each one. Besides that, some detectors may
serve for both one-stage and two-stage categories.
Object detection-based methods can be described in three compo -
nents: a) backbone, which is responsible to extract semantic features
from images; b) the neck, which is an intermediate component between
the backbone and the head components, used to enrich the features
obtained by the backbone, and; c) head component, which performs the
detection and classification of the bounding boxes.
The backbone is a CNN that receives as input an image and outputs a
feature map that describes the image with semantically features. In the
DL, the state-of-the-art is composed of the following backbones: VGG
(Simonyan and Zisserman, 2015), ResNet (He et al., 2016), ResNeXt (Xie
et al., 2017), HRNet (Wang et al., 2020), RegNet (Radosavovic et al.,
2020), Res2Net (Gao et al., 2021), and ResNesT (Zhang et al., 2020d).
The neck component combines in several scales low-resolution and
semantically strong features, capable of detecting large objects, with
high-resolution and semantically weak features, capable of detecting
small objects, which is done with the lateral and top-down connections
of the convolutional layers of the Feature Pyramid Network (FPN) (Lin
et al., 2017b), and its variants like PAFPN (Liu et al., 2018) and NAS-
FPN (Ghiasi et al., 2019). Although FPN was originally designed to be
a two-stage method, the methods ’ purpose was a manner to use the FPN
on single-stage detectors by removing RPN and adding a classification
subnet and a bounding box regression subnet. The head component is
responsible for the detection of the objects with the softmax classifica -
tion layer, which produces probabilities for all classes and a regression
layer to predict the relative offset of the bounding box positions with the
ground truth.
Despite the differences in object detectors (one or two-stage), their
universal problem consists of dealing with a large gap between positive
samples (foreground) and negative samples (background) during
training, i.e. class imbalance problem that can deteriorate the accuracy
results (Chen et al., 2020). In these detectors, the candidate bounding
boxes can be represented into two main classes: positive samples, which
are bounding boxes that match with the ground-truth, according to a
metric; and negative samples, which do not match with the ground-
truth. In this sense, a non-max suppression filter can be used to refine
these dense candidates by removing overlaps to the most promising
ones. The Libra-RCNN (Pang et al., 2019), ATSS (Zhang et al., 2019c),
Guided Anchoring (Wang et al., 2019), FSAF (Zhu et al., 2019a), PAA
(Kim and Lee, 2020), GFL (Li et al., 2020a), PISA (Cao et al., 2020) and
VFNet (Zhang et al., 2020c) detectors explore different sampling stra -
tegies and new loss metrics to improve the quality of selected positive
samples and reduce the weight of the large negative samples.
Another theme explored in the DL literature is the strategy of
L.P. Osco et al.
Wu et al., 2020b
Thoma, 2016
Chen et al.,
2016
Sharma and Mir, 2020
Lathuilire et al., 2020
Simonyan and Zisserman, 2015
He
et al., 2016
Lathuilire
et
al.,
2020
Krizhevsky et al., 2012
Zou et al., 2015
Ma et al., 2019
Fig. 6
Zhao et al., 2019
Liu et al., 2019
Wu et al., 2020b
Zhao et al., 2019
Cai and Vasconcelos, 2018
Li et al., 2019
Lu et al., 2019
Zhang et al., 2020b
Qiao et al., 2020
Simonyan and Zisserman, 2015
He et al., 2016
Xie
et al., 2017
Wang et al., 2020
Radosavovic et al.,
2020
Gao et al., 2021
Zhang et al., 2020d
Lin
et al., 2017b
Liu et al., 2018
Ghiasi et al., 2019
Chen et al., 2020
Pang et al., 2019
Zhang et al., 2019c
Wang et al., 2019
Zhu et al., 2019a
Kim and Lee, 2020
Li et al., 2020a
Cao et al., 2020
Zhang et al., 2020c
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
8 encoding the bounding boxes, which influences the accuracy of the one-
stage detectors as they do not use region proposal networks (Zhang
et al., 2020c). In this report (Zhang et al., 2020c), the authors represent
the bounding boxes like a set of representatives or key-points and find
the farthest top, bottom, left, and right points. CenterNet (Duan et al.,
2019) detects the object center point instead of using bounding boxes,
while CornerNet (Law and Deng, 2020) estimates the top-left corner and
the bottom-right corner of the objects. SABL (Wang et al., 2020a) uses a
chunk based strategy to discretize horizontally and vertically the image
and estimate the offset of each side (bottom, up, left, and right). The
VFNet (Zhang et al., 2020c) method proposes a loss function and a star-
shaped bounding box (described by nine sampling points) to improve
the location of objects.
Regarding semantic segmentation and instance segmentation ap -
proaches, they are generally defined as a pixel-level classification
problem (Minaee et al., 2020). The main difference between semantic
and instance is that the former one is capable to identify pixels belonging
to one class but can not distinguish objects of the same class in the
image. However, instance segmentation approaches can not distinguish
overlapping of different objects, since they are concerned with identi -
fying objects separately. For example, it may be problematic to identify
in an aerial urban image the location of the cars, trucks, motorcycle, and
the asphalt pavement which consists of the background or region in
which the other objects are located. To unify these two approaches, a
method was recently proposed in (Kirillov et al., 2019), named panoptic
segmentation. With panoptic segmentation, the pixels that are contained
in uncountable regions (e.g. background) receive a specific value indi -
cating it.
Considering the success of the RPN method for object detection,
some variants of Faster R-CNN were considered to instance segmenta -
tion as Mask R-CNN (He et al., 2017), which in parallel to bounding box
regression branch add a new branch to predict the mask of the objects
(mask generation). The Cascade Mask R-CNN (Cai and Vasconcelos,
2019) and HTC (Chen et al., 2019) extend Mask R-CNN to refine in a
cascade manner the object localization and mask estimation. The
PointRend (Kirillov et al., 2020) is a point-based method that reformu -
lates the mask generation branch as a rendering problem to iteratively
select points around the contour of the object. Regarding semantic
segmentation, methods like U-Net (Ronneberger et al., 2015), SegNet
(Badrinarayanan et al., 2017), DeepLabV3 + (Chen et al., 2018), and
Deep Dual-domain Convolutional Neural Network (DDCN) (Nogueira
et al., 2019) have also been regularly used and adapted for recent remote
sensing investigations (Nogueira et al., 2020). Another important
remote sensing approach that is been currently investigated is the seg -
mentation of objects considering sparse annotations (Hua et al., 2021).
Still, as of today, the CGnet (Wu et al., 2020a) and DLNet (Yin et al.,
2020) are considered the state-of-art methods for semantic
segmentation.
3. Deep learning in UAV imagery
To identify works related to DL in UAV remote sensing applications,
we performed a search in the Web of Science (WOS) and Google Scholar
databases. WOS is one of the most respected scientific databases and
hosts a high number of scientific journals and publications. We con -
ducted a search using the following string in the WOS: ( “ TS = ((deep
learning OR CNN OR convolutional neural network) AND (UAV OR
unmanned aerial vehicle OR drone OR RPAS) AND (remote sensing OR
Fig. 6. Labeled examples. The first-row consists of a bounding-box type of object detection approach label-example to identify individual tree-species in an urban
environment. The second-row is a labeled-example of instance segmentation to detect rooftops in the same environment.
L.P. Osco et al.
Zhang
et al., 2020c
Zhang et al., 2020c
Duan et al.,
2019
Law and Deng, 2020
Wang et al., 2020a
Zhang et al., 2020c
Minaee et al., 2020
Kirillov et al., 2019
He et al., 2017
Cai and Vasconcelos,
2019
Chen et al., 2019
Kirillov et al., 2020
Ronneberger et al., 2015
Badrinarayanan et al., 2017
Chen et al., 2018
Nogueira
et al., 2019
Nogueira
et
al.,
2020
Hua et al., 2021
Wu et al., 2020a
Yin et al.,
2020
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
9 photogrammetry)) AND LANGUAGE: (English) AND Types of Docu -
ment: (Article OR Book OR Book Chapter OR Book Review OR Letter OR
Proceedings Paper OR Review); Indexes = SCI-EXPANDED, SSCI, A%
HCI, CPCI-S, CPCI-SSH, ESCI. Stipulated-time = every-years. ” ). We
considered DL, but added CNN, as it is one of the main DL-based ar -
chitectures used in remote sensing applications (Ma et al., 2019). As
such, published materials that use these terms in their titles, abstracts or
keywords were investigated and included. For such reasons, we opted
for this string to achieve a generalist investigation.
We filtered the results to consider only papers that implemented
approaches with UAV-based systems. A total of 190 papers were found
in the WOS database, where 136 were articles, 46 proceedings, and 10
reviews. An additional search was conducted in the Google Scholar
database to identify works not detected in the WOS. We adopted the
same combination of keywords in this search. We performed a detailed
evaluation of its results and selected only those that, although from
respected journals, were not encountered in the WOS search. This
resulted in a total of 34 articles, 16 proceedings, and 8 reviews. The
entire dataset was composed of 232 articles + proceedings and 18 re -
views from scientific journals indexed in those bases. These papers were
then organized and revised. Fig. 7 demonstrates the main steps to map
this research. The encountered publications were registered only in the
last five years (from 2016 to 2021), which indicates how recent UAV-
based approaches integrated with DL methods are in the scientific
journals.
The review articles gathered at those bases were separated and
mostly used in the cloud text analysis of Fig. 1, while the remaining
papers (articles and proceedings) were organized according to their
category. A total of 283.785 words were analyzed for the word-cloud, as
we removed words with less than 5% occurrences to cut lesser-used
words unrelated to the theme, and higher than 95% occurrences to
remove plain and simple words frequently used in the English language.
The published articles and proceedings were divided in terms of DL-
based networks (classification: scene-wise classification, segmentation,
and object detection and; regression), sensor types (RGB, multispectral,
hyperspectral, and LiDAR); and; applications (environmental, urban,
and agricultural context). We also provided, in a subsequent section,
datasets from previously conducted research for further investigation by
novel studies. These datasets were organized and their characteristics
were also summarized accordingly.
Most of our research was composed of publications from peer-review
publishers in the area of remote sensing journals (Fig. 8). Even though
the review articles encountered in the WoS and Google Scholar data -
bases do mention, to some extent, UAV-based applications, none of them
were dedicated to it. Towards the end of our paper, we examined state-
of-the-art approaches, like real-time processing, data dimensionality
reduction, domain adaptation, attention-based mechanisms, few-shot
learning, open-set, semi-supervised and unsupervised learning, and
others. This information provided an overview of the future opportu -
nities and perspectives on DL methods applied in UAV-based images,
where we discuss the implications and challenges of novel approaches.
The 232 papers (articles + proceedings) were investigated through a
quantitative perspective, where we evaluated the number of occurrences
per journal, the number of citations, year of publication, and location of
the conducted applications according to country. We also prepared and
organized a sampling portion in relation to the corresponding cate -
gories, as previously explained, identifying characteristics like archi -
tecture used, evaluation metric approach, task conducted, and type of
sensor and mapping context objectives. After evaluating it, we adopted a
qualitative approach by revising and presenting some of the applications
conducted within the papers (UAV + DL) encountered in the scientific
databases, summarizing the most prominent ones. This narrative over
Fig. 7. The schematic procedure adopted to organize the revised material according to their respective categories as proposed in this review.
L.P. Osco et al.
Ma et al., 2019
Fig. 7
Fig. 1
Fig. 8
International Journal of Applied Earth Observation and Geoinformation 102 (2021) 102456
10 Fig. 8. The distribution of the evaluated scientific material according to data gathered at Web of Science (WOS) and Google Scholar databases. The y-axis on the left
represents the number (n) of published papers, illustrated by solid-colored boxes. The y-axis on the right represents the number of citations that these publications,
according to peer-review scientific journals, received since their publication, illustrated by dashed-lines of the same color to its corresponding solid-colored box.
Fig. 9. Diagram describing proceedings and articles according to the defined categories using WOS and Google Scholar datasets.
L.P. Osco et al.
Previous  PDF Next  PDF
Article info Hide
Recommended Articles
Stakeholder analysis in sustainable forest management: An application in the Yavoriv region (Ukraine)
Oksana Pelyukh, … +2 … , David Troxler
Forest Policy and Economics • October 2021
Preview View PDF Save PDF
Combining spectral and textural information in UAV hyperspectral images to estimate rice grain yield
Fumin Wang, … +5 … , Jueyi Zheng
International Journal of Applied Earth Observation and Geoinformation • October 2021
Preview View PDF Save PDF
Prediction of insect-herbivory-damage and insect-type attack in maize plants using hyperspectral data
Danielle Elis Garcia Furuya, … +14 … , Lúcio André de Castro Jorge
International Journal of Applied Earth Observation and Geoinformation • 25 December 2021
Preview View PDF Save PDF
